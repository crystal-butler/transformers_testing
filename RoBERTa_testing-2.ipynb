{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import pdb\n",
    "import os\n",
    "from transformers import RobertaTokenizer, RobertaModel, RobertaForMaskedLM, RobertaConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/Notebooks/crystal/NLP/transformers/examples'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure we're in the transformers directory with fine-tuned model output.\n",
    "os.chdir('/home/jupyter/Notebooks/crystal/NLP/transformers/examples/')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_vocab(vocab_file):\n",
    "    vocab = []\n",
    "    with open(vocab_file, 'r') as v:\n",
    "        vocab = v.read().splitlines()\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = RobertaTokenizer.from_pretrained('./output_wiki-103/')\n",
    "\n",
    "model = RobertaForMaskedLM.from_pretrained('./output_wiki-103/')\n",
    "\n",
    "config = RobertaConfig.from_pretrained('./output_wiki-103/')\n",
    "config.output_hidden_states = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32759\n"
     ]
    }
   ],
   "source": [
    "# Adapted from transformer docs at https://huggingface.co/transformers/model_doc/roberta.html?highlight=vocabulary#transformers.RobertaTokenizer.save_vocabulary\n",
    "# and https://github.com/huggingface/transformers/issues/2072\n",
    "# See https://github.com/huggingface/transformers/blob/master/src/transformers/modeling_roberta.py\n",
    "# for the word_embeddings definition and related functions.\n",
    "# More helpful info on output of the forward pass and hidden layers is here:\n",
    "# https://github.com/huggingface/transformers/issues/1827\n",
    "\n",
    "# input_ids = torch.tensor(tokenizer.encode(\"disgusted\", add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n",
    "# print(input_ids[0][1].item())\n",
    "\n",
    "test_word = torch.tensor([tokenizer.encode(\"disgusted\")])\n",
    "# Print the index of the test word.\n",
    "print(test_word[0][1].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.modeling_roberta.RobertaForMaskedLM'>\n",
      "RobertaForMaskedLM(\n",
      "  (roberta): RobertaModel(\n",
      "    (embeddings): RobertaEmbeddings(\n",
      "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
      "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "      (token_type_embeddings): Embedding(1, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (lm_head): RobertaLMHead(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    (decoder): Linear(in_features=768, out_features=50265, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(type(model))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=768, out_features=50265, bias=True) \n",
      "\n",
      "Embedding(50265, 768, padding_idx=1) \n",
      "------------------------\n",
      "tensor([[ 5.2666e-02, -1.7146e-01,  1.6461e-02, -3.7467e-02, -1.3350e-01,\n",
      "          1.1051e-01, -1.2718e-01, -8.1737e-02,  3.5000e-02, -3.2664e-02,\n",
      "         -1.2303e-02,  2.1744e-01, -7.6540e-02,  2.6898e-02, -5.9862e-03,\n",
      "         -1.1723e-01,  9.6832e-03, -1.8487e-01,  4.3507e-02,  1.9149e-02,\n",
      "         -4.4449e-02, -4.5171e-02,  2.4407e-02, -1.6115e-01,  3.1173e-02,\n",
      "         -4.0548e-02,  3.5446e-02,  1.3479e-02, -2.2354e-01, -6.2794e-02,\n",
      "         -2.5782e-02,  4.1355e-02,  5.2338e-02,  9.5993e-02, -1.3193e-01,\n",
      "          4.9301e-02, -4.5019e-02,  3.0012e-02, -5.5757e-02, -2.4916e-01,\n",
      "          6.3038e-02, -5.4601e-02, -1.2683e-01,  3.0680e-01,  7.3173e-02,\n",
      "         -5.6098e-02, -1.7094e-02, -1.2768e-01,  1.5285e-01, -1.0663e-01,\n",
      "          1.5613e-02,  1.1909e-01, -1.0941e-01, -6.1781e-03, -6.4058e-02,\n",
      "          1.6774e-01,  6.7063e-02,  2.0279e-02, -2.2349e-01, -5.3811e-02,\n",
      "         -2.1909e-01, -2.7230e-01, -1.9166e-01,  9.5954e-02, -5.9843e-02,\n",
      "          1.1704e-01,  1.6822e-02,  2.4009e-01,  1.0668e-01,  1.6612e-01,\n",
      "         -9.3151e-03,  8.4032e-02, -3.8344e-02,  2.4828e-01, -5.9048e-02,\n",
      "         -1.0839e-01, -1.1540e-01,  2.2822e-01,  2.4443e-01, -1.3865e-01,\n",
      "         -2.0168e-01,  4.4759e-02, -8.4387e-02,  2.6697e-02,  2.4196e-02,\n",
      "         -2.4502e-01,  2.8394e-01, -9.5237e-02,  1.1014e-01, -3.3774e-02,\n",
      "         -3.9847e-03,  3.7001e-01,  1.2843e-01, -8.7512e-03,  1.9900e-02,\n",
      "         -2.9772e-02, -1.8129e-01,  1.1201e-02,  1.4643e-02,  6.0254e-03,\n",
      "         -1.8717e-01, -2.0946e-01,  2.9511e-02, -2.0297e-02,  1.5254e-01,\n",
      "         -4.8271e-02, -3.2722e-02, -3.1118e-04,  7.1639e-02, -1.6709e-01,\n",
      "          7.2827e-02, -6.9863e-03,  2.2008e-02,  5.7827e-02,  8.0109e-02,\n",
      "          3.2244e-03, -6.2371e-02, -2.3136e-01, -7.9289e-02,  3.4351e-02,\n",
      "         -5.6394e-02, -2.2467e-01, -8.4158e-02,  1.7847e-01,  6.6835e-02,\n",
      "          4.9858e-02, -1.8005e-01,  7.5202e-02, -1.7991e-01,  7.7818e-02,\n",
      "          3.2288e-02, -2.0133e-01,  1.5198e-01, -5.0406e-02,  3.7835e-02,\n",
      "         -1.2882e-02, -1.0590e-01, -4.8960e-02, -1.0702e-01, -1.6980e-01,\n",
      "          1.9616e-01, -8.6710e-03,  1.8460e-02, -2.1911e-01, -5.1771e-02,\n",
      "          1.0652e-01,  1.4909e-01, -2.2672e-01,  7.5968e-02, -2.8173e-02,\n",
      "          1.4788e-01, -7.3070e-02,  3.8658e-02, -4.5777e-02,  3.0161e-02,\n",
      "          9.1261e-02,  4.3882e-02, -1.9097e-02, -6.0398e-02, -3.9202e-02,\n",
      "         -2.4050e-01,  6.3642e-02, -1.5341e-02,  5.3542e-02,  1.7889e-02,\n",
      "         -7.2870e-02, -2.0868e-02, -5.0399e-02, -5.7573e-02, -2.7524e-01,\n",
      "         -1.1911e-01,  4.8916e-04, -3.2794e-02, -2.1695e-01, -1.1371e-02,\n",
      "          3.2950e-02,  5.5383e-02,  5.4400e-02,  1.1928e-01, -1.0876e-01,\n",
      "         -9.8652e-02,  2.0569e-02, -5.3902e-02, -3.1644e-01,  2.1308e-02,\n",
      "         -2.4151e-01,  4.4791e-02,  1.0496e-01, -5.0706e-02,  9.3321e-02,\n",
      "         -1.9727e-01, -3.1353e-02, -1.0182e-01,  1.8852e-01,  2.8153e-01,\n",
      "         -5.5249e-02, -1.1108e-01, -4.8473e-02, -5.4385e-02,  1.5437e-01,\n",
      "          4.1809e-04,  6.5495e-02, -1.7060e-01,  2.2685e-02, -1.1752e-01,\n",
      "          7.7730e-02, -5.8968e-02,  6.9466e-02, -6.1325e-02,  4.5276e-02,\n",
      "          8.4401e-02, -3.3520e-01,  3.2768e-02, -1.4405e-02, -3.2128e-02,\n",
      "          9.8083e-02,  1.9533e-01, -3.1208e-02, -7.7863e-02, -3.2531e-01,\n",
      "          4.0640e-02,  7.5689e-02, -1.8424e-01, -1.0304e-01,  4.4884e-03,\n",
      "         -3.6592e-02, -1.1014e-01, -1.4013e-01,  9.9976e-04,  1.0000e-01,\n",
      "         -3.1617e-02, -2.4353e-01,  2.9208e-03, -2.0608e-01, -2.0042e-02,\n",
      "         -7.2096e-03,  3.2967e-02,  3.1974e-02,  4.1436e-02, -2.2161e-01,\n",
      "         -6.7926e-02, -3.0882e-02, -1.3054e-01,  1.1650e-01, -1.1596e-01,\n",
      "         -2.2270e-01, -9.5661e-02,  7.1203e-02,  2.3829e-01, -4.6107e-02,\n",
      "          2.4670e-01, -5.6143e-02,  1.9771e-02, -7.3920e-02,  1.8560e-02,\n",
      "          7.9878e-02,  2.2388e-03,  6.9792e-02, -1.7303e-02, -2.0883e-02,\n",
      "         -5.4950e-02, -2.0480e-01,  3.0750e-01,  7.2141e-03, -3.5509e-01,\n",
      "          2.0629e-02, -2.0818e-01, -1.4081e-02, -1.0339e-01,  9.7010e-02,\n",
      "         -6.6333e-02, -8.5350e-02,  4.3423e-02, -2.8552e-02, -8.2612e-02,\n",
      "          3.2987e-02,  1.1613e-01, -1.7402e-02,  2.1812e-01, -5.9105e-02,\n",
      "         -2.3829e-01, -9.4043e-02, -5.9251e-02,  4.1317e-02,  2.2040e-01,\n",
      "          9.3168e-02,  5.7548e-02, -3.8121e-01,  1.1236e-01,  4.3814e-03,\n",
      "          7.8622e-02, -1.9209e-01,  3.0967e-02, -1.0774e-01, -3.7907e-04,\n",
      "         -9.9692e-02,  5.7778e-02,  1.5737e-01, -1.3917e-01,  1.3187e-02,\n",
      "          7.0388e-02,  1.2422e-01,  2.2815e-01, -3.2738e-02,  1.5536e-02,\n",
      "          3.6131e-02, -1.2813e-01, -4.0653e-02, -6.7038e-03,  1.1802e-01,\n",
      "         -5.3060e-02,  6.0364e-02, -1.2792e-01,  8.3941e-03, -2.7864e-02,\n",
      "         -4.2335e-02, -3.3806e-01, -2.2802e-01, -4.9199e-02,  1.3459e-01,\n",
      "          1.9356e-01,  5.3323e-02,  1.5108e-01,  2.8331e-02, -1.0162e-01,\n",
      "         -2.5981e-02,  1.1541e-01, -1.5828e-01,  8.4248e-02,  1.3642e-01,\n",
      "         -8.9982e-02,  1.1936e-01,  7.7981e-02,  1.4104e-01,  4.0153e-02,\n",
      "          7.1061e-02,  7.2709e-03,  1.0755e-01,  1.1405e-01, -3.3763e-02,\n",
      "          2.9053e-02,  9.8410e-02, -4.1996e-02, -8.6497e-02, -1.0951e-01,\n",
      "          4.1997e-02,  1.6792e-01, -5.1700e-02,  5.4263e-02, -1.0638e-01,\n",
      "          8.5214e-02, -6.1330e-02,  4.4897e-02, -1.5911e-01,  7.2154e-02,\n",
      "         -1.0720e-02, -2.2490e-02, -1.9524e-01, -1.0028e-01, -4.6111e-03,\n",
      "          2.3800e-02, -2.0992e-01,  3.5458e-02,  8.8471e-02,  2.7159e-02,\n",
      "          6.0531e-02,  2.9700e-02,  1.6021e-01, -7.1578e-02, -4.8880e-03,\n",
      "         -4.0164e-03, -4.0261e-02,  2.4170e-01, -2.2563e-01,  6.5666e-02,\n",
      "         -1.9448e-01,  4.2242e-02,  1.1736e-01, -6.1862e-02, -1.9605e-01,\n",
      "         -6.7958e-02,  2.2745e-01,  1.2008e-01,  5.6734e-03,  1.2698e-02,\n",
      "         -1.7784e-01, -1.4972e-01, -3.5175e-02, -1.1418e-01,  2.8927e-02,\n",
      "         -1.7886e-01, -2.4708e-01,  1.8288e-02, -3.3376e-02,  4.3880e-02,\n",
      "          1.1843e-01, -3.4825e-02,  2.9826e-02,  8.6474e-02,  4.7542e-03,\n",
      "          8.7251e-02, -3.2878e-01, -6.3554e-02, -9.6475e-03, -2.1439e-02,\n",
      "         -1.0016e-02, -3.8272e-02, -5.3013e-02, -2.4076e-01, -2.9126e-01,\n",
      "         -1.2069e-01, -2.1198e-01, -7.6206e-04, -2.1260e-01, -3.0677e-01,\n",
      "          3.0528e-01,  1.0266e-01, -6.1106e-03, -5.4420e-02,  8.5421e-02,\n",
      "         -1.4571e-01,  6.3839e-02, -7.9875e-02,  3.4192e-02, -1.2977e-01,\n",
      "          2.2959e-01, -1.2297e-01, -1.9788e-01, -1.9635e-01,  8.9883e-02,\n",
      "          8.8174e-02,  1.6380e-02, -1.0479e-01,  5.7349e-02, -2.5094e-01,\n",
      "          8.9665e-02,  4.8428e-02, -3.4885e-02, -2.0286e-01,  1.1778e-01,\n",
      "          2.4105e-01, -4.8361e-02,  1.1791e-02,  9.0864e-02, -2.2714e-01,\n",
      "         -1.5769e-01, -2.1829e-02,  3.3417e-02, -8.2926e-02, -7.6242e-02,\n",
      "          2.4489e-01,  1.9734e-02,  1.0572e-01,  6.6060e-02, -5.1649e-02,\n",
      "          2.1412e-01, -1.5812e-02,  7.8707e-02, -7.3281e-02, -2.4224e-01,\n",
      "         -1.0030e-01,  1.2143e-01, -8.6357e-02,  2.7385e-04,  5.3909e-02,\n",
      "          8.0750e-02,  1.9321e-02,  1.8253e-02,  3.1497e-01,  5.8660e-03,\n",
      "         -2.2031e-01,  1.4843e-01,  4.2710e-02, -7.6751e-02,  1.8832e-01,\n",
      "          1.1510e-01, -1.2679e-02,  1.7653e-02,  8.5363e-02,  2.4617e-01,\n",
      "         -1.5879e-01, -1.1668e-01, -4.0485e-03, -1.8665e-01,  9.9936e-02,\n",
      "         -1.1399e-01,  5.9518e-03,  1.0765e-01, -4.8124e-02,  7.0068e-02,\n",
      "         -6.2171e-02,  7.9660e-02, -8.6336e-02, -7.8110e-03, -2.2301e-01,\n",
      "         -3.2877e-02,  8.7861e-02, -5.2366e-02, -6.9136e-02,  1.5763e-02,\n",
      "          7.9198e-02, -2.0480e-01, -1.1065e-01,  4.7016e-02,  1.0682e-02,\n",
      "          1.3733e-01, -4.6592e-02,  7.2816e-03, -2.2298e-01, -8.7274e-02,\n",
      "         -8.9290e-03, -2.3820e-01, -1.9860e-01, -2.0513e-01,  1.7446e-01,\n",
      "          3.1014e-02, -1.5470e-02, -3.6383e-02,  1.3377e-02, -2.4410e-01,\n",
      "         -8.9049e-02,  3.7072e-02,  1.1706e-01, -5.5266e-02,  3.0442e-02,\n",
      "         -1.3010e-03, -2.4687e-01,  1.0455e-01, -3.7629e-02, -1.0807e-01,\n",
      "         -6.5150e-02, -1.6994e-02,  4.7654e-03, -8.4196e-02, -1.8728e-01,\n",
      "          8.6446e-02,  4.4770e-02,  1.4002e-02,  3.1606e-01, -2.2193e-02,\n",
      "         -3.3748e-01, -4.4699e-02,  3.7405e-01, -9.3770e-02, -1.7077e-02,\n",
      "          1.2196e-02, -1.7353e-02, -1.1586e-01,  8.7279e-02, -2.2867e-01,\n",
      "          2.1451e-01,  3.9531e-02, -2.0955e-02,  1.0747e-01,  6.3235e-02,\n",
      "         -2.4801e-01, -8.0254e-02,  5.7667e-02, -1.7735e-01,  3.5458e-02,\n",
      "          1.2178e-01,  5.3088e-02, -2.4297e-02, -1.1932e-01, -1.1815e-01,\n",
      "          9.7313e-02, -2.4228e-01,  2.2788e-01,  4.8516e-02, -5.1418e-02,\n",
      "         -1.1237e-01, -1.4530e-02, -2.5028e-01, -5.3685e-02, -1.3721e-02,\n",
      "         -2.3228e-01, -5.4789e-02,  4.4762e-02,  1.4874e-01,  4.7897e-02,\n",
      "          4.2012e-02, -7.1082e-03,  5.1748e-02,  2.5355e-01,  8.2366e-02,\n",
      "          2.0421e-02,  1.4479e-01, -1.2489e-01,  5.9676e-02,  1.9220e-01,\n",
      "          2.1110e-01,  1.5810e-01, -3.7120e-01,  6.1932e-02, -1.9448e-01,\n",
      "          2.1239e-01,  1.2304e-02,  9.6926e-02, -5.9846e-02, -2.2505e-01,\n",
      "          4.3152e-02, -1.4389e-01, -3.6987e-02, -1.6292e-01,  3.3383e-02,\n",
      "         -3.9027e-02, -3.0015e-02,  1.1812e-01, -1.5461e-02,  2.9501e-02,\n",
      "         -1.6268e-02,  3.0289e-02,  2.8908e-02,  4.7717e-02, -6.2571e-02,\n",
      "          1.7731e-01, -9.9097e-02, -1.1254e-01,  2.1965e-01, -1.4052e-01,\n",
      "         -2.4300e-03,  4.1973e-02,  1.7241e-01,  6.7095e-02, -1.5869e-01,\n",
      "          1.1534e-01,  3.1893e-02, -3.1641e-01, -1.6834e-02, -4.2266e-02,\n",
      "          3.1402e-02, -1.4672e-02, -2.1316e-01, -2.3284e-01,  1.7578e-02,\n",
      "          7.7999e-04, -2.5302e-02,  1.7040e-01,  9.8276e-02,  5.8246e-02,\n",
      "         -8.8974e-02, -2.5736e-01,  2.1826e-01,  3.5308e-02,  2.9083e-02,\n",
      "          5.4321e-02,  6.8674e-03,  2.5432e-02, -3.8861e-01,  1.3139e-02,\n",
      "         -5.1577e-02,  3.5308e-02, -5.3608e-02, -1.1926e-01, -3.4426e-02,\n",
      "         -5.2649e-02,  2.2907e-02, -2.4070e-01,  2.1482e-02,  8.0273e-02,\n",
      "          2.2735e-02, -1.0399e-01,  1.3468e-02, -6.2462e-02,  7.1004e-02,\n",
      "         -2.9883e-02,  5.7479e-02,  5.1685e-03, -8.7578e-02, -4.5416e-02,\n",
      "          6.0239e-02, -5.4835e-02, -1.3837e-01,  1.8277e-01,  1.0222e-01,\n",
      "         -1.2526e-01, -6.3666e-02, -2.9672e-02, -1.4645e-01,  3.2657e-02,\n",
      "         -1.6751e-02,  5.7423e-02,  2.0916e-01, -9.7723e-02, -1.9327e-01,\n",
      "         -5.3711e-02,  6.7779e-02,  1.0239e-02,  7.9863e-02,  6.2240e-02,\n",
      "          1.8265e-02,  1.4697e-02, -1.1838e-01,  1.1749e-01, -8.5208e-03,\n",
      "          9.4145e-02, -1.0226e-01, -6.5950e-02, -5.7108e-02, -5.6130e-02,\n",
      "         -1.5237e-01, -3.3692e-02, -9.2181e-02,  9.0722e-03, -1.5076e-01,\n",
      "          1.0740e-01,  2.0853e-01, -4.1650e-02, -1.5644e-02,  5.5766e-02,\n",
      "          2.1534e-02, -9.6754e-02, -7.9212e-03,  2.3975e-02, -4.5004e-02,\n",
      "         -1.6535e-01,  1.0548e-01, -1.1173e-01, -1.2052e-01,  1.2423e-01,\n",
      "          2.4465e-01,  6.5380e-03,  9.5652e-02, -8.6491e-03,  1.5258e-02,\n",
      "          7.9553e-02,  7.7334e-02, -8.6168e-03,  9.1304e-02, -1.0777e-01,\n",
      "         -4.8914e-02,  3.6677e-02,  6.7422e-02,  1.1185e-01, -1.7370e-01,\n",
      "          5.8163e-02, -2.4906e-01,  1.5732e-01, -4.2910e-02, -3.3430e-02,\n",
      "          6.8524e-02, -1.0069e-01,  8.4733e-02, -1.2177e-01,  2.9602e-02,\n",
      "         -1.1868e-01, -1.4949e-01, -2.3034e-02,  1.0815e-01, -1.8753e-01,\n",
      "          2.0770e-01, -2.8077e-02, -6.1605e-02,  6.3012e-02, -2.4215e-01,\n",
      "          2.5454e-01, -1.2053e-01,  2.7599e-01,  2.3079e-02, -1.3574e-01,\n",
      "          3.9612e-02, -9.2089e-02, -1.3796e-01, -1.9897e-01,  3.3573e-02,\n",
      "         -1.1330e-01, -7.2416e-03,  5.7551e-02]], grad_fn=<EmbeddingBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Try getting both input and output embeddings using transformers methods.\n",
    "output_embeddings_test = model.get_output_embeddings()\n",
    "print(output_embeddings_test,'\\n')\n",
    "input_embeddings_test = model.get_input_embeddings()\n",
    "print(input_embeddings_test,'\\n------------------------')\n",
    "\n",
    "# Print the value of the input embeddings for our test word.\n",
    "# These values match what is extracted manually in RoBERTa_testing-1.py\n",
    "print(input_embeddings_test(torch.LongTensor([32759])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1768, grad_fn=<SelectBackward>) \n",
      "\n",
      "\n",
      "0.15049785375595093\n"
     ]
    }
   ],
   "source": [
    "# Try getting various embeddings as output by the RoBERTa model.\n",
    "# These values are different from the input values because the model\n",
    "# is returning a contextual embedding for the single test word given.\n",
    "embedding_test = model.roberta.embeddings(test_word)\n",
    "embedding_test_word = model.roberta.embeddings.word_embeddings(test_word)\n",
    "print(embedding_test[0][0][0],'\\n\\n')\n",
    "print(embedding_test_word[0][0][0].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 outputs.\n",
      "There are 13 hidden states.\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0982, -0.3758,  0.1873,  ..., -0.2205, -0.0786,  0.2975],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Try extracting embeddings using hidden states directly.\n",
    "output = model(test_word)\n",
    "print(f'There are {len(output)} outputs.')\n",
    "hidden_states = output[-1]\n",
    "print(f'There are {len(hidden_states)} hidden states.')\n",
    "embedding_test_hidden = hidden_states[0]\n",
    "print(embedding_test_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[26.1772, -5.4167, 13.9335,  ...,  0.9339,  2.4213, 10.8156],\n",
      "         [ 0.2701, -5.7334,  5.5102,  ..., -4.2464, -3.5145,  1.1312],\n",
      "         [ 8.6342, -6.2831, 12.5975,  ..., -2.8398, -1.4640,  5.4114]]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Or try using the sequence output at the last layer of the model.\n",
    "# This probably won't be useful for my task. Output values match\n",
    "# the prediction scores\n",
    "output = model(test_word)\n",
    "sequence_output = output[0]\n",
    "print(sequence_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1502, grad_fn=<NllLossBackward>)\n",
      "tensor([[[26.1772, -5.4167, 13.9335,  ...,  0.9339,  2.4213, 10.8156],\n",
      "         [ 0.2701, -5.7334,  5.5102,  ..., -4.2464, -3.5145,  1.1312],\n",
      "         [ 8.6342, -6.2831, 12.5975,  ..., -2.8398, -1.4640,  5.4114]]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input_ids = torch.tensor(tokenizer.encode(\"disgusted\", add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n",
    "outputs = model(input_ids, masked_lm_labels=input_ids)\n",
    "loss, prediction_scores = outputs[:2]\n",
    "print(loss)\n",
    "print(prediction_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_file = '/home/jupyter/Notebooks/crystal/NLP/MiFace/Python/vocab_files/vocab_checked.txt'\n",
    "vocab = make_vocab(vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aback is at index 36347\n",
      "Saved the embedding for aback.\n",
      "abashed is at index 4091\n",
      "Saved the embedding for abashed.\n",
      "abhor is at index 35350\n",
      "Saved the embedding for abhor.\n",
      "abhorred is at index 35350\n",
      "Saved the embedding for abhorred.\n",
      "abhorrence is at index 35350\n",
      "Saved the embedding for abhorrence.\n",
      "abhorrent is at index 35350\n",
      "Saved the embedding for abhorrent.\n",
      "abominable is at index 4091\n",
      "Saved the embedding for abominable.\n",
      "abound is at index 32937\n",
      "Saved the embedding for abound.\n",
      "absent is at index 11640\n",
      "Saved the embedding for absent.\n",
      "absorbed is at index 22416\n",
      "Saved the embedding for absorbed.\n",
      "acceptance is at index 10502\n",
      "Saved the embedding for acceptance.\n",
      "accepted is at index 3903\n",
      "Saved the embedding for accepted.\n",
      "accepting is at index 8394\n",
      "Saved the embedding for accepting.\n",
      "accommodating is at index 33681\n",
      "Saved the embedding for accommodating.\n",
      "accomplished is at index 9370\n",
      "Saved the embedding for accomplished.\n",
      "accordant is at index 10170\n",
      "Saved the embedding for accordant.\n",
      "accursed is at index 7678\n",
      "Saved the embedding for accursed.\n",
      "accusatory is at index 23123\n",
      "Saved the embedding for accusatory.\n",
      "accused is at index 1238\n",
      "Saved the embedding for accused.\n",
      "accusing is at index 8601\n",
      "Saved the embedding for accusing.\n",
      "acerbic is at index 4285\n",
      "Saved the embedding for acerbic.\n",
      "acidic is at index 41314\n",
      "Saved the embedding for acidic.\n",
      "active is at index 2171\n",
      "Saved the embedding for active.\n",
      "acute is at index 13827\n",
      "Saved the embedding for acute.\n",
      "adamant is at index 22668\n",
      "Saved the embedding for adamant.\n",
      "addled is at index 1606\n",
      "Saved the embedding for addled.\n",
      "admiration is at index 24287\n",
      "Saved the embedding for admiration.\n",
      "admit is at index 8109\n",
      "Saved the embedding for admit.\n",
      "adoration is at index 2329\n",
      "Saved the embedding for adoration.\n",
      "adoring is at index 2329\n",
      "Saved the embedding for adoring.\n",
      "adrift is at index 2329\n",
      "Saved the embedding for adrift.\n",
      "adversarial is at index 37930\n",
      "Saved the embedding for adversarial.\n",
      "affability is at index 11129\n",
      "Saved the embedding for affability.\n",
      "affected is at index 2132\n",
      "Saved the embedding for affected.\n",
      "affectionate is at index 15955\n",
      "Saved the embedding for affectionate.\n",
      "afflicted is at index 39234\n",
      "Saved the embedding for afflicted.\n",
      "affronted is at index 11129\n",
      "Saved the embedding for affronted.\n",
      "aflutter is at index 10\n",
      "Saved the embedding for aflutter.\n",
      "afraid is at index 6023\n",
      "Saved the embedding for afraid.\n",
      "agape is at index 5951\n",
      "Saved the embedding for agape.\n",
      "aggravated is at index 10040\n",
      "Saved the embedding for aggravated.\n",
      "aggravation is at index 29223\n",
      "Saved the embedding for aggravation.\n",
      "aggression is at index 14227\n",
      "Saved the embedding for aggression.\n",
      "aggressive is at index 4353\n",
      "Saved the embedding for aggressive.\n",
      "aggrieve is at index 28940\n",
      "Saved the embedding for aggrieve.\n",
      "aggrieved is at index 28940\n",
      "Saved the embedding for aggrieved.\n",
      "aghast is at index 10\n",
      "Saved the embedding for aghast.\n",
      "agitated is at index 33426\n",
      "Saved the embedding for agitated.\n",
      "agog is at index 5951\n",
      "Saved the embedding for agog.\n",
      "agonized is at index 27497\n",
      "Saved the embedding for agonized.\n",
      "agreeable is at index 43359\n",
      "Saved the embedding for agreeable.\n",
      "agressive is at index 5951\n",
      "Saved the embedding for agressive.\n",
      "airhead is at index 935\n",
      "Saved the embedding for airhead.\n",
      "alarm is at index 8054\n",
      "Saved the embedding for alarm.\n",
      "alarmed is at index 23438\n",
      "Saved the embedding for alarmed.\n",
      "alarming is at index 16156\n",
      "Saved the embedding for alarming.\n",
      "alert is at index 5439\n",
      "Saved the embedding for alert.\n",
      "alerted is at index 14588\n",
      "Saved the embedding for alerted.\n",
      "alienated is at index 36462\n",
      "Saved the embedding for alienated.\n",
      "allergic is at index 28349\n",
      "Saved the embedding for allergic.\n",
      "alleviated is at index 32216\n",
      "Saved the embedding for alleviated.\n",
      "alluring is at index 70\n",
      "Saved the embedding for alluring.\n",
      "aloof is at index 1076\n",
      "Saved the embedding for aloof.\n",
      "amatory is at index 524\n",
      "Saved the embedding for amatory.\n",
      "amazed is at index 22431\n",
      "Saved the embedding for amazed.\n",
      "amazement is at index 42402\n",
      "Saved the embedding for amazement.\n",
      "amazing is at index 2770\n",
      "Saved the embedding for amazing.\n",
      "ambition is at index 12831\n",
      "Saved the embedding for ambition.\n",
      "ambitious is at index 8263\n",
      "Saved the embedding for ambitious.\n",
      "ambivalence is at index 13569\n",
      "Saved the embedding for ambivalence.\n",
      "ambivalent is at index 13569\n",
      "Saved the embedding for ambivalent.\n",
      "amenable is at index 524\n",
      "Saved the embedding for amenable.\n",
      "amiable is at index 524\n",
      "Saved the embedding for amiable.\n",
      "amicable is at index 524\n",
      "Saved the embedding for amicable.\n",
      "amused is at index 36530\n",
      "Saved the embedding for amused.\n",
      "amusement is at index 28445\n",
      "Saved the embedding for amusement.\n",
      "analytical is at index 23554\n",
      "Saved the embedding for analytical.\n",
      "analyzing is at index 18999\n",
      "Saved the embedding for analyzing.\n",
      "anger is at index 6378\n",
      "Saved the embedding for anger.\n",
      "angered is at index 20166\n",
      "Saved the embedding for angered.\n",
      "angrily is at index 30302\n",
      "Saved the embedding for angrily.\n",
      "angry is at index 5800\n",
      "Saved the embedding for angry.\n",
      "angst is at index 33010\n",
      "Saved the embedding for angst.\n",
      "anguish is at index 32446\n",
      "Saved the embedding for anguish.\n",
      "anguished is at index 5667\n",
      "Saved the embedding for anguished.\n",
      "animated is at index 12847\n",
      "Saved the embedding for animated.\n",
      "animosity is at index 34351\n",
      "Saved the embedding for animosity.\n",
      "annoyance is at index 39341\n",
      "Saved the embedding for annoyance.\n",
      "annoyed is at index 26678\n",
      "Saved the embedding for annoyed.\n",
      "annoying is at index 19887\n",
      "Saved the embedding for annoying.\n",
      "antagonistic is at index 32726\n",
      "Saved the embedding for antagonistic.\n",
      "antagonized is at index 32726\n",
      "Saved the embedding for antagonized.\n",
      "anticipated is at index 5291\n",
      "Saved the embedding for anticipated.\n",
      "anticipating is at index 22535\n",
      "Saved the embedding for anticipating.\n",
      "anticipation is at index 14714\n",
      "Saved the embedding for anticipation.\n",
      "anticipative is at index 21428\n",
      "Saved the embedding for anticipative.\n",
      "anticipatory is at index 21428\n",
      "Saved the embedding for anticipatory.\n",
      "antipathy is at index 37554\n",
      "Saved the embedding for antipathy.\n",
      "antsy is at index 32855\n",
      "Saved the embedding for antsy.\n",
      "anxiety is at index 6882\n",
      "Saved the embedding for anxiety.\n",
      "anxious is at index 13473\n",
      "Saved the embedding for anxious.\n",
      "anxiously is at index 27442\n",
      "Saved the embedding for anxiously.\n",
      "apathetic is at index 6256\n",
      "Saved the embedding for apathetic.\n",
      "apathy is at index 6256\n",
      "Saved the embedding for apathy.\n",
      "apologetic is at index 23842\n",
      "Saved the embedding for apologetic.\n",
      "appalled is at index 31514\n",
      "Saved the embedding for appalled.\n",
      "appallingly is at index 1553\n",
      "Saved the embedding for appallingly.\n",
      "appeased is at index 44151\n",
      "Saved the embedding for appeased.\n",
      "appeasing is at index 44151\n",
      "Saved the embedding for appeasing.\n",
      "appreciative is at index 14137\n",
      "Saved the embedding for appreciative.\n",
      "apprehension is at index 34640\n",
      "Saved the embedding for apprehension.\n",
      "apprehensive is at index 33655\n",
      "Saved the embedding for apprehensive.\n",
      "approve is at index 7244\n",
      "Saved the embedding for approve.\n",
      "approved is at index 2033\n",
      "Saved the embedding for approved.\n",
      "approving is at index 20499\n",
      "Saved the embedding for approving.\n",
      "argue is at index 5848\n",
      "Saved the embedding for argue.\n",
      "argumentative is at index 4795\n",
      "Saved the embedding for argumentative.\n",
      "aroused is at index 42941\n",
      "Saved the embedding for aroused.\n",
      "arrogance is at index 32818\n",
      "Saved the embedding for arrogance.\n",
      "arrogant is at index 30967\n",
      "Saved the embedding for arrogant.\n",
      "arrogantly is at index 46553\n",
      "Saved the embedding for arrogantly.\n",
      "artificial is at index 7350\n",
      "Saved the embedding for artificial.\n",
      "ashamed is at index 20085\n",
      "Saved the embedding for ashamed.\n",
      "aspiring is at index 18885\n",
      "Saved the embedding for aspiring.\n",
      "assertive is at index 18088\n",
      "Saved the embedding for assertive.\n",
      "assertively is at index 18088\n",
      "Saved the embedding for assertively.\n",
      "assessing is at index 16629\n",
      "Saved the embedding for assessing.\n",
      "assured is at index 7189\n",
      "Saved the embedding for assured.\n",
      "astonished is at index 40788\n",
      "Saved the embedding for astonished.\n",
      "astonishment is at index 44434\n",
      "Saved the embedding for astonishment.\n",
      "astounded is at index 12976\n",
      "Saved the embedding for astounded.\n",
      "attempting is at index 6475\n",
      "Saved the embedding for attempting.\n",
      "attentive is at index 36670\n",
      "Saved the embedding for attentive.\n",
      "attentiveness is at index 39879\n",
      "Saved the embedding for attentiveness.\n",
      "attracted is at index 7671\n",
      "Saved the embedding for attracted.\n",
      "avenging is at index 38796\n",
      "Saved the embedding for avenging.\n",
      "averse is at index 10\n",
      "Saved the embedding for averse.\n",
      "aversion is at index 33814\n",
      "Saved the embedding for aversion.\n",
      "aversive is at index 10\n",
      "Saved the embedding for aversive.\n",
      "avid is at index 20137\n",
      "Saved the embedding for avid.\n",
      "avoiding is at index 11473\n",
      "Saved the embedding for avoiding.\n",
      "awaiting is at index 10254\n",
      "Saved the embedding for awaiting.\n",
      "awakened is at index 40593\n",
      "Saved the embedding for awakened.\n",
      "aware is at index 2542\n",
      "Saved the embedding for aware.\n",
      "awareness is at index 4199\n",
      "Saved the embedding for awareness.\n",
      "awe is at index 21531\n",
      "Saved the embedding for awe.\n",
      "awed is at index 19267\n",
      "Saved the embedding for awed.\n",
      "awestruck is at index 19267\n",
      "Saved the embedding for awestruck.\n",
      "awful is at index 11522\n",
      "Saved the embedding for awful.\n",
      "awkward is at index 11789\n",
      "Saved the embedding for awkward.\n",
      "awkwardness is at index 11789\n",
      "Saved the embedding for awkwardness.\n",
      "axed is at index 18884\n",
      "Saved the embedding for axed.\n",
      "backhanded is at index 124\n",
      "Saved the embedding for backhanded.\n",
      "badly is at index 7340\n",
      "Saved the embedding for badly.\n",
      "baffle is at index 33139\n",
      "Saved the embedding for baffle.\n",
      "baffled is at index 33396\n",
      "Saved the embedding for baffled.\n",
      "baffling is at index 33139\n",
      "Saved the embedding for baffling.\n",
      "baked is at index 17241\n",
      "Saved the embedding for baked.\n",
      "banal is at index 2020\n",
      "Saved the embedding for banal.\n",
      "barking is at index 35828\n",
      "Saved the embedding for barking.\n",
      "bashful is at index 12882\n",
      "Saved the embedding for bashful.\n",
      "beaming is at index 28\n",
      "Saved the embedding for beaming.\n",
      "bearish is at index 4649\n",
      "Saved the embedding for bearish.\n",
      "beat is at index 1451\n",
      "Saved the embedding for beat.\n",
      "beaten is at index 6432\n",
      "Saved the embedding for beaten.\n",
      "bedeviled is at index 3267\n",
      "Saved the embedding for bedeviled.\n",
      "befuddled is at index 28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for befuddled.\n",
      "begging is at index 22901\n",
      "Saved the embedding for begging.\n",
      "begrudge is at index 28\n",
      "Saved the embedding for begrudge.\n",
      "begrudging is at index 28\n",
      "Saved the embedding for begrudging.\n",
      "begrudgingly is at index 28\n",
      "Saved the embedding for begrudgingly.\n",
      "beguiled is at index 21422\n",
      "Saved the embedding for beguiled.\n",
      "belated is at index 12138\n",
      "Saved the embedding for belated.\n",
      "belittling is at index 12138\n",
      "Saved the embedding for belittling.\n",
      "belligerence is at index 35756\n",
      "Saved the embedding for belligerence.\n",
      "belligerent is at index 35756\n",
      "Saved the embedding for belligerent.\n",
      "belonging is at index 11441\n",
      "Saved the embedding for belonging.\n",
      "bemused is at index 28\n",
      "Saved the embedding for bemused.\n",
      "bemusement is at index 28\n",
      "Saved the embedding for bemusement.\n",
      "benevolence is at index 42364\n",
      "Saved the embedding for benevolence.\n",
      "benevolent is at index 43186\n",
      "Saved the embedding for benevolent.\n",
      "benumbed is at index 21576\n",
      "Saved the embedding for benumbed.\n",
      "berate is at index 14719\n",
      "Saved the embedding for berate.\n",
      "berating is at index 14719\n",
      "Saved the embedding for berating.\n",
      "bereaved is at index 17738\n",
      "Saved the embedding for bereaved.\n",
      "bereft is at index 17738\n",
      "Saved the embedding for bereft.\n",
      "beseeching is at index 9988\n",
      "Saved the embedding for beseeching.\n",
      "bested is at index 275\n",
      "Saved the embedding for bested.\n",
      "betrayal is at index 26760\n",
      "Saved the embedding for betrayal.\n",
      "betrayed is at index 26913\n",
      "Saved the embedding for betrayed.\n",
      "bewildered is at index 33304\n",
      "Saved the embedding for bewildered.\n",
      "bewilderment is at index 33304\n",
      "Saved the embedding for bewilderment.\n",
      "bi is at index 4003\n",
      "Saved the embedding for bi.\n",
      "bilious is at index 31617\n",
      "Saved the embedding for bilious.\n",
      "bit is at index 828\n",
      "Saved the embedding for bit.\n",
      "biting is at index 25609\n",
      "Saved the embedding for biting.\n",
      "bitter is at index 10513\n",
      "Saved the embedding for bitter.\n",
      "bittersweet is at index 28609\n",
      "Saved the embedding for bittersweet.\n",
      "blaming is at index 15249\n",
      "Saved the embedding for blaming.\n",
      "bland is at index 35063\n",
      "Saved the embedding for bland.\n",
      "blank is at index 15818\n",
      "Saved the embedding for blank.\n",
      "blase is at index 3089\n",
      "Saved the embedding for blase.\n",
      "blazed is at index 3089\n",
      "Saved the embedding for blazed.\n",
      "bleak is at index 23530\n",
      "Saved the embedding for bleak.\n",
      "bleary is at index 13819\n",
      "Saved the embedding for bleary.\n",
      "blessed is at index 12230\n",
      "Saved the embedding for blessed.\n",
      "blew is at index 10879\n",
      "Saved the embedding for blew.\n",
      "blinded is at index 40094\n",
      "Saved the embedding for blinded.\n",
      "blindsided is at index 7709\n",
      "Saved the embedding for blindsided.\n",
      "bliss is at index 30299\n",
      "Saved the embedding for bliss.\n",
      "blissful is at index 30299\n",
      "Saved the embedding for blissful.\n",
      "blissfully is at index 30299\n",
      "Saved the embedding for blissfully.\n",
      "blithe is at index 3089\n",
      "Saved the embedding for blithe.\n",
      "blown is at index 12315\n",
      "Saved the embedding for blown.\n",
      "blue is at index 2440\n",
      "Saved the embedding for blue.\n",
      "blues is at index 15629\n",
      "Saved the embedding for blues.\n",
      "bluffing is at index 37372\n",
      "Saved the embedding for bluffing.\n",
      "blunt is at index 18720\n",
      "Saved the embedding for blunt.\n",
      "blushing is at index 3089\n",
      "Saved the embedding for blushing.\n",
      "blustering is at index 3089\n",
      "Saved the embedding for blustering.\n",
      "boastful is at index 18639\n",
      "Saved the embedding for boastful.\n",
      "boggled is at index 741\n",
      "Saved the embedding for boggled.\n",
      "boiling is at index 27513\n",
      "Saved the embedding for boiling.\n",
      "boisterous is at index 5276\n",
      "Saved the embedding for boisterous.\n",
      "bold is at index 7457\n",
      "Saved the embedding for bold.\n",
      "bored is at index 23809\n",
      "Saved the embedding for bored.\n",
      "boredom is at index 40326\n",
      "Saved the embedding for boredom.\n",
      "boring is at index 15305\n",
      "Saved the embedding for boring.\n",
      "bothered is at index 18523\n",
      "Saved the embedding for bothered.\n",
      "bounder is at index 8191\n",
      "Saved the embedding for bounder.\n",
      "brashness is at index 5378\n",
      "Saved the embedding for brashness.\n",
      "bratty is at index 5378\n",
      "Saved the embedding for bratty.\n",
      "brave is at index 10025\n",
      "Saved the embedding for brave.\n",
      "bright is at index 4520\n",
      "Saved the embedding for bright.\n",
      "bristling is at index 37135\n",
      "Saved the embedding for bristling.\n",
      "broken is at index 3187\n",
      "Saved the embedding for broken.\n",
      "brokenhearted is at index 3187\n",
      "Saved the embedding for brokenhearted.\n",
      "brokenheartedly is at index 3187\n",
      "Saved the embedding for brokenheartedly.\n",
      "brooding is at index 11051\n",
      "Saved the embedding for brooding.\n",
      "broody is at index 11051\n",
      "Saved the embedding for broody.\n",
      "bruised is at index 26360\n",
      "Saved the embedding for bruised.\n",
      "brusque is at index 5378\n",
      "Saved the embedding for brusque.\n",
      "bug is at index 13673\n",
      "Saved the embedding for bug.\n",
      "bulging is at index 22382\n",
      "Saved the embedding for bulging.\n",
      "bully is at index 23934\n",
      "Saved the embedding for bully.\n",
      "bullying is at index 11902\n",
      "Saved the embedding for bullying.\n",
      "bummed is at index 29673\n",
      "Saved the embedding for bummed.\n",
      "buoyant is at index 15980\n",
      "Saved the embedding for buoyant.\n",
      "burdened is at index 32875\n",
      "Saved the embedding for burdened.\n",
      "burn is at index 7403\n",
      "Saved the embedding for burn.\n",
      "bursting is at index 28548\n",
      "Saved the embedding for bursting.\n",
      "bushed is at index 2353\n",
      "Saved the embedding for bushed.\n",
      "cagey is at index 16051\n",
      "Saved the embedding for cagey.\n",
      "cagy is at index 740\n",
      "Saved the embedding for cagy.\n",
      "calculating is at index 29770\n",
      "Saved the embedding for calculating.\n",
      "callous is at index 486\n",
      "Saved the embedding for callous.\n",
      "callused is at index 486\n",
      "Saved the embedding for callused.\n",
      "calm is at index 6327\n",
      "Saved the embedding for calm.\n",
      "calming is at index 31220\n",
      "Saved the embedding for calming.\n",
      "calmness is at index 6327\n",
      "Saved the embedding for calmness.\n",
      "canny is at index 64\n",
      "Saved the embedding for canny.\n",
      "cantankerous is at index 17672\n",
      "Saved the embedding for cantankerous.\n",
      "capable is at index 4453\n",
      "Saved the embedding for capable.\n",
      "capricious is at index 2927\n",
      "Saved the embedding for capricious.\n",
      "captivated is at index 13363\n",
      "Saved the embedding for captivated.\n",
      "captive is at index 24145\n",
      "Saved the embedding for captive.\n",
      "carefree is at index 575\n",
      "Saved the embedding for carefree.\n",
      "careful is at index 7316\n",
      "Saved the embedding for careful.\n",
      "careless is at index 29399\n",
      "Saved the embedding for careless.\n",
      "caring is at index 10837\n",
      "Saved the embedding for caring.\n",
      "catty is at index 4758\n",
      "Saved the embedding for catty.\n",
      "caustic is at index 6056\n",
      "Saved the embedding for caustic.\n",
      "cautionary is at index 8038\n",
      "Saved the embedding for cautionary.\n",
      "cautious is at index 9420\n",
      "Saved the embedding for cautious.\n",
      "cavalier is at index 41869\n",
      "Saved the embedding for cavalier.\n",
      "celebrating is at index 6146\n",
      "Saved the embedding for celebrating.\n",
      "celebration is at index 4821\n",
      "Saved the embedding for celebration.\n",
      "censure is at index 26489\n",
      "Saved the embedding for censure.\n",
      "centered is at index 14889\n",
      "Saved the embedding for centered.\n",
      "certain is at index 1402\n",
      "Saved the embedding for certain.\n",
      "chafed is at index 1855\n",
      "Saved the embedding for chafed.\n",
      "chagrin is at index 1855\n",
      "Saved the embedding for chagrin.\n",
      "chagrined is at index 1855\n",
      "Saved the embedding for chagrined.\n",
      "chagrinned is at index 1855\n",
      "Saved the embedding for chagrinned.\n",
      "challenge is at index 1539\n",
      "Saved the embedding for challenge.\n",
      "challenged is at index 6835\n",
      "Saved the embedding for challenged.\n",
      "challenging is at index 4087\n",
      "Saved the embedding for challenging.\n",
      "chaotic is at index 16529\n",
      "Saved the embedding for chaotic.\n",
      "charged is at index 1340\n",
      "Saved the embedding for charged.\n",
      "charmed is at index 16224\n",
      "Saved the embedding for charmed.\n",
      "charming is at index 18452\n",
      "Saved the embedding for charming.\n",
      "chary is at index 1855\n",
      "Saved the embedding for chary.\n",
      "cheated is at index 25177\n",
      "Saved the embedding for cheated.\n",
      "cheeky is at index 15401\n",
      "Saved the embedding for cheeky.\n",
      "cheered is at index 18643\n",
      "Saved the embedding for cheered.\n",
      "cheerful is at index 33928\n",
      "Saved the embedding for cheerful.\n",
      "cheering is at index 16765\n",
      "Saved the embedding for cheering.\n",
      "cheerless is at index 9450\n",
      "Saved the embedding for cheerless.\n",
      "cheery is at index 5851\n",
      "Saved the embedding for cheery.\n",
      "cheesy is at index 36331\n",
      "Saved the embedding for cheesy.\n",
      "chesty is at index 7050\n",
      "Saved the embedding for chesty.\n",
      "chide is at index 1855\n",
      "Saved the embedding for chide.\n",
      "chiding is at index 1855\n",
      "Saved the embedding for chiding.\n",
      "childish is at index 40531\n",
      "Saved the embedding for childish.\n",
      "childishly is at index 920\n",
      "Saved the embedding for childishly.\n",
      "childlike is at index 920\n",
      "Saved the embedding for childlike.\n",
      "chill is at index 13146\n",
      "Saved the embedding for chill.\n",
      "chilled is at index 32338\n",
      "Saved the embedding for chilled.\n",
      "chilling is at index 22577\n",
      "Saved the embedding for chilling.\n",
      "chipper is at index 1855\n",
      "Saved the embedding for chipper.\n",
      "chirpy is at index 1855\n",
      "Saved the embedding for chirpy.\n",
      "choleric is at index 1855\n",
      "Saved the embedding for choleric.\n",
      "chortling is at index 1855\n",
      "Saved the embedding for chortling.\n",
      "chuckle is at index 37496\n",
      "Saved the embedding for chuckle.\n",
      "chuckling is at index 34600\n",
      "Saved the embedding for chuckling.\n",
      "churlish is at index 1855\n",
      "Saved the embedding for churlish.\n",
      "circumspect is at index 38529\n",
      "Saved the embedding for circumspect.\n",
      "clamorous is at index 24045\n",
      "Saved the embedding for clamorous.\n",
      "clash is at index 6064\n",
      "Saved the embedding for clash.\n",
      "clear is at index 699\n",
      "Saved the embedding for clear.\n",
      "clenched is at index 44646\n",
      "Saved the embedding for clenched.\n",
      "clever is at index 13074\n",
      "Saved the embedding for clever.\n",
      "close is at index 593\n",
      "Saved the embedding for close.\n",
      "closed is at index 1367\n",
      "Saved the embedding for closed.\n",
      "closemouthed is at index 593\n",
      "Saved the embedding for closemouthed.\n",
      "cloy is at index 3741\n",
      "Saved the embedding for cloy.\n",
      "clueless is at index 36776\n",
      "Saved the embedding for clueless.\n",
      "clutched is at index 29409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for clutched.\n",
      "cluttered is at index 29409\n",
      "Saved the embedding for cluttered.\n",
      "cockeyed is at index 740\n",
      "Saved the embedding for cockeyed.\n",
      "cockiness is at index 24231\n",
      "Saved the embedding for cockiness.\n",
      "cocksure is at index 740\n",
      "Saved the embedding for cocksure.\n",
      "cocky is at index 24231\n",
      "Saved the embedding for cocky.\n",
      "cognizant is at index 28105\n",
      "Saved the embedding for cognizant.\n",
      "cold is at index 2569\n",
      "Saved the embedding for cold.\n",
      "collected is at index 4786\n",
      "Saved the embedding for collected.\n",
      "collusive is at index 9843\n",
      "Saved the embedding for collusive.\n",
      "colonized is at index 17735\n",
      "Saved the embedding for colonized.\n",
      "combative is at index 14960\n",
      "Saved the embedding for combative.\n",
      "comedic is at index 29045\n",
      "Saved the embedding for comedic.\n",
      "comfort is at index 5863\n",
      "Saved the embedding for comfort.\n",
      "comfortable is at index 3473\n",
      "Saved the embedding for comfortable.\n",
      "comforted is at index 5863\n",
      "Saved the embedding for comforted.\n",
      "comical is at index 3137\n",
      "Saved the embedding for comical.\n",
      "commanding is at index 20510\n",
      "Saved the embedding for commanding.\n",
      "commiserating is at index 7034\n",
      "Saved the embedding for commiserating.\n",
      "commiserative is at index 7034\n",
      "Saved the embedding for commiserative.\n",
      "communicative is at index 16759\n",
      "Saved the embedding for communicative.\n",
      "compassion is at index 14736\n",
      "Saved the embedding for compassion.\n",
      "compassionate is at index 23303\n",
      "Saved the embedding for compassionate.\n",
      "competent is at index 17451\n",
      "Saved the embedding for competent.\n",
      "competitive is at index 2695\n",
      "Saved the embedding for competitive.\n",
      "complacence is at index 13000\n",
      "Saved the embedding for complacence.\n",
      "complacency is at index 13000\n",
      "Saved the embedding for complacency.\n",
      "complacent is at index 13000\n",
      "Saved the embedding for complacent.\n",
      "complacently is at index 13000\n",
      "Saved the embedding for complacently.\n",
      "complain is at index 11316\n",
      "Saved the embedding for complain.\n",
      "complaining is at index 13689\n",
      "Saved the embedding for complaining.\n",
      "composed is at index 14092\n",
      "Saved the embedding for composed.\n",
      "comprehending is at index 30030\n",
      "Saved the embedding for comprehending.\n",
      "compulsive is at index 7753\n",
      "Saved the embedding for compulsive.\n",
      "concealed is at index 17180\n",
      "Saved the embedding for concealed.\n",
      "conceding is at index 24647\n",
      "Saved the embedding for conceding.\n",
      "conceited is at index 21177\n",
      "Saved the embedding for conceited.\n",
      "concentrated is at index 15450\n",
      "Saved the embedding for concentrated.\n",
      "concentrating is at index 28619\n",
      "Saved the embedding for concentrating.\n",
      "concentration is at index 11772\n",
      "Saved the embedding for concentration.\n",
      "concern is at index 2212\n",
      "Saved the embedding for concern.\n",
      "concerned is at index 2273\n",
      "Saved the embedding for concerned.\n",
      "conciliatory is at index 10146\n",
      "Saved the embedding for conciliatory.\n",
      "conclusive is at index 37847\n",
      "Saved the embedding for conclusive.\n",
      "condemning is at index 21856\n",
      "Saved the embedding for condemning.\n",
      "condescending is at index 40742\n",
      "Saved the embedding for condescending.\n",
      "condoling is at index 35279\n",
      "Saved the embedding for condoling.\n",
      "confidence is at index 2123\n",
      "Saved the embedding for confidence.\n",
      "confident is at index 3230\n",
      "Saved the embedding for confident.\n",
      "confidently is at index 27447\n",
      "Saved the embedding for confidently.\n",
      "conflicted is at index 34428\n",
      "Saved the embedding for conflicted.\n",
      "confound is at index 7856\n",
      "Saved the embedding for confound.\n",
      "confounded is at index 7856\n",
      "Saved the embedding for confounded.\n",
      "confrontational is at index 10749\n",
      "Saved the embedding for confrontational.\n",
      "confused is at index 10985\n",
      "Saved the embedding for confused.\n",
      "confusion is at index 9655\n",
      "Saved the embedding for confusion.\n",
      "congenial is at index 36764\n",
      "Saved the embedding for congenial.\n",
      "congratulatory is at index 26303\n",
      "Saved the embedding for congratulatory.\n",
      "conniving is at index 39277\n",
      "Saved the embedding for conniving.\n",
      "conscious is at index 13316\n",
      "Saved the embedding for conscious.\n",
      "conservative is at index 3354\n",
      "Saved the embedding for conservative.\n",
      "considerate is at index 1701\n",
      "Saved the embedding for considerate.\n",
      "considering is at index 2811\n",
      "Saved the embedding for considering.\n",
      "consoling is at index 7407\n",
      "Saved the embedding for consoling.\n",
      "conspiratorial is at index 31150\n",
      "Saved the embedding for conspiratorial.\n",
      "conspiring is at index 27230\n",
      "Saved the embedding for conspiring.\n",
      "consternation is at index 10759\n",
      "Saved the embedding for consternation.\n",
      "constipated is at index 10759\n",
      "Saved the embedding for constipated.\n",
      "constrained is at index 26525\n",
      "Saved the embedding for constrained.\n",
      "consumed is at index 13056\n",
      "Saved the embedding for consumed.\n",
      "consuming is at index 16997\n",
      "Saved the embedding for consuming.\n",
      "contained is at index 5558\n",
      "Saved the embedding for contained.\n",
      "contemplate is at index 32848\n",
      "Saved the embedding for contemplate.\n",
      "contemplating is at index 27744\n",
      "Saved the embedding for contemplating.\n",
      "contemplation is at index 44072\n",
      "Saved the embedding for contemplation.\n",
      "contemplative is at index 43580\n",
      "Saved the embedding for contemplative.\n",
      "contempt is at index 16176\n",
      "Saved the embedding for contempt.\n",
      "contemptuous is at index 16176\n",
      "Saved the embedding for contemptuous.\n",
      "content is at index 1383\n",
      "Saved the embedding for content.\n",
      "contented is at index 1383\n",
      "Saved the embedding for contented.\n",
      "contentious is at index 14883\n",
      "Saved the embedding for contentious.\n",
      "contently is at index 8541\n",
      "Saved the embedding for contently.\n",
      "contentment is at index 1383\n",
      "Saved the embedding for contentment.\n",
      "contradictory is at index 31515\n",
      "Saved the embedding for contradictory.\n",
      "contrary is at index 11159\n",
      "Saved the embedding for contrary.\n",
      "contrite is at index 17035\n",
      "Saved the embedding for contrite.\n",
      "controlled is at index 4875\n",
      "Saved the embedding for controlled.\n",
      "controlling is at index 10568\n",
      "Saved the embedding for controlling.\n",
      "controversial is at index 4456\n",
      "Saved the embedding for controversial.\n",
      "contumacious is at index 8541\n",
      "Saved the embedding for contumacious.\n",
      "convinced is at index 7013\n",
      "Saved the embedding for convinced.\n",
      "cool is at index 3035\n",
      "Saved the embedding for cool.\n",
      "cooperative is at index 18777\n",
      "Saved the embedding for cooperative.\n",
      "cordial is at index 13051\n",
      "Saved the embedding for cordial.\n",
      "courageous is at index 24219\n",
      "Saved the embedding for courageous.\n",
      "covert is at index 25523\n",
      "Saved the embedding for covert.\n",
      "cowardly is at index 36881\n",
      "Saved the embedding for cowardly.\n",
      "coy is at index 20176\n",
      "Saved the embedding for coy.\n",
      "crabby is at index 23320\n",
      "Saved the embedding for crabby.\n",
      "crafty is at index 6306\n",
      "Saved the embedding for crafty.\n",
      "cranky is at index 30952\n",
      "Saved the embedding for cranky.\n",
      "crazed is at index 26002\n",
      "Saved the embedding for crazed.\n",
      "crazy is at index 5373\n",
      "Saved the embedding for crazy.\n",
      "credulous is at index 18994\n",
      "Saved the embedding for credulous.\n",
      "creepy is at index 23814\n",
      "Saved the embedding for creepy.\n",
      "crestfallen is at index 32220\n",
      "Saved the embedding for crestfallen.\n",
      "cringing is at index 3977\n",
      "Saved the embedding for cringing.\n",
      "critical is at index 2008\n",
      "Saved the embedding for critical.\n",
      "cross is at index 2116\n",
      "Saved the embedding for cross.\n",
      "crotchety is at index 11398\n",
      "Saved the embedding for crotchety.\n",
      "crude is at index 2976\n",
      "Saved the embedding for crude.\n",
      "cruel is at index 15939\n",
      "Saved the embedding for cruel.\n",
      "crushed is at index 14045\n",
      "Saved the embedding for crushed.\n",
      "cry is at index 8930\n",
      "Saved the embedding for cry.\n",
      "crying is at index 9701\n",
      "Saved the embedding for crying.\n",
      "cryptic is at index 35916\n",
      "Saved the embedding for cryptic.\n",
      "culpable is at index 29410\n",
      "Saved the embedding for culpable.\n",
      "cunning is at index 41526\n",
      "Saved the embedding for cunning.\n",
      "curios is at index 5350\n",
      "Saved the embedding for curios.\n",
      "curiosity is at index 20610\n",
      "Saved the embedding for curiosity.\n",
      "curious is at index 10691\n",
      "Saved the embedding for curious.\n",
      "cutting is at index 3931\n",
      "Saved the embedding for cutting.\n",
      "cynic is at index 40240\n",
      "Saved the embedding for cynic.\n",
      "cynical is at index 27566\n",
      "Saved the embedding for cynical.\n",
      "cynicism is at index 39245\n",
      "Saved the embedding for cynicism.\n",
      "dalliance is at index 385\n",
      "Saved the embedding for dalliance.\n",
      "dandy is at index 385\n",
      "Saved the embedding for dandy.\n",
      "dangerous is at index 2702\n",
      "Saved the embedding for dangerous.\n",
      "darkly is at index 2933\n",
      "Saved the embedding for darkly.\n",
      "daunted is at index 385\n",
      "Saved the embedding for daunted.\n",
      "daydream is at index 183\n",
      "Saved the embedding for daydream.\n",
      "daydreaming is at index 183\n",
      "Saved the embedding for daydreaming.\n",
      "dazed is at index 385\n",
      "Saved the embedding for dazed.\n",
      "dazzled is at index 32614\n",
      "Saved the embedding for dazzled.\n",
      "deadly is at index 4847\n",
      "Saved the embedding for deadly.\n",
      "deadpan is at index 1462\n",
      "Saved the embedding for deadpan.\n",
      "debate is at index 2625\n",
      "Saved the embedding for debate.\n",
      "debating is at index 24996\n",
      "Saved the embedding for debating.\n",
      "debauched is at index 10189\n",
      "Saved the embedding for debauched.\n",
      "deceitful is at index 35049\n",
      "Saved the embedding for deceitful.\n",
      "deceived is at index 38079\n",
      "Saved the embedding for deceived.\n",
      "deceiving is at index 34575\n",
      "Saved the embedding for deceiving.\n",
      "deceivingly is at index 34575\n",
      "Saved the embedding for deceivingly.\n",
      "deception is at index 29244\n",
      "Saved the embedding for deception.\n",
      "deceptive is at index 31405\n",
      "Saved the embedding for deceptive.\n",
      "deciding is at index 8997\n",
      "Saved the embedding for deciding.\n",
      "decisive is at index 12703\n",
      "Saved the embedding for decisive.\n",
      "dedicated is at index 3688\n",
      "Saved the embedding for dedicated.\n",
      "defeat is at index 3002\n",
      "Saved the embedding for defeat.\n",
      "defeated is at index 5125\n",
      "Saved the embedding for defeated.\n",
      "defenseless is at index 3816\n",
      "Saved the embedding for defenseless.\n",
      "defensive is at index 2465\n",
      "Saved the embedding for defensive.\n",
      "defiance is at index 25442\n",
      "Saved the embedding for defiance.\n",
      "defiant is at index 23802\n",
      "Saved the embedding for defiant.\n",
      "deflated is at index 3816\n",
      "Saved the embedding for deflated.\n",
      "degage is at index 31295\n",
      "Saved the embedding for degage.\n",
      "degrading is at index 36892\n",
      "Saved the embedding for degrading.\n",
      "dejected is at index 263\n",
      "Saved the embedding for dejected.\n",
      "dejection is at index 263\n",
      "Saved the embedding for dejection.\n",
      "deliberate is at index 14775\n",
      "Saved the embedding for deliberate.\n",
      "deliberating is at index 21614\n",
      "Saved the embedding for deliberating.\n",
      "delight is at index 13213\n",
      "Saved the embedding for delight.\n",
      "delighted is at index 7808\n",
      "Saved the embedding for delighted.\n",
      "delightful is at index 24897\n",
      "Saved the embedding for delightful.\n",
      "delirious is at index 2424\n",
      "Saved the embedding for delirious.\n",
      "delirium is at index 2424\n",
      "Saved the embedding for delirium.\n",
      "delude is at index 2424\n",
      "Saved the embedding for delude.\n",
      "delusional is at index 40160\n",
      "Saved the embedding for delusional.\n",
      "demanding is at index 5783\n",
      "Saved the embedding for demanding.\n",
      "demeaning is at index 4410\n",
      "Saved the embedding for demeaning.\n",
      "demented is at index 44202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for demented.\n",
      "demised is at index 4410\n",
      "Saved the embedding for demised.\n",
      "demoralized is at index 36810\n",
      "Saved the embedding for demoralized.\n",
      "demure is at index 4410\n",
      "Saved the embedding for demure.\n",
      "denied is at index 2296\n",
      "Saved the embedding for denied.\n",
      "denouncing is at index 32439\n",
      "Saved the embedding for denouncing.\n",
      "depleted is at index 26391\n",
      "Saved the embedding for depleted.\n",
      "deplorable is at index 28156\n",
      "Saved the embedding for deplorable.\n",
      "deprecating is at index 8273\n",
      "Saved the embedding for deprecating.\n",
      "depressed is at index 16658\n",
      "Saved the embedding for depressed.\n",
      "depression is at index 6943\n",
      "Saved the embedding for depression.\n",
      "deprived is at index 22632\n",
      "Saved the embedding for deprived.\n",
      "deranged is at index 1935\n",
      "Saved the embedding for deranged.\n",
      "derision is at index 1935\n",
      "Saved the embedding for derision.\n",
      "derisive is at index 1935\n",
      "Saved the embedding for derisive.\n",
      "derogatory is at index 30971\n",
      "Saved the embedding for derogatory.\n",
      "desire is at index 4724\n",
      "Saved the embedding for desire.\n",
      "desiring is at index 2694\n",
      "Saved the embedding for desiring.\n",
      "desirous is at index 2694\n",
      "Saved the embedding for desirous.\n",
      "desolate is at index 43177\n",
      "Saved the embedding for desolate.\n",
      "despair is at index 21508\n",
      "Saved the embedding for despair.\n",
      "despaired is at index 2694\n",
      "Saved the embedding for despaired.\n",
      "despairing is at index 21508\n",
      "Saved the embedding for despairing.\n",
      "desperate is at index 7764\n",
      "Saved the embedding for desperate.\n",
      "desperation is at index 24278\n",
      "Saved the embedding for desperation.\n",
      "despise is at index 43255\n",
      "Saved the embedding for despise.\n",
      "despondent is at index 18690\n",
      "Saved the embedding for despondent.\n",
      "destitute is at index 15357\n",
      "Saved the embedding for destitute.\n",
      "destroyed is at index 4957\n",
      "Saved the embedding for destroyed.\n",
      "detached is at index 27687\n",
      "Saved the embedding for detached.\n",
      "determination is at index 8964\n",
      "Saved the embedding for determination.\n",
      "determined is at index 3030\n",
      "Saved the embedding for determined.\n",
      "determining is at index 13684\n",
      "Saved the embedding for determining.\n",
      "deterred is at index 10922\n",
      "Saved the embedding for deterred.\n",
      "detest is at index 6769\n",
      "Saved the embedding for detest.\n",
      "detestable is at index 6769\n",
      "Saved the embedding for detestable.\n",
      "detesting is at index 6769\n",
      "Saved the embedding for detesting.\n",
      "detriment is at index 31969\n",
      "Saved the embedding for detriment.\n",
      "devastated is at index 11521\n",
      "Saved the embedding for devastated.\n",
      "deviant is at index 8709\n",
      "Saved the embedding for deviant.\n",
      "devilish is at index 22406\n",
      "Saved the embedding for devilish.\n",
      "devious is at index 263\n",
      "Saved the embedding for devious.\n",
      "devising is at index 8709\n",
      "Saved the embedding for devising.\n",
      "diffident is at index 25871\n",
      "Saved the embedding for diffident.\n",
      "dilatory is at index 14632\n",
      "Saved the embedding for dilatory.\n",
      "diligent is at index 33721\n",
      "Saved the embedding for diligent.\n",
      "dimwitted is at index 14548\n",
      "Saved the embedding for dimwitted.\n",
      "dire is at index 10697\n",
      "Saved the embedding for dire.\n",
      "disagree is at index 11967\n",
      "Saved the embedding for disagree.\n",
      "disagreeable is at index 11967\n",
      "Saved the embedding for disagreeable.\n",
      "disagreement is at index 20628\n",
      "Saved the embedding for disagreement.\n",
      "disappointed is at index 5779\n",
      "Saved the embedding for disappointed.\n",
      "disappointing is at index 6770\n",
      "Saved the embedding for disappointing.\n",
      "disappointment is at index 10208\n",
      "Saved the embedding for disappointment.\n",
      "disapproval is at index 32129\n",
      "Saved the embedding for disapproval.\n",
      "disapproving is at index 36631\n",
      "Saved the embedding for disapproving.\n",
      "disbelief is at index 26440\n",
      "Saved the embedding for disbelief.\n",
      "disbelieve is at index 45668\n",
      "Saved the embedding for disbelieve.\n",
      "disbelieving is at index 45668\n",
      "Saved the embedding for disbelieving.\n",
      "discerning is at index 9553\n",
      "Saved the embedding for discerning.\n",
      "discombobulated is at index 2982\n",
      "Saved the embedding for discombobulated.\n",
      "discomfited is at index 2982\n",
      "Saved the embedding for discomfited.\n",
      "discomfort is at index 19535\n",
      "Saved the embedding for discomfort.\n",
      "discomforted is at index 19535\n",
      "Saved the embedding for discomforted.\n",
      "disconcerted is at index 2982\n",
      "Saved the embedding for disconcerted.\n",
      "disconnected is at index 30005\n",
      "Saved the embedding for disconnected.\n",
      "disconsolate is at index 9553\n",
      "Saved the embedding for disconsolate.\n",
      "discontent is at index 27478\n",
      "Saved the embedding for discontent.\n",
      "discontented is at index 47772\n",
      "Saved the embedding for discontented.\n",
      "discounted is at index 17533\n",
      "Saved the embedding for discounted.\n",
      "discouraged is at index 25788\n",
      "Saved the embedding for discouraged.\n",
      "discovery is at index 6953\n",
      "Saved the embedding for discovery.\n",
      "discriminating is at index 38303\n",
      "Saved the embedding for discriminating.\n",
      "discussed is at index 3373\n",
      "Saved the embedding for discussed.\n",
      "disdain is at index 29512\n",
      "Saved the embedding for disdain.\n",
      "disdained is at index 2982\n",
      "Saved the embedding for disdained.\n",
      "disdainful is at index 29512\n",
      "Saved the embedding for disdainful.\n",
      "disdainfully is at index 29512\n",
      "Saved the embedding for disdainfully.\n",
      "disenchanted is at index 2982\n",
      "Saved the embedding for disenchanted.\n",
      "disengaged is at index 35170\n",
      "Saved the embedding for disengaged.\n",
      "disgraced is at index 25425\n",
      "Saved the embedding for disgraced.\n",
      "disgruntled is at index 29412\n",
      "Saved the embedding for disgruntled.\n",
      "disgruntlement is at index 25425\n",
      "Saved the embedding for disgruntlement.\n",
      "disgust is at index 30883\n",
      "Saved the embedding for disgust.\n",
      "disgusted is at index 32759\n",
      "Saved the embedding for disgusted.\n",
      "disgustedly is at index 32759\n",
      "Saved the embedding for disgustedly.\n",
      "disgusting is at index 21096\n",
      "Saved the embedding for disgusting.\n",
      "disheartened is at index 2982\n",
      "Saved the embedding for disheartened.\n",
      "dishonest is at index 27820\n",
      "Saved the embedding for dishonest.\n",
      "disillusioned is at index 33447\n",
      "Saved the embedding for disillusioned.\n",
      "disinclined is at index 2982\n",
      "Saved the embedding for disinclined.\n",
      "disingenuous is at index 39622\n",
      "Saved the embedding for disingenuous.\n",
      "disinterest is at index 2982\n",
      "Saved the embedding for disinterest.\n",
      "disinterested is at index 2982\n",
      "Saved the embedding for disinterested.\n",
      "disjointed is at index 2982\n",
      "Saved the embedding for disjointed.\n",
      "dislike is at index 28101\n",
      "Saved the embedding for dislike.\n",
      "disliked is at index 40891\n",
      "Saved the embedding for disliked.\n",
      "disliking is at index 19131\n",
      "Saved the embedding for disliking.\n",
      "dismal is at index 23446\n",
      "Saved the embedding for dismal.\n",
      "disman is at index 2982\n",
      "Saved the embedding for disman.\n",
      "dismay is at index 22135\n",
      "Saved the embedding for dismay.\n",
      "dismayed is at index 22135\n",
      "Saved the embedding for dismayed.\n",
      "dismissive is at index 37890\n",
      "Saved the embedding for dismissive.\n",
      "disobedient is at index 43738\n",
      "Saved the embedding for disobedient.\n",
      "disorderly is at index 23547\n",
      "Saved the embedding for disorderly.\n",
      "disoriented is at index 2982\n",
      "Saved the embedding for disoriented.\n",
      "dispair is at index 11734\n",
      "Saved the embedding for dispair.\n",
      "disparaging is at index 24331\n",
      "Saved the embedding for disparaging.\n",
      "dispassionate is at index 11734\n",
      "Saved the embedding for dispassionate.\n",
      "dispirited is at index 2982\n",
      "Saved the embedding for dispirited.\n",
      "dispiritedness is at index 2982\n",
      "Saved the embedding for dispiritedness.\n",
      "displeased is at index 43709\n",
      "Saved the embedding for displeased.\n",
      "displeasure is at index 30201\n",
      "Saved the embedding for displeasure.\n",
      "disquiet is at index 2982\n",
      "Saved the embedding for disquiet.\n",
      "disquieted is at index 2982\n",
      "Saved the embedding for disquieted.\n",
      "disregard is at index 21034\n",
      "Saved the embedding for disregard.\n",
      "disrespectful is at index 26401\n",
      "Saved the embedding for disrespectful.\n",
      "disrupted is at index 15902\n",
      "Saved the embedding for disrupted.\n",
      "disruptive is at index 17561\n",
      "Saved the embedding for disruptive.\n",
      "dissatisfaction is at index 31776\n",
      "Saved the embedding for dissatisfaction.\n",
      "dissatisfied is at index 37278\n",
      "Saved the embedding for dissatisfied.\n",
      "dissatisfy is at index 48830\n",
      "Saved the embedding for dissatisfy.\n",
      "dissecting is at index 33562\n",
      "Saved the embedding for dissecting.\n",
      "dissociated is at index 14863\n",
      "Saved the embedding for dissociated.\n",
      "dissonant is at index 43162\n",
      "Saved the embedding for dissonant.\n",
      "distain is at index 7018\n",
      "Saved the embedding for distain.\n",
      "distant is at index 13258\n",
      "Saved the embedding for distant.\n",
      "distaste is at index 7018\n",
      "Saved the embedding for distaste.\n",
      "distasteful is at index 7018\n",
      "Saved the embedding for distasteful.\n",
      "distracted is at index 16573\n",
      "Saved the embedding for distracted.\n",
      "distraught is at index 30719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for distraught.\n",
      "distress is at index 13250\n",
      "Saved the embedding for distress.\n",
      "distressed is at index 21460\n",
      "Saved the embedding for distressed.\n",
      "distressing is at index 7018\n",
      "Saved the embedding for distressing.\n",
      "distrust is at index 27948\n",
      "Saved the embedding for distrust.\n",
      "distrustful is at index 27948\n",
      "Saved the embedding for distrustful.\n",
      "distrusting is at index 27948\n",
      "Saved the embedding for distrusting.\n",
      "disturbed is at index 22938\n",
      "Saved the embedding for disturbed.\n",
      "diverted is at index 19070\n",
      "Saved the embedding for diverted.\n",
      "dodgy is at index 25744\n",
      "Saved the embedding for dodgy.\n",
      "doleful is at index 109\n",
      "Saved the embedding for doleful.\n",
      "doltish is at index 385\n",
      "Saved the embedding for doltish.\n",
      "dominant is at index 7353\n",
      "Saved the embedding for dominant.\n",
      "dominating is at index 17349\n",
      "Saved the embedding for dominating.\n",
      "domineering is at index 13567\n",
      "Saved the embedding for domineering.\n",
      "done is at index 626\n",
      "Saved the embedding for done.\n",
      "doomed is at index 23326\n",
      "Saved the embedding for doomed.\n",
      "dopey is at index 32331\n",
      "Saved the embedding for dopey.\n",
      "doting is at index 385\n",
      "Saved the embedding for doting.\n",
      "doubt is at index 2980\n",
      "Saved the embedding for doubt.\n",
      "doubter is at index 26463\n",
      "Saved the embedding for doubter.\n",
      "doubtful is at index 26645\n",
      "Saved the embedding for doubtful.\n",
      "doubtfully is at index 2980\n",
      "Saved the embedding for doubtfully.\n",
      "doubtfulness is at index 2980\n",
      "Saved the embedding for doubtfulness.\n",
      "doubting is at index 26463\n",
      "Saved the embedding for doubting.\n",
      "dour is at index 385\n",
      "Saved the embedding for dour.\n",
      "down is at index 159\n",
      "Saved the embedding for down.\n",
      "downcast is at index 159\n",
      "Saved the embedding for downcast.\n",
      "downhearted is at index 159\n",
      "Saved the embedding for downhearted.\n",
      "downheartedness is at index 159\n",
      "Saved the embedding for downheartedness.\n",
      "downtrodden is at index 29407\n",
      "Saved the embedding for downtrodden.\n",
      "dozing is at index 109\n",
      "Saved the embedding for dozing.\n",
      "drained is at index 23544\n",
      "Saved the embedding for drained.\n",
      "dramatic is at index 5386\n",
      "Saved the embedding for dramatic.\n",
      "drawn is at index 4777\n",
      "Saved the embedding for drawn.\n",
      "dread is at index 24506\n",
      "Saved the embedding for dread.\n",
      "dreadful is at index 31715\n",
      "Saved the embedding for dreadful.\n",
      "dreading is at index 24506\n",
      "Saved the embedding for dreading.\n",
      "dreaming is at index 26240\n",
      "Saved the embedding for dreaming.\n",
      "dreamy is at index 3366\n",
      "Saved the embedding for dreamy.\n",
      "dreary is at index 385\n",
      "Saved the embedding for dreary.\n",
      "driven is at index 3185\n",
      "Saved the embedding for driven.\n",
      "drowsy is at index 385\n",
      "Saved the embedding for drowsy.\n",
      "drugged is at index 385\n",
      "Saved the embedding for drugged.\n",
      "drunk is at index 10789\n",
      "Saved the embedding for drunk.\n",
      "drunkenness is at index 19835\n",
      "Saved the embedding for drunkenness.\n",
      "dubiety is at index 30180\n",
      "Saved the embedding for dubiety.\n",
      "dubious is at index 24381\n",
      "Saved the embedding for dubious.\n",
      "dubiously is at index 30180\n",
      "Saved the embedding for dubiously.\n",
      "dull is at index 22018\n",
      "Saved the embedding for dull.\n",
      "dumb is at index 16881\n",
      "Saved the embedding for dumb.\n",
      "dumbfound is at index 16881\n",
      "Saved the embedding for dumbfound.\n",
      "dumbfounded is at index 16881\n",
      "Saved the embedding for dumbfounded.\n",
      "dumbstruck is at index 16881\n",
      "Saved the embedding for dumbstruck.\n",
      "dumfounded is at index 385\n",
      "Saved the embedding for dumfounded.\n",
      "dupe is at index 4279\n",
      "Saved the embedding for dupe.\n",
      "duplicitous is at index 30501\n",
      "Saved the embedding for duplicitous.\n",
      "dysphoric is at index 44153\n",
      "Saved the embedding for dysphoric.\n",
      "eager is at index 7921\n",
      "Saved the embedding for eager.\n",
      "eagerness is at index 7921\n",
      "Saved the embedding for eagerness.\n",
      "earnest is at index 22623\n",
      "Saved the embedding for earnest.\n",
      "easy is at index 1365\n",
      "Saved the embedding for easy.\n",
      "ebullient is at index 364\n",
      "Saved the embedding for ebullient.\n",
      "ecstasy is at index 37695\n",
      "Saved the embedding for ecstasy.\n",
      "ecstatic is at index 30754\n",
      "Saved the embedding for ecstatic.\n",
      "ecstatically is at index 20508\n",
      "Saved the embedding for ecstatically.\n",
      "edgy is at index 4803\n",
      "Saved the embedding for edgy.\n",
      "eerie is at index 33960\n",
      "Saved the embedding for eerie.\n",
      "effulgent is at index 22089\n",
      "Saved the embedding for effulgent.\n",
      "egoistic is at index 21450\n",
      "Saved the embedding for egoistic.\n",
      "egotistical is at index 364\n",
      "Saved the embedding for egotistical.\n",
      "egregious is at index 28971\n",
      "Saved the embedding for egregious.\n",
      "elated is at index 1615\n",
      "Saved the embedding for elated.\n",
      "elation is at index 1615\n",
      "Saved the embedding for elation.\n",
      "electrified is at index 17995\n",
      "Saved the embedding for electrified.\n",
      "elusive is at index 21483\n",
      "Saved the embedding for elusive.\n",
      "embarrassed is at index 17319\n",
      "Saved the embedding for embarrassed.\n",
      "embarrassment is at index 19124\n",
      "Saved the embedding for embarrassment.\n",
      "embittered is at index 2841\n",
      "Saved the embedding for embittered.\n",
      "embody is at index 33865\n",
      "Saved the embedding for embody.\n",
      "emotional is at index 3722\n",
      "Saved the embedding for emotional.\n",
      "emotionless is at index 11926\n",
      "Saved the embedding for emotionless.\n",
      "empathetic is at index 2841\n",
      "Saved the embedding for empathetic.\n",
      "empathic is at index 2841\n",
      "Saved the embedding for empathic.\n",
      "empathy is at index 17805\n",
      "Saved the embedding for empathy.\n",
      "emptiness is at index 44480\n",
      "Saved the embedding for emptiness.\n",
      "empty is at index 5802\n",
      "Saved the embedding for empty.\n",
      "enamored is at index 1177\n",
      "Saved the embedding for enamored.\n",
      "enchanted is at index 44141\n",
      "Saved the embedding for enchanted.\n",
      "encouraged is at index 4446\n",
      "Saved the embedding for encouraged.\n",
      "encouragement is at index 18197\n",
      "Saved the embedding for encouragement.\n",
      "encouraging is at index 5513\n",
      "Saved the embedding for encouraging.\n",
      "endeared is at index 253\n",
      "Saved the embedding for endeared.\n",
      "endearing is at index 253\n",
      "Saved the embedding for endearing.\n",
      "enduring is at index 16480\n",
      "Saved the embedding for enduring.\n",
      "energetic is at index 20425\n",
      "Saved the embedding for energetic.\n",
      "energized is at index 15957\n",
      "Saved the embedding for energized.\n",
      "engaged is at index 4009\n",
      "Saved the embedding for engaged.\n",
      "engrossed is at index 20407\n",
      "Saved the embedding for engrossed.\n",
      "engrossment is at index 20407\n",
      "Saved the embedding for engrossment.\n",
      "enigmatic is at index 38910\n",
      "Saved the embedding for enigmatic.\n",
      "enjoy is at index 2254\n",
      "Saved the embedding for enjoy.\n",
      "enjoying is at index 6218\n",
      "Saved the embedding for enjoying.\n",
      "enjoyment is at index 26611\n",
      "Saved the embedding for enjoyment.\n",
      "enlightened is at index 38853\n",
      "Saved the embedding for enlightened.\n",
      "enmity is at index 1177\n",
      "Saved the embedding for enmity.\n",
      "ennui is at index 1177\n",
      "Saved the embedding for ennui.\n",
      "enraged is at index 33415\n",
      "Saved the embedding for enraged.\n",
      "enraging is at index 1177\n",
      "Saved the embedding for enraging.\n",
      "enraptured is at index 1177\n",
      "Saved the embedding for enraptured.\n",
      "entertained is at index 23979\n",
      "Saved the embedding for entertained.\n",
      "enthralled is at index 3838\n",
      "Saved the embedding for enthralled.\n",
      "enthused is at index 3838\n",
      "Saved the embedding for enthused.\n",
      "enthusiasm is at index 11240\n",
      "Saved the embedding for enthusiasm.\n",
      "enthusiastic is at index 15947\n",
      "Saved the embedding for enthusiastic.\n",
      "enticed is at index 3838\n",
      "Saved the embedding for enticed.\n",
      "entranced is at index 3838\n",
      "Saved the embedding for entranced.\n",
      "envious is at index 1177\n",
      "Saved the embedding for envious.\n",
      "envy is at index 29778\n",
      "Saved the embedding for envy.\n",
      "erotically is at index 3335\n",
      "Saved the embedding for erotically.\n",
      "estranged is at index 20599\n",
      "Saved the embedding for estranged.\n",
      "etched is at index 35542\n",
      "Saved the embedding for etched.\n",
      "euphoric is at index 30882\n",
      "Saved the embedding for euphoric.\n",
      "evaluating is at index 15190\n",
      "Saved the embedding for evaluating.\n",
      "evasive is at index 7630\n",
      "Saved the embedding for evasive.\n",
      "evil is at index 9247\n",
      "Saved the embedding for evil.\n",
      "evoke is at index 35334\n",
      "Saved the embedding for evoke.\n",
      "exacerbated is at index 24961\n",
      "Saved the embedding for exacerbated.\n",
      "exalted is at index 45514\n",
      "Saved the embedding for exalted.\n",
      "examining is at index 14951\n",
      "Saved the embedding for examining.\n",
      "exasperate is at index 1931\n",
      "Saved the embedding for exasperate.\n",
      "exasperated is at index 34698\n",
      "Saved the embedding for exasperated.\n",
      "exasperation is at index 34698\n",
      "Saved the embedding for exasperation.\n",
      "excited is at index 2283\n",
      "Saved the embedding for excited.\n",
      "excitedly is at index 2283\n",
      "Saved the embedding for excitedly.\n",
      "excitement is at index 8354\n",
      "Saved the embedding for excitement.\n",
      "exclamation is at index 1931\n",
      "Saved the embedding for exclamation.\n",
      "exclamatory is at index 1931\n",
      "Saved the embedding for exclamatory.\n",
      "exhausted is at index 17067\n",
      "Saved the embedding for exhausted.\n",
      "exhaustion is at index 30567\n",
      "Saved the embedding for exhaustion.\n",
      "exhaustive is at index 29180\n",
      "Saved the embedding for exhaustive.\n",
      "exhilarated is at index 32749\n",
      "Saved the embedding for exhilarated.\n",
      "exhilaration is at index 32749\n",
      "Saved the embedding for exhilaration.\n",
      "exited is at index 17469\n",
      "Saved the embedding for exited.\n",
      "expectant is at index 1057\n",
      "Saved the embedding for expectant.\n",
      "expectation is at index 9250\n",
      "Saved the embedding for expectation.\n",
      "expecting is at index 4804\n",
      "Saved the embedding for expecting.\n",
      "explain is at index 3922\n",
      "Saved the embedding for explain.\n",
      "explaining is at index 8926\n",
      "Saved the embedding for explaining.\n",
      "exploitive is at index 38984\n",
      "Saved the embedding for exploitive.\n",
      "explosive is at index 8560\n",
      "Saved the embedding for explosive.\n",
      "exposure is at index 4895\n",
      "Saved the embedding for exposure.\n",
      "expressive is at index 36340\n",
      "Saved the embedding for expressive.\n",
      "exuberant is at index 1931\n",
      "Saved the embedding for exuberant.\n",
      "exultant is at index 1931\n",
      "Saved the embedding for exultant.\n",
      "exulted is at index 1931\n",
      "Saved the embedding for exulted.\n",
      "eye is at index 2295\n",
      "Saved the embedding for eye.\n",
      "eyed is at index 36235\n",
      "Saved the embedding for eyed.\n",
      "faced is at index 2713\n",
      "Saved the embedding for faced.\n",
      "facetious is at index 34407\n",
      "Saved the embedding for facetious.\n",
      "failure is at index 2988\n",
      "Saved the embedding for failure.\n",
      "faint is at index 27922\n",
      "Saved the embedding for faint.\n",
      "fair is at index 2105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for fair.\n",
      "fake is at index 4486\n",
      "Saved the embedding for fake.\n",
      "faking is at index 856\n",
      "Saved the embedding for faking.\n",
      "falter is at index 14848\n",
      "Saved the embedding for falter.\n",
      "famished is at index 13403\n",
      "Saved the embedding for famished.\n",
      "fanatic is at index 38604\n",
      "Saved the embedding for fanatic.\n",
      "fanciful is at index 33639\n",
      "Saved the embedding for fanciful.\n",
      "fart is at index 36762\n",
      "Saved the embedding for fart.\n",
      "fascinated is at index 27025\n",
      "Saved the embedding for fascinated.\n",
      "fastidious is at index 1769\n",
      "Saved the embedding for fastidious.\n",
      "fatigue is at index 16069\n",
      "Saved the embedding for fatigue.\n",
      "fatigued is at index 36239\n",
      "Saved the embedding for fatigued.\n",
      "faultfinding is at index 7684\n",
      "Saved the embedding for faultfinding.\n",
      "favorable is at index 9879\n",
      "Saved the embedding for favorable.\n",
      "fawning is at index 856\n",
      "Saved the embedding for fawning.\n",
      "fazed is at index 856\n",
      "Saved the embedding for fazed.\n",
      "fear is at index 2490\n",
      "Saved the embedding for fear.\n",
      "feared is at index 9741\n",
      "Saved the embedding for feared.\n",
      "fearful is at index 23526\n",
      "Saved the embedding for fearful.\n",
      "fearing is at index 21510\n",
      "Saved the embedding for fearing.\n",
      "fearless is at index 29107\n",
      "Saved the embedding for fearless.\n",
      "fearsome is at index 39185\n",
      "Saved the embedding for fearsome.\n",
      "feckless is at index 10668\n",
      "Saved the embedding for feckless.\n",
      "fed is at index 9789\n",
      "Saved the embedding for fed.\n",
      "feeble is at index 42217\n",
      "Saved the embedding for feeble.\n",
      "feign is at index 10668\n",
      "Saved the embedding for feign.\n",
      "felicitous is at index 14383\n",
      "Saved the embedding for felicitous.\n",
      "ferocious is at index 31429\n",
      "Saved the embedding for ferocious.\n",
      "ferocity is at index 16022\n",
      "Saved the embedding for ferocity.\n",
      "festive is at index 12298\n",
      "Saved the embedding for festive.\n",
      "fidgety is at index 856\n",
      "Saved the embedding for fidgety.\n",
      "fiendish is at index 13383\n",
      "Saved the embedding for fiendish.\n",
      "fierce is at index 11039\n",
      "Saved the embedding for fierce.\n",
      "fiery is at index 19068\n",
      "Saved the embedding for fiery.\n",
      "fighting is at index 2190\n",
      "Saved the embedding for fighting.\n",
      "fine is at index 2051\n",
      "Saved the embedding for fine.\n",
      "finished is at index 1550\n",
      "Saved the embedding for finished.\n",
      "firm is at index 933\n",
      "Saved the embedding for firm.\n",
      "fishy is at index 3539\n",
      "Saved the embedding for fishy.\n",
      "fixated is at index 4190\n",
      "Saved the embedding for fixated.\n",
      "fixed is at index 4460\n",
      "Saved the embedding for fixed.\n",
      "flabbergasted is at index 2342\n",
      "Saved the embedding for flabbergasted.\n",
      "flaming is at index 37222\n",
      "Saved the embedding for flaming.\n",
      "flat is at index 3269\n",
      "Saved the embedding for flat.\n",
      "flaunting is at index 2342\n",
      "Saved the embedding for flaunting.\n",
      "flighty is at index 2524\n",
      "Saved the embedding for flighty.\n",
      "flippant is at index 2342\n",
      "Saved the embedding for flippant.\n",
      "flipped is at index 18626\n",
      "Saved the embedding for flipped.\n",
      "flirtation is at index 33743\n",
      "Saved the embedding for flirtation.\n",
      "flirtatious is at index 33743\n",
      "Saved the embedding for flirtatious.\n",
      "flirty is at index 2342\n",
      "Saved the embedding for flirty.\n",
      "floored is at index 27325\n",
      "Saved the embedding for floored.\n",
      "flummoxed is at index 2342\n",
      "Saved the embedding for flummoxed.\n",
      "flustered is at index 2342\n",
      "Saved the embedding for flustered.\n",
      "focus is at index 1056\n",
      "Saved the embedding for focus.\n",
      "focused is at index 2061\n",
      "Saved the embedding for focused.\n",
      "focusing is at index 5650\n",
      "Saved the embedding for focusing.\n",
      "foiled is at index 9565\n",
      "Saved the embedding for foiled.\n",
      "foolish is at index 22789\n",
      "Saved the embedding for foolish.\n",
      "forbearing is at index 34550\n",
      "Saved the embedding for forbearing.\n",
      "forbidding is at index 34550\n",
      "Saved the embedding for forbidding.\n",
      "forced is at index 1654\n",
      "Saved the embedding for forced.\n",
      "forceful is at index 32165\n",
      "Saved the embedding for forceful.\n",
      "forfeited is at index 31844\n",
      "Saved the embedding for forfeited.\n",
      "forlorn is at index 13\n",
      "Saved the embedding for forlorn.\n",
      "fortunate is at index 10583\n",
      "Saved the embedding for fortunate.\n",
      "forward is at index 556\n",
      "Saved the embedding for forward.\n",
      "foul is at index 6962\n",
      "Saved the embedding for foul.\n",
      "fractious is at index 38251\n",
      "Saved the embedding for fractious.\n",
      "fragile is at index 14283\n",
      "Saved the embedding for fragile.\n",
      "frantic is at index 27396\n",
      "Saved the embedding for frantic.\n",
      "fraudulent is at index 15381\n",
      "Saved the embedding for fraudulent.\n",
      "fraught is at index 25481\n",
      "Saved the embedding for fraught.\n",
      "frazzled is at index 26830\n",
      "Saved the embedding for frazzled.\n",
      "freaked is at index 7619\n",
      "Saved the embedding for freaked.\n",
      "frenzied is at index 26908\n",
      "Saved the embedding for frenzied.\n",
      "fretful is at index 31391\n",
      "Saved the embedding for fretful.\n",
      "friendliness is at index 1441\n",
      "Saved the embedding for friendliness.\n",
      "friendly is at index 5192\n",
      "Saved the embedding for friendly.\n",
      "fright is at index 32580\n",
      "Saved the embedding for fright.\n",
      "frightened is at index 26851\n",
      "Saved the embedding for frightened.\n",
      "frightening is at index 21111\n",
      "Saved the embedding for frightening.\n",
      "frigid is at index 25805\n",
      "Saved the embedding for frigid.\n",
      "frisky is at index 6664\n",
      "Saved the embedding for frisky.\n",
      "frolicker is at index 856\n",
      "Saved the embedding for frolicker.\n",
      "frown is at index 41588\n",
      "Saved the embedding for frown.\n",
      "frowning is at index 41588\n",
      "Saved the embedding for frowning.\n",
      "frozen is at index 9214\n",
      "Saved the embedding for frozen.\n",
      "frumpy is at index 6664\n",
      "Saved the embedding for frumpy.\n",
      "frustrated is at index 8164\n",
      "Saved the embedding for frustrated.\n",
      "frustration is at index 8413\n",
      "Saved the embedding for frustration.\n",
      "fulfilled is at index 20218\n",
      "Saved the embedding for fulfilled.\n",
      "fumed is at index 856\n",
      "Saved the embedding for fumed.\n",
      "fuming is at index 856\n",
      "Saved the embedding for fuming.\n",
      "fun is at index 1531\n",
      "Saved the embedding for fun.\n",
      "funny is at index 6269\n",
      "Saved the embedding for funny.\n",
      "furious is at index 15940\n",
      "Saved the embedding for furious.\n",
      "furiously is at index 39202\n",
      "Saved the embedding for furiously.\n",
      "furiousness is at index 15940\n",
      "Saved the embedding for furiousness.\n",
      "furrowed is at index 15503\n",
      "Saved the embedding for furrowed.\n",
      "furtive is at index 856\n",
      "Saved the embedding for furtive.\n",
      "fury is at index 22228\n",
      "Saved the embedding for fury.\n",
      "fussy is at index 856\n",
      "Saved the embedding for fussy.\n",
      "galled is at index 821\n",
      "Saved the embedding for galled.\n",
      "galling is at index 19869\n",
      "Saved the embedding for galling.\n",
      "gasp is at index 41681\n",
      "Saved the embedding for gasp.\n",
      "gasped is at index 44918\n",
      "Saved the embedding for gasped.\n",
      "gasping is at index 1123\n",
      "Saved the embedding for gasping.\n",
      "gay is at index 5100\n",
      "Saved the embedding for gay.\n",
      "gazing is at index 40804\n",
      "Saved the embedding for gazing.\n",
      "genial is at index 12358\n",
      "Saved the embedding for genial.\n",
      "gentle is at index 16634\n",
      "Saved the embedding for gentle.\n",
      "genuine is at index 8916\n",
      "Saved the embedding for genuine.\n",
      "ghastly is at index 34648\n",
      "Saved the embedding for ghastly.\n",
      "giddy is at index 821\n",
      "Saved the embedding for giddy.\n",
      "giggle is at index 821\n",
      "Saved the embedding for giggle.\n",
      "giggling is at index 33786\n",
      "Saved the embedding for giggling.\n",
      "glad is at index 7785\n",
      "Saved the embedding for glad.\n",
      "gladdened is at index 5921\n",
      "Saved the embedding for gladdened.\n",
      "gladiola is at index 7785\n",
      "Saved the embedding for gladiola.\n",
      "gladness is at index 7785\n",
      "Saved the embedding for gladness.\n",
      "gladsome is at index 5921\n",
      "Saved the embedding for gladsome.\n",
      "glare is at index 37355\n",
      "Saved the embedding for glare.\n",
      "glaring is at index 26077\n",
      "Saved the embedding for glaring.\n",
      "glazed is at index 5921\n",
      "Saved the embedding for glazed.\n",
      "glee is at index 821\n",
      "Saved the embedding for glee.\n",
      "gleeful is at index 22460\n",
      "Saved the embedding for gleeful.\n",
      "gleefully is at index 22460\n",
      "Saved the embedding for gleefully.\n",
      "glib is at index 5921\n",
      "Saved the embedding for glib.\n",
      "gloating is at index 5921\n",
      "Saved the embedding for gloating.\n",
      "gloom is at index 31752\n",
      "Saved the embedding for gloom.\n",
      "gloomy is at index 32627\n",
      "Saved the embedding for gloomy.\n",
      "glowering is at index 5921\n",
      "Saved the embedding for glowering.\n",
      "glowing is at index 22285\n",
      "Saved the embedding for glowing.\n",
      "glum is at index 5921\n",
      "Saved the embedding for glum.\n",
      "gnarl is at index 31021\n",
      "Saved the embedding for gnarl.\n",
      "gobsmacked is at index 213\n",
      "Saved the embedding for gobsmacked.\n",
      "good is at index 205\n",
      "Saved the embedding for good.\n",
      "goofy is at index 36302\n",
      "Saved the embedding for goofy.\n",
      "gossipy is at index 20445\n",
      "Saved the embedding for gossipy.\n",
      "grandiose is at index 2821\n",
      "Saved the embedding for grandiose.\n",
      "grateful is at index 6161\n",
      "Saved the embedding for grateful.\n",
      "gratified is at index 20153\n",
      "Saved the embedding for gratified.\n",
      "grave is at index 9753\n",
      "Saved the embedding for grave.\n",
      "great is at index 372\n",
      "Saved the embedding for great.\n",
      "greedy is at index 34405\n",
      "Saved the embedding for greedy.\n",
      "greeting is at index 25801\n",
      "Saved the embedding for greeting.\n",
      "grief is at index 12903\n",
      "Saved the embedding for grief.\n",
      "grieved is at index 821\n",
      "Saved the embedding for grieved.\n",
      "grieving is at index 22567\n",
      "Saved the embedding for grieving.\n",
      "grim is at index 17081\n",
      "Saved the embedding for grim.\n",
      "grimace is at index 17081\n",
      "Saved the embedding for grimace.\n",
      "grimacing is at index 17081\n",
      "Saved the embedding for grimacing.\n",
      "grin is at index 30986\n",
      "Saved the embedding for grin.\n",
      "grinning is at index 39662\n",
      "Saved the embedding for grinning.\n",
      "griping is at index 11155\n",
      "Saved the embedding for griping.\n",
      "gross is at index 4200\n",
      "Saved the embedding for gross.\n",
      "grossed is at index 4200\n",
      "Saved the embedding for grossed.\n",
      "grouchy is at index 22970\n",
      "Saved the embedding for grouchy.\n",
      "growl is at index 1733\n",
      "Saved the embedding for growl.\n",
      "growling is at index 1733\n",
      "Saved the embedding for growling.\n",
      "grudge is at index 4435\n",
      "Saved the embedding for grudge.\n",
      "grudging is at index 4435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for grudging.\n",
      "gruff is at index 15551\n",
      "Saved the embedding for gruff.\n",
      "grumbling is at index 4435\n",
      "Saved the embedding for grumbling.\n",
      "grumpy is at index 4435\n",
      "Saved the embedding for grumpy.\n",
      "grunt is at index 44376\n",
      "Saved the embedding for grunt.\n",
      "grunting is at index 39204\n",
      "Saved the embedding for grunting.\n",
      "guarded is at index 25853\n",
      "Saved the embedding for guarded.\n",
      "guilty is at index 2181\n",
      "Saved the embedding for guilty.\n",
      "gulp is at index 821\n",
      "Saved the embedding for gulp.\n",
      "haggard is at index 1368\n",
      "Saved the embedding for haggard.\n",
      "halfhearted is at index 457\n",
      "Saved the embedding for halfhearted.\n",
      "halted is at index 12856\n",
      "Saved the embedding for halted.\n",
      "hapless is at index 2489\n",
      "Saved the embedding for hapless.\n",
      "happiness is at index 11098\n",
      "Saved the embedding for happiness.\n",
      "happy is at index 1372\n",
      "Saved the embedding for happy.\n",
      "harassed is at index 16835\n",
      "Saved the embedding for harassed.\n",
      "hard is at index 543\n",
      "Saved the embedding for hard.\n",
      "hardened is at index 33631\n",
      "Saved the embedding for hardened.\n",
      "harmful is at index 11190\n",
      "Saved the embedding for harmful.\n",
      "harried is at index 12280\n",
      "Saved the embedding for harried.\n",
      "harsh is at index 9776\n",
      "Saved the embedding for harsh.\n",
      "hate is at index 4157\n",
      "Saved the embedding for hate.\n",
      "hateful is at index 26393\n",
      "Saved the embedding for hateful.\n",
      "hating is at index 40873\n",
      "Saved the embedding for hating.\n",
      "hatred is at index 13453\n",
      "Saved the embedding for hatred.\n",
      "haughty is at index 2489\n",
      "Saved the embedding for haughty.\n",
      "haunted is at index 22717\n",
      "Saved the embedding for haunted.\n",
      "hazy is at index 2489\n",
      "Saved the embedding for hazy.\n",
      "headshake is at index 471\n",
      "Saved the embedding for headshake.\n",
      "heartache is at index 1144\n",
      "Saved the embedding for heartache.\n",
      "heartbroken is at index 1144\n",
      "Saved the embedding for heartbroken.\n",
      "hearted is at index 1144\n",
      "Saved the embedding for hearted.\n",
      "heartsick is at index 7754\n",
      "Saved the embedding for heartsick.\n",
      "heated is at index 10819\n",
      "Saved the embedding for heated.\n",
      "heavyhearted is at index 2016\n",
      "Saved the embedding for heavyhearted.\n",
      "heckle is at index 17835\n",
      "Saved the embedding for heckle.\n",
      "heedful is at index 25432\n",
      "Saved the embedding for heedful.\n",
      "heinous is at index 30091\n",
      "Saved the embedding for heinous.\n",
      "helpful is at index 7163\n",
      "Saved the embedding for helpful.\n",
      "helpless is at index 22445\n",
      "Saved the embedding for helpless.\n",
      "hesitant is at index 24668\n",
      "Saved the embedding for hesitant.\n",
      "hesitantly is at index 36279\n",
      "Saved the embedding for hesitantly.\n",
      "hesitating is at index 36279\n",
      "Saved the embedding for hesitating.\n",
      "hesitation is at index 28946\n",
      "Saved the embedding for hesitation.\n",
      "high is at index 239\n",
      "Saved the embedding for high.\n",
      "hollering is at index 1368\n",
      "Saved the embedding for hollering.\n",
      "homicidal is at index 9486\n",
      "Saved the embedding for homicidal.\n",
      "honest is at index 5322\n",
      "Saved the embedding for honest.\n",
      "honorable is at index 28537\n",
      "Saved the embedding for honorable.\n",
      "hope is at index 1034\n",
      "Saved the embedding for hope.\n",
      "hopeful is at index 7917\n",
      "Saved the embedding for hopeful.\n",
      "hopefulness is at index 7917\n",
      "Saved the embedding for hopefulness.\n",
      "hopeless is at index 24418\n",
      "Saved the embedding for hopeless.\n",
      "hoping is at index 2818\n",
      "Saved the embedding for hoping.\n",
      "horny is at index 46216\n",
      "Saved the embedding for horny.\n",
      "horrible is at index 11385\n",
      "Saved the embedding for horrible.\n",
      "horrified is at index 27807\n",
      "Saved the embedding for horrified.\n",
      "horrify is at index 48067\n",
      "Saved the embedding for horrify.\n",
      "horrifying is at index 28242\n",
      "Saved the embedding for horrifying.\n",
      "horror is at index 8444\n",
      "Saved the embedding for horror.\n",
      "hostile is at index 11928\n",
      "Saved the embedding for hostile.\n",
      "hostility is at index 22069\n",
      "Saved the embedding for hostility.\n",
      "hot is at index 2131\n",
      "Saved the embedding for hot.\n",
      "hotshot is at index 2131\n",
      "Saved the embedding for hotshot.\n",
      "huffiness is at index 1368\n",
      "Saved the embedding for huffiness.\n",
      "huffy is at index 1368\n",
      "Saved the embedding for huffy.\n",
      "humble is at index 14083\n",
      "Saved the embedding for humble.\n",
      "humbled is at index 10080\n",
      "Saved the embedding for humbled.\n",
      "humdrum is at index 10080\n",
      "Saved the embedding for humdrum.\n",
      "humiliated is at index 32386\n",
      "Saved the embedding for humiliated.\n",
      "humility is at index 27352\n",
      "Saved the embedding for humility.\n",
      "humming is at index 35774\n",
      "Saved the embedding for humming.\n",
      "humor is at index 12073\n",
      "Saved the embedding for humor.\n",
      "humored is at index 10080\n",
      "Saved the embedding for humored.\n",
      "humorous is at index 31214\n",
      "Saved the embedding for humorous.\n",
      "hunger is at index 12226\n",
      "Saved the embedding for hunger.\n",
      "hungry is at index 11130\n",
      "Saved the embedding for hungry.\n",
      "hunted is at index 32602\n",
      "Saved the embedding for hunted.\n",
      "hurt is at index 2581\n",
      "Saved the embedding for hurt.\n",
      "hurtful is at index 2581\n",
      "Saved the embedding for hurtful.\n",
      "hurting is at index 12780\n",
      "Saved the embedding for hurting.\n",
      "hush is at index 1368\n",
      "Saved the embedding for hush.\n",
      "hushed is at index 33476\n",
      "Saved the embedding for hushed.\n",
      "hyper is at index 8944\n",
      "Saved the embedding for hyper.\n",
      "hyperactive is at index 8944\n",
      "Saved the embedding for hyperactive.\n",
      "hypnotized is at index 39040\n",
      "Saved the embedding for hypnotized.\n",
      "hypocritical is at index 37769\n",
      "Saved the embedding for hypocritical.\n",
      "hysteria is at index 35099\n",
      "Saved the embedding for hysteria.\n",
      "hysterical is at index 38561\n",
      "Saved the embedding for hysterical.\n",
      "idiotic is at index 13561\n",
      "Saved the embedding for idiotic.\n",
      "ignorant is at index 27726\n",
      "Saved the embedding for ignorant.\n",
      "ignoring is at index 15515\n",
      "Saved the embedding for ignoring.\n",
      "ill is at index 4812\n",
      "Saved the embedding for ill.\n",
      "imaginative is at index 35026\n",
      "Saved the embedding for imaginative.\n",
      "immature is at index 39001\n",
      "Saved the embedding for immature.\n",
      "immersed is at index 31971\n",
      "Saved the embedding for immersed.\n",
      "impacted is at index 7284\n",
      "Saved the embedding for impacted.\n",
      "impartial is at index 24283\n",
      "Saved the embedding for impartial.\n",
      "impassioned is at index 4023\n",
      "Saved the embedding for impassioned.\n",
      "impassive is at index 4023\n",
      "Saved the embedding for impassive.\n",
      "impatience is at index 43635\n",
      "Saved the embedding for impatience.\n",
      "impatient is at index 32601\n",
      "Saved the embedding for impatient.\n",
      "imperious is at index 21245\n",
      "Saved the embedding for imperious.\n",
      "impersonal is at index 23153\n",
      "Saved the embedding for impersonal.\n",
      "impertinent is at index 21245\n",
      "Saved the embedding for impertinent.\n",
      "impish is at index 4023\n",
      "Saved the embedding for impish.\n",
      "implicated is at index 23316\n",
      "Saved the embedding for implicated.\n",
      "imploring is at index 12956\n",
      "Saved the embedding for imploring.\n",
      "important is at index 505\n",
      "Saved the embedding for important.\n",
      "impressed is at index 6889\n",
      "Saved the embedding for impressed.\n",
      "impulsive is at index 4023\n",
      "Saved the embedding for impulsive.\n",
      "inactive is at index 25986\n",
      "Saved the embedding for inactive.\n",
      "inadequate is at index 15650\n",
      "Saved the embedding for inadequate.\n",
      "inarticulate is at index 11\n",
      "Saved the embedding for inarticulate.\n",
      "inattentive is at index 11\n",
      "Saved the embedding for inattentive.\n",
      "inaudible is at index 11\n",
      "Saved the embedding for inaudible.\n",
      "inauthentic is at index 11\n",
      "Saved the embedding for inauthentic.\n",
      "incapable is at index 30256\n",
      "Saved the embedding for incapable.\n",
      "incensed is at index 5853\n",
      "Saved the embedding for incensed.\n",
      "incertain is at index 5853\n",
      "Saved the embedding for incertain.\n",
      "incertitude is at index 5853\n",
      "Saved the embedding for incertitude.\n",
      "incited is at index 5853\n",
      "Saved the embedding for incited.\n",
      "incomprehensible is at index 42494\n",
      "Saved the embedding for incomprehensible.\n",
      "inconspicuous is at index 40817\n",
      "Saved the embedding for inconspicuous.\n",
      "incredulity is at index 38366\n",
      "Saved the embedding for incredulity.\n",
      "incredulous is at index 38366\n",
      "Saved the embedding for incredulous.\n",
      "incredulously is at index 38366\n",
      "Saved the embedding for incredulously.\n",
      "inculpate is at index 5853\n",
      "Saved the embedding for inculpate.\n",
      "incurious is at index 5853\n",
      "Saved the embedding for incurious.\n",
      "indecipherable is at index 32227\n",
      "Saved the embedding for indecipherable.\n",
      "indecision is at index 32227\n",
      "Saved the embedding for indecision.\n",
      "indecisive is at index 32227\n",
      "Saved the embedding for indecisive.\n",
      "indifferent is at index 34657\n",
      "Saved the embedding for indifferent.\n",
      "indifferently is at index 34657\n",
      "Saved the embedding for indifferently.\n",
      "indignant is at index 9473\n",
      "Saved the embedding for indignant.\n",
      "indolent is at index 9473\n",
      "Saved the embedding for indolent.\n",
      "inebriated is at index 11\n",
      "Saved the embedding for inebriated.\n",
      "inert is at index 43783\n",
      "Saved the embedding for inert.\n",
      "infatuating is at index 4047\n",
      "Saved the embedding for infatuating.\n",
      "inferior is at index 28510\n",
      "Saved the embedding for inferior.\n",
      "inferiority is at index 28510\n",
      "Saved the embedding for inferiority.\n",
      "inflamed is at index 11411\n",
      "Saved the embedding for inflamed.\n",
      "informal is at index 14110\n",
      "Saved the embedding for informal.\n",
      "informing is at index 21835\n",
      "Saved the embedding for informing.\n",
      "infuriated is at index 26974\n",
      "Saved the embedding for infuriated.\n",
      "inhibited is at index 45427\n",
      "Saved the embedding for inhibited.\n",
      "inhibiting is at index 38512\n",
      "Saved the embedding for inhibiting.\n",
      "inimical is at index 11\n",
      "Saved the embedding for inimical.\n",
      "injured is at index 1710\n",
      "Saved the embedding for injured.\n",
      "innocent is at index 7850\n",
      "Saved the embedding for innocent.\n",
      "inpatient is at index 11\n",
      "Saved the embedding for inpatient.\n",
      "inquiring is at index 27874\n",
      "Saved the embedding for inquiring.\n",
      "inquisitive is at index 27874\n",
      "Saved the embedding for inquisitive.\n",
      "insane is at index 18544\n",
      "Saved the embedding for insane.\n",
      "inscrutable is at index 7540\n",
      "Saved the embedding for inscrutable.\n",
      "insecure is at index 27810\n",
      "Saved the embedding for insecure.\n",
      "insecurity is at index 19401\n",
      "Saved the embedding for insecurity.\n",
      "insensitive is at index 29401\n",
      "Saved the embedding for insensitive.\n",
      "insidious is at index 40012\n",
      "Saved the embedding for insidious.\n",
      "insinuating is at index 32016\n",
      "Saved the embedding for insinuating.\n",
      "insistence is at index 24974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for insistence.\n",
      "insistent is at index 7540\n",
      "Saved the embedding for insistent.\n",
      "insisting is at index 13875\n",
      "Saved the embedding for insisting.\n",
      "insolent is at index 23799\n",
      "Saved the embedding for insolent.\n",
      "insouciance is at index 7540\n",
      "Saved the embedding for insouciance.\n",
      "insouciant is at index 7540\n",
      "Saved the embedding for insouciant.\n",
      "inspired is at index 4083\n",
      "Saved the embedding for inspired.\n",
      "inspiring is at index 11653\n",
      "Saved the embedding for inspiring.\n",
      "instigating is at index 9084\n",
      "Saved the embedding for instigating.\n",
      "instructing is at index 20587\n",
      "Saved the embedding for instructing.\n",
      "insubordinate is at index 7540\n",
      "Saved the embedding for insubordinate.\n",
      "insular is at index 7540\n",
      "Saved the embedding for insular.\n",
      "insulted is at index 32149\n",
      "Saved the embedding for insulted.\n",
      "insulting is at index 22602\n",
      "Saved the embedding for insulting.\n",
      "intelligence is at index 2316\n",
      "Saved the embedding for intelligence.\n",
      "intense is at index 5676\n",
      "Saved the embedding for intense.\n",
      "intensely is at index 29727\n",
      "Saved the embedding for intensely.\n",
      "intensity is at index 10603\n",
      "Saved the embedding for intensity.\n",
      "intensive is at index 12296\n",
      "Saved the embedding for intensive.\n",
      "intent is at index 5927\n",
      "Saved the embedding for intent.\n",
      "intentional is at index 18797\n",
      "Saved the embedding for intentional.\n",
      "interacting is at index 23140\n",
      "Saved the embedding for interacting.\n",
      "interest is at index 773\n",
      "Saved the embedding for interest.\n",
      "interested is at index 2509\n",
      "Saved the embedding for interested.\n",
      "interjecting is at index 3222\n",
      "Saved the embedding for interjecting.\n",
      "internalizing is at index 3425\n",
      "Saved the embedding for internalizing.\n",
      "interrogating is at index 28592\n",
      "Saved the embedding for interrogating.\n",
      "interrupting is at index 22749\n",
      "Saved the embedding for interrupting.\n",
      "intimidated is at index 25443\n",
      "Saved the embedding for intimidated.\n",
      "intimidating is at index 23292\n",
      "Saved the embedding for intimidating.\n",
      "intolerant is at index 39348\n",
      "Saved the embedding for intolerant.\n",
      "intoxicated is at index 20600\n",
      "Saved the embedding for intoxicated.\n",
      "intrigue is at index 30368\n",
      "Saved the embedding for intrigue.\n",
      "intrigued is at index 28622\n",
      "Saved the embedding for intrigued.\n",
      "intriguing is at index 14816\n",
      "Saved the embedding for intriguing.\n",
      "introspective is at index 22845\n",
      "Saved the embedding for introspective.\n",
      "invested is at index 5221\n",
      "Saved the embedding for invested.\n",
      "investigate is at index 4830\n",
      "Saved the embedding for investigate.\n",
      "investigative is at index 13222\n",
      "Saved the embedding for investigative.\n",
      "investigatory is at index 25463\n",
      "Saved the embedding for investigatory.\n",
      "invigorated is at index 12259\n",
      "Saved the embedding for invigorated.\n",
      "involved is at index 963\n",
      "Saved the embedding for involved.\n",
      "irascible is at index 10209\n",
      "Saved the embedding for irascible.\n",
      "irate is at index 10209\n",
      "Saved the embedding for irate.\n",
      "ire is at index 25509\n",
      "Saved the embedding for ire.\n",
      "ireful is at index 25509\n",
      "Saved the embedding for ireful.\n",
      "irked is at index 10209\n",
      "Saved the embedding for irked.\n",
      "ironic is at index 25553\n",
      "Saved the embedding for ironic.\n",
      "irony is at index 21490\n",
      "Saved the embedding for irony.\n",
      "irresolute is at index 10209\n",
      "Saved the embedding for irresolute.\n",
      "irritable is at index 26570\n",
      "Saved the embedding for irritable.\n",
      "irritably is at index 26570\n",
      "Saved the embedding for irritably.\n",
      "irritated is at index 35270\n",
      "Saved the embedding for irritated.\n",
      "irritation is at index 32776\n",
      "Saved the embedding for irritation.\n",
      "isolated is at index 8067\n",
      "Saved the embedding for isolated.\n",
      "jabbed is at index 27916\n",
      "Saved the embedding for jabbed.\n",
      "jaded is at index 1236\n",
      "Saved the embedding for jaded.\n",
      "jarred is at index 25413\n",
      "Saved the embedding for jarred.\n",
      "jarring is at index 35659\n",
      "Saved the embedding for jarring.\n",
      "jaunty is at index 1236\n",
      "Saved the embedding for jaunty.\n",
      "jawed is at index 15345\n",
      "Saved the embedding for jawed.\n",
      "jealous is at index 27064\n",
      "Saved the embedding for jealous.\n",
      "jeering is at index 4112\n",
      "Saved the embedding for jeering.\n",
      "jesting is at index 1236\n",
      "Saved the embedding for jesting.\n",
      "jilted is at index 1236\n",
      "Saved the embedding for jilted.\n",
      "jittery is at index 1236\n",
      "Saved the embedding for jittery.\n",
      "jocular is at index 1236\n",
      "Saved the embedding for jocular.\n",
      "joking is at index 22024\n",
      "Saved the embedding for joking.\n",
      "jolly is at index 1236\n",
      "Saved the embedding for jolly.\n",
      "jolted is at index 1236\n",
      "Saved the embedding for jolted.\n",
      "jovial is at index 1236\n",
      "Saved the embedding for jovial.\n",
      "joy is at index 5823\n",
      "Saved the embedding for joy.\n",
      "joyful is at index 32076\n",
      "Saved the embedding for joyful.\n",
      "joyfulness is at index 5823\n",
      "Saved the embedding for joyfulness.\n",
      "joyless is at index 5823\n",
      "Saved the embedding for joyless.\n",
      "joyous is at index 5823\n",
      "Saved the embedding for joyous.\n",
      "jubilant is at index 1236\n",
      "Saved the embedding for jubilant.\n",
      "jubilation is at index 1236\n",
      "Saved the embedding for jubilation.\n",
      "judgemental is at index 17219\n",
      "Saved the embedding for judgemental.\n",
      "judging is at index 17298\n",
      "Saved the embedding for judging.\n",
      "judgmental is at index 7579\n",
      "Saved the embedding for judgmental.\n",
      "judicious is at index 21392\n",
      "Saved the embedding for judicious.\n",
      "jumpy is at index 3704\n",
      "Saved the embedding for jumpy.\n",
      "justified is at index 14267\n",
      "Saved the embedding for justified.\n",
      "keen is at index 5609\n",
      "Saved the embedding for keen.\n",
      "kind is at index 761\n",
      "Saved the embedding for kind.\n",
      "kindhearted is at index 761\n",
      "Saved the embedding for kindhearted.\n",
      "kiss is at index 13301\n",
      "Saved the embedding for kiss.\n",
      "knowing is at index 4730\n",
      "Saved the embedding for knowing.\n",
      "knowledgable is at index 216\n",
      "Saved the embedding for knowledgable.\n",
      "knowledgeable is at index 26782\n",
      "Saved the embedding for knowledgeable.\n",
      "kosher is at index 36930\n",
      "Saved the embedding for kosher.\n",
      "lackadaisical is at index 1762\n",
      "Saved the embedding for lackadaisical.\n",
      "lackluster is at index 28369\n",
      "Saved the embedding for lackluster.\n",
      "laconic is at index 784\n",
      "Saved the embedding for laconic.\n",
      "lambaste is at index 17988\n",
      "Saved the embedding for lambaste.\n",
      "lamentable is at index 25532\n",
      "Saved the embedding for lamentable.\n",
      "lamenting is at index 25532\n",
      "Saved the embedding for lamenting.\n",
      "lascivious is at index 784\n",
      "Saved the embedding for lascivious.\n",
      "laugh is at index 7923\n",
      "Saved the embedding for laugh.\n",
      "laughing is at index 11339\n",
      "Saved the embedding for laughing.\n",
      "laughter is at index 16805\n",
      "Saved the embedding for laughter.\n",
      "lazy is at index 22414\n",
      "Saved the embedding for lazy.\n",
      "leaving is at index 1618\n",
      "Saved the embedding for leaving.\n",
      "lecherous is at index 2084\n",
      "Saved the embedding for lecherous.\n",
      "lecturing is at index 25673\n",
      "Saved the embedding for lecturing.\n",
      "leering is at index 2084\n",
      "Saved the embedding for leering.\n",
      "leery is at index 2084\n",
      "Saved the embedding for leery.\n",
      "letdown is at index 905\n",
      "Saved the embedding for letdown.\n",
      "lethargic is at index 35370\n",
      "Saved the embedding for lethargic.\n",
      "levelheaded is at index 672\n",
      "Saved the embedding for levelheaded.\n",
      "lewd is at index 31942\n",
      "Saved the embedding for lewd.\n",
      "libidinous is at index 21748\n",
      "Saved the embedding for libidinous.\n",
      "lifeless is at index 37019\n",
      "Saved the embedding for lifeless.\n",
      "lighthearted is at index 1109\n",
      "Saved the embedding for lighthearted.\n",
      "lipped is at index 784\n",
      "Saved the embedding for lipped.\n",
      "listening is at index 6288\n",
      "Saved the embedding for listening.\n",
      "listless is at index 889\n",
      "Saved the embedding for listless.\n",
      "lively is at index 20902\n",
      "Saved the embedding for lively.\n",
      "livid is at index 784\n",
      "Saved the embedding for livid.\n",
      "loaded is at index 7973\n",
      "Saved the embedding for loaded.\n",
      "loath is at index 4600\n",
      "Saved the embedding for loath.\n",
      "loathe is at index 4600\n",
      "Saved the embedding for loathe.\n",
      "loathing is at index 4600\n",
      "Saved the embedding for loathing.\n",
      "loathsome is at index 4600\n",
      "Saved the embedding for loathsome.\n",
      "locked is at index 5930\n",
      "Saved the embedding for locked.\n",
      "loneliness is at index 27942\n",
      "Saved the embedding for loneliness.\n",
      "lonely is at index 20100\n",
      "Saved the embedding for lonely.\n",
      "longing is at index 36171\n",
      "Saved the embedding for longing.\n",
      "looking is at index 546\n",
      "Saved the embedding for looking.\n",
      "loony is at index 4600\n",
      "Saved the embedding for loony.\n",
      "loss is at index 872\n",
      "Saved the embedding for loss.\n",
      "lost is at index 685\n",
      "Saved the embedding for lost.\n",
      "loud is at index 7337\n",
      "Saved the embedding for loud.\n",
      "lousy is at index 38909\n",
      "Saved the embedding for lousy.\n",
      "love is at index 657\n",
      "Saved the embedding for love.\n",
      "loving is at index 8520\n",
      "Saved the embedding for loving.\n",
      "lowliness is at index 614\n",
      "Saved the embedding for lowliness.\n",
      "lurid is at index 30461\n",
      "Saved the embedding for lurid.\n",
      "lustful is at index 30864\n",
      "Saved the embedding for lustful.\n",
      "lusting is at index 30864\n",
      "Saved the embedding for lusting.\n",
      "lusty is at index 30864\n",
      "Saved the embedding for lusty.\n",
      "lying is at index 6480\n",
      "Saved the embedding for lying.\n",
      "mad is at index 7758\n",
      "Saved the embedding for mad.\n",
      "maddened is at index 475\n",
      "Saved the embedding for maddened.\n",
      "madness is at index 24714\n",
      "Saved the embedding for madness.\n",
      "malcontent is at index 8196\n",
      "Saved the embedding for malcontent.\n",
      "maleficent is at index 8196\n",
      "Saved the embedding for maleficent.\n",
      "malevolent is at index 2943\n",
      "Saved the embedding for malevolent.\n",
      "malice is at index 39625\n",
      "Saved the embedding for malice.\n",
      "malicious is at index 15237\n",
      "Saved the embedding for malicious.\n",
      "malignant is at index 8196\n",
      "Saved the embedding for malignant.\n",
      "maniacal is at index 41288\n",
      "Saved the embedding for maniacal.\n",
      "manipulative is at index 39802\n",
      "Saved the embedding for manipulative.\n",
      "marveled is at index 25591\n",
      "Saved the embedding for marveled.\n",
      "master is at index 4710\n",
      "Saved the embedding for master.\n",
      "mean is at index 1266\n",
      "Saved the embedding for mean.\n",
      "meaningful is at index 6667\n",
      "Saved the embedding for meaningful.\n",
      "meditative is at index 5679\n",
      "Saved the embedding for meditative.\n",
      "meek is at index 162\n",
      "Saved the embedding for meek.\n",
      "melancholic is at index 45565\n",
      "Saved the embedding for melancholic.\n",
      "melancholy is at index 40602\n",
      "Saved the embedding for melancholy.\n",
      "mellow is at index 34384\n",
      "Saved the embedding for mellow.\n",
      "menace is at index 24213\n",
      "Saved the embedding for menace.\n",
      "menacing is at index 32002\n",
      "Saved the embedding for menacing.\n",
      "mental is at index 2536\n",
      "Saved the embedding for mental.\n",
      "merrily is at index 9374\n",
      "Saved the embedding for merrily.\n",
      "merry is at index 35814\n",
      "Saved the embedding for merry.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mesmerized is at index 31294\n",
      "Saved the embedding for mesmerized.\n",
      "miffed is at index 475\n",
      "Saved the embedding for miffed.\n",
      "mild is at index 10439\n",
      "Saved the embedding for mild.\n",
      "mincing is at index 5251\n",
      "Saved the embedding for mincing.\n",
      "mindful is at index 20807\n",
      "Saved the embedding for mindful.\n",
      "mindless is at index 41406\n",
      "Saved the embedding for mindless.\n",
      "mirrored is at index 31349\n",
      "Saved the embedding for mirrored.\n",
      "mirth is at index 475\n",
      "Saved the embedding for mirth.\n",
      "mirthful is at index 475\n",
      "Saved the embedding for mirthful.\n",
      "misanthropic is at index 3834\n",
      "Saved the embedding for misanthropic.\n",
      "mischief is at index 26245\n",
      "Saved the embedding for mischief.\n",
      "mischievous is at index 3834\n",
      "Saved the embedding for mischievous.\n",
      "mischievousness is at index 3834\n",
      "Saved the embedding for mischievousness.\n",
      "miserable is at index 20161\n",
      "Saved the embedding for miserable.\n",
      "misery is at index 23110\n",
      "Saved the embedding for misery.\n",
      "misgiving is at index 3834\n",
      "Saved the embedding for misgiving.\n",
      "mislead is at index 34747\n",
      "Saved the embedding for mislead.\n",
      "mistrust is at index 34873\n",
      "Saved the embedding for mistrust.\n",
      "mistrustful is at index 34873\n",
      "Saved the embedding for mistrustful.\n",
      "mistrusting is at index 34873\n",
      "Saved the embedding for mistrusting.\n",
      "misunderstood is at index 32085\n",
      "Saved the embedding for misunderstood.\n",
      "mockery is at index 34641\n",
      "Saved the embedding for mockery.\n",
      "mocking is at index 27813\n",
      "Saved the embedding for mocking.\n",
      "mockingly is at index 16177\n",
      "Saved the embedding for mockingly.\n",
      "modest is at index 6473\n",
      "Saved the embedding for modest.\n",
      "monotone is at index 6154\n",
      "Saved the embedding for monotone.\n",
      "monster is at index 13317\n",
      "Saved the embedding for monster.\n",
      "moody is at index 6711\n",
      "Saved the embedding for moody.\n",
      "mopey is at index 475\n",
      "Saved the embedding for mopey.\n",
      "morose is at index 14628\n",
      "Saved the embedding for morose.\n",
      "mortified is at index 18631\n",
      "Saved the embedding for mortified.\n",
      "motivated is at index 7958\n",
      "Saved the embedding for motivated.\n",
      "mournful is at index 15213\n",
      "Saved the embedding for mournful.\n",
      "mournfulness is at index 15213\n",
      "Saved the embedding for mournfulness.\n",
      "mourning is at index 19293\n",
      "Saved the embedding for mourning.\n",
      "mouthed is at index 475\n",
      "Saved the embedding for mouthed.\n",
      "moved is at index 1410\n",
      "Saved the embedding for moved.\n",
      "muddled is at index 475\n",
      "Saved the embedding for muddled.\n",
      "mum is at index 8562\n",
      "Saved the embedding for mum.\n",
      "murderous is at index 32883\n",
      "Saved the embedding for murderous.\n",
      "musical is at index 4388\n",
      "Saved the embedding for musical.\n",
      "musing is at index 11721\n",
      "Saved the embedding for musing.\n",
      "muster is at index 27665\n",
      "Saved the embedding for muster.\n",
      "mute is at index 33758\n",
      "Saved the embedding for mute.\n",
      "muted is at index 21677\n",
      "Saved the embedding for muted.\n",
      "muttering is at index 16119\n",
      "Saved the embedding for muttering.\n",
      "mysterious is at index 12754\n",
      "Saved the embedding for mysterious.\n",
      "mystical is at index 39795\n",
      "Saved the embedding for mystical.\n",
      "mystified is at index 37763\n",
      "Saved the embedding for mystified.\n",
      "naive is at index 25672\n",
      "Saved the embedding for naive.\n",
      "napping is at index 295\n",
      "Saved the embedding for napping.\n",
      "narrow is at index 6787\n",
      "Saved the embedding for narrow.\n",
      "nasty is at index 15455\n",
      "Saved the embedding for nasty.\n",
      "natural is at index 1632\n",
      "Saved the embedding for natural.\n",
      "natured is at index 23577\n",
      "Saved the embedding for natured.\n",
      "naughty is at index 38384\n",
      "Saved the embedding for naughty.\n",
      "nausea is at index 27214\n",
      "Saved the embedding for nausea.\n",
      "nauseated is at index 39117\n",
      "Saved the embedding for nauseated.\n",
      "nauseous is at index 39117\n",
      "Saved the embedding for nauseous.\n",
      "needy is at index 28166\n",
      "Saved the embedding for needy.\n",
      "nefarious is at index 33952\n",
      "Saved the embedding for nefarious.\n",
      "negating is at index 15183\n",
      "Saved the embedding for negating.\n",
      "negative is at index 2430\n",
      "Saved the embedding for negative.\n",
      "negativity is at index 30269\n",
      "Saved the embedding for negativity.\n",
      "neglected is at index 20428\n",
      "Saved the embedding for neglected.\n",
      "nerdy is at index 38286\n",
      "Saved the embedding for nerdy.\n",
      "nerved is at index 295\n",
      "Saved the embedding for nerved.\n",
      "nerves is at index 17358\n",
      "Saved the embedding for nerves.\n",
      "nervous is at index 7464\n",
      "Saved the embedding for nervous.\n",
      "nervously is at index 40968\n",
      "Saved the embedding for nervously.\n",
      "nervousness is at index 7464\n",
      "Saved the embedding for nervousness.\n",
      "nescient is at index 295\n",
      "Saved the embedding for nescient.\n",
      "nettled is at index 1161\n",
      "Saved the embedding for nettled.\n",
      "neutral is at index 7974\n",
      "Saved the embedding for neutral.\n",
      "neutrality is at index 18755\n",
      "Saved the embedding for neutrality.\n",
      "nice is at index 2579\n",
      "Saved the embedding for nice.\n",
      "noisy is at index 28269\n",
      "Saved the embedding for noisy.\n",
      "nonbelief is at index 786\n",
      "Saved the embedding for nonbelief.\n",
      "nonchalance is at index 786\n",
      "Saved the embedding for nonchalance.\n",
      "nonchalant is at index 786\n",
      "Saved the embedding for nonchalant.\n",
      "noncommittal is at index 786\n",
      "Saved the embedding for noncommittal.\n",
      "noncompliant is at index 786\n",
      "Saved the embedding for noncompliant.\n",
      "nonplussed is at index 786\n",
      "Saved the embedding for nonplussed.\n",
      "nonsensical is at index 42475\n",
      "Saved the embedding for nonsensical.\n",
      "normal is at index 2340\n",
      "Saved the embedding for normal.\n",
      "nosey is at index 8658\n",
      "Saved the embedding for nosey.\n",
      "nostalgic is at index 28055\n",
      "Saved the embedding for nostalgic.\n",
      "nosy is at index 13736\n",
      "Saved the embedding for nosy.\n",
      "numb is at index 31086\n",
      "Saved the embedding for numb.\n",
      "obedient is at index 44729\n",
      "Saved the embedding for obedient.\n",
      "objecting is at index 7626\n",
      "Saved the embedding for objecting.\n",
      "objection is at index 24763\n",
      "Saved the embedding for objection.\n",
      "objective is at index 4554\n",
      "Saved the embedding for objective.\n",
      "obliged is at index 23964\n",
      "Saved the embedding for obliged.\n",
      "obliging is at index 23762\n",
      "Saved the embedding for obliging.\n",
      "oblivious is at index 35606\n",
      "Saved the embedding for oblivious.\n",
      "observant is at index 20717\n",
      "Saved the embedding for observant.\n",
      "observing is at index 21981\n",
      "Saved the embedding for observing.\n",
      "obsessed is at index 17593\n",
      "Saved the embedding for obsessed.\n",
      "obstinate is at index 30896\n",
      "Saved the embedding for obstinate.\n",
      "occupied is at index 9533\n",
      "Saved the embedding for occupied.\n",
      "odd is at index 8372\n",
      "Saved the embedding for odd.\n",
      "odious is at index 7452\n",
      "Saved the embedding for odious.\n",
      "off is at index 160\n",
      "Saved the embedding for off.\n",
      "offended is at index 22169\n",
      "Saved the embedding for offended.\n",
      "offensive is at index 2555\n",
      "Saved the embedding for offensive.\n",
      "ogling is at index 1021\n",
      "Saved the embedding for ogling.\n",
      "okay is at index 8578\n",
      "Saved the embedding for okay.\n",
      "on is at index 15\n",
      "Saved the embedding for on.\n",
      "open is at index 490\n",
      "Saved the embedding for open.\n",
      "openness is at index 23163\n",
      "Saved the embedding for openness.\n",
      "opposed is at index 4340\n",
      "Saved the embedding for opposed.\n",
      "oppositional is at index 39734\n",
      "Saved the embedding for oppositional.\n",
      "oppressed is at index 32881\n",
      "Saved the embedding for oppressed.\n",
      "optimism is at index 9743\n",
      "Saved the embedding for optimism.\n",
      "optimistic is at index 7168\n",
      "Saved the embedding for optimistic.\n",
      "ordering is at index 12926\n",
      "Saved the embedding for ordering.\n",
      "orgasmic is at index 39396\n",
      "Saved the embedding for orgasmic.\n",
      "ornery is at index 50\n",
      "Saved the embedding for ornery.\n",
      "ouch is at index 1021\n",
      "Saved the embedding for ouch.\n",
      "out is at index 66\n",
      "Saved the embedding for out.\n",
      "outburst is at index 28999\n",
      "Saved the embedding for outburst.\n",
      "outcry is at index 19900\n",
      "Saved the embedding for outcry.\n",
      "outed is at index 66\n",
      "Saved the embedding for outed.\n",
      "outlandish is at index 35785\n",
      "Saved the embedding for outlandish.\n",
      "outrage is at index 10618\n",
      "Saved the embedding for outrage.\n",
      "outraged is at index 22339\n",
      "Saved the embedding for outraged.\n",
      "outspoken is at index 16120\n",
      "Saved the embedding for outspoken.\n",
      "overbearing is at index 81\n",
      "Saved the embedding for overbearing.\n",
      "overexcited is at index 39919\n",
      "Saved the embedding for overexcited.\n",
      "overjoyed is at index 81\n",
      "Saved the embedding for overjoyed.\n",
      "overshadowed is at index 22140\n",
      "Saved the embedding for overshadowed.\n",
      "overstrung is at index 81\n",
      "Saved the embedding for overstrung.\n",
      "overwhelmed is at index 13203\n",
      "Saved the embedding for overwhelmed.\n",
      "overworked is at index 81\n",
      "Saved the embedding for overworked.\n",
      "overwrought is at index 42674\n",
      "Saved the embedding for overwrought.\n",
      "pain is at index 2400\n",
      "Saved the embedding for pain.\n",
      "pained is at index 181\n",
      "Saved the embedding for pained.\n",
      "painful is at index 8661\n",
      "Saved the embedding for painful.\n",
      "painfully is at index 32020\n",
      "Saved the embedding for painfully.\n",
      "panic is at index 9810\n",
      "Saved the embedding for panic.\n",
      "panicked is at index 28604\n",
      "Saved the embedding for panicked.\n",
      "panicky is at index 5730\n",
      "Saved the embedding for panicky.\n",
      "paralyzed is at index 28582\n",
      "Saved the embedding for paralyzed.\n",
      "paranoid is at index 33554\n",
      "Saved the embedding for paranoid.\n",
      "passionate is at index 8840\n",
      "Saved the embedding for passionate.\n",
      "passive is at index 18718\n",
      "Saved the embedding for passive.\n",
      "patience is at index 11383\n",
      "Saved the embedding for patience.\n",
      "patient is at index 3186\n",
      "Saved the embedding for patient.\n",
      "patronizing is at index 18528\n",
      "Saved the embedding for patronizing.\n",
      "pause is at index 13787\n",
      "Saved the embedding for pause.\n",
      "pausing is at index 6044\n",
      "Saved the embedding for pausing.\n",
      "peaceful is at index 7053\n",
      "Saved the embedding for peaceful.\n",
      "peculiar is at index 28178\n",
      "Saved the embedding for peculiar.\n",
      "peering is at index 3723\n",
      "Saved the embedding for peering.\n",
      "peeved is at index 32734\n",
      "Saved the embedding for peeved.\n",
      "peevish is at index 3723\n",
      "Saved the embedding for peevish.\n",
      "pensive is at index 181\n",
      "Saved the embedding for pensive.\n",
      "peppy is at index 3723\n",
      "Saved the embedding for peppy.\n",
      "perceptive is at index 228\n",
      "Saved the embedding for perceptive.\n",
      "perfidious is at index 32168\n",
      "Saved the embedding for perfidious.\n",
      "perky is at index 228\n",
      "Saved the embedding for perky.\n",
      "perplexed is at index 33708\n",
      "Saved the embedding for perplexed.\n",
      "perplexing is at index 33708\n",
      "Saved the embedding for perplexing.\n",
      "persistent is at index 13109\n",
      "Saved the embedding for persistent.\n",
      "personable is at index 621\n",
      "Saved the embedding for personable.\n",
      "perturbed is at index 32819\n",
      "Saved the embedding for perturbed.\n",
      "perverse is at index 41271\n",
      "Saved the embedding for perverse.\n",
      "pesky is at index 38432\n",
      "Saved the embedding for pesky.\n",
      "pessimism is at index 36494\n",
      "Saved the embedding for pessimism.\n",
      "pessimistic is at index 32415\n",
      "Saved the embedding for pessimistic.\n",
      "pestered is at index 19024\n",
      "Saved the embedding for pestered.\n",
      "petitioning is at index 5265\n",
      "Saved the embedding for petitioning.\n",
      "petrified is at index 4716\n",
      "Saved the embedding for petrified.\n",
      "petty is at index 25070\n",
      "Saved the embedding for petty.\n",
      "petulant is at index 4716\n",
      "Saved the embedding for petulant.\n",
      "picked is at index 2738\n",
      "Saved the embedding for picked.\n",
      "piercing is at index 38105\n",
      "Saved the embedding for piercing.\n",
      "pinched is at index 7756\n",
      "Saved the embedding for pinched.\n",
      "pious is at index 44843\n",
      "Saved the embedding for pious.\n",
      "piqued is at index 181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for piqued.\n",
      "pissed is at index 34449\n",
      "Saved the embedding for pissed.\n",
      "pitiable is at index 8516\n",
      "Saved the embedding for pitiable.\n",
      "pitiful is at index 8516\n",
      "Saved the embedding for pitiful.\n",
      "pity is at index 31373\n",
      "Saved the embedding for pity.\n",
      "pitying is at index 31373\n",
      "Saved the embedding for pitying.\n",
      "placated is at index 15155\n",
      "Saved the embedding for placated.\n",
      "placation is at index 15155\n",
      "Saved the embedding for placation.\n",
      "placid is at index 15155\n",
      "Saved the embedding for placid.\n",
      "plain is at index 10798\n",
      "Saved the embedding for plain.\n",
      "plaintive is at index 46560\n",
      "Saved the embedding for plaintive.\n",
      "planning is at index 1884\n",
      "Saved the embedding for planning.\n",
      "playful is at index 23317\n",
      "Saved the embedding for playful.\n",
      "playfully is at index 310\n",
      "Saved the embedding for playfully.\n",
      "pleading is at index 17532\n",
      "Saved the embedding for pleading.\n",
      "pleasant is at index 16219\n",
      "Saved the embedding for pleasant.\n",
      "pleased is at index 4343\n",
      "Saved the embedding for pleased.\n",
      "pleasing is at index 25234\n",
      "Saved the embedding for pleasing.\n",
      "pleasurable is at index 19518\n",
      "Saved the embedding for pleasurable.\n",
      "pleasure is at index 10483\n",
      "Saved the embedding for pleasure.\n",
      "pleasured is at index 19518\n",
      "Saved the embedding for pleasured.\n",
      "pliant is at index 2968\n",
      "Saved the embedding for pliant.\n",
      "plotting is at index 22849\n",
      "Saved the embedding for plotting.\n",
      "poignant is at index 27274\n",
      "Saved the embedding for poignant.\n",
      "pointed is at index 3273\n",
      "Saved the embedding for pointed.\n",
      "poised is at index 10137\n",
      "Saved the embedding for poised.\n",
      "polite is at index 24908\n",
      "Saved the embedding for polite.\n",
      "pompous is at index 34415\n",
      "Saved the embedding for pompous.\n",
      "ponder is at index 31930\n",
      "Saved the embedding for ponder.\n",
      "pondering is at index 13362\n",
      "Saved the embedding for pondering.\n",
      "pooping is at index 4202\n",
      "Saved the embedding for pooping.\n",
      "pop is at index 3495\n",
      "Saved the embedding for pop.\n",
      "posing is at index 12681\n",
      "Saved the embedding for posing.\n",
      "positive is at index 1313\n",
      "Saved the embedding for positive.\n",
      "positivity is at index 8593\n",
      "Saved the embedding for positivity.\n",
      "possibly is at index 3544\n",
      "Saved the embedding for possibly.\n",
      "pout is at index 181\n",
      "Saved the embedding for pout.\n",
      "pouting is at index 181\n",
      "Saved the embedding for pouting.\n",
      "pouty is at index 181\n",
      "Saved the embedding for pouty.\n",
      "powerful is at index 2247\n",
      "Saved the embedding for powerful.\n",
      "powerless is at index 33128\n",
      "Saved the embedding for powerless.\n",
      "pranking is at index 3349\n",
      "Saved the embedding for pranking.\n",
      "precarious is at index 27180\n",
      "Saved the embedding for precarious.\n",
      "predatory is at index 29216\n",
      "Saved the embedding for predatory.\n",
      "prejudiced is at index 34286\n",
      "Saved the embedding for prejudiced.\n",
      "preoccupied is at index 1198\n",
      "Saved the embedding for preoccupied.\n",
      "prepared is at index 2460\n",
      "Saved the embedding for prepared.\n",
      "preparing is at index 4568\n",
      "Saved the embedding for preparing.\n",
      "pretending is at index 23748\n",
      "Saved the embedding for pretending.\n",
      "pretentious is at index 11857\n",
      "Saved the embedding for pretentious.\n",
      "prideful is at index 7040\n",
      "Saved the embedding for prideful.\n",
      "priggish is at index 3349\n",
      "Saved the embedding for priggish.\n",
      "primed is at index 32575\n",
      "Saved the embedding for primed.\n",
      "private is at index 940\n",
      "Saved the embedding for private.\n",
      "processing is at index 5774\n",
      "Saved the embedding for processing.\n",
      "propositioning is at index 16104\n",
      "Saved the embedding for propositioning.\n",
      "proud is at index 2602\n",
      "Saved the embedding for proud.\n",
      "provocative is at index 21051\n",
      "Saved the embedding for provocative.\n",
      "provoke is at index 28184\n",
      "Saved the embedding for provoke.\n",
      "provoked is at index 24972\n",
      "Saved the embedding for provoked.\n",
      "provoking is at index 35359\n",
      "Saved the embedding for provoking.\n",
      "prying is at index 181\n",
      "Saved the embedding for prying.\n",
      "psycho is at index 37338\n",
      "Saved the embedding for psycho.\n",
      "psychotic is at index 41559\n",
      "Saved the embedding for psychotic.\n",
      "puckish is at index 9258\n",
      "Saved the embedding for puckish.\n",
      "puerile is at index 181\n",
      "Saved the embedding for puerile.\n",
      "pugnacious is at index 181\n",
      "Saved the embedding for pugnacious.\n",
      "punished is at index 14459\n",
      "Saved the embedding for punished.\n",
      "punishing is at index 23477\n",
      "Saved the embedding for punishing.\n",
      "punitive is at index 21987\n",
      "Saved the embedding for punitive.\n",
      "punk is at index 19742\n",
      "Saved the embedding for punk.\n",
      "puppyish is at index 20830\n",
      "Saved the embedding for puppyish.\n",
      "purposeful is at index 3508\n",
      "Saved the embedding for purposeful.\n",
      "pursed is at index 26934\n",
      "Saved the embedding for pursed.\n",
      "put is at index 342\n",
      "Saved the embedding for put.\n",
      "putting is at index 2057\n",
      "Saved the embedding for putting.\n",
      "puzzled is at index 36742\n",
      "Saved the embedding for puzzled.\n",
      "puzzlement is at index 47037\n",
      "Saved the embedding for puzzlement.\n",
      "qualms is at index 22043\n",
      "Saved the embedding for qualms.\n",
      "quarrelsome is at index 39486\n",
      "Saved the embedding for quarrelsome.\n",
      "queasy is at index 1192\n",
      "Saved the embedding for queasy.\n",
      "quenched is at index 2677\n",
      "Saved the embedding for quenched.\n",
      "questionable is at index 12474\n",
      "Saved the embedding for questionable.\n",
      "questioning is at index 8026\n",
      "Saved the embedding for questioning.\n",
      "questioningly is at index 864\n",
      "Saved the embedding for questioningly.\n",
      "quiet is at index 5128\n",
      "Saved the embedding for quiet.\n",
      "quietness is at index 5128\n",
      "Saved the embedding for quietness.\n",
      "quilt is at index 2677\n",
      "Saved the embedding for quilt.\n",
      "quirky is at index 22364\n",
      "Saved the embedding for quirky.\n",
      "quizzical is at index 29316\n",
      "Saved the embedding for quizzical.\n",
      "rabid is at index 39660\n",
      "Saved the embedding for rabid.\n",
      "racked is at index 20208\n",
      "Saved the embedding for racked.\n",
      "radiant is at index 35787\n",
      "Saved the embedding for radiant.\n",
      "rage is at index 14706\n",
      "Saved the embedding for rage.\n",
      "raged is at index 31927\n",
      "Saved the embedding for raged.\n",
      "ragged is at index 910\n",
      "Saved the embedding for ragged.\n",
      "raging is at index 23333\n",
      "Saved the embedding for raging.\n",
      "rancorous is at index 21560\n",
      "Saved the embedding for rancorous.\n",
      "randy is at index 910\n",
      "Saved the embedding for randy.\n",
      "rapt is at index 34524\n",
      "Saved the embedding for rapt.\n",
      "rattled is at index 21602\n",
      "Saved the embedding for rattled.\n",
      "raving is at index 910\n",
      "Saved the embedding for raving.\n",
      "reactive is at index 34729\n",
      "Saved the embedding for reactive.\n",
      "ready is at index 1227\n",
      "Saved the embedding for ready.\n",
      "realization is at index 24179\n",
      "Saved the embedding for realization.\n",
      "reassured is at index 29336\n",
      "Saved the embedding for reassured.\n",
      "rebellious is at index 38017\n",
      "Saved the embedding for rebellious.\n",
      "rebuke is at index 28155\n",
      "Saved the embedding for rebuke.\n",
      "recalling is at index 20239\n",
      "Saved the embedding for recalling.\n",
      "receptive is at index 33052\n",
      "Saved the embedding for receptive.\n",
      "reckless is at index 13508\n",
      "Saved the embedding for reckless.\n",
      "recoil is at index 44983\n",
      "Saved the embedding for recoil.\n",
      "recoiling is at index 3872\n",
      "Saved the embedding for recoiling.\n",
      "reflecting is at index 10811\n",
      "Saved the embedding for reflecting.\n",
      "reflection is at index 12456\n",
      "Saved the embedding for reflection.\n",
      "reflective is at index 22213\n",
      "Saved the embedding for reflective.\n",
      "refulgent is at index 769\n",
      "Saved the embedding for refulgent.\n",
      "refusing is at index 10520\n",
      "Saved the embedding for refusing.\n",
      "regret is at index 9917\n",
      "Saved the embedding for regret.\n",
      "regretful is at index 9917\n",
      "Saved the embedding for regretful.\n",
      "rejected is at index 3946\n",
      "Saved the embedding for rejected.\n",
      "rejecting is at index 19695\n",
      "Saved the embedding for rejecting.\n",
      "rejection is at index 16117\n",
      "Saved the embedding for rejection.\n",
      "rejoicing is at index 24586\n",
      "Saved the embedding for rejoicing.\n",
      "relaxation is at index 26545\n",
      "Saved the embedding for relaxation.\n",
      "relaxed is at index 11956\n",
      "Saved the embedding for relaxed.\n",
      "relentless is at index 16476\n",
      "Saved the embedding for relentless.\n",
      "relief is at index 3500\n",
      "Saved the embedding for relief.\n",
      "relieved is at index 15126\n",
      "Saved the embedding for relieved.\n",
      "relived is at index 6258\n",
      "Saved the embedding for relived.\n",
      "reluctant is at index 11923\n",
      "Saved the embedding for reluctant.\n",
      "reluctantly is at index 33146\n",
      "Saved the embedding for reluctantly.\n",
      "remorse is at index 23312\n",
      "Saved the embedding for remorse.\n",
      "remorseful is at index 23312\n",
      "Saved the embedding for remorseful.\n",
      "repelled is at index 25633\n",
      "Saved the embedding for repelled.\n",
      "repressed is at index 2851\n",
      "Saved the embedding for repressed.\n",
      "reproach is at index 2851\n",
      "Saved the embedding for reproach.\n",
      "reproachful is at index 2851\n",
      "Saved the embedding for reproachful.\n",
      "repugnance is at index 2851\n",
      "Saved the embedding for repugnance.\n",
      "repugnant is at index 2851\n",
      "Saved the embedding for repugnant.\n",
      "repulsed is at index 2851\n",
      "Saved the embedding for repulsed.\n",
      "repulsion is at index 2851\n",
      "Saved the embedding for repulsion.\n",
      "resent is at index 31379\n",
      "Saved the embedding for resent.\n",
      "resentful is at index 31379\n",
      "Saved the embedding for resentful.\n",
      "resenting is at index 31379\n",
      "Saved the embedding for resenting.\n",
      "resentment is at index 27111\n",
      "Saved the embedding for resentment.\n",
      "reserved is at index 1875\n",
      "Saved the embedding for reserved.\n",
      "resignation is at index 6985\n",
      "Saved the embedding for resignation.\n",
      "resigned is at index 6490\n",
      "Saved the embedding for resigned.\n",
      "resilience is at index 13790\n",
      "Saved the embedding for resilience.\n",
      "resistance is at index 5910\n",
      "Saved the embedding for resistance.\n",
      "resistant is at index 19152\n",
      "Saved the embedding for resistant.\n",
      "resistent is at index 11942\n",
      "Saved the embedding for resistent.\n",
      "resisting is at index 18907\n",
      "Saved the embedding for resisting.\n",
      "resolute is at index 5032\n",
      "Saved the embedding for resolute.\n",
      "resolved is at index 8179\n",
      "Saved the embedding for resolved.\n",
      "responsive is at index 20666\n",
      "Saved the embedding for responsive.\n",
      "restful is at index 1079\n",
      "Saved the embedding for restful.\n",
      "resting is at index 18403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for resting.\n",
      "restless is at index 36844\n",
      "Saved the embedding for restless.\n",
      "restlessness is at index 1079\n",
      "Saved the embedding for restlessness.\n",
      "restrained is at index 25063\n",
      "Saved the embedding for restrained.\n",
      "restraint is at index 20219\n",
      "Saved the embedding for restraint.\n",
      "retaliating is at index 18570\n",
      "Saved the embedding for retaliating.\n",
      "retaliatory is at index 18570\n",
      "Saved the embedding for retaliatory.\n",
      "rethinking is at index 769\n",
      "Saved the embedding for rethinking.\n",
      "reticence is at index 5494\n",
      "Saved the embedding for reticence.\n",
      "reticent is at index 5494\n",
      "Saved the embedding for reticent.\n",
      "revengeful is at index 13543\n",
      "Saved the embedding for revengeful.\n",
      "reverent is at index 26911\n",
      "Saved the embedding for reverent.\n",
      "revolted is at index 34633\n",
      "Saved the embedding for revolted.\n",
      "revulsion is at index 6910\n",
      "Saved the embedding for revulsion.\n",
      "righteous is at index 37909\n",
      "Saved the embedding for righteous.\n",
      "rigid is at index 24577\n",
      "Saved the embedding for rigid.\n",
      "riled is at index 910\n",
      "Saved the embedding for riled.\n",
      "riotous is at index 13069\n",
      "Saved the embedding for riotous.\n",
      "riveted is at index 32886\n",
      "Saved the embedding for riveted.\n",
      "roar is at index 31733\n",
      "Saved the embedding for roar.\n",
      "roguish is at index 4533\n",
      "Saved the embedding for roguish.\n",
      "roiled is at index 4533\n",
      "Saved the embedding for roiled.\n",
      "rough is at index 6744\n",
      "Saved the embedding for rough.\n",
      "roused is at index 910\n",
      "Saved the embedding for roused.\n",
      "rude is at index 21820\n",
      "Saved the embedding for rude.\n",
      "rueful is at index 910\n",
      "Saved the embedding for rueful.\n",
      "ruffled is at index 910\n",
      "Saved the embedding for ruffled.\n",
      "ruminating is at index 11122\n",
      "Saved the embedding for ruminating.\n",
      "rustled is at index 18309\n",
      "Saved the embedding for rustled.\n",
      "ruthless is at index 25597\n",
      "Saved the embedding for ruthless.\n",
      "sad is at index 5074\n",
      "Saved the embedding for sad.\n",
      "sadden is at index 23330\n",
      "Saved the embedding for sadden.\n",
      "saddened is at index 19934\n",
      "Saved the embedding for saddened.\n",
      "sadistic is at index 5074\n",
      "Saved the embedding for sadistic.\n",
      "sadness is at index 17437\n",
      "Saved the embedding for sadness.\n",
      "salacious is at index 6641\n",
      "Saved the embedding for salacious.\n",
      "salivating is at index 6641\n",
      "Saved the embedding for salivating.\n",
      "sanctimonious is at index 27600\n",
      "Saved the embedding for sanctimonious.\n",
      "sane is at index 37091\n",
      "Saved the embedding for sane.\n",
      "sanguine is at index 579\n",
      "Saved the embedding for sanguine.\n",
      "sappy is at index 2241\n",
      "Saved the embedding for sappy.\n",
      "sarcasm is at index 38522\n",
      "Saved the embedding for sarcasm.\n",
      "sarcastic is at index 39580\n",
      "Saved the embedding for sarcastic.\n",
      "sardonic is at index 579\n",
      "Saved the embedding for sardonic.\n",
      "sassy is at index 579\n",
      "Saved the embedding for sassy.\n",
      "sated is at index 579\n",
      "Saved the embedding for sated.\n",
      "satiated is at index 4005\n",
      "Saved the embedding for satiated.\n",
      "satirical is at index 33937\n",
      "Saved the embedding for satirical.\n",
      "satisfaction is at index 11658\n",
      "Saved the embedding for satisfaction.\n",
      "satisfied is at index 10028\n",
      "Saved the embedding for satisfied.\n",
      "satisfy is at index 15332\n",
      "Saved the embedding for satisfy.\n",
      "saturnine is at index 4005\n",
      "Saved the embedding for saturnine.\n",
      "saucy is at index 2241\n",
      "Saved the embedding for saucy.\n",
      "savage is at index 32264\n",
      "Saved the embedding for savage.\n",
      "scandalized is at index 4220\n",
      "Saved the embedding for scandalized.\n",
      "scare is at index 13207\n",
      "Saved the embedding for scare.\n",
      "scared is at index 8265\n",
      "Saved the embedding for scared.\n",
      "scary is at index 10222\n",
      "Saved the embedding for scary.\n",
      "scattered is at index 12827\n",
      "Saved the embedding for scattered.\n",
      "schadenfreude is at index 8447\n",
      "Saved the embedding for schadenfreude.\n",
      "scheming is at index 30315\n",
      "Saved the embedding for scheming.\n",
      "scoffer is at index 34564\n",
      "Saved the embedding for scoffer.\n",
      "scoffing is at index 34564\n",
      "Saved the embedding for scoffing.\n",
      "scorn is at index 38430\n",
      "Saved the embedding for scorn.\n",
      "scorned is at index 2850\n",
      "Saved the embedding for scorned.\n",
      "scornful is at index 38430\n",
      "Saved the embedding for scornful.\n",
      "scowl is at index 2850\n",
      "Saved the embedding for scowl.\n",
      "scowling is at index 2850\n",
      "Saved the embedding for scowling.\n",
      "scream is at index 22093\n",
      "Saved the embedding for scream.\n",
      "screaming is at index 11347\n",
      "Saved the embedding for screaming.\n",
      "scrutinizing is at index 18470\n",
      "Saved the embedding for scrutinizing.\n",
      "sealed is at index 10497\n",
      "Saved the embedding for sealed.\n",
      "searching is at index 6062\n",
      "Saved the embedding for searching.\n",
      "secretive is at index 27174\n",
      "Saved the embedding for secretive.\n",
      "secretively is at index 3556\n",
      "Saved the embedding for secretively.\n",
      "secure is at index 2823\n",
      "Saved the embedding for secure.\n",
      "sedate is at index 10195\n",
      "Saved the embedding for sedate.\n",
      "seduction is at index 10195\n",
      "Saved the embedding for seduction.\n",
      "seductive is at index 10195\n",
      "Saved the embedding for seductive.\n",
      "seething is at index 842\n",
      "Saved the embedding for seething.\n",
      "self is at index 1403\n",
      "Saved the embedding for self.\n",
      "sensual is at index 18105\n",
      "Saved the embedding for sensual.\n",
      "sentimental is at index 32693\n",
      "Saved the embedding for sentimental.\n",
      "serene is at index 842\n",
      "Saved the embedding for serene.\n",
      "serious is at index 1473\n",
      "Saved the embedding for serious.\n",
      "seriousness is at index 24146\n",
      "Saved the embedding for seriousness.\n",
      "servile is at index 18527\n",
      "Saved the embedding for servile.\n",
      "set is at index 278\n",
      "Saved the embedding for set.\n",
      "severe is at index 3814\n",
      "Saved the embedding for severe.\n",
      "shabby is at index 1481\n",
      "Saved the embedding for shabby.\n",
      "shady is at index 31665\n",
      "Saved the embedding for shady.\n",
      "shaken is at index 17548\n",
      "Saved the embedding for shaken.\n",
      "shaky is at index 22032\n",
      "Saved the embedding for shaky.\n",
      "shame is at index 9208\n",
      "Saved the embedding for shame.\n",
      "shamed is at index 1481\n",
      "Saved the embedding for shamed.\n",
      "shamefaced is at index 9208\n",
      "Saved the embedding for shamefaced.\n",
      "shameful is at index 26722\n",
      "Saved the embedding for shameful.\n",
      "shameless is at index 36778\n",
      "Saved the embedding for shameless.\n",
      "sharp is at index 4406\n",
      "Saved the embedding for sharp.\n",
      "sheepish is at index 14336\n",
      "Saved the embedding for sheepish.\n",
      "sheepishness is at index 14336\n",
      "Saved the embedding for sheepishness.\n",
      "shelled is at index 79\n",
      "Saved the embedding for shelled.\n",
      "shifty is at index 37503\n",
      "Saved the embedding for shifty.\n",
      "shock is at index 4817\n",
      "Saved the embedding for shock.\n",
      "shocked is at index 6649\n",
      "Saved the embedding for shocked.\n",
      "shocking is at index 8777\n",
      "Saved the embedding for shocking.\n",
      "shockingly is at index 36804\n",
      "Saved the embedding for shockingly.\n",
      "shook is at index 14774\n",
      "Saved the embedding for shook.\n",
      "shout is at index 18066\n",
      "Saved the embedding for shout.\n",
      "shouting is at index 14487\n",
      "Saved the embedding for shouting.\n",
      "shrewd is at index 36943\n",
      "Saved the embedding for shrewd.\n",
      "shy is at index 9152\n",
      "Saved the embedding for shy.\n",
      "shyness is at index 9152\n",
      "Saved the embedding for shyness.\n",
      "sick is at index 4736\n",
      "Saved the embedding for sick.\n",
      "sicken is at index 579\n",
      "Saved the embedding for sicken.\n",
      "sickened is at index 4736\n",
      "Saved the embedding for sickened.\n",
      "sigh is at index 27305\n",
      "Saved the embedding for sigh.\n",
      "silenced is at index 30125\n",
      "Saved the embedding for silenced.\n",
      "silent is at index 8454\n",
      "Saved the embedding for silent.\n",
      "silliness is at index 38052\n",
      "Saved the embedding for silliness.\n",
      "silly is at index 15470\n",
      "Saved the embedding for silly.\n",
      "simmering is at index 25726\n",
      "Saved the embedding for simmering.\n",
      "simper is at index 16207\n",
      "Saved the embedding for simper.\n",
      "simpering is at index 16207\n",
      "Saved the embedding for simpering.\n",
      "simple is at index 2007\n",
      "Saved the embedding for simple.\n",
      "simplicity is at index 25342\n",
      "Saved the embedding for simplicity.\n",
      "sincere is at index 19255\n",
      "Saved the embedding for sincere.\n",
      "sinful is at index 44364\n",
      "Saved the embedding for sinful.\n",
      "singing is at index 6970\n",
      "Saved the embedding for singing.\n",
      "sinister is at index 27570\n",
      "Saved the embedding for sinister.\n",
      "sinisterly is at index 27570\n",
      "Saved the embedding for sinisterly.\n",
      "sizing is at index 39328\n",
      "Saved the embedding for sizing.\n",
      "skeptic is at index 42386\n",
      "Saved the embedding for skeptic.\n",
      "skeptical is at index 14992\n",
      "Saved the embedding for skeptical.\n",
      "skeptically is at index 42386\n",
      "Saved the embedding for skeptically.\n",
      "skepticism is at index 22222\n",
      "Saved the embedding for skepticism.\n",
      "sketchy is at index 15923\n",
      "Saved the embedding for sketchy.\n",
      "skittish is at index 2972\n",
      "Saved the embedding for skittish.\n",
      "slack is at index 25163\n",
      "Saved the embedding for slack.\n",
      "sleazy is at index 18388\n",
      "Saved the embedding for sleazy.\n",
      "sleepy is at index 33782\n",
      "Saved the embedding for sleepy.\n",
      "slick is at index 19038\n",
      "Saved the embedding for slick.\n",
      "slothful is at index 3369\n",
      "Saved the embedding for slothful.\n",
      "slow is at index 2635\n",
      "Saved the embedding for slow.\n",
      "sluggish is at index 16642\n",
      "Saved the embedding for sluggish.\n",
      "sly is at index 40568\n",
      "Saved the embedding for sly.\n",
      "smarmy is at index 5278\n",
      "Saved the embedding for smarmy.\n",
      "smart is at index 2793\n",
      "Saved the embedding for smart.\n",
      "smashed is at index 13263\n",
      "Saved the embedding for smashed.\n",
      "smile is at index 6675\n",
      "Saved the embedding for smile.\n",
      "smiley is at index 6675\n",
      "Saved the embedding for smiley.\n",
      "smiling is at index 12382\n",
      "Saved the embedding for smiling.\n",
      "smirk is at index 5278\n",
      "Saved the embedding for smirk.\n",
      "smirking is at index 44414\n",
      "Saved the embedding for smirking.\n",
      "smoldering is at index 5278\n",
      "Saved the embedding for smoldering.\n",
      "smooching is at index 5278\n",
      "Saved the embedding for smooching.\n",
      "smooth is at index 6921\n",
      "Saved the embedding for smooth.\n",
      "smug is at index 41283\n",
      "Saved the embedding for smug.\n",
      "smugness is at index 41283\n",
      "Saved the embedding for smugness.\n",
      "snake is at index 16173\n",
      "Saved the embedding for snake.\n",
      "snappy is at index 4543\n",
      "Saved the embedding for snappy.\n",
      "snarky is at index 4543\n",
      "Saved the embedding for snarky.\n",
      "snarl is at index 4543\n",
      "Saved the embedding for snarl.\n",
      "snarled is at index 4543\n",
      "Saved the embedding for snarled.\n",
      "snarling is at index 4543\n",
      "Saved the embedding for snarling.\n",
      "snarly is at index 4543\n",
      "Saved the embedding for snarly.\n",
      "sneaky is at index 39399\n",
      "Saved the embedding for sneaky.\n",
      "sneer is at index 18013\n",
      "Saved the embedding for sneer.\n",
      "sneering is at index 18013\n",
      "Saved the embedding for sneering.\n",
      "sneeze is at index 18013\n",
      "Saved the embedding for sneeze.\n",
      "sneezing is at index 18013\n",
      "Saved the embedding for sneezing.\n",
      "snicker is at index 4543\n",
      "Saved the embedding for snicker.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snickering is at index 4543\n",
      "Saved the embedding for snickering.\n",
      "snide is at index 4543\n",
      "Saved the embedding for snide.\n",
      "sniggering is at index 4543\n",
      "Saved the embedding for sniggering.\n",
      "sniveling is at index 4543\n",
      "Saved the embedding for sniveling.\n",
      "snobbish is at index 4543\n",
      "Saved the embedding for snobbish.\n",
      "snobby is at index 4543\n",
      "Saved the embedding for snobby.\n",
      "snooty is at index 4543\n",
      "Saved the embedding for snooty.\n",
      "snotty is at index 579\n",
      "Saved the embedding for snotty.\n",
      "sociable is at index 17380\n",
      "Saved the embedding for sociable.\n",
      "soft is at index 3793\n",
      "Saved the embedding for soft.\n",
      "solemn is at index 29807\n",
      "Saved the embedding for solemn.\n",
      "solicitous is at index 22706\n",
      "Saved the embedding for solicitous.\n",
      "solitary is at index 24429\n",
      "Saved the embedding for solitary.\n",
      "solitude is at index 41813\n",
      "Saved the embedding for solitude.\n",
      "somber is at index 16487\n",
      "Saved the embedding for somber.\n",
      "somberly is at index 16487\n",
      "Saved the embedding for somberly.\n",
      "somnolent is at index 16487\n",
      "Saved the embedding for somnolent.\n",
      "soothed is at index 98\n",
      "Saved the embedding for soothed.\n",
      "sore is at index 12867\n",
      "Saved the embedding for sore.\n",
      "sorrow is at index 26130\n",
      "Saved the embedding for sorrow.\n",
      "sorrowful is at index 26130\n",
      "Saved the embedding for sorrowful.\n",
      "sorry is at index 6661\n",
      "Saved the embedding for sorry.\n",
      "sour is at index 16933\n",
      "Saved the embedding for sour.\n",
      "spaced is at index 42926\n",
      "Saved the embedding for spaced.\n",
      "spacing is at index 39152\n",
      "Saved the embedding for spacing.\n",
      "spastic is at index 2292\n",
      "Saved the embedding for spastic.\n",
      "speaking is at index 2686\n",
      "Saved the embedding for speaking.\n",
      "specious is at index 12002\n",
      "Saved the embedding for specious.\n",
      "speculative is at index 21779\n",
      "Saved the embedding for speculative.\n",
      "speechless is at index 1901\n",
      "Saved the embedding for speechless.\n",
      "spent is at index 1240\n",
      "Saved the embedding for spent.\n",
      "spirited is at index 27206\n",
      "Saved the embedding for spirited.\n",
      "spiritless is at index 4780\n",
      "Saved the embedding for spiritless.\n",
      "spite is at index 14117\n",
      "Saved the embedding for spite.\n",
      "spiteful is at index 14117\n",
      "Saved the embedding for spiteful.\n",
      "spoiled is at index 29136\n",
      "Saved the embedding for spoiled.\n",
      "spooked is at index 2292\n",
      "Saved the embedding for spooked.\n",
      "squeamish is at index 33380\n",
      "Saved the embedding for squeamish.\n",
      "staggered is at index 37646\n",
      "Saved the embedding for staggered.\n",
      "stalker is at index 1690\n",
      "Saved the embedding for stalker.\n",
      "stare is at index 27655\n",
      "Saved the embedding for stare.\n",
      "staring is at index 19311\n",
      "Saved the embedding for staring.\n",
      "starstruck is at index 999\n",
      "Saved the embedding for starstruck.\n",
      "started is at index 554\n",
      "Saved the embedding for started.\n",
      "startled is at index 37747\n",
      "Saved the embedding for startled.\n",
      "stately is at index 194\n",
      "Saved the embedding for stately.\n",
      "steadfast is at index 25781\n",
      "Saved the embedding for steadfast.\n",
      "steady is at index 5204\n",
      "Saved the embedding for steady.\n",
      "stealthy is at index 27026\n",
      "Saved the embedding for stealthy.\n",
      "steamed is at index 11235\n",
      "Saved the embedding for steamed.\n",
      "steaming is at index 11235\n",
      "Saved the embedding for steaming.\n",
      "steeling is at index 3689\n",
      "Saved the embedding for steeling.\n",
      "steely is at index 1690\n",
      "Saved the embedding for steely.\n",
      "stern is at index 23427\n",
      "Saved the embedding for stern.\n",
      "stiff is at index 13116\n",
      "Saved the embedding for stiff.\n",
      "stifled is at index 1690\n",
      "Saved the embedding for stifled.\n",
      "stifling is at index 1690\n",
      "Saved the embedding for stifling.\n",
      "still is at index 202\n",
      "Saved the embedding for still.\n",
      "stillness is at index 202\n",
      "Saved the embedding for stillness.\n",
      "stimulated is at index 42040\n",
      "Saved the embedding for stimulated.\n",
      "stinky is at index 1690\n",
      "Saved the embedding for stinky.\n",
      "stirred is at index 26158\n",
      "Saved the embedding for stirred.\n",
      "stoic is at index 20572\n",
      "Saved the embedding for stoic.\n",
      "stoical is at index 20572\n",
      "Saved the embedding for stoical.\n",
      "stolid is at index 1690\n",
      "Saved the embedding for stolid.\n",
      "stoned is at index 1690\n",
      "Saved the embedding for stoned.\n",
      "storming is at index 2130\n",
      "Saved the embedding for storming.\n",
      "stormy is at index 2130\n",
      "Saved the embedding for stormy.\n",
      "stout is at index 34636\n",
      "Saved the embedding for stout.\n",
      "straight is at index 1359\n",
      "Saved the embedding for straight.\n",
      "strained is at index 15718\n",
      "Saved the embedding for strained.\n",
      "strange is at index 7782\n",
      "Saved the embedding for strange.\n",
      "stressed is at index 5882\n",
      "Saved the embedding for stressed.\n",
      "stricken is at index 35876\n",
      "Saved the embedding for stricken.\n",
      "strict is at index 8414\n",
      "Saved the embedding for strict.\n",
      "strong is at index 670\n",
      "Saved the embedding for strong.\n",
      "struck is at index 2322\n",
      "Saved the embedding for struck.\n",
      "stubborn is at index 20476\n",
      "Saved the embedding for stubborn.\n",
      "stubbornness is at index 20476\n",
      "Saved the embedding for stubbornness.\n",
      "studious is at index 15863\n",
      "Saved the embedding for studious.\n",
      "studying is at index 7739\n",
      "Saved the embedding for studying.\n",
      "stumped is at index 1690\n",
      "Saved the embedding for stumped.\n",
      "stung is at index 1690\n",
      "Saved the embedding for stung.\n",
      "stunned is at index 12144\n",
      "Saved the embedding for stunned.\n",
      "stupefaction is at index 1690\n",
      "Saved the embedding for stupefaction.\n",
      "stupefied is at index 1690\n",
      "Saved the embedding for stupefied.\n",
      "stupefy is at index 1690\n",
      "Saved the embedding for stupefy.\n",
      "stupid is at index 12103\n",
      "Saved the embedding for stupid.\n",
      "stuporous is at index 1690\n",
      "Saved the embedding for stuporous.\n",
      "suave is at index 2628\n",
      "Saved the embedding for suave.\n",
      "subdued is at index 20247\n",
      "Saved the embedding for subdued.\n",
      "sublime is at index 32477\n",
      "Saved the embedding for sublime.\n",
      "submissive is at index 2849\n",
      "Saved the embedding for submissive.\n",
      "suffering is at index 3606\n",
      "Saved the embedding for suffering.\n",
      "suggestive is at index 38907\n",
      "Saved the embedding for suggestive.\n",
      "sulking is at index 26648\n",
      "Saved the embedding for sulking.\n",
      "sulky is at index 26648\n",
      "Saved the embedding for sulky.\n",
      "sullen is at index 2628\n",
      "Saved the embedding for sullen.\n",
      "sullenness is at index 2628\n",
      "Saved the embedding for sullenness.\n",
      "sunny is at index 5419\n",
      "Saved the embedding for sunny.\n",
      "superior is at index 10295\n",
      "Saved the embedding for superior.\n",
      "superiority is at index 32951\n",
      "Saved the embedding for superiority.\n",
      "suppressed is at index 31683\n",
      "Saved the embedding for suppressed.\n",
      "suppressing is at index 38919\n",
      "Saved the embedding for suppressing.\n",
      "suppression is at index 25276\n",
      "Saved the embedding for suppression.\n",
      "sure is at index 686\n",
      "Saved the embedding for sure.\n",
      "surly is at index 8113\n",
      "Saved the embedding for surly.\n",
      "surprise is at index 2755\n",
      "Saved the embedding for surprise.\n",
      "surprised is at index 3911\n",
      "Saved the embedding for surprised.\n",
      "surprising is at index 6167\n",
      "Saved the embedding for surprising.\n",
      "surprisingly is at index 10262\n",
      "Saved the embedding for surprisingly.\n",
      "surreptitious is at index 8113\n",
      "Saved the embedding for surreptitious.\n",
      "suspect is at index 1985\n",
      "Saved the embedding for suspect.\n",
      "suspecting is at index 1985\n",
      "Saved the embedding for suspecting.\n",
      "suspense is at index 31803\n",
      "Saved the embedding for suspense.\n",
      "suspicion is at index 8551\n",
      "Saved the embedding for suspicion.\n",
      "suspicious is at index 7775\n",
      "Saved the embedding for suspicious.\n",
      "suspiciously is at index 7775\n",
      "Saved the embedding for suspiciously.\n",
      "suspiciousness is at index 7775\n",
      "Saved the embedding for suspiciousness.\n",
      "swaggering is at index 3514\n",
      "Saved the embedding for swaggering.\n",
      "swearing is at index 21854\n",
      "Saved the embedding for swearing.\n",
      "sympathetic is at index 22869\n",
      "Saved the embedding for sympathetic.\n",
      "sympathizing is at index 19023\n",
      "Saved the embedding for sympathizing.\n",
      "sympathy is at index 16554\n",
      "Saved the embedding for sympathy.\n",
      "taciturn is at index 36502\n",
      "Saved the embedding for taciturn.\n",
      "talkative is at index 1067\n",
      "Saved the embedding for talkative.\n",
      "talking is at index 1686\n",
      "Saved the embedding for talking.\n",
      "tantalized is at index 33496\n",
      "Saved the embedding for tantalized.\n",
      "tart is at index 27468\n",
      "Saved the embedding for tart.\n",
      "tasteful is at index 24867\n",
      "Saved the embedding for tasteful.\n",
      "tattling is at index 45951\n",
      "Saved the embedding for tattling.\n",
      "taunt is at index 44048\n",
      "Saved the embedding for taunt.\n",
      "taunting is at index 326\n",
      "Saved the embedding for taunting.\n",
      "taut is at index 326\n",
      "Saved the embedding for taut.\n",
      "tearful is at index 7366\n",
      "Saved the embedding for tearful.\n",
      "teary is at index 7366\n",
      "Saved the embedding for teary.\n",
      "tease is at index 29993\n",
      "Saved the embedding for tease.\n",
      "teasing is at index 29752\n",
      "Saved the embedding for teasing.\n",
      "tempered is at index 31380\n",
      "Saved the embedding for tempered.\n",
      "tempest is at index 32196\n",
      "Saved the embedding for tempest.\n",
      "tempestuous is at index 32196\n",
      "Saved the embedding for tempestuous.\n",
      "tempted is at index 23448\n",
      "Saved the embedding for tempted.\n",
      "tenacious is at index 2724\n",
      "Saved the embedding for tenacious.\n",
      "tender is at index 8780\n",
      "Saved the embedding for tender.\n",
      "tenderness is at index 8780\n",
      "Saved the embedding for tenderness.\n",
      "tense is at index 13554\n",
      "Saved the embedding for tense.\n",
      "tensed is at index 7281\n",
      "Saved the embedding for tensed.\n",
      "tension is at index 8556\n",
      "Saved the embedding for tension.\n",
      "tentative is at index 22948\n",
      "Saved the embedding for tentative.\n",
      "terrified is at index 19419\n",
      "Saved the embedding for terrified.\n",
      "terror is at index 5231\n",
      "Saved the embedding for terror.\n",
      "terrorized is at index 5231\n",
      "Saved the embedding for terrorized.\n",
      "terrorizing is at index 5231\n",
      "Saved the embedding for terrorizing.\n",
      "terse is at index 8470\n",
      "Saved the embedding for terse.\n",
      "testy is at index 1296\n",
      "Saved the embedding for testy.\n",
      "tetchy is at index 326\n",
      "Saved the embedding for tetchy.\n",
      "thankful is at index 12025\n",
      "Saved the embedding for thankful.\n",
      "thinking is at index 2053\n",
      "Saved the embedding for thinking.\n",
      "thought is at index 802\n",
      "Saved the embedding for thought.\n",
      "thoughtful is at index 16801\n",
      "Saved the embedding for thoughtful.\n",
      "thoughtfulness is at index 802\n",
      "Saved the embedding for thoughtfulness.\n",
      "threat is at index 1856\n",
      "Saved the embedding for threat.\n",
      "threatened is at index 3711\n",
      "Saved the embedding for threatened.\n",
      "threatening is at index 5608\n",
      "Saved the embedding for threatening.\n",
      "thrilled is at index 8689\n",
      "Saved the embedding for thrilled.\n",
      "thrown is at index 5629\n",
      "Saved the embedding for thrown.\n",
      "thunderstruck is at index 4775\n",
      "Saved the embedding for thunderstruck.\n",
      "thwarted is at index 28299\n",
      "Saved the embedding for thwarted.\n",
      "ticked is at index 10457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for ticked.\n",
      "tickled is at index 10457\n",
      "Saved the embedding for tickled.\n",
      "tied is at index 3016\n",
      "Saved the embedding for tied.\n",
      "tiered is at index 3318\n",
      "Saved the embedding for tiered.\n",
      "tight is at index 3229\n",
      "Saved the embedding for tight.\n",
      "tightlipped is at index 3229\n",
      "Saved the embedding for tightlipped.\n",
      "timid is at index 39649\n",
      "Saved the embedding for timid.\n",
      "timidly is at index 39649\n",
      "Saved the embedding for timidly.\n",
      "timidness is at index 39649\n",
      "Saved the embedding for timidness.\n",
      "tired is at index 7428\n",
      "Saved the embedding for tired.\n",
      "tiredly is at index 7428\n",
      "Saved the embedding for tiredly.\n",
      "tiredness is at index 7428\n",
      "Saved the embedding for tiredness.\n",
      "titillated is at index 13515\n",
      "Saved the embedding for titillated.\n",
      "tolerant is at index 32836\n",
      "Saved the embedding for tolerant.\n",
      "tongue is at index 15686\n",
      "Saved the embedding for tongue.\n",
      "tormented is at index 16535\n",
      "Saved the embedding for tormented.\n",
      "touched is at index 6699\n",
      "Saved the embedding for touched.\n",
      "tough is at index 1828\n",
      "Saved the embedding for tough.\n",
      "toying is at index 7\n",
      "Saved the embedding for toying.\n",
      "tragic is at index 8805\n",
      "Saved the embedding for tragic.\n",
      "tragical is at index 2664\n",
      "Saved the embedding for tragical.\n",
      "tranquil is at index 33535\n",
      "Saved the embedding for tranquil.\n",
      "tranquility is at index 36474\n",
      "Saved the embedding for tranquility.\n",
      "transfixed is at index 30387\n",
      "Saved the embedding for transfixed.\n",
      "traumatized is at index 25178\n",
      "Saved the embedding for traumatized.\n",
      "trembling is at index 44912\n",
      "Saved the embedding for trembling.\n",
      "trepid is at index 6110\n",
      "Saved the embedding for trepid.\n",
      "trepidation is at index 6110\n",
      "Saved the embedding for trepidation.\n",
      "trickster is at index 7610\n",
      "Saved the embedding for trickster.\n",
      "tricky is at index 12792\n",
      "Saved the embedding for tricky.\n",
      "triumphant is at index 32025\n",
      "Saved the embedding for triumphant.\n",
      "troubled is at index 9895\n",
      "Saved the embedding for troubled.\n",
      "troublesome is at index 34056\n",
      "Saved the embedding for troublesome.\n",
      "troubling is at index 15554\n",
      "Saved the embedding for troubling.\n",
      "trusting is at index 28969\n",
      "Saved the embedding for trusting.\n",
      "trustworthy is at index 32101\n",
      "Saved the embedding for trustworthy.\n",
      "tumultuous is at index 23787\n",
      "Saved the embedding for tumultuous.\n",
      "turbulent is at index 23415\n",
      "Saved the embedding for turbulent.\n",
      "twinkly is at index 11901\n",
      "Saved the embedding for twinkly.\n",
      "umbrage is at index 7252\n",
      "Saved the embedding for umbrage.\n",
      "umbrageous is at index 7252\n",
      "Saved the embedding for umbrageous.\n",
      "unaffected is at index 32512\n",
      "Saved the embedding for unaffected.\n",
      "unagitated is at index 542\n",
      "Saved the embedding for unagitated.\n",
      "unamused is at index 542\n",
      "Saved the embedding for unamused.\n",
      "unappreciative is at index 542\n",
      "Saved the embedding for unappreciative.\n",
      "unapproachable is at index 542\n",
      "Saved the embedding for unapproachable.\n",
      "unassertive is at index 542\n",
      "Saved the embedding for unassertive.\n",
      "unassuming is at index 542\n",
      "Saved the embedding for unassuming.\n",
      "unaware is at index 14021\n",
      "Saved the embedding for unaware.\n",
      "unbelief is at index 46646\n",
      "Saved the embedding for unbelief.\n",
      "unbelievable is at index 14011\n",
      "Saved the embedding for unbelievable.\n",
      "unbelieving is at index 46646\n",
      "Saved the embedding for unbelieving.\n",
      "unbothered is at index 542\n",
      "Saved the embedding for unbothered.\n",
      "uncaring is at index 16511\n",
      "Saved the embedding for uncaring.\n",
      "uncertain is at index 9684\n",
      "Saved the embedding for uncertain.\n",
      "uncertainly is at index 9684\n",
      "Saved the embedding for uncertainly.\n",
      "uncertainty is at index 4983\n",
      "Saved the embedding for uncertainty.\n",
      "uncivil is at index 16511\n",
      "Saved the embedding for uncivil.\n",
      "uncomfortable is at index 9800\n",
      "Saved the embedding for uncomfortable.\n",
      "uncommitted is at index 32275\n",
      "Saved the embedding for uncommitted.\n",
      "uncommunicative is at index 32275\n",
      "Saved the embedding for uncommunicative.\n",
      "uncomprehending is at index 32275\n",
      "Saved the embedding for uncomprehending.\n",
      "uncompromising is at index 32213\n",
      "Saved the embedding for uncompromising.\n",
      "unconcerned is at index 28198\n",
      "Saved the embedding for unconcerned.\n",
      "unconfident is at index 542\n",
      "Saved the embedding for unconfident.\n",
      "unconvinced is at index 28198\n",
      "Saved the embedding for unconvinced.\n",
      "uncooperative is at index 542\n",
      "Saved the embedding for uncooperative.\n",
      "uncurious is at index 16511\n",
      "Saved the embedding for uncurious.\n",
      "undecided is at index 28598\n",
      "Saved the embedding for undecided.\n",
      "underhanded is at index 223\n",
      "Saved the embedding for underhanded.\n",
      "understanding is at index 2969\n",
      "Saved the embedding for understanding.\n",
      "undesirable is at index 39028\n",
      "Saved the embedding for undesirable.\n",
      "unease is at index 12515\n",
      "Saved the embedding for unease.\n",
      "uneasily is at index 12515\n",
      "Saved the embedding for uneasily.\n",
      "uneasiness is at index 12515\n",
      "Saved the embedding for uneasiness.\n",
      "uneasy is at index 29569\n",
      "Saved the embedding for uneasy.\n",
      "unemotional is at index 542\n",
      "Saved the embedding for unemotional.\n",
      "unenthusiastic is at index 542\n",
      "Saved the embedding for unenthusiastic.\n",
      "unexcited is at index 39432\n",
      "Saved the embedding for unexcited.\n",
      "unexpected is at index 7152\n",
      "Saved the embedding for unexpected.\n",
      "unfamiliar is at index 21942\n",
      "Saved the embedding for unfamiliar.\n",
      "unfathomable is at index 9515\n",
      "Saved the embedding for unfathomable.\n",
      "unfazed is at index 9515\n",
      "Saved the embedding for unfazed.\n",
      "unfeeling is at index 9515\n",
      "Saved the embedding for unfeeling.\n",
      "unfocused is at index 47306\n",
      "Saved the embedding for unfocused.\n",
      "unforeseen is at index 33257\n",
      "Saved the embedding for unforeseen.\n",
      "unforgiving is at index 34262\n",
      "Saved the embedding for unforgiving.\n",
      "unforthcoming is at index 9515\n",
      "Saved the embedding for unforthcoming.\n",
      "unfortunate is at index 9327\n",
      "Saved the embedding for unfortunate.\n",
      "unfriendly is at index 9515\n",
      "Saved the embedding for unfriendly.\n",
      "unhappy is at index 13865\n",
      "Saved the embedding for unhappy.\n",
      "unhinged is at index 542\n",
      "Saved the embedding for unhinged.\n",
      "unimpressed is at index 542\n",
      "Saved the embedding for unimpressed.\n",
      "uninformed is at index 21969\n",
      "Saved the embedding for uninformed.\n",
      "uninspired is at index 542\n",
      "Saved the embedding for uninspired.\n",
      "uninterested is at index 542\n",
      "Saved the embedding for uninterested.\n",
      "uninvolved is at index 542\n",
      "Saved the embedding for uninvolved.\n",
      "unique is at index 2216\n",
      "Saved the embedding for unique.\n",
      "unlikeable is at index 7328\n",
      "Saved the embedding for unlikeable.\n",
      "unmoved is at index 30780\n",
      "Saved the embedding for unmoved.\n",
      "unnerved is at index 31550\n",
      "Saved the embedding for unnerved.\n",
      "unpleasant is at index 26262\n",
      "Saved the embedding for unpleasant.\n",
      "unprepared is at index 35578\n",
      "Saved the embedding for unprepared.\n",
      "unquiet is at index 542\n",
      "Saved the embedding for unquiet.\n",
      "unreactive is at index 21153\n",
      "Saved the embedding for unreactive.\n",
      "unresolved is at index 29909\n",
      "Saved the embedding for unresolved.\n",
      "unrestrained is at index 12254\n",
      "Saved the embedding for unrestrained.\n",
      "unruffled is at index 542\n",
      "Saved the embedding for unruffled.\n",
      "unsatisfied is at index 36010\n",
      "Saved the embedding for unsatisfied.\n",
      "unsettled is at index 30933\n",
      "Saved the embedding for unsettled.\n",
      "unsociable is at index 9977\n",
      "Saved the embedding for unsociable.\n",
      "unspeaking is at index 542\n",
      "Saved the embedding for unspeaking.\n",
      "unspoken is at index 542\n",
      "Saved the embedding for unspoken.\n",
      "unstrung is at index 542\n",
      "Saved the embedding for unstrung.\n",
      "unsuccessful is at index 15943\n",
      "Saved the embedding for unsuccessful.\n",
      "unsure is at index 17118\n",
      "Saved the embedding for unsure.\n",
      "unsurprised is at index 36637\n",
      "Saved the embedding for unsurprised.\n",
      "unsuspecting is at index 32276\n",
      "Saved the embedding for unsuspecting.\n",
      "unswayed is at index 9977\n",
      "Saved the embedding for unswayed.\n",
      "unsympathetic is at index 542\n",
      "Saved the embedding for unsympathetic.\n",
      "untouched is at index 29929\n",
      "Saved the embedding for untouched.\n",
      "untroubled is at index 7587\n",
      "Saved the embedding for untroubled.\n",
      "untrusting is at index 7587\n",
      "Saved the embedding for untrusting.\n",
      "unwanted is at index 15067\n",
      "Saved the embedding for unwanted.\n",
      "unwavering is at index 10963\n",
      "Saved the embedding for unwavering.\n",
      "unwelcoming is at index 10963\n",
      "Saved the embedding for unwelcoming.\n",
      "unwell is at index 542\n",
      "Saved the embedding for unwell.\n",
      "unwilling is at index 20656\n",
      "Saved the embedding for unwilling.\n",
      "unyielding is at index 542\n",
      "Saved the embedding for unyielding.\n",
      "up is at index 62\n",
      "Saved the embedding for up.\n",
      "upbeat is at index 14899\n",
      "Saved the embedding for upbeat.\n",
      "uplifting is at index 17627\n",
      "Saved the embedding for uplifting.\n",
      "uppity is at index 1717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for uppity.\n",
      "upset is at index 4904\n",
      "Saved the embedding for upset.\n",
      "uptight is at index 18256\n",
      "Saved the embedding for uptight.\n",
      "useless is at index 23584\n",
      "Saved the embedding for useless.\n",
      "vacant is at index 11042\n",
      "Saved the embedding for vacant.\n",
      "vacuous is at index 18721\n",
      "Saved the embedding for vacuous.\n",
      "vanquished is at index 44400\n",
      "Saved the embedding for vanquished.\n",
      "vehement is at index 45373\n",
      "Saved the embedding for vehement.\n",
      "vengeful is at index 748\n",
      "Saved the embedding for vengeful.\n",
      "venomous is at index 32051\n",
      "Saved the embedding for venomous.\n",
      "vex is at index 37894\n",
      "Saved the embedding for vex.\n",
      "vexation is at index 37894\n",
      "Saved the embedding for vexation.\n",
      "vexed is at index 37894\n",
      "Saved the embedding for vexed.\n",
      "vicious is at index 16339\n",
      "Saved the embedding for vicious.\n",
      "victorious is at index 22518\n",
      "Saved the embedding for victorious.\n",
      "vigilant is at index 17258\n",
      "Saved the embedding for vigilant.\n",
      "vile is at index 32359\n",
      "Saved the embedding for vile.\n",
      "villainous is at index 17031\n",
      "Saved the embedding for villainous.\n",
      "vindictive is at index 21339\n",
      "Saved the embedding for vindictive.\n",
      "violence is at index 1476\n",
      "Saved the embedding for violence.\n",
      "violent is at index 4153\n",
      "Saved the embedding for violent.\n",
      "viperous is at index 748\n",
      "Saved the embedding for viperous.\n",
      "vituperative is at index 14306\n",
      "Saved the embedding for vituperative.\n",
      "vocal is at index 7578\n",
      "Saved the embedding for vocal.\n",
      "vocalized is at index 7578\n",
      "Saved the embedding for vocalized.\n",
      "vulgar is at index 28792\n",
      "Saved the embedding for vulgar.\n",
      "vulnerability is at index 15661\n",
      "Saved the embedding for vulnerability.\n",
      "vulnerable is at index 4478\n",
      "Saved the embedding for vulnerable.\n",
      "wacky is at index 885\n",
      "Saved the embedding for wacky.\n",
      "waiting is at index 2445\n",
      "Saved the embedding for waiting.\n",
      "wanted is at index 770\n",
      "Saved the embedding for wanted.\n",
      "wanting is at index 6923\n",
      "Saved the embedding for wanting.\n",
      "wanton is at index 236\n",
      "Saved the embedding for wanton.\n",
      "wariness is at index 997\n",
      "Saved the embedding for wariness.\n",
      "warm is at index 3279\n",
      "Saved the embedding for warm.\n",
      "wary is at index 13441\n",
      "Saved the embedding for wary.\n",
      "wasted is at index 14260\n",
      "Saved the embedding for wasted.\n",
      "watch is at index 1183\n",
      "Saved the embedding for watch.\n",
      "watchful is at index 1183\n",
      "Saved the embedding for watchful.\n",
      "watching is at index 2494\n",
      "Saved the embedding for watching.\n",
      "wavering is at index 13332\n",
      "Saved the embedding for wavering.\n",
      "weariness is at index 3568\n",
      "Saved the embedding for weariness.\n",
      "weary is at index 31554\n",
      "Saved the embedding for weary.\n",
      "weeping is at index 39423\n",
      "Saved the embedding for weeping.\n",
      "weird is at index 7735\n",
      "Saved the embedding for weird.\n",
      "welcome is at index 2814\n",
      "Saved the embedding for welcome.\n",
      "welcoming is at index 10423\n",
      "Saved the embedding for welcoming.\n",
      "whatever is at index 3046\n",
      "Saved the embedding for whatever.\n",
      "whimpering is at index 31754\n",
      "Saved the embedding for whimpering.\n",
      "whimsical is at index 29363\n",
      "Saved the embedding for whimsical.\n",
      "whisper is at index 37539\n",
      "Saved the embedding for whisper.\n",
      "whistle is at index 16867\n",
      "Saved the embedding for whistle.\n",
      "white is at index 1104\n",
      "Saved the embedding for white.\n",
      "wicked is at index 28418\n",
      "Saved the embedding for wicked.\n",
      "wild is at index 3418\n",
      "Saved the embedding for wild.\n",
      "willful is at index 40960\n",
      "Saved the embedding for willful.\n",
      "willing is at index 2882\n",
      "Saved the embedding for willing.\n",
      "wily is at index 885\n",
      "Saved the embedding for wily.\n",
      "wink is at index 39422\n",
      "Saved the embedding for wink.\n",
      "wired is at index 26977\n",
      "Saved the embedding for wired.\n",
      "wishful is at index 2813\n",
      "Saved the embedding for wishful.\n",
      "wistful is at index 885\n",
      "Saved the embedding for wistful.\n",
      "wistfully is at index 885\n",
      "Saved the embedding for wistfully.\n",
      "withdraw is at index 8202\n",
      "Saved the embedding for withdraw.\n",
      "withdrawn is at index 13375\n",
      "Saved the embedding for withdrawn.\n",
      "withheld is at index 22292\n",
      "Saved the embedding for withheld.\n",
      "withholding is at index 25661\n",
      "Saved the embedding for withholding.\n",
      "woe is at index 885\n",
      "Saved the embedding for woe.\n",
      "woeful is at index 19958\n",
      "Saved the embedding for woeful.\n",
      "wonder is at index 5170\n",
      "Saved the embedding for wonder.\n",
      "wondering is at index 8020\n",
      "Saved the embedding for wondering.\n",
      "wonderment is at index 5170\n",
      "Saved the embedding for wonderment.\n",
      "wooly is at index 24815\n",
      "Saved the embedding for wooly.\n",
      "woozy is at index 24815\n",
      "Saved the embedding for woozy.\n",
      "worn is at index 10610\n",
      "Saved the embedding for worn.\n",
      "worried is at index 3915\n",
      "Saved the embedding for worried.\n",
      "worrisome is at index 29611\n",
      "Saved the embedding for worrisome.\n",
      "worry is at index 4022\n",
      "Saved the embedding for worry.\n",
      "worrying is at index 12648\n",
      "Saved the embedding for worrying.\n",
      "worryingly is at index 4022\n",
      "Saved the embedding for worryingly.\n",
      "wounded is at index 5424\n",
      "Saved the embedding for wounded.\n",
      "wow is at index 26388\n",
      "Saved the embedding for wow.\n",
      "wrathful is at index 30220\n",
      "Saved the embedding for wrathful.\n",
      "wrathfully is at index 30220\n",
      "Saved the embedding for wrathfully.\n",
      "wrecked is at index 30090\n",
      "Saved the embedding for wrecked.\n",
      "wretched is at index 42824\n",
      "Saved the embedding for wretched.\n",
      "wronged is at index 1593\n",
      "Saved the embedding for wronged.\n",
      "wroth is at index 885\n",
      "Saved the embedding for wroth.\n",
      "wry is at index 885\n",
      "Saved the embedding for wry.\n",
      "yawn is at index 39654\n",
      "Saved the embedding for yawn.\n",
      "yawning is at index 39654\n",
      "Saved the embedding for yawning.\n",
      "yearning is at index 76\n",
      "Saved the embedding for yearning.\n",
      "yell is at index 28930\n",
      "Saved the embedding for yell.\n",
      "yelling is at index 16600\n",
      "Saved the embedding for yelling.\n",
      "yielding is at index 25438\n",
      "Saved the embedding for yielding.\n",
      "yuck is at index 1423\n",
      "Saved the embedding for yuck.\n",
      "zany is at index 992\n",
      "Saved the embedding for zany.\n",
      "zealous is at index 992\n",
      "Saved the embedding for zealous.\n",
      "zen is at index 992\n",
      "Saved the embedding for zen.\n",
      "zoned is at index 992\n",
      "Saved the embedding for zoned.\n"
     ]
    }
   ],
   "source": [
    "################################################\n",
    "# This cell will write out input embeddings    #\n",
    "# for all the words in my vocabulary, using    #\n",
    "# pre-trained RoBERTa with no fine-tuning.     #\n",
    "################################################\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "model = RobertaForMaskedLM.from_pretrained('roberta-base', config=config)\n",
    "\n",
    "config = RobertaConfig.from_pretrained('roberta-base')\n",
    "config.output_hidden_states = True\n",
    "input_embeddings = model.get_input_embeddings()\n",
    "embeddings_file = '/home/jupyter/Notebooks/crystal/NLP/nlp_testing/embeddings_context_vocab/roberta_input.txt'\n",
    "for v in vocab:\n",
    "    v_tensor = torch.tensor([tokenizer.encode(v)])\n",
    "    # Print the index of the test word.\n",
    "    print(f'{v} is at index {v_tensor[0][1].item()}')\n",
    "#     print(input_embeddings_test(torch.LongTensor([v_tensor[0][1].item()])))\n",
    "    v_embed = input_embeddings(torch.LongTensor([v_tensor[0][1].item()]))\n",
    "#     for n in range(v_embed.size()[1])\n",
    "    try:\n",
    "        with open(embeddings_file, 'a') as f:\n",
    "            f.write(v)\n",
    "            for value in v_embed[0]:\n",
    "                f.write(' ' + str(value.item()))\n",
    "            f.write('\\n')\n",
    "        print(f'Saved the embedding for {v}.')\n",
    "    except:\n",
    "        print('Oh no! Unable to write to the embeddings file.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aback is at index 36347\n",
      "Saved the embedding for aback.\n",
      "abashed is at index 4091\n",
      "Saved the embedding for abashed.\n",
      "abhor is at index 35350\n",
      "Saved the embedding for abhor.\n",
      "abhorred is at index 35350\n",
      "Saved the embedding for abhorred.\n",
      "abhorrence is at index 35350\n",
      "Saved the embedding for abhorrence.\n",
      "abhorrent is at index 35350\n",
      "Saved the embedding for abhorrent.\n",
      "abominable is at index 4091\n",
      "Saved the embedding for abominable.\n",
      "abound is at index 32937\n",
      "Saved the embedding for abound.\n",
      "absent is at index 11640\n",
      "Saved the embedding for absent.\n",
      "absorbed is at index 22416\n",
      "Saved the embedding for absorbed.\n",
      "acceptance is at index 10502\n",
      "Saved the embedding for acceptance.\n",
      "accepted is at index 3903\n",
      "Saved the embedding for accepted.\n",
      "accepting is at index 8394\n",
      "Saved the embedding for accepting.\n",
      "accommodating is at index 33681\n",
      "Saved the embedding for accommodating.\n",
      "accomplished is at index 9370\n",
      "Saved the embedding for accomplished.\n",
      "accordant is at index 10170\n",
      "Saved the embedding for accordant.\n",
      "accursed is at index 7678\n",
      "Saved the embedding for accursed.\n",
      "accusatory is at index 23123\n",
      "Saved the embedding for accusatory.\n",
      "accused is at index 1238\n",
      "Saved the embedding for accused.\n",
      "accusing is at index 8601\n",
      "Saved the embedding for accusing.\n",
      "acerbic is at index 4285\n",
      "Saved the embedding for acerbic.\n",
      "acidic is at index 41314\n",
      "Saved the embedding for acidic.\n",
      "active is at index 2171\n",
      "Saved the embedding for active.\n",
      "acute is at index 13827\n",
      "Saved the embedding for acute.\n",
      "adamant is at index 22668\n",
      "Saved the embedding for adamant.\n",
      "addled is at index 1606\n",
      "Saved the embedding for addled.\n",
      "admiration is at index 24287\n",
      "Saved the embedding for admiration.\n",
      "admit is at index 8109\n",
      "Saved the embedding for admit.\n",
      "adoration is at index 2329\n",
      "Saved the embedding for adoration.\n",
      "adoring is at index 2329\n",
      "Saved the embedding for adoring.\n",
      "adrift is at index 2329\n",
      "Saved the embedding for adrift.\n",
      "adversarial is at index 37930\n",
      "Saved the embedding for adversarial.\n",
      "affability is at index 11129\n",
      "Saved the embedding for affability.\n",
      "affected is at index 2132\n",
      "Saved the embedding for affected.\n",
      "affectionate is at index 15955\n",
      "Saved the embedding for affectionate.\n",
      "afflicted is at index 39234\n",
      "Saved the embedding for afflicted.\n",
      "affronted is at index 11129\n",
      "Saved the embedding for affronted.\n",
      "aflutter is at index 10\n",
      "Saved the embedding for aflutter.\n",
      "afraid is at index 6023\n",
      "Saved the embedding for afraid.\n",
      "agape is at index 5951\n",
      "Saved the embedding for agape.\n",
      "aggravated is at index 10040\n",
      "Saved the embedding for aggravated.\n",
      "aggravation is at index 29223\n",
      "Saved the embedding for aggravation.\n",
      "aggression is at index 14227\n",
      "Saved the embedding for aggression.\n",
      "aggressive is at index 4353\n",
      "Saved the embedding for aggressive.\n",
      "aggrieve is at index 28940\n",
      "Saved the embedding for aggrieve.\n",
      "aggrieved is at index 28940\n",
      "Saved the embedding for aggrieved.\n",
      "aghast is at index 10\n",
      "Saved the embedding for aghast.\n",
      "agitated is at index 33426\n",
      "Saved the embedding for agitated.\n",
      "agog is at index 5951\n",
      "Saved the embedding for agog.\n",
      "agonized is at index 27497\n",
      "Saved the embedding for agonized.\n",
      "agreeable is at index 43359\n",
      "Saved the embedding for agreeable.\n",
      "agressive is at index 5951\n",
      "Saved the embedding for agressive.\n",
      "airhead is at index 935\n",
      "Saved the embedding for airhead.\n",
      "alarm is at index 8054\n",
      "Saved the embedding for alarm.\n",
      "alarmed is at index 23438\n",
      "Saved the embedding for alarmed.\n",
      "alarming is at index 16156\n",
      "Saved the embedding for alarming.\n",
      "alert is at index 5439\n",
      "Saved the embedding for alert.\n",
      "alerted is at index 14588\n",
      "Saved the embedding for alerted.\n",
      "alienated is at index 36462\n",
      "Saved the embedding for alienated.\n",
      "allergic is at index 28349\n",
      "Saved the embedding for allergic.\n",
      "alleviated is at index 32216\n",
      "Saved the embedding for alleviated.\n",
      "alluring is at index 70\n",
      "Saved the embedding for alluring.\n",
      "aloof is at index 1076\n",
      "Saved the embedding for aloof.\n",
      "amatory is at index 524\n",
      "Saved the embedding for amatory.\n",
      "amazed is at index 22431\n",
      "Saved the embedding for amazed.\n",
      "amazement is at index 42402\n",
      "Saved the embedding for amazement.\n",
      "amazing is at index 2770\n",
      "Saved the embedding for amazing.\n",
      "ambition is at index 12831\n",
      "Saved the embedding for ambition.\n",
      "ambitious is at index 8263\n",
      "Saved the embedding for ambitious.\n",
      "ambivalence is at index 13569\n",
      "Saved the embedding for ambivalence.\n",
      "ambivalent is at index 13569\n",
      "Saved the embedding for ambivalent.\n",
      "amenable is at index 524\n",
      "Saved the embedding for amenable.\n",
      "amiable is at index 524\n",
      "Saved the embedding for amiable.\n",
      "amicable is at index 524\n",
      "Saved the embedding for amicable.\n",
      "amused is at index 36530\n",
      "Saved the embedding for amused.\n",
      "amusement is at index 28445\n",
      "Saved the embedding for amusement.\n",
      "analytical is at index 23554\n",
      "Saved the embedding for analytical.\n",
      "analyzing is at index 18999\n",
      "Saved the embedding for analyzing.\n",
      "anger is at index 6378\n",
      "Saved the embedding for anger.\n",
      "angered is at index 20166\n",
      "Saved the embedding for angered.\n",
      "angrily is at index 30302\n",
      "Saved the embedding for angrily.\n",
      "angry is at index 5800\n",
      "Saved the embedding for angry.\n",
      "angst is at index 33010\n",
      "Saved the embedding for angst.\n",
      "anguish is at index 32446\n",
      "Saved the embedding for anguish.\n",
      "anguished is at index 5667\n",
      "Saved the embedding for anguished.\n",
      "animated is at index 12847\n",
      "Saved the embedding for animated.\n",
      "animosity is at index 34351\n",
      "Saved the embedding for animosity.\n",
      "annoyance is at index 39341\n",
      "Saved the embedding for annoyance.\n",
      "annoyed is at index 26678\n",
      "Saved the embedding for annoyed.\n",
      "annoying is at index 19887\n",
      "Saved the embedding for annoying.\n",
      "antagonistic is at index 32726\n",
      "Saved the embedding for antagonistic.\n",
      "antagonized is at index 32726\n",
      "Saved the embedding for antagonized.\n",
      "anticipated is at index 5291\n",
      "Saved the embedding for anticipated.\n",
      "anticipating is at index 22535\n",
      "Saved the embedding for anticipating.\n",
      "anticipation is at index 14714\n",
      "Saved the embedding for anticipation.\n",
      "anticipative is at index 21428\n",
      "Saved the embedding for anticipative.\n",
      "anticipatory is at index 21428\n",
      "Saved the embedding for anticipatory.\n",
      "antipathy is at index 37554\n",
      "Saved the embedding for antipathy.\n",
      "antsy is at index 32855\n",
      "Saved the embedding for antsy.\n",
      "anxiety is at index 6882\n",
      "Saved the embedding for anxiety.\n",
      "anxious is at index 13473\n",
      "Saved the embedding for anxious.\n",
      "anxiously is at index 27442\n",
      "Saved the embedding for anxiously.\n",
      "apathetic is at index 6256\n",
      "Saved the embedding for apathetic.\n",
      "apathy is at index 6256\n",
      "Saved the embedding for apathy.\n",
      "apologetic is at index 23842\n",
      "Saved the embedding for apologetic.\n",
      "appalled is at index 31514\n",
      "Saved the embedding for appalled.\n",
      "appallingly is at index 1553\n",
      "Saved the embedding for appallingly.\n",
      "appeased is at index 44151\n",
      "Saved the embedding for appeased.\n",
      "appeasing is at index 44151\n",
      "Saved the embedding for appeasing.\n",
      "appreciative is at index 14137\n",
      "Saved the embedding for appreciative.\n",
      "apprehension is at index 34640\n",
      "Saved the embedding for apprehension.\n",
      "apprehensive is at index 33655\n",
      "Saved the embedding for apprehensive.\n",
      "approve is at index 7244\n",
      "Saved the embedding for approve.\n",
      "approved is at index 2033\n",
      "Saved the embedding for approved.\n",
      "approving is at index 20499\n",
      "Saved the embedding for approving.\n",
      "argue is at index 5848\n",
      "Saved the embedding for argue.\n",
      "argumentative is at index 4795\n",
      "Saved the embedding for argumentative.\n",
      "aroused is at index 42941\n",
      "Saved the embedding for aroused.\n",
      "arrogance is at index 32818\n",
      "Saved the embedding for arrogance.\n",
      "arrogant is at index 30967\n",
      "Saved the embedding for arrogant.\n",
      "arrogantly is at index 46553\n",
      "Saved the embedding for arrogantly.\n",
      "artificial is at index 7350\n",
      "Saved the embedding for artificial.\n",
      "ashamed is at index 20085\n",
      "Saved the embedding for ashamed.\n",
      "aspiring is at index 18885\n",
      "Saved the embedding for aspiring.\n",
      "assertive is at index 18088\n",
      "Saved the embedding for assertive.\n",
      "assertively is at index 18088\n",
      "Saved the embedding for assertively.\n",
      "assessing is at index 16629\n",
      "Saved the embedding for assessing.\n",
      "assured is at index 7189\n",
      "Saved the embedding for assured.\n",
      "astonished is at index 40788\n",
      "Saved the embedding for astonished.\n",
      "astonishment is at index 44434\n",
      "Saved the embedding for astonishment.\n",
      "astounded is at index 12976\n",
      "Saved the embedding for astounded.\n",
      "attempting is at index 6475\n",
      "Saved the embedding for attempting.\n",
      "attentive is at index 36670\n",
      "Saved the embedding for attentive.\n",
      "attentiveness is at index 39879\n",
      "Saved the embedding for attentiveness.\n",
      "attracted is at index 7671\n",
      "Saved the embedding for attracted.\n",
      "avenging is at index 38796\n",
      "Saved the embedding for avenging.\n",
      "averse is at index 10\n",
      "Saved the embedding for averse.\n",
      "aversion is at index 33814\n",
      "Saved the embedding for aversion.\n",
      "aversive is at index 10\n",
      "Saved the embedding for aversive.\n",
      "avid is at index 20137\n",
      "Saved the embedding for avid.\n",
      "avoiding is at index 11473\n",
      "Saved the embedding for avoiding.\n",
      "awaiting is at index 10254\n",
      "Saved the embedding for awaiting.\n",
      "awakened is at index 40593\n",
      "Saved the embedding for awakened.\n",
      "aware is at index 2542\n",
      "Saved the embedding for aware.\n",
      "awareness is at index 4199\n",
      "Saved the embedding for awareness.\n",
      "awe is at index 21531\n",
      "Saved the embedding for awe.\n",
      "awed is at index 19267\n",
      "Saved the embedding for awed.\n",
      "awestruck is at index 19267\n",
      "Saved the embedding for awestruck.\n",
      "awful is at index 11522\n",
      "Saved the embedding for awful.\n",
      "awkward is at index 11789\n",
      "Saved the embedding for awkward.\n",
      "awkwardness is at index 11789\n",
      "Saved the embedding for awkwardness.\n",
      "axed is at index 18884\n",
      "Saved the embedding for axed.\n",
      "backhanded is at index 124\n",
      "Saved the embedding for backhanded.\n",
      "badly is at index 7340\n",
      "Saved the embedding for badly.\n",
      "baffle is at index 33139\n",
      "Saved the embedding for baffle.\n",
      "baffled is at index 33396\n",
      "Saved the embedding for baffled.\n",
      "baffling is at index 33139\n",
      "Saved the embedding for baffling.\n",
      "baked is at index 17241\n",
      "Saved the embedding for baked.\n",
      "banal is at index 2020\n",
      "Saved the embedding for banal.\n",
      "barking is at index 35828\n",
      "Saved the embedding for barking.\n",
      "bashful is at index 12882\n",
      "Saved the embedding for bashful.\n",
      "beaming is at index 28\n",
      "Saved the embedding for beaming.\n",
      "bearish is at index 4649\n",
      "Saved the embedding for bearish.\n",
      "beat is at index 1451\n",
      "Saved the embedding for beat.\n",
      "beaten is at index 6432\n",
      "Saved the embedding for beaten.\n",
      "bedeviled is at index 3267\n",
      "Saved the embedding for bedeviled.\n",
      "befuddled is at index 28\n",
      "Saved the embedding for befuddled.\n",
      "begging is at index 22901\n",
      "Saved the embedding for begging.\n",
      "begrudge is at index 28\n",
      "Saved the embedding for begrudge.\n",
      "begrudging is at index 28\n",
      "Saved the embedding for begrudging.\n",
      "begrudgingly is at index 28\n",
      "Saved the embedding for begrudgingly.\n",
      "beguiled is at index 21422\n",
      "Saved the embedding for beguiled.\n",
      "belated is at index 12138\n",
      "Saved the embedding for belated.\n",
      "belittling is at index 12138\n",
      "Saved the embedding for belittling.\n",
      "belligerence is at index 35756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for belligerence.\n",
      "belligerent is at index 35756\n",
      "Saved the embedding for belligerent.\n",
      "belonging is at index 11441\n",
      "Saved the embedding for belonging.\n",
      "bemused is at index 28\n",
      "Saved the embedding for bemused.\n",
      "bemusement is at index 28\n",
      "Saved the embedding for bemusement.\n",
      "benevolence is at index 42364\n",
      "Saved the embedding for benevolence.\n",
      "benevolent is at index 43186\n",
      "Saved the embedding for benevolent.\n",
      "benumbed is at index 21576\n",
      "Saved the embedding for benumbed.\n",
      "berate is at index 14719\n",
      "Saved the embedding for berate.\n",
      "berating is at index 14719\n",
      "Saved the embedding for berating.\n",
      "bereaved is at index 17738\n",
      "Saved the embedding for bereaved.\n",
      "bereft is at index 17738\n",
      "Saved the embedding for bereft.\n",
      "beseeching is at index 9988\n",
      "Saved the embedding for beseeching.\n",
      "bested is at index 275\n",
      "Saved the embedding for bested.\n",
      "betrayal is at index 26760\n",
      "Saved the embedding for betrayal.\n",
      "betrayed is at index 26913\n",
      "Saved the embedding for betrayed.\n",
      "bewildered is at index 33304\n",
      "Saved the embedding for bewildered.\n",
      "bewilderment is at index 33304\n",
      "Saved the embedding for bewilderment.\n",
      "bi is at index 4003\n",
      "Saved the embedding for bi.\n",
      "bilious is at index 31617\n",
      "Saved the embedding for bilious.\n",
      "bit is at index 828\n",
      "Saved the embedding for bit.\n",
      "biting is at index 25609\n",
      "Saved the embedding for biting.\n",
      "bitter is at index 10513\n",
      "Saved the embedding for bitter.\n",
      "bittersweet is at index 28609\n",
      "Saved the embedding for bittersweet.\n",
      "blaming is at index 15249\n",
      "Saved the embedding for blaming.\n",
      "bland is at index 35063\n",
      "Saved the embedding for bland.\n",
      "blank is at index 15818\n",
      "Saved the embedding for blank.\n",
      "blase is at index 3089\n",
      "Saved the embedding for blase.\n",
      "blazed is at index 3089\n",
      "Saved the embedding for blazed.\n",
      "bleak is at index 23530\n",
      "Saved the embedding for bleak.\n",
      "bleary is at index 13819\n",
      "Saved the embedding for bleary.\n",
      "blessed is at index 12230\n",
      "Saved the embedding for blessed.\n",
      "blew is at index 10879\n",
      "Saved the embedding for blew.\n",
      "blinded is at index 40094\n",
      "Saved the embedding for blinded.\n",
      "blindsided is at index 7709\n",
      "Saved the embedding for blindsided.\n",
      "bliss is at index 30299\n",
      "Saved the embedding for bliss.\n",
      "blissful is at index 30299\n",
      "Saved the embedding for blissful.\n",
      "blissfully is at index 30299\n",
      "Saved the embedding for blissfully.\n",
      "blithe is at index 3089\n",
      "Saved the embedding for blithe.\n",
      "blown is at index 12315\n",
      "Saved the embedding for blown.\n",
      "blue is at index 2440\n",
      "Saved the embedding for blue.\n",
      "blues is at index 15629\n",
      "Saved the embedding for blues.\n",
      "bluffing is at index 37372\n",
      "Saved the embedding for bluffing.\n",
      "blunt is at index 18720\n",
      "Saved the embedding for blunt.\n",
      "blushing is at index 3089\n",
      "Saved the embedding for blushing.\n",
      "blustering is at index 3089\n",
      "Saved the embedding for blustering.\n",
      "boastful is at index 18639\n",
      "Saved the embedding for boastful.\n",
      "boggled is at index 741\n",
      "Saved the embedding for boggled.\n",
      "boiling is at index 27513\n",
      "Saved the embedding for boiling.\n",
      "boisterous is at index 5276\n",
      "Saved the embedding for boisterous.\n",
      "bold is at index 7457\n",
      "Saved the embedding for bold.\n",
      "bored is at index 23809\n",
      "Saved the embedding for bored.\n",
      "boredom is at index 40326\n",
      "Saved the embedding for boredom.\n",
      "boring is at index 15305\n",
      "Saved the embedding for boring.\n",
      "bothered is at index 18523\n",
      "Saved the embedding for bothered.\n",
      "bounder is at index 8191\n",
      "Saved the embedding for bounder.\n",
      "brashness is at index 5378\n",
      "Saved the embedding for brashness.\n",
      "bratty is at index 5378\n",
      "Saved the embedding for bratty.\n",
      "brave is at index 10025\n",
      "Saved the embedding for brave.\n",
      "bright is at index 4520\n",
      "Saved the embedding for bright.\n",
      "bristling is at index 37135\n",
      "Saved the embedding for bristling.\n",
      "broken is at index 3187\n",
      "Saved the embedding for broken.\n",
      "brokenhearted is at index 3187\n",
      "Saved the embedding for brokenhearted.\n",
      "brokenheartedly is at index 3187\n",
      "Saved the embedding for brokenheartedly.\n",
      "brooding is at index 11051\n",
      "Saved the embedding for brooding.\n",
      "broody is at index 11051\n",
      "Saved the embedding for broody.\n",
      "bruised is at index 26360\n",
      "Saved the embedding for bruised.\n",
      "brusque is at index 5378\n",
      "Saved the embedding for brusque.\n",
      "bug is at index 13673\n",
      "Saved the embedding for bug.\n",
      "bulging is at index 22382\n",
      "Saved the embedding for bulging.\n",
      "bully is at index 23934\n",
      "Saved the embedding for bully.\n",
      "bullying is at index 11902\n",
      "Saved the embedding for bullying.\n",
      "bummed is at index 29673\n",
      "Saved the embedding for bummed.\n",
      "buoyant is at index 15980\n",
      "Saved the embedding for buoyant.\n",
      "burdened is at index 32875\n",
      "Saved the embedding for burdened.\n",
      "burn is at index 7403\n",
      "Saved the embedding for burn.\n",
      "bursting is at index 28548\n",
      "Saved the embedding for bursting.\n",
      "bushed is at index 2353\n",
      "Saved the embedding for bushed.\n",
      "cagey is at index 16051\n",
      "Saved the embedding for cagey.\n",
      "cagy is at index 740\n",
      "Saved the embedding for cagy.\n",
      "calculating is at index 29770\n",
      "Saved the embedding for calculating.\n",
      "callous is at index 486\n",
      "Saved the embedding for callous.\n",
      "callused is at index 486\n",
      "Saved the embedding for callused.\n",
      "calm is at index 6327\n",
      "Saved the embedding for calm.\n",
      "calming is at index 31220\n",
      "Saved the embedding for calming.\n",
      "calmness is at index 6327\n",
      "Saved the embedding for calmness.\n",
      "canny is at index 64\n",
      "Saved the embedding for canny.\n",
      "cantankerous is at index 17672\n",
      "Saved the embedding for cantankerous.\n",
      "capable is at index 4453\n",
      "Saved the embedding for capable.\n",
      "capricious is at index 2927\n",
      "Saved the embedding for capricious.\n",
      "captivated is at index 13363\n",
      "Saved the embedding for captivated.\n",
      "captive is at index 24145\n",
      "Saved the embedding for captive.\n",
      "carefree is at index 575\n",
      "Saved the embedding for carefree.\n",
      "careful is at index 7316\n",
      "Saved the embedding for careful.\n",
      "careless is at index 29399\n",
      "Saved the embedding for careless.\n",
      "caring is at index 10837\n",
      "Saved the embedding for caring.\n",
      "catty is at index 4758\n",
      "Saved the embedding for catty.\n",
      "caustic is at index 6056\n",
      "Saved the embedding for caustic.\n",
      "cautionary is at index 8038\n",
      "Saved the embedding for cautionary.\n",
      "cautious is at index 9420\n",
      "Saved the embedding for cautious.\n",
      "cavalier is at index 41869\n",
      "Saved the embedding for cavalier.\n",
      "celebrating is at index 6146\n",
      "Saved the embedding for celebrating.\n",
      "celebration is at index 4821\n",
      "Saved the embedding for celebration.\n",
      "censure is at index 26489\n",
      "Saved the embedding for censure.\n",
      "centered is at index 14889\n",
      "Saved the embedding for centered.\n",
      "certain is at index 1402\n",
      "Saved the embedding for certain.\n",
      "chafed is at index 1855\n",
      "Saved the embedding for chafed.\n",
      "chagrin is at index 1855\n",
      "Saved the embedding for chagrin.\n",
      "chagrined is at index 1855\n",
      "Saved the embedding for chagrined.\n",
      "chagrinned is at index 1855\n",
      "Saved the embedding for chagrinned.\n",
      "challenge is at index 1539\n",
      "Saved the embedding for challenge.\n",
      "challenged is at index 6835\n",
      "Saved the embedding for challenged.\n",
      "challenging is at index 4087\n",
      "Saved the embedding for challenging.\n",
      "chaotic is at index 16529\n",
      "Saved the embedding for chaotic.\n",
      "charged is at index 1340\n",
      "Saved the embedding for charged.\n",
      "charmed is at index 16224\n",
      "Saved the embedding for charmed.\n",
      "charming is at index 18452\n",
      "Saved the embedding for charming.\n",
      "chary is at index 1855\n",
      "Saved the embedding for chary.\n",
      "cheated is at index 25177\n",
      "Saved the embedding for cheated.\n",
      "cheeky is at index 15401\n",
      "Saved the embedding for cheeky.\n",
      "cheered is at index 18643\n",
      "Saved the embedding for cheered.\n",
      "cheerful is at index 33928\n",
      "Saved the embedding for cheerful.\n",
      "cheering is at index 16765\n",
      "Saved the embedding for cheering.\n",
      "cheerless is at index 9450\n",
      "Saved the embedding for cheerless.\n",
      "cheery is at index 5851\n",
      "Saved the embedding for cheery.\n",
      "cheesy is at index 36331\n",
      "Saved the embedding for cheesy.\n",
      "chesty is at index 7050\n",
      "Saved the embedding for chesty.\n",
      "chide is at index 1855\n",
      "Saved the embedding for chide.\n",
      "chiding is at index 1855\n",
      "Saved the embedding for chiding.\n",
      "childish is at index 40531\n",
      "Saved the embedding for childish.\n",
      "childishly is at index 920\n",
      "Saved the embedding for childishly.\n",
      "childlike is at index 920\n",
      "Saved the embedding for childlike.\n",
      "chill is at index 13146\n",
      "Saved the embedding for chill.\n",
      "chilled is at index 32338\n",
      "Saved the embedding for chilled.\n",
      "chilling is at index 22577\n",
      "Saved the embedding for chilling.\n",
      "chipper is at index 1855\n",
      "Saved the embedding for chipper.\n",
      "chirpy is at index 1855\n",
      "Saved the embedding for chirpy.\n",
      "choleric is at index 1855\n",
      "Saved the embedding for choleric.\n",
      "chortling is at index 1855\n",
      "Saved the embedding for chortling.\n",
      "chuckle is at index 37496\n",
      "Saved the embedding for chuckle.\n",
      "chuckling is at index 34600\n",
      "Saved the embedding for chuckling.\n",
      "churlish is at index 1855\n",
      "Saved the embedding for churlish.\n",
      "circumspect is at index 38529\n",
      "Saved the embedding for circumspect.\n",
      "clamorous is at index 24045\n",
      "Saved the embedding for clamorous.\n",
      "clash is at index 6064\n",
      "Saved the embedding for clash.\n",
      "clear is at index 699\n",
      "Saved the embedding for clear.\n",
      "clenched is at index 44646\n",
      "Saved the embedding for clenched.\n",
      "clever is at index 13074\n",
      "Saved the embedding for clever.\n",
      "close is at index 593\n",
      "Saved the embedding for close.\n",
      "closed is at index 1367\n",
      "Saved the embedding for closed.\n",
      "closemouthed is at index 593\n",
      "Saved the embedding for closemouthed.\n",
      "cloy is at index 3741\n",
      "Saved the embedding for cloy.\n",
      "clueless is at index 36776\n",
      "Saved the embedding for clueless.\n",
      "clutched is at index 29409\n",
      "Saved the embedding for clutched.\n",
      "cluttered is at index 29409\n",
      "Saved the embedding for cluttered.\n",
      "cockeyed is at index 740\n",
      "Saved the embedding for cockeyed.\n",
      "cockiness is at index 24231\n",
      "Saved the embedding for cockiness.\n",
      "cocksure is at index 740\n",
      "Saved the embedding for cocksure.\n",
      "cocky is at index 24231\n",
      "Saved the embedding for cocky.\n",
      "cognizant is at index 28105\n",
      "Saved the embedding for cognizant.\n",
      "cold is at index 2569\n",
      "Saved the embedding for cold.\n",
      "collected is at index 4786\n",
      "Saved the embedding for collected.\n",
      "collusive is at index 9843\n",
      "Saved the embedding for collusive.\n",
      "colonized is at index 17735\n",
      "Saved the embedding for colonized.\n",
      "combative is at index 14960\n",
      "Saved the embedding for combative.\n",
      "comedic is at index 29045\n",
      "Saved the embedding for comedic.\n",
      "comfort is at index 5863\n",
      "Saved the embedding for comfort.\n",
      "comfortable is at index 3473\n",
      "Saved the embedding for comfortable.\n",
      "comforted is at index 5863\n",
      "Saved the embedding for comforted.\n",
      "comical is at index 3137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for comical.\n",
      "commanding is at index 20510\n",
      "Saved the embedding for commanding.\n",
      "commiserating is at index 7034\n",
      "Saved the embedding for commiserating.\n",
      "commiserative is at index 7034\n",
      "Saved the embedding for commiserative.\n",
      "communicative is at index 16759\n",
      "Saved the embedding for communicative.\n",
      "compassion is at index 14736\n",
      "Saved the embedding for compassion.\n",
      "compassionate is at index 23303\n",
      "Saved the embedding for compassionate.\n",
      "competent is at index 17451\n",
      "Saved the embedding for competent.\n",
      "competitive is at index 2695\n",
      "Saved the embedding for competitive.\n",
      "complacence is at index 13000\n",
      "Saved the embedding for complacence.\n",
      "complacency is at index 13000\n",
      "Saved the embedding for complacency.\n",
      "complacent is at index 13000\n",
      "Saved the embedding for complacent.\n",
      "complacently is at index 13000\n",
      "Saved the embedding for complacently.\n",
      "complain is at index 11316\n",
      "Saved the embedding for complain.\n",
      "complaining is at index 13689\n",
      "Saved the embedding for complaining.\n",
      "composed is at index 14092\n",
      "Saved the embedding for composed.\n",
      "comprehending is at index 30030\n",
      "Saved the embedding for comprehending.\n",
      "compulsive is at index 7753\n",
      "Saved the embedding for compulsive.\n",
      "concealed is at index 17180\n",
      "Saved the embedding for concealed.\n",
      "conceding is at index 24647\n",
      "Saved the embedding for conceding.\n",
      "conceited is at index 21177\n",
      "Saved the embedding for conceited.\n",
      "concentrated is at index 15450\n",
      "Saved the embedding for concentrated.\n",
      "concentrating is at index 28619\n",
      "Saved the embedding for concentrating.\n",
      "concentration is at index 11772\n",
      "Saved the embedding for concentration.\n",
      "concern is at index 2212\n",
      "Saved the embedding for concern.\n",
      "concerned is at index 2273\n",
      "Saved the embedding for concerned.\n",
      "conciliatory is at index 10146\n",
      "Saved the embedding for conciliatory.\n",
      "conclusive is at index 37847\n",
      "Saved the embedding for conclusive.\n",
      "condemning is at index 21856\n",
      "Saved the embedding for condemning.\n",
      "condescending is at index 40742\n",
      "Saved the embedding for condescending.\n",
      "condoling is at index 35279\n",
      "Saved the embedding for condoling.\n",
      "confidence is at index 2123\n",
      "Saved the embedding for confidence.\n",
      "confident is at index 3230\n",
      "Saved the embedding for confident.\n",
      "confidently is at index 27447\n",
      "Saved the embedding for confidently.\n",
      "conflicted is at index 34428\n",
      "Saved the embedding for conflicted.\n",
      "confound is at index 7856\n",
      "Saved the embedding for confound.\n",
      "confounded is at index 7856\n",
      "Saved the embedding for confounded.\n",
      "confrontational is at index 10749\n",
      "Saved the embedding for confrontational.\n",
      "confused is at index 10985\n",
      "Saved the embedding for confused.\n",
      "confusion is at index 9655\n",
      "Saved the embedding for confusion.\n",
      "congenial is at index 36764\n",
      "Saved the embedding for congenial.\n",
      "congratulatory is at index 26303\n",
      "Saved the embedding for congratulatory.\n",
      "conniving is at index 39277\n",
      "Saved the embedding for conniving.\n",
      "conscious is at index 13316\n",
      "Saved the embedding for conscious.\n",
      "conservative is at index 3354\n",
      "Saved the embedding for conservative.\n",
      "considerate is at index 1701\n",
      "Saved the embedding for considerate.\n",
      "considering is at index 2811\n",
      "Saved the embedding for considering.\n",
      "consoling is at index 7407\n",
      "Saved the embedding for consoling.\n",
      "conspiratorial is at index 31150\n",
      "Saved the embedding for conspiratorial.\n",
      "conspiring is at index 27230\n",
      "Saved the embedding for conspiring.\n",
      "consternation is at index 10759\n",
      "Saved the embedding for consternation.\n",
      "constipated is at index 10759\n",
      "Saved the embedding for constipated.\n",
      "constrained is at index 26525\n",
      "Saved the embedding for constrained.\n",
      "consumed is at index 13056\n",
      "Saved the embedding for consumed.\n",
      "consuming is at index 16997\n",
      "Saved the embedding for consuming.\n",
      "contained is at index 5558\n",
      "Saved the embedding for contained.\n",
      "contemplate is at index 32848\n",
      "Saved the embedding for contemplate.\n",
      "contemplating is at index 27744\n",
      "Saved the embedding for contemplating.\n",
      "contemplation is at index 44072\n",
      "Saved the embedding for contemplation.\n",
      "contemplative is at index 43580\n",
      "Saved the embedding for contemplative.\n",
      "contempt is at index 16176\n",
      "Saved the embedding for contempt.\n",
      "contemptuous is at index 16176\n",
      "Saved the embedding for contemptuous.\n",
      "content is at index 1383\n",
      "Saved the embedding for content.\n",
      "contented is at index 1383\n",
      "Saved the embedding for contented.\n",
      "contentious is at index 14883\n",
      "Saved the embedding for contentious.\n",
      "contently is at index 8541\n",
      "Saved the embedding for contently.\n",
      "contentment is at index 1383\n",
      "Saved the embedding for contentment.\n",
      "contradictory is at index 31515\n",
      "Saved the embedding for contradictory.\n",
      "contrary is at index 11159\n",
      "Saved the embedding for contrary.\n",
      "contrite is at index 17035\n",
      "Saved the embedding for contrite.\n",
      "controlled is at index 4875\n",
      "Saved the embedding for controlled.\n",
      "controlling is at index 10568\n",
      "Saved the embedding for controlling.\n",
      "controversial is at index 4456\n",
      "Saved the embedding for controversial.\n",
      "contumacious is at index 8541\n",
      "Saved the embedding for contumacious.\n",
      "convinced is at index 7013\n",
      "Saved the embedding for convinced.\n",
      "cool is at index 3035\n",
      "Saved the embedding for cool.\n",
      "cooperative is at index 18777\n",
      "Saved the embedding for cooperative.\n",
      "cordial is at index 13051\n",
      "Saved the embedding for cordial.\n",
      "courageous is at index 24219\n",
      "Saved the embedding for courageous.\n",
      "covert is at index 25523\n",
      "Saved the embedding for covert.\n",
      "cowardly is at index 36881\n",
      "Saved the embedding for cowardly.\n",
      "coy is at index 20176\n",
      "Saved the embedding for coy.\n",
      "crabby is at index 23320\n",
      "Saved the embedding for crabby.\n",
      "crafty is at index 6306\n",
      "Saved the embedding for crafty.\n",
      "cranky is at index 30952\n",
      "Saved the embedding for cranky.\n",
      "crazed is at index 26002\n",
      "Saved the embedding for crazed.\n",
      "crazy is at index 5373\n",
      "Saved the embedding for crazy.\n",
      "credulous is at index 18994\n",
      "Saved the embedding for credulous.\n",
      "creepy is at index 23814\n",
      "Saved the embedding for creepy.\n",
      "crestfallen is at index 32220\n",
      "Saved the embedding for crestfallen.\n",
      "cringing is at index 3977\n",
      "Saved the embedding for cringing.\n",
      "critical is at index 2008\n",
      "Saved the embedding for critical.\n",
      "cross is at index 2116\n",
      "Saved the embedding for cross.\n",
      "crotchety is at index 11398\n",
      "Saved the embedding for crotchety.\n",
      "crude is at index 2976\n",
      "Saved the embedding for crude.\n",
      "cruel is at index 15939\n",
      "Saved the embedding for cruel.\n",
      "crushed is at index 14045\n",
      "Saved the embedding for crushed.\n",
      "cry is at index 8930\n",
      "Saved the embedding for cry.\n",
      "crying is at index 9701\n",
      "Saved the embedding for crying.\n",
      "cryptic is at index 35916\n",
      "Saved the embedding for cryptic.\n",
      "culpable is at index 29410\n",
      "Saved the embedding for culpable.\n",
      "cunning is at index 41526\n",
      "Saved the embedding for cunning.\n",
      "curios is at index 5350\n",
      "Saved the embedding for curios.\n",
      "curiosity is at index 20610\n",
      "Saved the embedding for curiosity.\n",
      "curious is at index 10691\n",
      "Saved the embedding for curious.\n",
      "cutting is at index 3931\n",
      "Saved the embedding for cutting.\n",
      "cynic is at index 40240\n",
      "Saved the embedding for cynic.\n",
      "cynical is at index 27566\n",
      "Saved the embedding for cynical.\n",
      "cynicism is at index 39245\n",
      "Saved the embedding for cynicism.\n",
      "dalliance is at index 385\n",
      "Saved the embedding for dalliance.\n",
      "dandy is at index 385\n",
      "Saved the embedding for dandy.\n",
      "dangerous is at index 2702\n",
      "Saved the embedding for dangerous.\n",
      "darkly is at index 2933\n",
      "Saved the embedding for darkly.\n",
      "daunted is at index 385\n",
      "Saved the embedding for daunted.\n",
      "daydream is at index 183\n",
      "Saved the embedding for daydream.\n",
      "daydreaming is at index 183\n",
      "Saved the embedding for daydreaming.\n",
      "dazed is at index 385\n",
      "Saved the embedding for dazed.\n",
      "dazzled is at index 32614\n",
      "Saved the embedding for dazzled.\n",
      "deadly is at index 4847\n",
      "Saved the embedding for deadly.\n",
      "deadpan is at index 1462\n",
      "Saved the embedding for deadpan.\n",
      "debate is at index 2625\n",
      "Saved the embedding for debate.\n",
      "debating is at index 24996\n",
      "Saved the embedding for debating.\n",
      "debauched is at index 10189\n",
      "Saved the embedding for debauched.\n",
      "deceitful is at index 35049\n",
      "Saved the embedding for deceitful.\n",
      "deceived is at index 38079\n",
      "Saved the embedding for deceived.\n",
      "deceiving is at index 34575\n",
      "Saved the embedding for deceiving.\n",
      "deceivingly is at index 34575\n",
      "Saved the embedding for deceivingly.\n",
      "deception is at index 29244\n",
      "Saved the embedding for deception.\n",
      "deceptive is at index 31405\n",
      "Saved the embedding for deceptive.\n",
      "deciding is at index 8997\n",
      "Saved the embedding for deciding.\n",
      "decisive is at index 12703\n",
      "Saved the embedding for decisive.\n",
      "dedicated is at index 3688\n",
      "Saved the embedding for dedicated.\n",
      "defeat is at index 3002\n",
      "Saved the embedding for defeat.\n",
      "defeated is at index 5125\n",
      "Saved the embedding for defeated.\n",
      "defenseless is at index 3816\n",
      "Saved the embedding for defenseless.\n",
      "defensive is at index 2465\n",
      "Saved the embedding for defensive.\n",
      "defiance is at index 25442\n",
      "Saved the embedding for defiance.\n",
      "defiant is at index 23802\n",
      "Saved the embedding for defiant.\n",
      "deflated is at index 3816\n",
      "Saved the embedding for deflated.\n",
      "degage is at index 31295\n",
      "Saved the embedding for degage.\n",
      "degrading is at index 36892\n",
      "Saved the embedding for degrading.\n",
      "dejected is at index 263\n",
      "Saved the embedding for dejected.\n",
      "dejection is at index 263\n",
      "Saved the embedding for dejection.\n",
      "deliberate is at index 14775\n",
      "Saved the embedding for deliberate.\n",
      "deliberating is at index 21614\n",
      "Saved the embedding for deliberating.\n",
      "delight is at index 13213\n",
      "Saved the embedding for delight.\n",
      "delighted is at index 7808\n",
      "Saved the embedding for delighted.\n",
      "delightful is at index 24897\n",
      "Saved the embedding for delightful.\n",
      "delirious is at index 2424\n",
      "Saved the embedding for delirious.\n",
      "delirium is at index 2424\n",
      "Saved the embedding for delirium.\n",
      "delude is at index 2424\n",
      "Saved the embedding for delude.\n",
      "delusional is at index 40160\n",
      "Saved the embedding for delusional.\n",
      "demanding is at index 5783\n",
      "Saved the embedding for demanding.\n",
      "demeaning is at index 4410\n",
      "Saved the embedding for demeaning.\n",
      "demented is at index 44202\n",
      "Saved the embedding for demented.\n",
      "demised is at index 4410\n",
      "Saved the embedding for demised.\n",
      "demoralized is at index 36810\n",
      "Saved the embedding for demoralized.\n",
      "demure is at index 4410\n",
      "Saved the embedding for demure.\n",
      "denied is at index 2296\n",
      "Saved the embedding for denied.\n",
      "denouncing is at index 32439\n",
      "Saved the embedding for denouncing.\n",
      "depleted is at index 26391\n",
      "Saved the embedding for depleted.\n",
      "deplorable is at index 28156\n",
      "Saved the embedding for deplorable.\n",
      "deprecating is at index 8273\n",
      "Saved the embedding for deprecating.\n",
      "depressed is at index 16658\n",
      "Saved the embedding for depressed.\n",
      "depression is at index 6943\n",
      "Saved the embedding for depression.\n",
      "deprived is at index 22632\n",
      "Saved the embedding for deprived.\n",
      "deranged is at index 1935\n",
      "Saved the embedding for deranged.\n",
      "derision is at index 1935\n",
      "Saved the embedding for derision.\n",
      "derisive is at index 1935\n",
      "Saved the embedding for derisive.\n",
      "derogatory is at index 30971\n",
      "Saved the embedding for derogatory.\n",
      "desire is at index 4724\n",
      "Saved the embedding for desire.\n",
      "desiring is at index 2694\n",
      "Saved the embedding for desiring.\n",
      "desirous is at index 2694\n",
      "Saved the embedding for desirous.\n",
      "desolate is at index 43177\n",
      "Saved the embedding for desolate.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "despair is at index 21508\n",
      "Saved the embedding for despair.\n",
      "despaired is at index 2694\n",
      "Saved the embedding for despaired.\n",
      "despairing is at index 21508\n",
      "Saved the embedding for despairing.\n",
      "desperate is at index 7764\n",
      "Saved the embedding for desperate.\n",
      "desperation is at index 24278\n",
      "Saved the embedding for desperation.\n",
      "despise is at index 43255\n",
      "Saved the embedding for despise.\n",
      "despondent is at index 18690\n",
      "Saved the embedding for despondent.\n",
      "destitute is at index 15357\n",
      "Saved the embedding for destitute.\n",
      "destroyed is at index 4957\n",
      "Saved the embedding for destroyed.\n",
      "detached is at index 27687\n",
      "Saved the embedding for detached.\n",
      "determination is at index 8964\n",
      "Saved the embedding for determination.\n",
      "determined is at index 3030\n",
      "Saved the embedding for determined.\n",
      "determining is at index 13684\n",
      "Saved the embedding for determining.\n",
      "deterred is at index 10922\n",
      "Saved the embedding for deterred.\n",
      "detest is at index 6769\n",
      "Saved the embedding for detest.\n",
      "detestable is at index 6769\n",
      "Saved the embedding for detestable.\n",
      "detesting is at index 6769\n",
      "Saved the embedding for detesting.\n",
      "detriment is at index 31969\n",
      "Saved the embedding for detriment.\n",
      "devastated is at index 11521\n",
      "Saved the embedding for devastated.\n",
      "deviant is at index 8709\n",
      "Saved the embedding for deviant.\n",
      "devilish is at index 22406\n",
      "Saved the embedding for devilish.\n",
      "devious is at index 263\n",
      "Saved the embedding for devious.\n",
      "devising is at index 8709\n",
      "Saved the embedding for devising.\n",
      "diffident is at index 25871\n",
      "Saved the embedding for diffident.\n",
      "dilatory is at index 14632\n",
      "Saved the embedding for dilatory.\n",
      "diligent is at index 33721\n",
      "Saved the embedding for diligent.\n",
      "dimwitted is at index 14548\n",
      "Saved the embedding for dimwitted.\n",
      "dire is at index 10697\n",
      "Saved the embedding for dire.\n",
      "disagree is at index 11967\n",
      "Saved the embedding for disagree.\n",
      "disagreeable is at index 11967\n",
      "Saved the embedding for disagreeable.\n",
      "disagreement is at index 20628\n",
      "Saved the embedding for disagreement.\n",
      "disappointed is at index 5779\n",
      "Saved the embedding for disappointed.\n",
      "disappointing is at index 6770\n",
      "Saved the embedding for disappointing.\n",
      "disappointment is at index 10208\n",
      "Saved the embedding for disappointment.\n",
      "disapproval is at index 32129\n",
      "Saved the embedding for disapproval.\n",
      "disapproving is at index 36631\n",
      "Saved the embedding for disapproving.\n",
      "disbelief is at index 26440\n",
      "Saved the embedding for disbelief.\n",
      "disbelieve is at index 45668\n",
      "Saved the embedding for disbelieve.\n",
      "disbelieving is at index 45668\n",
      "Saved the embedding for disbelieving.\n",
      "discerning is at index 9553\n",
      "Saved the embedding for discerning.\n",
      "discombobulated is at index 2982\n",
      "Saved the embedding for discombobulated.\n",
      "discomfited is at index 2982\n",
      "Saved the embedding for discomfited.\n",
      "discomfort is at index 19535\n",
      "Saved the embedding for discomfort.\n",
      "discomforted is at index 19535\n",
      "Saved the embedding for discomforted.\n",
      "disconcerted is at index 2982\n",
      "Saved the embedding for disconcerted.\n",
      "disconnected is at index 30005\n",
      "Saved the embedding for disconnected.\n",
      "disconsolate is at index 9553\n",
      "Saved the embedding for disconsolate.\n",
      "discontent is at index 27478\n",
      "Saved the embedding for discontent.\n",
      "discontented is at index 47772\n",
      "Saved the embedding for discontented.\n",
      "discounted is at index 17533\n",
      "Saved the embedding for discounted.\n",
      "discouraged is at index 25788\n",
      "Saved the embedding for discouraged.\n",
      "discovery is at index 6953\n",
      "Saved the embedding for discovery.\n",
      "discriminating is at index 38303\n",
      "Saved the embedding for discriminating.\n",
      "discussed is at index 3373\n",
      "Saved the embedding for discussed.\n",
      "disdain is at index 29512\n",
      "Saved the embedding for disdain.\n",
      "disdained is at index 2982\n",
      "Saved the embedding for disdained.\n",
      "disdainful is at index 29512\n",
      "Saved the embedding for disdainful.\n",
      "disdainfully is at index 29512\n",
      "Saved the embedding for disdainfully.\n",
      "disenchanted is at index 2982\n",
      "Saved the embedding for disenchanted.\n",
      "disengaged is at index 35170\n",
      "Saved the embedding for disengaged.\n",
      "disgraced is at index 25425\n",
      "Saved the embedding for disgraced.\n",
      "disgruntled is at index 29412\n",
      "Saved the embedding for disgruntled.\n",
      "disgruntlement is at index 25425\n",
      "Saved the embedding for disgruntlement.\n",
      "disgust is at index 30883\n",
      "Saved the embedding for disgust.\n",
      "disgusted is at index 32759\n",
      "Saved the embedding for disgusted.\n",
      "disgustedly is at index 32759\n",
      "Saved the embedding for disgustedly.\n",
      "disgusting is at index 21096\n",
      "Saved the embedding for disgusting.\n",
      "disheartened is at index 2982\n",
      "Saved the embedding for disheartened.\n",
      "dishonest is at index 27820\n",
      "Saved the embedding for dishonest.\n",
      "disillusioned is at index 33447\n",
      "Saved the embedding for disillusioned.\n",
      "disinclined is at index 2982\n",
      "Saved the embedding for disinclined.\n",
      "disingenuous is at index 39622\n",
      "Saved the embedding for disingenuous.\n",
      "disinterest is at index 2982\n",
      "Saved the embedding for disinterest.\n",
      "disinterested is at index 2982\n",
      "Saved the embedding for disinterested.\n",
      "disjointed is at index 2982\n",
      "Saved the embedding for disjointed.\n",
      "dislike is at index 28101\n",
      "Saved the embedding for dislike.\n",
      "disliked is at index 40891\n",
      "Saved the embedding for disliked.\n",
      "disliking is at index 19131\n",
      "Saved the embedding for disliking.\n",
      "dismal is at index 23446\n",
      "Saved the embedding for dismal.\n",
      "disman is at index 2982\n",
      "Saved the embedding for disman.\n",
      "dismay is at index 22135\n",
      "Saved the embedding for dismay.\n",
      "dismayed is at index 22135\n",
      "Saved the embedding for dismayed.\n",
      "dismissive is at index 37890\n",
      "Saved the embedding for dismissive.\n",
      "disobedient is at index 43738\n",
      "Saved the embedding for disobedient.\n",
      "disorderly is at index 23547\n",
      "Saved the embedding for disorderly.\n",
      "disoriented is at index 2982\n",
      "Saved the embedding for disoriented.\n",
      "dispair is at index 11734\n",
      "Saved the embedding for dispair.\n",
      "disparaging is at index 24331\n",
      "Saved the embedding for disparaging.\n",
      "dispassionate is at index 11734\n",
      "Saved the embedding for dispassionate.\n",
      "dispirited is at index 2982\n",
      "Saved the embedding for dispirited.\n",
      "dispiritedness is at index 2982\n",
      "Saved the embedding for dispiritedness.\n",
      "displeased is at index 43709\n",
      "Saved the embedding for displeased.\n",
      "displeasure is at index 30201\n",
      "Saved the embedding for displeasure.\n",
      "disquiet is at index 2982\n",
      "Saved the embedding for disquiet.\n",
      "disquieted is at index 2982\n",
      "Saved the embedding for disquieted.\n",
      "disregard is at index 21034\n",
      "Saved the embedding for disregard.\n",
      "disrespectful is at index 26401\n",
      "Saved the embedding for disrespectful.\n",
      "disrupted is at index 15902\n",
      "Saved the embedding for disrupted.\n",
      "disruptive is at index 17561\n",
      "Saved the embedding for disruptive.\n",
      "dissatisfaction is at index 31776\n",
      "Saved the embedding for dissatisfaction.\n",
      "dissatisfied is at index 37278\n",
      "Saved the embedding for dissatisfied.\n",
      "dissatisfy is at index 48830\n",
      "Saved the embedding for dissatisfy.\n",
      "dissecting is at index 33562\n",
      "Saved the embedding for dissecting.\n",
      "dissociated is at index 14863\n",
      "Saved the embedding for dissociated.\n",
      "dissonant is at index 43162\n",
      "Saved the embedding for dissonant.\n",
      "distain is at index 7018\n",
      "Saved the embedding for distain.\n",
      "distant is at index 13258\n",
      "Saved the embedding for distant.\n",
      "distaste is at index 7018\n",
      "Saved the embedding for distaste.\n",
      "distasteful is at index 7018\n",
      "Saved the embedding for distasteful.\n",
      "distracted is at index 16573\n",
      "Saved the embedding for distracted.\n",
      "distraught is at index 30719\n",
      "Saved the embedding for distraught.\n",
      "distress is at index 13250\n",
      "Saved the embedding for distress.\n",
      "distressed is at index 21460\n",
      "Saved the embedding for distressed.\n",
      "distressing is at index 7018\n",
      "Saved the embedding for distressing.\n",
      "distrust is at index 27948\n",
      "Saved the embedding for distrust.\n",
      "distrustful is at index 27948\n",
      "Saved the embedding for distrustful.\n",
      "distrusting is at index 27948\n",
      "Saved the embedding for distrusting.\n",
      "disturbed is at index 22938\n",
      "Saved the embedding for disturbed.\n",
      "diverted is at index 19070\n",
      "Saved the embedding for diverted.\n",
      "dodgy is at index 25744\n",
      "Saved the embedding for dodgy.\n",
      "doleful is at index 109\n",
      "Saved the embedding for doleful.\n",
      "doltish is at index 385\n",
      "Saved the embedding for doltish.\n",
      "dominant is at index 7353\n",
      "Saved the embedding for dominant.\n",
      "dominating is at index 17349\n",
      "Saved the embedding for dominating.\n",
      "domineering is at index 13567\n",
      "Saved the embedding for domineering.\n",
      "done is at index 626\n",
      "Saved the embedding for done.\n",
      "doomed is at index 23326\n",
      "Saved the embedding for doomed.\n",
      "dopey is at index 32331\n",
      "Saved the embedding for dopey.\n",
      "doting is at index 385\n",
      "Saved the embedding for doting.\n",
      "doubt is at index 2980\n",
      "Saved the embedding for doubt.\n",
      "doubter is at index 26463\n",
      "Saved the embedding for doubter.\n",
      "doubtful is at index 26645\n",
      "Saved the embedding for doubtful.\n",
      "doubtfully is at index 2980\n",
      "Saved the embedding for doubtfully.\n",
      "doubtfulness is at index 2980\n",
      "Saved the embedding for doubtfulness.\n",
      "doubting is at index 26463\n",
      "Saved the embedding for doubting.\n",
      "dour is at index 385\n",
      "Saved the embedding for dour.\n",
      "down is at index 159\n",
      "Saved the embedding for down.\n",
      "downcast is at index 159\n",
      "Saved the embedding for downcast.\n",
      "downhearted is at index 159\n",
      "Saved the embedding for downhearted.\n",
      "downheartedness is at index 159\n",
      "Saved the embedding for downheartedness.\n",
      "downtrodden is at index 29407\n",
      "Saved the embedding for downtrodden.\n",
      "dozing is at index 109\n",
      "Saved the embedding for dozing.\n",
      "drained is at index 23544\n",
      "Saved the embedding for drained.\n",
      "dramatic is at index 5386\n",
      "Saved the embedding for dramatic.\n",
      "drawn is at index 4777\n",
      "Saved the embedding for drawn.\n",
      "dread is at index 24506\n",
      "Saved the embedding for dread.\n",
      "dreadful is at index 31715\n",
      "Saved the embedding for dreadful.\n",
      "dreading is at index 24506\n",
      "Saved the embedding for dreading.\n",
      "dreaming is at index 26240\n",
      "Saved the embedding for dreaming.\n",
      "dreamy is at index 3366\n",
      "Saved the embedding for dreamy.\n",
      "dreary is at index 385\n",
      "Saved the embedding for dreary.\n",
      "driven is at index 3185\n",
      "Saved the embedding for driven.\n",
      "drowsy is at index 385\n",
      "Saved the embedding for drowsy.\n",
      "drugged is at index 385\n",
      "Saved the embedding for drugged.\n",
      "drunk is at index 10789\n",
      "Saved the embedding for drunk.\n",
      "drunkenness is at index 19835\n",
      "Saved the embedding for drunkenness.\n",
      "dubiety is at index 30180\n",
      "Saved the embedding for dubiety.\n",
      "dubious is at index 24381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for dubious.\n",
      "dubiously is at index 30180\n",
      "Saved the embedding for dubiously.\n",
      "dull is at index 22018\n",
      "Saved the embedding for dull.\n",
      "dumb is at index 16881\n",
      "Saved the embedding for dumb.\n",
      "dumbfound is at index 16881\n",
      "Saved the embedding for dumbfound.\n",
      "dumbfounded is at index 16881\n",
      "Saved the embedding for dumbfounded.\n",
      "dumbstruck is at index 16881\n",
      "Saved the embedding for dumbstruck.\n",
      "dumfounded is at index 385\n",
      "Saved the embedding for dumfounded.\n",
      "dupe is at index 4279\n",
      "Saved the embedding for dupe.\n",
      "duplicitous is at index 30501\n",
      "Saved the embedding for duplicitous.\n",
      "dysphoric is at index 44153\n",
      "Saved the embedding for dysphoric.\n",
      "eager is at index 7921\n",
      "Saved the embedding for eager.\n",
      "eagerness is at index 7921\n",
      "Saved the embedding for eagerness.\n",
      "earnest is at index 22623\n",
      "Saved the embedding for earnest.\n",
      "easy is at index 1365\n",
      "Saved the embedding for easy.\n",
      "ebullient is at index 364\n",
      "Saved the embedding for ebullient.\n",
      "ecstasy is at index 37695\n",
      "Saved the embedding for ecstasy.\n",
      "ecstatic is at index 30754\n",
      "Saved the embedding for ecstatic.\n",
      "ecstatically is at index 20508\n",
      "Saved the embedding for ecstatically.\n",
      "edgy is at index 4803\n",
      "Saved the embedding for edgy.\n",
      "eerie is at index 33960\n",
      "Saved the embedding for eerie.\n",
      "effulgent is at index 22089\n",
      "Saved the embedding for effulgent.\n",
      "egoistic is at index 21450\n",
      "Saved the embedding for egoistic.\n",
      "egotistical is at index 364\n",
      "Saved the embedding for egotistical.\n",
      "egregious is at index 28971\n",
      "Saved the embedding for egregious.\n",
      "elated is at index 1615\n",
      "Saved the embedding for elated.\n",
      "elation is at index 1615\n",
      "Saved the embedding for elation.\n",
      "electrified is at index 17995\n",
      "Saved the embedding for electrified.\n",
      "elusive is at index 21483\n",
      "Saved the embedding for elusive.\n",
      "embarrassed is at index 17319\n",
      "Saved the embedding for embarrassed.\n",
      "embarrassment is at index 19124\n",
      "Saved the embedding for embarrassment.\n",
      "embittered is at index 2841\n",
      "Saved the embedding for embittered.\n",
      "embody is at index 33865\n",
      "Saved the embedding for embody.\n",
      "emotional is at index 3722\n",
      "Saved the embedding for emotional.\n",
      "emotionless is at index 11926\n",
      "Saved the embedding for emotionless.\n",
      "empathetic is at index 2841\n",
      "Saved the embedding for empathetic.\n",
      "empathic is at index 2841\n",
      "Saved the embedding for empathic.\n",
      "empathy is at index 17805\n",
      "Saved the embedding for empathy.\n",
      "emptiness is at index 44480\n",
      "Saved the embedding for emptiness.\n",
      "empty is at index 5802\n",
      "Saved the embedding for empty.\n",
      "enamored is at index 1177\n",
      "Saved the embedding for enamored.\n",
      "enchanted is at index 44141\n",
      "Saved the embedding for enchanted.\n",
      "encouraged is at index 4446\n",
      "Saved the embedding for encouraged.\n",
      "encouragement is at index 18197\n",
      "Saved the embedding for encouragement.\n",
      "encouraging is at index 5513\n",
      "Saved the embedding for encouraging.\n",
      "endeared is at index 253\n",
      "Saved the embedding for endeared.\n",
      "endearing is at index 253\n",
      "Saved the embedding for endearing.\n",
      "enduring is at index 16480\n",
      "Saved the embedding for enduring.\n",
      "energetic is at index 20425\n",
      "Saved the embedding for energetic.\n",
      "energized is at index 15957\n",
      "Saved the embedding for energized.\n",
      "engaged is at index 4009\n",
      "Saved the embedding for engaged.\n",
      "engrossed is at index 20407\n",
      "Saved the embedding for engrossed.\n",
      "engrossment is at index 20407\n",
      "Saved the embedding for engrossment.\n",
      "enigmatic is at index 38910\n",
      "Saved the embedding for enigmatic.\n",
      "enjoy is at index 2254\n",
      "Saved the embedding for enjoy.\n",
      "enjoying is at index 6218\n",
      "Saved the embedding for enjoying.\n",
      "enjoyment is at index 26611\n",
      "Saved the embedding for enjoyment.\n",
      "enlightened is at index 38853\n",
      "Saved the embedding for enlightened.\n",
      "enmity is at index 1177\n",
      "Saved the embedding for enmity.\n",
      "ennui is at index 1177\n",
      "Saved the embedding for ennui.\n",
      "enraged is at index 33415\n",
      "Saved the embedding for enraged.\n",
      "enraging is at index 1177\n",
      "Saved the embedding for enraging.\n",
      "enraptured is at index 1177\n",
      "Saved the embedding for enraptured.\n",
      "entertained is at index 23979\n",
      "Saved the embedding for entertained.\n",
      "enthralled is at index 3838\n",
      "Saved the embedding for enthralled.\n",
      "enthused is at index 3838\n",
      "Saved the embedding for enthused.\n",
      "enthusiasm is at index 11240\n",
      "Saved the embedding for enthusiasm.\n",
      "enthusiastic is at index 15947\n",
      "Saved the embedding for enthusiastic.\n",
      "enticed is at index 3838\n",
      "Saved the embedding for enticed.\n",
      "entranced is at index 3838\n",
      "Saved the embedding for entranced.\n",
      "envious is at index 1177\n",
      "Saved the embedding for envious.\n",
      "envy is at index 29778\n",
      "Saved the embedding for envy.\n",
      "erotically is at index 3335\n",
      "Saved the embedding for erotically.\n",
      "estranged is at index 20599\n",
      "Saved the embedding for estranged.\n",
      "etched is at index 35542\n",
      "Saved the embedding for etched.\n",
      "euphoric is at index 30882\n",
      "Saved the embedding for euphoric.\n",
      "evaluating is at index 15190\n",
      "Saved the embedding for evaluating.\n",
      "evasive is at index 7630\n",
      "Saved the embedding for evasive.\n",
      "evil is at index 9247\n",
      "Saved the embedding for evil.\n",
      "evoke is at index 35334\n",
      "Saved the embedding for evoke.\n",
      "exacerbated is at index 24961\n",
      "Saved the embedding for exacerbated.\n",
      "exalted is at index 45514\n",
      "Saved the embedding for exalted.\n",
      "examining is at index 14951\n",
      "Saved the embedding for examining.\n",
      "exasperate is at index 1931\n",
      "Saved the embedding for exasperate.\n",
      "exasperated is at index 34698\n",
      "Saved the embedding for exasperated.\n",
      "exasperation is at index 34698\n",
      "Saved the embedding for exasperation.\n",
      "excited is at index 2283\n",
      "Saved the embedding for excited.\n",
      "excitedly is at index 2283\n",
      "Saved the embedding for excitedly.\n",
      "excitement is at index 8354\n",
      "Saved the embedding for excitement.\n",
      "exclamation is at index 1931\n",
      "Saved the embedding for exclamation.\n",
      "exclamatory is at index 1931\n",
      "Saved the embedding for exclamatory.\n",
      "exhausted is at index 17067\n",
      "Saved the embedding for exhausted.\n",
      "exhaustion is at index 30567\n",
      "Saved the embedding for exhaustion.\n",
      "exhaustive is at index 29180\n",
      "Saved the embedding for exhaustive.\n",
      "exhilarated is at index 32749\n",
      "Saved the embedding for exhilarated.\n",
      "exhilaration is at index 32749\n",
      "Saved the embedding for exhilaration.\n",
      "exited is at index 17469\n",
      "Saved the embedding for exited.\n",
      "expectant is at index 1057\n",
      "Saved the embedding for expectant.\n",
      "expectation is at index 9250\n",
      "Saved the embedding for expectation.\n",
      "expecting is at index 4804\n",
      "Saved the embedding for expecting.\n",
      "explain is at index 3922\n",
      "Saved the embedding for explain.\n",
      "explaining is at index 8926\n",
      "Saved the embedding for explaining.\n",
      "exploitive is at index 38984\n",
      "Saved the embedding for exploitive.\n",
      "explosive is at index 8560\n",
      "Saved the embedding for explosive.\n",
      "exposure is at index 4895\n",
      "Saved the embedding for exposure.\n",
      "expressive is at index 36340\n",
      "Saved the embedding for expressive.\n",
      "exuberant is at index 1931\n",
      "Saved the embedding for exuberant.\n",
      "exultant is at index 1931\n",
      "Saved the embedding for exultant.\n",
      "exulted is at index 1931\n",
      "Saved the embedding for exulted.\n",
      "eye is at index 2295\n",
      "Saved the embedding for eye.\n",
      "eyed is at index 36235\n",
      "Saved the embedding for eyed.\n",
      "faced is at index 2713\n",
      "Saved the embedding for faced.\n",
      "facetious is at index 34407\n",
      "Saved the embedding for facetious.\n",
      "failure is at index 2988\n",
      "Saved the embedding for failure.\n",
      "faint is at index 27922\n",
      "Saved the embedding for faint.\n",
      "fair is at index 2105\n",
      "Saved the embedding for fair.\n",
      "fake is at index 4486\n",
      "Saved the embedding for fake.\n",
      "faking is at index 856\n",
      "Saved the embedding for faking.\n",
      "falter is at index 14848\n",
      "Saved the embedding for falter.\n",
      "famished is at index 13403\n",
      "Saved the embedding for famished.\n",
      "fanatic is at index 38604\n",
      "Saved the embedding for fanatic.\n",
      "fanciful is at index 33639\n",
      "Saved the embedding for fanciful.\n",
      "fart is at index 36762\n",
      "Saved the embedding for fart.\n",
      "fascinated is at index 27025\n",
      "Saved the embedding for fascinated.\n",
      "fastidious is at index 1769\n",
      "Saved the embedding for fastidious.\n",
      "fatigue is at index 16069\n",
      "Saved the embedding for fatigue.\n",
      "fatigued is at index 36239\n",
      "Saved the embedding for fatigued.\n",
      "faultfinding is at index 7684\n",
      "Saved the embedding for faultfinding.\n",
      "favorable is at index 9879\n",
      "Saved the embedding for favorable.\n",
      "fawning is at index 856\n",
      "Saved the embedding for fawning.\n",
      "fazed is at index 856\n",
      "Saved the embedding for fazed.\n",
      "fear is at index 2490\n",
      "Saved the embedding for fear.\n",
      "feared is at index 9741\n",
      "Saved the embedding for feared.\n",
      "fearful is at index 23526\n",
      "Saved the embedding for fearful.\n",
      "fearing is at index 21510\n",
      "Saved the embedding for fearing.\n",
      "fearless is at index 29107\n",
      "Saved the embedding for fearless.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fearsome is at index 39185\n",
      "Saved the embedding for fearsome.\n",
      "feckless is at index 10668\n",
      "Saved the embedding for feckless.\n",
      "fed is at index 9789\n",
      "Saved the embedding for fed.\n",
      "feeble is at index 42217\n",
      "Saved the embedding for feeble.\n",
      "feign is at index 10668\n",
      "Saved the embedding for feign.\n",
      "felicitous is at index 14383\n",
      "Saved the embedding for felicitous.\n",
      "ferocious is at index 31429\n",
      "Saved the embedding for ferocious.\n",
      "ferocity is at index 16022\n",
      "Saved the embedding for ferocity.\n",
      "festive is at index 12298\n",
      "Saved the embedding for festive.\n",
      "fidgety is at index 856\n",
      "Saved the embedding for fidgety.\n",
      "fiendish is at index 13383\n",
      "Saved the embedding for fiendish.\n",
      "fierce is at index 11039\n",
      "Saved the embedding for fierce.\n",
      "fiery is at index 19068\n",
      "Saved the embedding for fiery.\n",
      "fighting is at index 2190\n",
      "Saved the embedding for fighting.\n",
      "fine is at index 2051\n",
      "Saved the embedding for fine.\n",
      "finished is at index 1550\n",
      "Saved the embedding for finished.\n",
      "firm is at index 933\n",
      "Saved the embedding for firm.\n",
      "fishy is at index 3539\n",
      "Saved the embedding for fishy.\n",
      "fixated is at index 4190\n",
      "Saved the embedding for fixated.\n",
      "fixed is at index 4460\n",
      "Saved the embedding for fixed.\n",
      "flabbergasted is at index 2342\n",
      "Saved the embedding for flabbergasted.\n",
      "flaming is at index 37222\n",
      "Saved the embedding for flaming.\n",
      "flat is at index 3269\n",
      "Saved the embedding for flat.\n",
      "flaunting is at index 2342\n",
      "Saved the embedding for flaunting.\n",
      "flighty is at index 2524\n",
      "Saved the embedding for flighty.\n",
      "flippant is at index 2342\n",
      "Saved the embedding for flippant.\n",
      "flipped is at index 18626\n",
      "Saved the embedding for flipped.\n",
      "flirtation is at index 33743\n",
      "Saved the embedding for flirtation.\n",
      "flirtatious is at index 33743\n",
      "Saved the embedding for flirtatious.\n",
      "flirty is at index 2342\n",
      "Saved the embedding for flirty.\n",
      "floored is at index 27325\n",
      "Saved the embedding for floored.\n",
      "flummoxed is at index 2342\n",
      "Saved the embedding for flummoxed.\n",
      "flustered is at index 2342\n",
      "Saved the embedding for flustered.\n",
      "focus is at index 1056\n",
      "Saved the embedding for focus.\n",
      "focused is at index 2061\n",
      "Saved the embedding for focused.\n",
      "focusing is at index 5650\n",
      "Saved the embedding for focusing.\n",
      "foiled is at index 9565\n",
      "Saved the embedding for foiled.\n",
      "foolish is at index 22789\n",
      "Saved the embedding for foolish.\n",
      "forbearing is at index 34550\n",
      "Saved the embedding for forbearing.\n",
      "forbidding is at index 34550\n",
      "Saved the embedding for forbidding.\n",
      "forced is at index 1654\n",
      "Saved the embedding for forced.\n",
      "forceful is at index 32165\n",
      "Saved the embedding for forceful.\n",
      "forfeited is at index 31844\n",
      "Saved the embedding for forfeited.\n",
      "forlorn is at index 13\n",
      "Saved the embedding for forlorn.\n",
      "fortunate is at index 10583\n",
      "Saved the embedding for fortunate.\n",
      "forward is at index 556\n",
      "Saved the embedding for forward.\n",
      "foul is at index 6962\n",
      "Saved the embedding for foul.\n",
      "fractious is at index 38251\n",
      "Saved the embedding for fractious.\n",
      "fragile is at index 14283\n",
      "Saved the embedding for fragile.\n",
      "frantic is at index 27396\n",
      "Saved the embedding for frantic.\n",
      "fraudulent is at index 15381\n",
      "Saved the embedding for fraudulent.\n",
      "fraught is at index 25481\n",
      "Saved the embedding for fraught.\n",
      "frazzled is at index 26830\n",
      "Saved the embedding for frazzled.\n",
      "freaked is at index 7619\n",
      "Saved the embedding for freaked.\n",
      "frenzied is at index 26908\n",
      "Saved the embedding for frenzied.\n",
      "fretful is at index 31391\n",
      "Saved the embedding for fretful.\n",
      "friendliness is at index 1441\n",
      "Saved the embedding for friendliness.\n",
      "friendly is at index 5192\n",
      "Saved the embedding for friendly.\n",
      "fright is at index 32580\n",
      "Saved the embedding for fright.\n",
      "frightened is at index 26851\n",
      "Saved the embedding for frightened.\n",
      "frightening is at index 21111\n",
      "Saved the embedding for frightening.\n",
      "frigid is at index 25805\n",
      "Saved the embedding for frigid.\n",
      "frisky is at index 6664\n",
      "Saved the embedding for frisky.\n",
      "frolicker is at index 856\n",
      "Saved the embedding for frolicker.\n",
      "frown is at index 41588\n",
      "Saved the embedding for frown.\n",
      "frowning is at index 41588\n",
      "Saved the embedding for frowning.\n",
      "frozen is at index 9214\n",
      "Saved the embedding for frozen.\n",
      "frumpy is at index 6664\n",
      "Saved the embedding for frumpy.\n",
      "frustrated is at index 8164\n",
      "Saved the embedding for frustrated.\n",
      "frustration is at index 8413\n",
      "Saved the embedding for frustration.\n",
      "fulfilled is at index 20218\n",
      "Saved the embedding for fulfilled.\n",
      "fumed is at index 856\n",
      "Saved the embedding for fumed.\n",
      "fuming is at index 856\n",
      "Saved the embedding for fuming.\n",
      "fun is at index 1531\n",
      "Saved the embedding for fun.\n",
      "funny is at index 6269\n",
      "Saved the embedding for funny.\n",
      "furious is at index 15940\n",
      "Saved the embedding for furious.\n",
      "furiously is at index 39202\n",
      "Saved the embedding for furiously.\n",
      "furiousness is at index 15940\n",
      "Saved the embedding for furiousness.\n",
      "furrowed is at index 15503\n",
      "Saved the embedding for furrowed.\n",
      "furtive is at index 856\n",
      "Saved the embedding for furtive.\n",
      "fury is at index 22228\n",
      "Saved the embedding for fury.\n",
      "fussy is at index 856\n",
      "Saved the embedding for fussy.\n",
      "galled is at index 821\n",
      "Saved the embedding for galled.\n",
      "galling is at index 19869\n",
      "Saved the embedding for galling.\n",
      "gasp is at index 41681\n",
      "Saved the embedding for gasp.\n",
      "gasped is at index 44918\n",
      "Saved the embedding for gasped.\n",
      "gasping is at index 1123\n",
      "Saved the embedding for gasping.\n",
      "gay is at index 5100\n",
      "Saved the embedding for gay.\n",
      "gazing is at index 40804\n",
      "Saved the embedding for gazing.\n",
      "genial is at index 12358\n",
      "Saved the embedding for genial.\n",
      "gentle is at index 16634\n",
      "Saved the embedding for gentle.\n",
      "genuine is at index 8916\n",
      "Saved the embedding for genuine.\n",
      "ghastly is at index 34648\n",
      "Saved the embedding for ghastly.\n",
      "giddy is at index 821\n",
      "Saved the embedding for giddy.\n",
      "giggle is at index 821\n",
      "Saved the embedding for giggle.\n",
      "giggling is at index 33786\n",
      "Saved the embedding for giggling.\n",
      "glad is at index 7785\n",
      "Saved the embedding for glad.\n",
      "gladdened is at index 5921\n",
      "Saved the embedding for gladdened.\n",
      "gladiola is at index 7785\n",
      "Saved the embedding for gladiola.\n",
      "gladness is at index 7785\n",
      "Saved the embedding for gladness.\n",
      "gladsome is at index 5921\n",
      "Saved the embedding for gladsome.\n",
      "glare is at index 37355\n",
      "Saved the embedding for glare.\n",
      "glaring is at index 26077\n",
      "Saved the embedding for glaring.\n",
      "glazed is at index 5921\n",
      "Saved the embedding for glazed.\n",
      "glee is at index 821\n",
      "Saved the embedding for glee.\n",
      "gleeful is at index 22460\n",
      "Saved the embedding for gleeful.\n",
      "gleefully is at index 22460\n",
      "Saved the embedding for gleefully.\n",
      "glib is at index 5921\n",
      "Saved the embedding for glib.\n",
      "gloating is at index 5921\n",
      "Saved the embedding for gloating.\n",
      "gloom is at index 31752\n",
      "Saved the embedding for gloom.\n",
      "gloomy is at index 32627\n",
      "Saved the embedding for gloomy.\n",
      "glowering is at index 5921\n",
      "Saved the embedding for glowering.\n",
      "glowing is at index 22285\n",
      "Saved the embedding for glowing.\n",
      "glum is at index 5921\n",
      "Saved the embedding for glum.\n",
      "gnarl is at index 31021\n",
      "Saved the embedding for gnarl.\n",
      "gobsmacked is at index 213\n",
      "Saved the embedding for gobsmacked.\n",
      "good is at index 205\n",
      "Saved the embedding for good.\n",
      "goofy is at index 36302\n",
      "Saved the embedding for goofy.\n",
      "gossipy is at index 20445\n",
      "Saved the embedding for gossipy.\n",
      "grandiose is at index 2821\n",
      "Saved the embedding for grandiose.\n",
      "grateful is at index 6161\n",
      "Saved the embedding for grateful.\n",
      "gratified is at index 20153\n",
      "Saved the embedding for gratified.\n",
      "grave is at index 9753\n",
      "Saved the embedding for grave.\n",
      "great is at index 372\n",
      "Saved the embedding for great.\n",
      "greedy is at index 34405\n",
      "Saved the embedding for greedy.\n",
      "greeting is at index 25801\n",
      "Saved the embedding for greeting.\n",
      "grief is at index 12903\n",
      "Saved the embedding for grief.\n",
      "grieved is at index 821\n",
      "Saved the embedding for grieved.\n",
      "grieving is at index 22567\n",
      "Saved the embedding for grieving.\n",
      "grim is at index 17081\n",
      "Saved the embedding for grim.\n",
      "grimace is at index 17081\n",
      "Saved the embedding for grimace.\n",
      "grimacing is at index 17081\n",
      "Saved the embedding for grimacing.\n",
      "grin is at index 30986\n",
      "Saved the embedding for grin.\n",
      "grinning is at index 39662\n",
      "Saved the embedding for grinning.\n",
      "griping is at index 11155\n",
      "Saved the embedding for griping.\n",
      "gross is at index 4200\n",
      "Saved the embedding for gross.\n",
      "grossed is at index 4200\n",
      "Saved the embedding for grossed.\n",
      "grouchy is at index 22970\n",
      "Saved the embedding for grouchy.\n",
      "growl is at index 1733\n",
      "Saved the embedding for growl.\n",
      "growling is at index 1733\n",
      "Saved the embedding for growling.\n",
      "grudge is at index 4435\n",
      "Saved the embedding for grudge.\n",
      "grudging is at index 4435\n",
      "Saved the embedding for grudging.\n",
      "gruff is at index 15551\n",
      "Saved the embedding for gruff.\n",
      "grumbling is at index 4435\n",
      "Saved the embedding for grumbling.\n",
      "grumpy is at index 4435\n",
      "Saved the embedding for grumpy.\n",
      "grunt is at index 44376\n",
      "Saved the embedding for grunt.\n",
      "grunting is at index 39204\n",
      "Saved the embedding for grunting.\n",
      "guarded is at index 25853\n",
      "Saved the embedding for guarded.\n",
      "guilty is at index 2181\n",
      "Saved the embedding for guilty.\n",
      "gulp is at index 821\n",
      "Saved the embedding for gulp.\n",
      "haggard is at index 1368\n",
      "Saved the embedding for haggard.\n",
      "halfhearted is at index 457\n",
      "Saved the embedding for halfhearted.\n",
      "halted is at index 12856\n",
      "Saved the embedding for halted.\n",
      "hapless is at index 2489\n",
      "Saved the embedding for hapless.\n",
      "happiness is at index 11098\n",
      "Saved the embedding for happiness.\n",
      "happy is at index 1372\n",
      "Saved the embedding for happy.\n",
      "harassed is at index 16835\n",
      "Saved the embedding for harassed.\n",
      "hard is at index 543\n",
      "Saved the embedding for hard.\n",
      "hardened is at index 33631\n",
      "Saved the embedding for hardened.\n",
      "harmful is at index 11190\n",
      "Saved the embedding for harmful.\n",
      "harried is at index 12280\n",
      "Saved the embedding for harried.\n",
      "harsh is at index 9776\n",
      "Saved the embedding for harsh.\n",
      "hate is at index 4157\n",
      "Saved the embedding for hate.\n",
      "hateful is at index 26393\n",
      "Saved the embedding for hateful.\n",
      "hating is at index 40873\n",
      "Saved the embedding for hating.\n",
      "hatred is at index 13453\n",
      "Saved the embedding for hatred.\n",
      "haughty is at index 2489\n",
      "Saved the embedding for haughty.\n",
      "haunted is at index 22717\n",
      "Saved the embedding for haunted.\n",
      "hazy is at index 2489\n",
      "Saved the embedding for hazy.\n",
      "headshake is at index 471\n",
      "Saved the embedding for headshake.\n",
      "heartache is at index 1144\n",
      "Saved the embedding for heartache.\n",
      "heartbroken is at index 1144\n",
      "Saved the embedding for heartbroken.\n",
      "hearted is at index 1144\n",
      "Saved the embedding for hearted.\n",
      "heartsick is at index 7754\n",
      "Saved the embedding for heartsick.\n",
      "heated is at index 10819\n",
      "Saved the embedding for heated.\n",
      "heavyhearted is at index 2016\n",
      "Saved the embedding for heavyhearted.\n",
      "heckle is at index 17835\n",
      "Saved the embedding for heckle.\n",
      "heedful is at index 25432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for heedful.\n",
      "heinous is at index 30091\n",
      "Saved the embedding for heinous.\n",
      "helpful is at index 7163\n",
      "Saved the embedding for helpful.\n",
      "helpless is at index 22445\n",
      "Saved the embedding for helpless.\n",
      "hesitant is at index 24668\n",
      "Saved the embedding for hesitant.\n",
      "hesitantly is at index 36279\n",
      "Saved the embedding for hesitantly.\n",
      "hesitating is at index 36279\n",
      "Saved the embedding for hesitating.\n",
      "hesitation is at index 28946\n",
      "Saved the embedding for hesitation.\n",
      "high is at index 239\n",
      "Saved the embedding for high.\n",
      "hollering is at index 1368\n",
      "Saved the embedding for hollering.\n",
      "homicidal is at index 9486\n",
      "Saved the embedding for homicidal.\n",
      "honest is at index 5322\n",
      "Saved the embedding for honest.\n",
      "honorable is at index 28537\n",
      "Saved the embedding for honorable.\n",
      "hope is at index 1034\n",
      "Saved the embedding for hope.\n",
      "hopeful is at index 7917\n",
      "Saved the embedding for hopeful.\n",
      "hopefulness is at index 7917\n",
      "Saved the embedding for hopefulness.\n",
      "hopeless is at index 24418\n",
      "Saved the embedding for hopeless.\n",
      "hoping is at index 2818\n",
      "Saved the embedding for hoping.\n",
      "horny is at index 46216\n",
      "Saved the embedding for horny.\n",
      "horrible is at index 11385\n",
      "Saved the embedding for horrible.\n",
      "horrified is at index 27807\n",
      "Saved the embedding for horrified.\n",
      "horrify is at index 48067\n",
      "Saved the embedding for horrify.\n",
      "horrifying is at index 28242\n",
      "Saved the embedding for horrifying.\n",
      "horror is at index 8444\n",
      "Saved the embedding for horror.\n",
      "hostile is at index 11928\n",
      "Saved the embedding for hostile.\n",
      "hostility is at index 22069\n",
      "Saved the embedding for hostility.\n",
      "hot is at index 2131\n",
      "Saved the embedding for hot.\n",
      "hotshot is at index 2131\n",
      "Saved the embedding for hotshot.\n",
      "huffiness is at index 1368\n",
      "Saved the embedding for huffiness.\n",
      "huffy is at index 1368\n",
      "Saved the embedding for huffy.\n",
      "humble is at index 14083\n",
      "Saved the embedding for humble.\n",
      "humbled is at index 10080\n",
      "Saved the embedding for humbled.\n",
      "humdrum is at index 10080\n",
      "Saved the embedding for humdrum.\n",
      "humiliated is at index 32386\n",
      "Saved the embedding for humiliated.\n",
      "humility is at index 27352\n",
      "Saved the embedding for humility.\n",
      "humming is at index 35774\n",
      "Saved the embedding for humming.\n",
      "humor is at index 12073\n",
      "Saved the embedding for humor.\n",
      "humored is at index 10080\n",
      "Saved the embedding for humored.\n",
      "humorous is at index 31214\n",
      "Saved the embedding for humorous.\n",
      "hunger is at index 12226\n",
      "Saved the embedding for hunger.\n",
      "hungry is at index 11130\n",
      "Saved the embedding for hungry.\n",
      "hunted is at index 32602\n",
      "Saved the embedding for hunted.\n",
      "hurt is at index 2581\n",
      "Saved the embedding for hurt.\n",
      "hurtful is at index 2581\n",
      "Saved the embedding for hurtful.\n",
      "hurting is at index 12780\n",
      "Saved the embedding for hurting.\n",
      "hush is at index 1368\n",
      "Saved the embedding for hush.\n",
      "hushed is at index 33476\n",
      "Saved the embedding for hushed.\n",
      "hyper is at index 8944\n",
      "Saved the embedding for hyper.\n",
      "hyperactive is at index 8944\n",
      "Saved the embedding for hyperactive.\n",
      "hypnotized is at index 39040\n",
      "Saved the embedding for hypnotized.\n",
      "hypocritical is at index 37769\n",
      "Saved the embedding for hypocritical.\n",
      "hysteria is at index 35099\n",
      "Saved the embedding for hysteria.\n",
      "hysterical is at index 38561\n",
      "Saved the embedding for hysterical.\n",
      "idiotic is at index 13561\n",
      "Saved the embedding for idiotic.\n",
      "ignorant is at index 27726\n",
      "Saved the embedding for ignorant.\n",
      "ignoring is at index 15515\n",
      "Saved the embedding for ignoring.\n",
      "ill is at index 4812\n",
      "Saved the embedding for ill.\n",
      "imaginative is at index 35026\n",
      "Saved the embedding for imaginative.\n",
      "immature is at index 39001\n",
      "Saved the embedding for immature.\n",
      "immersed is at index 31971\n",
      "Saved the embedding for immersed.\n",
      "impacted is at index 7284\n",
      "Saved the embedding for impacted.\n",
      "impartial is at index 24283\n",
      "Saved the embedding for impartial.\n",
      "impassioned is at index 4023\n",
      "Saved the embedding for impassioned.\n",
      "impassive is at index 4023\n",
      "Saved the embedding for impassive.\n",
      "impatience is at index 43635\n",
      "Saved the embedding for impatience.\n",
      "impatient is at index 32601\n",
      "Saved the embedding for impatient.\n",
      "imperious is at index 21245\n",
      "Saved the embedding for imperious.\n",
      "impersonal is at index 23153\n",
      "Saved the embedding for impersonal.\n",
      "impertinent is at index 21245\n",
      "Saved the embedding for impertinent.\n",
      "impish is at index 4023\n",
      "Saved the embedding for impish.\n",
      "implicated is at index 23316\n",
      "Saved the embedding for implicated.\n",
      "imploring is at index 12956\n",
      "Saved the embedding for imploring.\n",
      "important is at index 505\n",
      "Saved the embedding for important.\n",
      "impressed is at index 6889\n",
      "Saved the embedding for impressed.\n",
      "impulsive is at index 4023\n",
      "Saved the embedding for impulsive.\n",
      "inactive is at index 25986\n",
      "Saved the embedding for inactive.\n",
      "inadequate is at index 15650\n",
      "Saved the embedding for inadequate.\n",
      "inarticulate is at index 11\n",
      "Saved the embedding for inarticulate.\n",
      "inattentive is at index 11\n",
      "Saved the embedding for inattentive.\n",
      "inaudible is at index 11\n",
      "Saved the embedding for inaudible.\n",
      "inauthentic is at index 11\n",
      "Saved the embedding for inauthentic.\n",
      "incapable is at index 30256\n",
      "Saved the embedding for incapable.\n",
      "incensed is at index 5853\n",
      "Saved the embedding for incensed.\n",
      "incertain is at index 5853\n",
      "Saved the embedding for incertain.\n",
      "incertitude is at index 5853\n",
      "Saved the embedding for incertitude.\n",
      "incited is at index 5853\n",
      "Saved the embedding for incited.\n",
      "incomprehensible is at index 42494\n",
      "Saved the embedding for incomprehensible.\n",
      "inconspicuous is at index 40817\n",
      "Saved the embedding for inconspicuous.\n",
      "incredulity is at index 38366\n",
      "Saved the embedding for incredulity.\n",
      "incredulous is at index 38366\n",
      "Saved the embedding for incredulous.\n",
      "incredulously is at index 38366\n",
      "Saved the embedding for incredulously.\n",
      "inculpate is at index 5853\n",
      "Saved the embedding for inculpate.\n",
      "incurious is at index 5853\n",
      "Saved the embedding for incurious.\n",
      "indecipherable is at index 32227\n",
      "Saved the embedding for indecipherable.\n",
      "indecision is at index 32227\n",
      "Saved the embedding for indecision.\n",
      "indecisive is at index 32227\n",
      "Saved the embedding for indecisive.\n",
      "indifferent is at index 34657\n",
      "Saved the embedding for indifferent.\n",
      "indifferently is at index 34657\n",
      "Saved the embedding for indifferently.\n",
      "indignant is at index 9473\n",
      "Saved the embedding for indignant.\n",
      "indolent is at index 9473\n",
      "Saved the embedding for indolent.\n",
      "inebriated is at index 11\n",
      "Saved the embedding for inebriated.\n",
      "inert is at index 43783\n",
      "Saved the embedding for inert.\n",
      "infatuating is at index 4047\n",
      "Saved the embedding for infatuating.\n",
      "inferior is at index 28510\n",
      "Saved the embedding for inferior.\n",
      "inferiority is at index 28510\n",
      "Saved the embedding for inferiority.\n",
      "inflamed is at index 11411\n",
      "Saved the embedding for inflamed.\n",
      "informal is at index 14110\n",
      "Saved the embedding for informal.\n",
      "informing is at index 21835\n",
      "Saved the embedding for informing.\n",
      "infuriated is at index 26974\n",
      "Saved the embedding for infuriated.\n",
      "inhibited is at index 45427\n",
      "Saved the embedding for inhibited.\n",
      "inhibiting is at index 38512\n",
      "Saved the embedding for inhibiting.\n",
      "inimical is at index 11\n",
      "Saved the embedding for inimical.\n",
      "injured is at index 1710\n",
      "Saved the embedding for injured.\n",
      "innocent is at index 7850\n",
      "Saved the embedding for innocent.\n",
      "inpatient is at index 11\n",
      "Saved the embedding for inpatient.\n",
      "inquiring is at index 27874\n",
      "Saved the embedding for inquiring.\n",
      "inquisitive is at index 27874\n",
      "Saved the embedding for inquisitive.\n",
      "insane is at index 18544\n",
      "Saved the embedding for insane.\n",
      "inscrutable is at index 7540\n",
      "Saved the embedding for inscrutable.\n",
      "insecure is at index 27810\n",
      "Saved the embedding for insecure.\n",
      "insecurity is at index 19401\n",
      "Saved the embedding for insecurity.\n",
      "insensitive is at index 29401\n",
      "Saved the embedding for insensitive.\n",
      "insidious is at index 40012\n",
      "Saved the embedding for insidious.\n",
      "insinuating is at index 32016\n",
      "Saved the embedding for insinuating.\n",
      "insistence is at index 24974\n",
      "Saved the embedding for insistence.\n",
      "insistent is at index 7540\n",
      "Saved the embedding for insistent.\n",
      "insisting is at index 13875\n",
      "Saved the embedding for insisting.\n",
      "insolent is at index 23799\n",
      "Saved the embedding for insolent.\n",
      "insouciance is at index 7540\n",
      "Saved the embedding for insouciance.\n",
      "insouciant is at index 7540\n",
      "Saved the embedding for insouciant.\n",
      "inspired is at index 4083\n",
      "Saved the embedding for inspired.\n",
      "inspiring is at index 11653\n",
      "Saved the embedding for inspiring.\n",
      "instigating is at index 9084\n",
      "Saved the embedding for instigating.\n",
      "instructing is at index 20587\n",
      "Saved the embedding for instructing.\n",
      "insubordinate is at index 7540\n",
      "Saved the embedding for insubordinate.\n",
      "insular is at index 7540\n",
      "Saved the embedding for insular.\n",
      "insulted is at index 32149\n",
      "Saved the embedding for insulted.\n",
      "insulting is at index 22602\n",
      "Saved the embedding for insulting.\n",
      "intelligence is at index 2316\n",
      "Saved the embedding for intelligence.\n",
      "intense is at index 5676\n",
      "Saved the embedding for intense.\n",
      "intensely is at index 29727\n",
      "Saved the embedding for intensely.\n",
      "intensity is at index 10603\n",
      "Saved the embedding for intensity.\n",
      "intensive is at index 12296\n",
      "Saved the embedding for intensive.\n",
      "intent is at index 5927\n",
      "Saved the embedding for intent.\n",
      "intentional is at index 18797\n",
      "Saved the embedding for intentional.\n",
      "interacting is at index 23140\n",
      "Saved the embedding for interacting.\n",
      "interest is at index 773\n",
      "Saved the embedding for interest.\n",
      "interested is at index 2509\n",
      "Saved the embedding for interested.\n",
      "interjecting is at index 3222\n",
      "Saved the embedding for interjecting.\n",
      "internalizing is at index 3425\n",
      "Saved the embedding for internalizing.\n",
      "interrogating is at index 28592\n",
      "Saved the embedding for interrogating.\n",
      "interrupting is at index 22749\n",
      "Saved the embedding for interrupting.\n",
      "intimidated is at index 25443\n",
      "Saved the embedding for intimidated.\n",
      "intimidating is at index 23292\n",
      "Saved the embedding for intimidating.\n",
      "intolerant is at index 39348\n",
      "Saved the embedding for intolerant.\n",
      "intoxicated is at index 20600\n",
      "Saved the embedding for intoxicated.\n",
      "intrigue is at index 30368\n",
      "Saved the embedding for intrigue.\n",
      "intrigued is at index 28622\n",
      "Saved the embedding for intrigued.\n",
      "intriguing is at index 14816\n",
      "Saved the embedding for intriguing.\n",
      "introspective is at index 22845\n",
      "Saved the embedding for introspective.\n",
      "invested is at index 5221\n",
      "Saved the embedding for invested.\n",
      "investigate is at index 4830\n",
      "Saved the embedding for investigate.\n",
      "investigative is at index 13222\n",
      "Saved the embedding for investigative.\n",
      "investigatory is at index 25463\n",
      "Saved the embedding for investigatory.\n",
      "invigorated is at index 12259\n",
      "Saved the embedding for invigorated.\n",
      "involved is at index 963\n",
      "Saved the embedding for involved.\n",
      "irascible is at index 10209\n",
      "Saved the embedding for irascible.\n",
      "irate is at index 10209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for irate.\n",
      "ire is at index 25509\n",
      "Saved the embedding for ire.\n",
      "ireful is at index 25509\n",
      "Saved the embedding for ireful.\n",
      "irked is at index 10209\n",
      "Saved the embedding for irked.\n",
      "ironic is at index 25553\n",
      "Saved the embedding for ironic.\n",
      "irony is at index 21490\n",
      "Saved the embedding for irony.\n",
      "irresolute is at index 10209\n",
      "Saved the embedding for irresolute.\n",
      "irritable is at index 26570\n",
      "Saved the embedding for irritable.\n",
      "irritably is at index 26570\n",
      "Saved the embedding for irritably.\n",
      "irritated is at index 35270\n",
      "Saved the embedding for irritated.\n",
      "irritation is at index 32776\n",
      "Saved the embedding for irritation.\n",
      "isolated is at index 8067\n",
      "Saved the embedding for isolated.\n",
      "jabbed is at index 27916\n",
      "Saved the embedding for jabbed.\n",
      "jaded is at index 1236\n",
      "Saved the embedding for jaded.\n",
      "jarred is at index 25413\n",
      "Saved the embedding for jarred.\n",
      "jarring is at index 35659\n",
      "Saved the embedding for jarring.\n",
      "jaunty is at index 1236\n",
      "Saved the embedding for jaunty.\n",
      "jawed is at index 15345\n",
      "Saved the embedding for jawed.\n",
      "jealous is at index 27064\n",
      "Saved the embedding for jealous.\n",
      "jeering is at index 4112\n",
      "Saved the embedding for jeering.\n",
      "jesting is at index 1236\n",
      "Saved the embedding for jesting.\n",
      "jilted is at index 1236\n",
      "Saved the embedding for jilted.\n",
      "jittery is at index 1236\n",
      "Saved the embedding for jittery.\n",
      "jocular is at index 1236\n",
      "Saved the embedding for jocular.\n",
      "joking is at index 22024\n",
      "Saved the embedding for joking.\n",
      "jolly is at index 1236\n",
      "Saved the embedding for jolly.\n",
      "jolted is at index 1236\n",
      "Saved the embedding for jolted.\n",
      "jovial is at index 1236\n",
      "Saved the embedding for jovial.\n",
      "joy is at index 5823\n",
      "Saved the embedding for joy.\n",
      "joyful is at index 32076\n",
      "Saved the embedding for joyful.\n",
      "joyfulness is at index 5823\n",
      "Saved the embedding for joyfulness.\n",
      "joyless is at index 5823\n",
      "Saved the embedding for joyless.\n",
      "joyous is at index 5823\n",
      "Saved the embedding for joyous.\n",
      "jubilant is at index 1236\n",
      "Saved the embedding for jubilant.\n",
      "jubilation is at index 1236\n",
      "Saved the embedding for jubilation.\n",
      "judgemental is at index 17219\n",
      "Saved the embedding for judgemental.\n",
      "judging is at index 17298\n",
      "Saved the embedding for judging.\n",
      "judgmental is at index 7579\n",
      "Saved the embedding for judgmental.\n",
      "judicious is at index 21392\n",
      "Saved the embedding for judicious.\n",
      "jumpy is at index 3704\n",
      "Saved the embedding for jumpy.\n",
      "justified is at index 14267\n",
      "Saved the embedding for justified.\n",
      "keen is at index 5609\n",
      "Saved the embedding for keen.\n",
      "kind is at index 761\n",
      "Saved the embedding for kind.\n",
      "kindhearted is at index 761\n",
      "Saved the embedding for kindhearted.\n",
      "kiss is at index 13301\n",
      "Saved the embedding for kiss.\n",
      "knowing is at index 4730\n",
      "Saved the embedding for knowing.\n",
      "knowledgable is at index 216\n",
      "Saved the embedding for knowledgable.\n",
      "knowledgeable is at index 26782\n",
      "Saved the embedding for knowledgeable.\n",
      "kosher is at index 36930\n",
      "Saved the embedding for kosher.\n",
      "lackadaisical is at index 1762\n",
      "Saved the embedding for lackadaisical.\n",
      "lackluster is at index 28369\n",
      "Saved the embedding for lackluster.\n",
      "laconic is at index 784\n",
      "Saved the embedding for laconic.\n",
      "lambaste is at index 17988\n",
      "Saved the embedding for lambaste.\n",
      "lamentable is at index 25532\n",
      "Saved the embedding for lamentable.\n",
      "lamenting is at index 25532\n",
      "Saved the embedding for lamenting.\n",
      "lascivious is at index 784\n",
      "Saved the embedding for lascivious.\n",
      "laugh is at index 7923\n",
      "Saved the embedding for laugh.\n",
      "laughing is at index 11339\n",
      "Saved the embedding for laughing.\n",
      "laughter is at index 16805\n",
      "Saved the embedding for laughter.\n",
      "lazy is at index 22414\n",
      "Saved the embedding for lazy.\n",
      "leaving is at index 1618\n",
      "Saved the embedding for leaving.\n",
      "lecherous is at index 2084\n",
      "Saved the embedding for lecherous.\n",
      "lecturing is at index 25673\n",
      "Saved the embedding for lecturing.\n",
      "leering is at index 2084\n",
      "Saved the embedding for leering.\n",
      "leery is at index 2084\n",
      "Saved the embedding for leery.\n",
      "letdown is at index 905\n",
      "Saved the embedding for letdown.\n",
      "lethargic is at index 35370\n",
      "Saved the embedding for lethargic.\n",
      "levelheaded is at index 672\n",
      "Saved the embedding for levelheaded.\n",
      "lewd is at index 31942\n",
      "Saved the embedding for lewd.\n",
      "libidinous is at index 21748\n",
      "Saved the embedding for libidinous.\n",
      "lifeless is at index 37019\n",
      "Saved the embedding for lifeless.\n",
      "lighthearted is at index 1109\n",
      "Saved the embedding for lighthearted.\n",
      "lipped is at index 784\n",
      "Saved the embedding for lipped.\n",
      "listening is at index 6288\n",
      "Saved the embedding for listening.\n",
      "listless is at index 889\n",
      "Saved the embedding for listless.\n",
      "lively is at index 20902\n",
      "Saved the embedding for lively.\n",
      "livid is at index 784\n",
      "Saved the embedding for livid.\n",
      "loaded is at index 7973\n",
      "Saved the embedding for loaded.\n",
      "loath is at index 4600\n",
      "Saved the embedding for loath.\n",
      "loathe is at index 4600\n",
      "Saved the embedding for loathe.\n",
      "loathing is at index 4600\n",
      "Saved the embedding for loathing.\n",
      "loathsome is at index 4600\n",
      "Saved the embedding for loathsome.\n",
      "locked is at index 5930\n",
      "Saved the embedding for locked.\n",
      "loneliness is at index 27942\n",
      "Saved the embedding for loneliness.\n",
      "lonely is at index 20100\n",
      "Saved the embedding for lonely.\n",
      "longing is at index 36171\n",
      "Saved the embedding for longing.\n",
      "looking is at index 546\n",
      "Saved the embedding for looking.\n",
      "loony is at index 4600\n",
      "Saved the embedding for loony.\n",
      "loss is at index 872\n",
      "Saved the embedding for loss.\n",
      "lost is at index 685\n",
      "Saved the embedding for lost.\n",
      "loud is at index 7337\n",
      "Saved the embedding for loud.\n",
      "lousy is at index 38909\n",
      "Saved the embedding for lousy.\n",
      "love is at index 657\n",
      "Saved the embedding for love.\n",
      "loving is at index 8520\n",
      "Saved the embedding for loving.\n",
      "lowliness is at index 614\n",
      "Saved the embedding for lowliness.\n",
      "lurid is at index 30461\n",
      "Saved the embedding for lurid.\n",
      "lustful is at index 30864\n",
      "Saved the embedding for lustful.\n",
      "lusting is at index 30864\n",
      "Saved the embedding for lusting.\n",
      "lusty is at index 30864\n",
      "Saved the embedding for lusty.\n",
      "lying is at index 6480\n",
      "Saved the embedding for lying.\n",
      "mad is at index 7758\n",
      "Saved the embedding for mad.\n",
      "maddened is at index 475\n",
      "Saved the embedding for maddened.\n",
      "madness is at index 24714\n",
      "Saved the embedding for madness.\n",
      "malcontent is at index 8196\n",
      "Saved the embedding for malcontent.\n",
      "maleficent is at index 8196\n",
      "Saved the embedding for maleficent.\n",
      "malevolent is at index 2943\n",
      "Saved the embedding for malevolent.\n",
      "malice is at index 39625\n",
      "Saved the embedding for malice.\n",
      "malicious is at index 15237\n",
      "Saved the embedding for malicious.\n",
      "malignant is at index 8196\n",
      "Saved the embedding for malignant.\n",
      "maniacal is at index 41288\n",
      "Saved the embedding for maniacal.\n",
      "manipulative is at index 39802\n",
      "Saved the embedding for manipulative.\n",
      "marveled is at index 25591\n",
      "Saved the embedding for marveled.\n",
      "master is at index 4710\n",
      "Saved the embedding for master.\n",
      "mean is at index 1266\n",
      "Saved the embedding for mean.\n",
      "meaningful is at index 6667\n",
      "Saved the embedding for meaningful.\n",
      "meditative is at index 5679\n",
      "Saved the embedding for meditative.\n",
      "meek is at index 162\n",
      "Saved the embedding for meek.\n",
      "melancholic is at index 45565\n",
      "Saved the embedding for melancholic.\n",
      "melancholy is at index 40602\n",
      "Saved the embedding for melancholy.\n",
      "mellow is at index 34384\n",
      "Saved the embedding for mellow.\n",
      "menace is at index 24213\n",
      "Saved the embedding for menace.\n",
      "menacing is at index 32002\n",
      "Saved the embedding for menacing.\n",
      "mental is at index 2536\n",
      "Saved the embedding for mental.\n",
      "merrily is at index 9374\n",
      "Saved the embedding for merrily.\n",
      "merry is at index 35814\n",
      "Saved the embedding for merry.\n",
      "mesmerized is at index 31294\n",
      "Saved the embedding for mesmerized.\n",
      "miffed is at index 475\n",
      "Saved the embedding for miffed.\n",
      "mild is at index 10439\n",
      "Saved the embedding for mild.\n",
      "mincing is at index 5251\n",
      "Saved the embedding for mincing.\n",
      "mindful is at index 20807\n",
      "Saved the embedding for mindful.\n",
      "mindless is at index 41406\n",
      "Saved the embedding for mindless.\n",
      "mirrored is at index 31349\n",
      "Saved the embedding for mirrored.\n",
      "mirth is at index 475\n",
      "Saved the embedding for mirth.\n",
      "mirthful is at index 475\n",
      "Saved the embedding for mirthful.\n",
      "misanthropic is at index 3834\n",
      "Saved the embedding for misanthropic.\n",
      "mischief is at index 26245\n",
      "Saved the embedding for mischief.\n",
      "mischievous is at index 3834\n",
      "Saved the embedding for mischievous.\n",
      "mischievousness is at index 3834\n",
      "Saved the embedding for mischievousness.\n",
      "miserable is at index 20161\n",
      "Saved the embedding for miserable.\n",
      "misery is at index 23110\n",
      "Saved the embedding for misery.\n",
      "misgiving is at index 3834\n",
      "Saved the embedding for misgiving.\n",
      "mislead is at index 34747\n",
      "Saved the embedding for mislead.\n",
      "mistrust is at index 34873\n",
      "Saved the embedding for mistrust.\n",
      "mistrustful is at index 34873\n",
      "Saved the embedding for mistrustful.\n",
      "mistrusting is at index 34873\n",
      "Saved the embedding for mistrusting.\n",
      "misunderstood is at index 32085\n",
      "Saved the embedding for misunderstood.\n",
      "mockery is at index 34641\n",
      "Saved the embedding for mockery.\n",
      "mocking is at index 27813\n",
      "Saved the embedding for mocking.\n",
      "mockingly is at index 16177\n",
      "Saved the embedding for mockingly.\n",
      "modest is at index 6473\n",
      "Saved the embedding for modest.\n",
      "monotone is at index 6154\n",
      "Saved the embedding for monotone.\n",
      "monster is at index 13317\n",
      "Saved the embedding for monster.\n",
      "moody is at index 6711\n",
      "Saved the embedding for moody.\n",
      "mopey is at index 475\n",
      "Saved the embedding for mopey.\n",
      "morose is at index 14628\n",
      "Saved the embedding for morose.\n",
      "mortified is at index 18631\n",
      "Saved the embedding for mortified.\n",
      "motivated is at index 7958\n",
      "Saved the embedding for motivated.\n",
      "mournful is at index 15213\n",
      "Saved the embedding for mournful.\n",
      "mournfulness is at index 15213\n",
      "Saved the embedding for mournfulness.\n",
      "mourning is at index 19293\n",
      "Saved the embedding for mourning.\n",
      "mouthed is at index 475\n",
      "Saved the embedding for mouthed.\n",
      "moved is at index 1410\n",
      "Saved the embedding for moved.\n",
      "muddled is at index 475\n",
      "Saved the embedding for muddled.\n",
      "mum is at index 8562\n",
      "Saved the embedding for mum.\n",
      "murderous is at index 32883\n",
      "Saved the embedding for murderous.\n",
      "musical is at index 4388\n",
      "Saved the embedding for musical.\n",
      "musing is at index 11721\n",
      "Saved the embedding for musing.\n",
      "muster is at index 27665\n",
      "Saved the embedding for muster.\n",
      "mute is at index 33758\n",
      "Saved the embedding for mute.\n",
      "muted is at index 21677\n",
      "Saved the embedding for muted.\n",
      "muttering is at index 16119\n",
      "Saved the embedding for muttering.\n",
      "mysterious is at index 12754\n",
      "Saved the embedding for mysterious.\n",
      "mystical is at index 39795\n",
      "Saved the embedding for mystical.\n",
      "mystified is at index 37763\n",
      "Saved the embedding for mystified.\n",
      "naive is at index 25672\n",
      "Saved the embedding for naive.\n",
      "napping is at index 295\n",
      "Saved the embedding for napping.\n",
      "narrow is at index 6787\n",
      "Saved the embedding for narrow.\n",
      "nasty is at index 15455\n",
      "Saved the embedding for nasty.\n",
      "natural is at index 1632\n",
      "Saved the embedding for natural.\n",
      "natured is at index 23577\n",
      "Saved the embedding for natured.\n",
      "naughty is at index 38384\n",
      "Saved the embedding for naughty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nausea is at index 27214\n",
      "Saved the embedding for nausea.\n",
      "nauseated is at index 39117\n",
      "Saved the embedding for nauseated.\n",
      "nauseous is at index 39117\n",
      "Saved the embedding for nauseous.\n",
      "needy is at index 28166\n",
      "Saved the embedding for needy.\n",
      "nefarious is at index 33952\n",
      "Saved the embedding for nefarious.\n",
      "negating is at index 15183\n",
      "Saved the embedding for negating.\n",
      "negative is at index 2430\n",
      "Saved the embedding for negative.\n",
      "negativity is at index 30269\n",
      "Saved the embedding for negativity.\n",
      "neglected is at index 20428\n",
      "Saved the embedding for neglected.\n",
      "nerdy is at index 38286\n",
      "Saved the embedding for nerdy.\n",
      "nerved is at index 295\n",
      "Saved the embedding for nerved.\n",
      "nerves is at index 17358\n",
      "Saved the embedding for nerves.\n",
      "nervous is at index 7464\n",
      "Saved the embedding for nervous.\n",
      "nervously is at index 40968\n",
      "Saved the embedding for nervously.\n",
      "nervousness is at index 7464\n",
      "Saved the embedding for nervousness.\n",
      "nescient is at index 295\n",
      "Saved the embedding for nescient.\n",
      "nettled is at index 1161\n",
      "Saved the embedding for nettled.\n",
      "neutral is at index 7974\n",
      "Saved the embedding for neutral.\n",
      "neutrality is at index 18755\n",
      "Saved the embedding for neutrality.\n",
      "nice is at index 2579\n",
      "Saved the embedding for nice.\n",
      "noisy is at index 28269\n",
      "Saved the embedding for noisy.\n",
      "nonbelief is at index 786\n",
      "Saved the embedding for nonbelief.\n",
      "nonchalance is at index 786\n",
      "Saved the embedding for nonchalance.\n",
      "nonchalant is at index 786\n",
      "Saved the embedding for nonchalant.\n",
      "noncommittal is at index 786\n",
      "Saved the embedding for noncommittal.\n",
      "noncompliant is at index 786\n",
      "Saved the embedding for noncompliant.\n",
      "nonplussed is at index 786\n",
      "Saved the embedding for nonplussed.\n",
      "nonsensical is at index 42475\n",
      "Saved the embedding for nonsensical.\n",
      "normal is at index 2340\n",
      "Saved the embedding for normal.\n",
      "nosey is at index 8658\n",
      "Saved the embedding for nosey.\n",
      "nostalgic is at index 28055\n",
      "Saved the embedding for nostalgic.\n",
      "nosy is at index 13736\n",
      "Saved the embedding for nosy.\n",
      "numb is at index 31086\n",
      "Saved the embedding for numb.\n",
      "obedient is at index 44729\n",
      "Saved the embedding for obedient.\n",
      "objecting is at index 7626\n",
      "Saved the embedding for objecting.\n",
      "objection is at index 24763\n",
      "Saved the embedding for objection.\n",
      "objective is at index 4554\n",
      "Saved the embedding for objective.\n",
      "obliged is at index 23964\n",
      "Saved the embedding for obliged.\n",
      "obliging is at index 23762\n",
      "Saved the embedding for obliging.\n",
      "oblivious is at index 35606\n",
      "Saved the embedding for oblivious.\n",
      "observant is at index 20717\n",
      "Saved the embedding for observant.\n",
      "observing is at index 21981\n",
      "Saved the embedding for observing.\n",
      "obsessed is at index 17593\n",
      "Saved the embedding for obsessed.\n",
      "obstinate is at index 30896\n",
      "Saved the embedding for obstinate.\n",
      "occupied is at index 9533\n",
      "Saved the embedding for occupied.\n",
      "odd is at index 8372\n",
      "Saved the embedding for odd.\n",
      "odious is at index 7452\n",
      "Saved the embedding for odious.\n",
      "off is at index 160\n",
      "Saved the embedding for off.\n",
      "offended is at index 22169\n",
      "Saved the embedding for offended.\n",
      "offensive is at index 2555\n",
      "Saved the embedding for offensive.\n",
      "ogling is at index 1021\n",
      "Saved the embedding for ogling.\n",
      "okay is at index 8578\n",
      "Saved the embedding for okay.\n",
      "on is at index 15\n",
      "Saved the embedding for on.\n",
      "open is at index 490\n",
      "Saved the embedding for open.\n",
      "openness is at index 23163\n",
      "Saved the embedding for openness.\n",
      "opposed is at index 4340\n",
      "Saved the embedding for opposed.\n",
      "oppositional is at index 39734\n",
      "Saved the embedding for oppositional.\n",
      "oppressed is at index 32881\n",
      "Saved the embedding for oppressed.\n",
      "optimism is at index 9743\n",
      "Saved the embedding for optimism.\n",
      "optimistic is at index 7168\n",
      "Saved the embedding for optimistic.\n",
      "ordering is at index 12926\n",
      "Saved the embedding for ordering.\n",
      "orgasmic is at index 39396\n",
      "Saved the embedding for orgasmic.\n",
      "ornery is at index 50\n",
      "Saved the embedding for ornery.\n",
      "ouch is at index 1021\n",
      "Saved the embedding for ouch.\n",
      "out is at index 66\n",
      "Saved the embedding for out.\n",
      "outburst is at index 28999\n",
      "Saved the embedding for outburst.\n",
      "outcry is at index 19900\n",
      "Saved the embedding for outcry.\n",
      "outed is at index 66\n",
      "Saved the embedding for outed.\n",
      "outlandish is at index 35785\n",
      "Saved the embedding for outlandish.\n",
      "outrage is at index 10618\n",
      "Saved the embedding for outrage.\n",
      "outraged is at index 22339\n",
      "Saved the embedding for outraged.\n",
      "outspoken is at index 16120\n",
      "Saved the embedding for outspoken.\n",
      "overbearing is at index 81\n",
      "Saved the embedding for overbearing.\n",
      "overexcited is at index 39919\n",
      "Saved the embedding for overexcited.\n",
      "overjoyed is at index 81\n",
      "Saved the embedding for overjoyed.\n",
      "overshadowed is at index 22140\n",
      "Saved the embedding for overshadowed.\n",
      "overstrung is at index 81\n",
      "Saved the embedding for overstrung.\n",
      "overwhelmed is at index 13203\n",
      "Saved the embedding for overwhelmed.\n",
      "overworked is at index 81\n",
      "Saved the embedding for overworked.\n",
      "overwrought is at index 42674\n",
      "Saved the embedding for overwrought.\n",
      "pain is at index 2400\n",
      "Saved the embedding for pain.\n",
      "pained is at index 181\n",
      "Saved the embedding for pained.\n",
      "painful is at index 8661\n",
      "Saved the embedding for painful.\n",
      "painfully is at index 32020\n",
      "Saved the embedding for painfully.\n",
      "panic is at index 9810\n",
      "Saved the embedding for panic.\n",
      "panicked is at index 28604\n",
      "Saved the embedding for panicked.\n",
      "panicky is at index 5730\n",
      "Saved the embedding for panicky.\n",
      "paralyzed is at index 28582\n",
      "Saved the embedding for paralyzed.\n",
      "paranoid is at index 33554\n",
      "Saved the embedding for paranoid.\n",
      "passionate is at index 8840\n",
      "Saved the embedding for passionate.\n",
      "passive is at index 18718\n",
      "Saved the embedding for passive.\n",
      "patience is at index 11383\n",
      "Saved the embedding for patience.\n",
      "patient is at index 3186\n",
      "Saved the embedding for patient.\n",
      "patronizing is at index 18528\n",
      "Saved the embedding for patronizing.\n",
      "pause is at index 13787\n",
      "Saved the embedding for pause.\n",
      "pausing is at index 6044\n",
      "Saved the embedding for pausing.\n",
      "peaceful is at index 7053\n",
      "Saved the embedding for peaceful.\n",
      "peculiar is at index 28178\n",
      "Saved the embedding for peculiar.\n",
      "peering is at index 3723\n",
      "Saved the embedding for peering.\n",
      "peeved is at index 32734\n",
      "Saved the embedding for peeved.\n",
      "peevish is at index 3723\n",
      "Saved the embedding for peevish.\n",
      "pensive is at index 181\n",
      "Saved the embedding for pensive.\n",
      "peppy is at index 3723\n",
      "Saved the embedding for peppy.\n",
      "perceptive is at index 228\n",
      "Saved the embedding for perceptive.\n",
      "perfidious is at index 32168\n",
      "Saved the embedding for perfidious.\n",
      "perky is at index 228\n",
      "Saved the embedding for perky.\n",
      "perplexed is at index 33708\n",
      "Saved the embedding for perplexed.\n",
      "perplexing is at index 33708\n",
      "Saved the embedding for perplexing.\n",
      "persistent is at index 13109\n",
      "Saved the embedding for persistent.\n",
      "personable is at index 621\n",
      "Saved the embedding for personable.\n",
      "perturbed is at index 32819\n",
      "Saved the embedding for perturbed.\n",
      "perverse is at index 41271\n",
      "Saved the embedding for perverse.\n",
      "pesky is at index 38432\n",
      "Saved the embedding for pesky.\n",
      "pessimism is at index 36494\n",
      "Saved the embedding for pessimism.\n",
      "pessimistic is at index 32415\n",
      "Saved the embedding for pessimistic.\n",
      "pestered is at index 19024\n",
      "Saved the embedding for pestered.\n",
      "petitioning is at index 5265\n",
      "Saved the embedding for petitioning.\n",
      "petrified is at index 4716\n",
      "Saved the embedding for petrified.\n",
      "petty is at index 25070\n",
      "Saved the embedding for petty.\n",
      "petulant is at index 4716\n",
      "Saved the embedding for petulant.\n",
      "picked is at index 2738\n",
      "Saved the embedding for picked.\n",
      "piercing is at index 38105\n",
      "Saved the embedding for piercing.\n",
      "pinched is at index 7756\n",
      "Saved the embedding for pinched.\n",
      "pious is at index 44843\n",
      "Saved the embedding for pious.\n",
      "piqued is at index 181\n",
      "Saved the embedding for piqued.\n",
      "pissed is at index 34449\n",
      "Saved the embedding for pissed.\n",
      "pitiable is at index 8516\n",
      "Saved the embedding for pitiable.\n",
      "pitiful is at index 8516\n",
      "Saved the embedding for pitiful.\n",
      "pity is at index 31373\n",
      "Saved the embedding for pity.\n",
      "pitying is at index 31373\n",
      "Saved the embedding for pitying.\n",
      "placated is at index 15155\n",
      "Saved the embedding for placated.\n",
      "placation is at index 15155\n",
      "Saved the embedding for placation.\n",
      "placid is at index 15155\n",
      "Saved the embedding for placid.\n",
      "plain is at index 10798\n",
      "Saved the embedding for plain.\n",
      "plaintive is at index 46560\n",
      "Saved the embedding for plaintive.\n",
      "planning is at index 1884\n",
      "Saved the embedding for planning.\n",
      "playful is at index 23317\n",
      "Saved the embedding for playful.\n",
      "playfully is at index 310\n",
      "Saved the embedding for playfully.\n",
      "pleading is at index 17532\n",
      "Saved the embedding for pleading.\n",
      "pleasant is at index 16219\n",
      "Saved the embedding for pleasant.\n",
      "pleased is at index 4343\n",
      "Saved the embedding for pleased.\n",
      "pleasing is at index 25234\n",
      "Saved the embedding for pleasing.\n",
      "pleasurable is at index 19518\n",
      "Saved the embedding for pleasurable.\n",
      "pleasure is at index 10483\n",
      "Saved the embedding for pleasure.\n",
      "pleasured is at index 19518\n",
      "Saved the embedding for pleasured.\n",
      "pliant is at index 2968\n",
      "Saved the embedding for pliant.\n",
      "plotting is at index 22849\n",
      "Saved the embedding for plotting.\n",
      "poignant is at index 27274\n",
      "Saved the embedding for poignant.\n",
      "pointed is at index 3273\n",
      "Saved the embedding for pointed.\n",
      "poised is at index 10137\n",
      "Saved the embedding for poised.\n",
      "polite is at index 24908\n",
      "Saved the embedding for polite.\n",
      "pompous is at index 34415\n",
      "Saved the embedding for pompous.\n",
      "ponder is at index 31930\n",
      "Saved the embedding for ponder.\n",
      "pondering is at index 13362\n",
      "Saved the embedding for pondering.\n",
      "pooping is at index 4202\n",
      "Saved the embedding for pooping.\n",
      "pop is at index 3495\n",
      "Saved the embedding for pop.\n",
      "posing is at index 12681\n",
      "Saved the embedding for posing.\n",
      "positive is at index 1313\n",
      "Saved the embedding for positive.\n",
      "positivity is at index 8593\n",
      "Saved the embedding for positivity.\n",
      "possibly is at index 3544\n",
      "Saved the embedding for possibly.\n",
      "pout is at index 181\n",
      "Saved the embedding for pout.\n",
      "pouting is at index 181\n",
      "Saved the embedding for pouting.\n",
      "pouty is at index 181\n",
      "Saved the embedding for pouty.\n",
      "powerful is at index 2247\n",
      "Saved the embedding for powerful.\n",
      "powerless is at index 33128\n",
      "Saved the embedding for powerless.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pranking is at index 3349\n",
      "Saved the embedding for pranking.\n",
      "precarious is at index 27180\n",
      "Saved the embedding for precarious.\n",
      "predatory is at index 29216\n",
      "Saved the embedding for predatory.\n",
      "prejudiced is at index 34286\n",
      "Saved the embedding for prejudiced.\n",
      "preoccupied is at index 1198\n",
      "Saved the embedding for preoccupied.\n",
      "prepared is at index 2460\n",
      "Saved the embedding for prepared.\n",
      "preparing is at index 4568\n",
      "Saved the embedding for preparing.\n",
      "pretending is at index 23748\n",
      "Saved the embedding for pretending.\n",
      "pretentious is at index 11857\n",
      "Saved the embedding for pretentious.\n",
      "prideful is at index 7040\n",
      "Saved the embedding for prideful.\n",
      "priggish is at index 3349\n",
      "Saved the embedding for priggish.\n",
      "primed is at index 32575\n",
      "Saved the embedding for primed.\n",
      "private is at index 940\n",
      "Saved the embedding for private.\n",
      "processing is at index 5774\n",
      "Saved the embedding for processing.\n",
      "propositioning is at index 16104\n",
      "Saved the embedding for propositioning.\n",
      "proud is at index 2602\n",
      "Saved the embedding for proud.\n",
      "provocative is at index 21051\n",
      "Saved the embedding for provocative.\n",
      "provoke is at index 28184\n",
      "Saved the embedding for provoke.\n",
      "provoked is at index 24972\n",
      "Saved the embedding for provoked.\n",
      "provoking is at index 35359\n",
      "Saved the embedding for provoking.\n",
      "prying is at index 181\n",
      "Saved the embedding for prying.\n",
      "psycho is at index 37338\n",
      "Saved the embedding for psycho.\n",
      "psychotic is at index 41559\n",
      "Saved the embedding for psychotic.\n",
      "puckish is at index 9258\n",
      "Saved the embedding for puckish.\n",
      "puerile is at index 181\n",
      "Saved the embedding for puerile.\n",
      "pugnacious is at index 181\n",
      "Saved the embedding for pugnacious.\n",
      "punished is at index 14459\n",
      "Saved the embedding for punished.\n",
      "punishing is at index 23477\n",
      "Saved the embedding for punishing.\n",
      "punitive is at index 21987\n",
      "Saved the embedding for punitive.\n",
      "punk is at index 19742\n",
      "Saved the embedding for punk.\n",
      "puppyish is at index 20830\n",
      "Saved the embedding for puppyish.\n",
      "purposeful is at index 3508\n",
      "Saved the embedding for purposeful.\n",
      "pursed is at index 26934\n",
      "Saved the embedding for pursed.\n",
      "put is at index 342\n",
      "Saved the embedding for put.\n",
      "putting is at index 2057\n",
      "Saved the embedding for putting.\n",
      "puzzled is at index 36742\n",
      "Saved the embedding for puzzled.\n",
      "puzzlement is at index 47037\n",
      "Saved the embedding for puzzlement.\n",
      "qualms is at index 22043\n",
      "Saved the embedding for qualms.\n",
      "quarrelsome is at index 39486\n",
      "Saved the embedding for quarrelsome.\n",
      "queasy is at index 1192\n",
      "Saved the embedding for queasy.\n",
      "quenched is at index 2677\n",
      "Saved the embedding for quenched.\n",
      "questionable is at index 12474\n",
      "Saved the embedding for questionable.\n",
      "questioning is at index 8026\n",
      "Saved the embedding for questioning.\n",
      "questioningly is at index 864\n",
      "Saved the embedding for questioningly.\n",
      "quiet is at index 5128\n",
      "Saved the embedding for quiet.\n",
      "quietness is at index 5128\n",
      "Saved the embedding for quietness.\n",
      "quilt is at index 2677\n",
      "Saved the embedding for quilt.\n",
      "quirky is at index 22364\n",
      "Saved the embedding for quirky.\n",
      "quizzical is at index 29316\n",
      "Saved the embedding for quizzical.\n",
      "rabid is at index 39660\n",
      "Saved the embedding for rabid.\n",
      "racked is at index 20208\n",
      "Saved the embedding for racked.\n",
      "radiant is at index 35787\n",
      "Saved the embedding for radiant.\n",
      "rage is at index 14706\n",
      "Saved the embedding for rage.\n",
      "raged is at index 31927\n",
      "Saved the embedding for raged.\n",
      "ragged is at index 910\n",
      "Saved the embedding for ragged.\n",
      "raging is at index 23333\n",
      "Saved the embedding for raging.\n",
      "rancorous is at index 21560\n",
      "Saved the embedding for rancorous.\n",
      "randy is at index 910\n",
      "Saved the embedding for randy.\n",
      "rapt is at index 34524\n",
      "Saved the embedding for rapt.\n",
      "rattled is at index 21602\n",
      "Saved the embedding for rattled.\n",
      "raving is at index 910\n",
      "Saved the embedding for raving.\n",
      "reactive is at index 34729\n",
      "Saved the embedding for reactive.\n",
      "ready is at index 1227\n",
      "Saved the embedding for ready.\n",
      "realization is at index 24179\n",
      "Saved the embedding for realization.\n",
      "reassured is at index 29336\n",
      "Saved the embedding for reassured.\n",
      "rebellious is at index 38017\n",
      "Saved the embedding for rebellious.\n",
      "rebuke is at index 28155\n",
      "Saved the embedding for rebuke.\n",
      "recalling is at index 20239\n",
      "Saved the embedding for recalling.\n",
      "receptive is at index 33052\n",
      "Saved the embedding for receptive.\n",
      "reckless is at index 13508\n",
      "Saved the embedding for reckless.\n",
      "recoil is at index 44983\n",
      "Saved the embedding for recoil.\n",
      "recoiling is at index 3872\n",
      "Saved the embedding for recoiling.\n",
      "reflecting is at index 10811\n",
      "Saved the embedding for reflecting.\n",
      "reflection is at index 12456\n",
      "Saved the embedding for reflection.\n",
      "reflective is at index 22213\n",
      "Saved the embedding for reflective.\n",
      "refulgent is at index 769\n",
      "Saved the embedding for refulgent.\n",
      "refusing is at index 10520\n",
      "Saved the embedding for refusing.\n",
      "regret is at index 9917\n",
      "Saved the embedding for regret.\n",
      "regretful is at index 9917\n",
      "Saved the embedding for regretful.\n",
      "rejected is at index 3946\n",
      "Saved the embedding for rejected.\n",
      "rejecting is at index 19695\n",
      "Saved the embedding for rejecting.\n",
      "rejection is at index 16117\n",
      "Saved the embedding for rejection.\n",
      "rejoicing is at index 24586\n",
      "Saved the embedding for rejoicing.\n",
      "relaxation is at index 26545\n",
      "Saved the embedding for relaxation.\n",
      "relaxed is at index 11956\n",
      "Saved the embedding for relaxed.\n",
      "relentless is at index 16476\n",
      "Saved the embedding for relentless.\n",
      "relief is at index 3500\n",
      "Saved the embedding for relief.\n",
      "relieved is at index 15126\n",
      "Saved the embedding for relieved.\n",
      "relived is at index 6258\n",
      "Saved the embedding for relived.\n",
      "reluctant is at index 11923\n",
      "Saved the embedding for reluctant.\n",
      "reluctantly is at index 33146\n",
      "Saved the embedding for reluctantly.\n",
      "remorse is at index 23312\n",
      "Saved the embedding for remorse.\n",
      "remorseful is at index 23312\n",
      "Saved the embedding for remorseful.\n",
      "repelled is at index 25633\n",
      "Saved the embedding for repelled.\n",
      "repressed is at index 2851\n",
      "Saved the embedding for repressed.\n",
      "reproach is at index 2851\n",
      "Saved the embedding for reproach.\n",
      "reproachful is at index 2851\n",
      "Saved the embedding for reproachful.\n",
      "repugnance is at index 2851\n",
      "Saved the embedding for repugnance.\n",
      "repugnant is at index 2851\n",
      "Saved the embedding for repugnant.\n",
      "repulsed is at index 2851\n",
      "Saved the embedding for repulsed.\n",
      "repulsion is at index 2851\n",
      "Saved the embedding for repulsion.\n",
      "resent is at index 31379\n",
      "Saved the embedding for resent.\n",
      "resentful is at index 31379\n",
      "Saved the embedding for resentful.\n",
      "resenting is at index 31379\n",
      "Saved the embedding for resenting.\n",
      "resentment is at index 27111\n",
      "Saved the embedding for resentment.\n",
      "reserved is at index 1875\n",
      "Saved the embedding for reserved.\n",
      "resignation is at index 6985\n",
      "Saved the embedding for resignation.\n",
      "resigned is at index 6490\n",
      "Saved the embedding for resigned.\n",
      "resilience is at index 13790\n",
      "Saved the embedding for resilience.\n",
      "resistance is at index 5910\n",
      "Saved the embedding for resistance.\n",
      "resistant is at index 19152\n",
      "Saved the embedding for resistant.\n",
      "resistent is at index 11942\n",
      "Saved the embedding for resistent.\n",
      "resisting is at index 18907\n",
      "Saved the embedding for resisting.\n",
      "resolute is at index 5032\n",
      "Saved the embedding for resolute.\n",
      "resolved is at index 8179\n",
      "Saved the embedding for resolved.\n",
      "responsive is at index 20666\n",
      "Saved the embedding for responsive.\n",
      "restful is at index 1079\n",
      "Saved the embedding for restful.\n",
      "resting is at index 18403\n",
      "Saved the embedding for resting.\n",
      "restless is at index 36844\n",
      "Saved the embedding for restless.\n",
      "restlessness is at index 1079\n",
      "Saved the embedding for restlessness.\n",
      "restrained is at index 25063\n",
      "Saved the embedding for restrained.\n",
      "restraint is at index 20219\n",
      "Saved the embedding for restraint.\n",
      "retaliating is at index 18570\n",
      "Saved the embedding for retaliating.\n",
      "retaliatory is at index 18570\n",
      "Saved the embedding for retaliatory.\n",
      "rethinking is at index 769\n",
      "Saved the embedding for rethinking.\n",
      "reticence is at index 5494\n",
      "Saved the embedding for reticence.\n",
      "reticent is at index 5494\n",
      "Saved the embedding for reticent.\n",
      "revengeful is at index 13543\n",
      "Saved the embedding for revengeful.\n",
      "reverent is at index 26911\n",
      "Saved the embedding for reverent.\n",
      "revolted is at index 34633\n",
      "Saved the embedding for revolted.\n",
      "revulsion is at index 6910\n",
      "Saved the embedding for revulsion.\n",
      "righteous is at index 37909\n",
      "Saved the embedding for righteous.\n",
      "rigid is at index 24577\n",
      "Saved the embedding for rigid.\n",
      "riled is at index 910\n",
      "Saved the embedding for riled.\n",
      "riotous is at index 13069\n",
      "Saved the embedding for riotous.\n",
      "riveted is at index 32886\n",
      "Saved the embedding for riveted.\n",
      "roar is at index 31733\n",
      "Saved the embedding for roar.\n",
      "roguish is at index 4533\n",
      "Saved the embedding for roguish.\n",
      "roiled is at index 4533\n",
      "Saved the embedding for roiled.\n",
      "rough is at index 6744\n",
      "Saved the embedding for rough.\n",
      "roused is at index 910\n",
      "Saved the embedding for roused.\n",
      "rude is at index 21820\n",
      "Saved the embedding for rude.\n",
      "rueful is at index 910\n",
      "Saved the embedding for rueful.\n",
      "ruffled is at index 910\n",
      "Saved the embedding for ruffled.\n",
      "ruminating is at index 11122\n",
      "Saved the embedding for ruminating.\n",
      "rustled is at index 18309\n",
      "Saved the embedding for rustled.\n",
      "ruthless is at index 25597\n",
      "Saved the embedding for ruthless.\n",
      "sad is at index 5074\n",
      "Saved the embedding for sad.\n",
      "sadden is at index 23330\n",
      "Saved the embedding for sadden.\n",
      "saddened is at index 19934\n",
      "Saved the embedding for saddened.\n",
      "sadistic is at index 5074\n",
      "Saved the embedding for sadistic.\n",
      "sadness is at index 17437\n",
      "Saved the embedding for sadness.\n",
      "salacious is at index 6641\n",
      "Saved the embedding for salacious.\n",
      "salivating is at index 6641\n",
      "Saved the embedding for salivating.\n",
      "sanctimonious is at index 27600\n",
      "Saved the embedding for sanctimonious.\n",
      "sane is at index 37091\n",
      "Saved the embedding for sane.\n",
      "sanguine is at index 579\n",
      "Saved the embedding for sanguine.\n",
      "sappy is at index 2241\n",
      "Saved the embedding for sappy.\n",
      "sarcasm is at index 38522\n",
      "Saved the embedding for sarcasm.\n",
      "sarcastic is at index 39580\n",
      "Saved the embedding for sarcastic.\n",
      "sardonic is at index 579\n",
      "Saved the embedding for sardonic.\n",
      "sassy is at index 579\n",
      "Saved the embedding for sassy.\n",
      "sated is at index 579\n",
      "Saved the embedding for sated.\n",
      "satiated is at index 4005\n",
      "Saved the embedding for satiated.\n",
      "satirical is at index 33937\n",
      "Saved the embedding for satirical.\n",
      "satisfaction is at index 11658\n",
      "Saved the embedding for satisfaction.\n",
      "satisfied is at index 10028\n",
      "Saved the embedding for satisfied.\n",
      "satisfy is at index 15332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for satisfy.\n",
      "saturnine is at index 4005\n",
      "Saved the embedding for saturnine.\n",
      "saucy is at index 2241\n",
      "Saved the embedding for saucy.\n",
      "savage is at index 32264\n",
      "Saved the embedding for savage.\n",
      "scandalized is at index 4220\n",
      "Saved the embedding for scandalized.\n",
      "scare is at index 13207\n",
      "Saved the embedding for scare.\n",
      "scared is at index 8265\n",
      "Saved the embedding for scared.\n",
      "scary is at index 10222\n",
      "Saved the embedding for scary.\n",
      "scattered is at index 12827\n",
      "Saved the embedding for scattered.\n",
      "schadenfreude is at index 8447\n",
      "Saved the embedding for schadenfreude.\n",
      "scheming is at index 30315\n",
      "Saved the embedding for scheming.\n",
      "scoffer is at index 34564\n",
      "Saved the embedding for scoffer.\n",
      "scoffing is at index 34564\n",
      "Saved the embedding for scoffing.\n",
      "scorn is at index 38430\n",
      "Saved the embedding for scorn.\n",
      "scorned is at index 2850\n",
      "Saved the embedding for scorned.\n",
      "scornful is at index 38430\n",
      "Saved the embedding for scornful.\n",
      "scowl is at index 2850\n",
      "Saved the embedding for scowl.\n",
      "scowling is at index 2850\n",
      "Saved the embedding for scowling.\n",
      "scream is at index 22093\n",
      "Saved the embedding for scream.\n",
      "screaming is at index 11347\n",
      "Saved the embedding for screaming.\n",
      "scrutinizing is at index 18470\n",
      "Saved the embedding for scrutinizing.\n",
      "sealed is at index 10497\n",
      "Saved the embedding for sealed.\n",
      "searching is at index 6062\n",
      "Saved the embedding for searching.\n",
      "secretive is at index 27174\n",
      "Saved the embedding for secretive.\n",
      "secretively is at index 3556\n",
      "Saved the embedding for secretively.\n",
      "secure is at index 2823\n",
      "Saved the embedding for secure.\n",
      "sedate is at index 10195\n",
      "Saved the embedding for sedate.\n",
      "seduction is at index 10195\n",
      "Saved the embedding for seduction.\n",
      "seductive is at index 10195\n",
      "Saved the embedding for seductive.\n",
      "seething is at index 842\n",
      "Saved the embedding for seething.\n",
      "self is at index 1403\n",
      "Saved the embedding for self.\n",
      "sensual is at index 18105\n",
      "Saved the embedding for sensual.\n",
      "sentimental is at index 32693\n",
      "Saved the embedding for sentimental.\n",
      "serene is at index 842\n",
      "Saved the embedding for serene.\n",
      "serious is at index 1473\n",
      "Saved the embedding for serious.\n",
      "seriousness is at index 24146\n",
      "Saved the embedding for seriousness.\n",
      "servile is at index 18527\n",
      "Saved the embedding for servile.\n",
      "set is at index 278\n",
      "Saved the embedding for set.\n",
      "severe is at index 3814\n",
      "Saved the embedding for severe.\n",
      "shabby is at index 1481\n",
      "Saved the embedding for shabby.\n",
      "shady is at index 31665\n",
      "Saved the embedding for shady.\n",
      "shaken is at index 17548\n",
      "Saved the embedding for shaken.\n",
      "shaky is at index 22032\n",
      "Saved the embedding for shaky.\n",
      "shame is at index 9208\n",
      "Saved the embedding for shame.\n",
      "shamed is at index 1481\n",
      "Saved the embedding for shamed.\n",
      "shamefaced is at index 9208\n",
      "Saved the embedding for shamefaced.\n",
      "shameful is at index 26722\n",
      "Saved the embedding for shameful.\n",
      "shameless is at index 36778\n",
      "Saved the embedding for shameless.\n",
      "sharp is at index 4406\n",
      "Saved the embedding for sharp.\n",
      "sheepish is at index 14336\n",
      "Saved the embedding for sheepish.\n",
      "sheepishness is at index 14336\n",
      "Saved the embedding for sheepishness.\n",
      "shelled is at index 79\n",
      "Saved the embedding for shelled.\n",
      "shifty is at index 37503\n",
      "Saved the embedding for shifty.\n",
      "shock is at index 4817\n",
      "Saved the embedding for shock.\n",
      "shocked is at index 6649\n",
      "Saved the embedding for shocked.\n",
      "shocking is at index 8777\n",
      "Saved the embedding for shocking.\n",
      "shockingly is at index 36804\n",
      "Saved the embedding for shockingly.\n",
      "shook is at index 14774\n",
      "Saved the embedding for shook.\n",
      "shout is at index 18066\n",
      "Saved the embedding for shout.\n",
      "shouting is at index 14487\n",
      "Saved the embedding for shouting.\n",
      "shrewd is at index 36943\n",
      "Saved the embedding for shrewd.\n",
      "shy is at index 9152\n",
      "Saved the embedding for shy.\n",
      "shyness is at index 9152\n",
      "Saved the embedding for shyness.\n",
      "sick is at index 4736\n",
      "Saved the embedding for sick.\n",
      "sicken is at index 579\n",
      "Saved the embedding for sicken.\n",
      "sickened is at index 4736\n",
      "Saved the embedding for sickened.\n",
      "sigh is at index 27305\n",
      "Saved the embedding for sigh.\n",
      "silenced is at index 30125\n",
      "Saved the embedding for silenced.\n",
      "silent is at index 8454\n",
      "Saved the embedding for silent.\n",
      "silliness is at index 38052\n",
      "Saved the embedding for silliness.\n",
      "silly is at index 15470\n",
      "Saved the embedding for silly.\n",
      "simmering is at index 25726\n",
      "Saved the embedding for simmering.\n",
      "simper is at index 16207\n",
      "Saved the embedding for simper.\n",
      "simpering is at index 16207\n",
      "Saved the embedding for simpering.\n",
      "simple is at index 2007\n",
      "Saved the embedding for simple.\n",
      "simplicity is at index 25342\n",
      "Saved the embedding for simplicity.\n",
      "sincere is at index 19255\n",
      "Saved the embedding for sincere.\n",
      "sinful is at index 44364\n",
      "Saved the embedding for sinful.\n",
      "singing is at index 6970\n",
      "Saved the embedding for singing.\n",
      "sinister is at index 27570\n",
      "Saved the embedding for sinister.\n",
      "sinisterly is at index 27570\n",
      "Saved the embedding for sinisterly.\n",
      "sizing is at index 39328\n",
      "Saved the embedding for sizing.\n",
      "skeptic is at index 42386\n",
      "Saved the embedding for skeptic.\n",
      "skeptical is at index 14992\n",
      "Saved the embedding for skeptical.\n",
      "skeptically is at index 42386\n",
      "Saved the embedding for skeptically.\n",
      "skepticism is at index 22222\n",
      "Saved the embedding for skepticism.\n",
      "sketchy is at index 15923\n",
      "Saved the embedding for sketchy.\n",
      "skittish is at index 2972\n",
      "Saved the embedding for skittish.\n",
      "slack is at index 25163\n",
      "Saved the embedding for slack.\n",
      "sleazy is at index 18388\n",
      "Saved the embedding for sleazy.\n",
      "sleepy is at index 33782\n",
      "Saved the embedding for sleepy.\n",
      "slick is at index 19038\n",
      "Saved the embedding for slick.\n",
      "slothful is at index 3369\n",
      "Saved the embedding for slothful.\n",
      "slow is at index 2635\n",
      "Saved the embedding for slow.\n",
      "sluggish is at index 16642\n",
      "Saved the embedding for sluggish.\n",
      "sly is at index 40568\n",
      "Saved the embedding for sly.\n",
      "smarmy is at index 5278\n",
      "Saved the embedding for smarmy.\n",
      "smart is at index 2793\n",
      "Saved the embedding for smart.\n",
      "smashed is at index 13263\n",
      "Saved the embedding for smashed.\n",
      "smile is at index 6675\n",
      "Saved the embedding for smile.\n",
      "smiley is at index 6675\n",
      "Saved the embedding for smiley.\n",
      "smiling is at index 12382\n",
      "Saved the embedding for smiling.\n",
      "smirk is at index 5278\n",
      "Saved the embedding for smirk.\n",
      "smirking is at index 44414\n",
      "Saved the embedding for smirking.\n",
      "smoldering is at index 5278\n",
      "Saved the embedding for smoldering.\n",
      "smooching is at index 5278\n",
      "Saved the embedding for smooching.\n",
      "smooth is at index 6921\n",
      "Saved the embedding for smooth.\n",
      "smug is at index 41283\n",
      "Saved the embedding for smug.\n",
      "smugness is at index 41283\n",
      "Saved the embedding for smugness.\n",
      "snake is at index 16173\n",
      "Saved the embedding for snake.\n",
      "snappy is at index 4543\n",
      "Saved the embedding for snappy.\n",
      "snarky is at index 4543\n",
      "Saved the embedding for snarky.\n",
      "snarl is at index 4543\n",
      "Saved the embedding for snarl.\n",
      "snarled is at index 4543\n",
      "Saved the embedding for snarled.\n",
      "snarling is at index 4543\n",
      "Saved the embedding for snarling.\n",
      "snarly is at index 4543\n",
      "Saved the embedding for snarly.\n",
      "sneaky is at index 39399\n",
      "Saved the embedding for sneaky.\n",
      "sneer is at index 18013\n",
      "Saved the embedding for sneer.\n",
      "sneering is at index 18013\n",
      "Saved the embedding for sneering.\n",
      "sneeze is at index 18013\n",
      "Saved the embedding for sneeze.\n",
      "sneezing is at index 18013\n",
      "Saved the embedding for sneezing.\n",
      "snicker is at index 4543\n",
      "Saved the embedding for snicker.\n",
      "snickering is at index 4543\n",
      "Saved the embedding for snickering.\n",
      "snide is at index 4543\n",
      "Saved the embedding for snide.\n",
      "sniggering is at index 4543\n",
      "Saved the embedding for sniggering.\n",
      "sniveling is at index 4543\n",
      "Saved the embedding for sniveling.\n",
      "snobbish is at index 4543\n",
      "Saved the embedding for snobbish.\n",
      "snobby is at index 4543\n",
      "Saved the embedding for snobby.\n",
      "snooty is at index 4543\n",
      "Saved the embedding for snooty.\n",
      "snotty is at index 579\n",
      "Saved the embedding for snotty.\n",
      "sociable is at index 17380\n",
      "Saved the embedding for sociable.\n",
      "soft is at index 3793\n",
      "Saved the embedding for soft.\n",
      "solemn is at index 29807\n",
      "Saved the embedding for solemn.\n",
      "solicitous is at index 22706\n",
      "Saved the embedding for solicitous.\n",
      "solitary is at index 24429\n",
      "Saved the embedding for solitary.\n",
      "solitude is at index 41813\n",
      "Saved the embedding for solitude.\n",
      "somber is at index 16487\n",
      "Saved the embedding for somber.\n",
      "somberly is at index 16487\n",
      "Saved the embedding for somberly.\n",
      "somnolent is at index 16487\n",
      "Saved the embedding for somnolent.\n",
      "soothed is at index 98\n",
      "Saved the embedding for soothed.\n",
      "sore is at index 12867\n",
      "Saved the embedding for sore.\n",
      "sorrow is at index 26130\n",
      "Saved the embedding for sorrow.\n",
      "sorrowful is at index 26130\n",
      "Saved the embedding for sorrowful.\n",
      "sorry is at index 6661\n",
      "Saved the embedding for sorry.\n",
      "sour is at index 16933\n",
      "Saved the embedding for sour.\n",
      "spaced is at index 42926\n",
      "Saved the embedding for spaced.\n",
      "spacing is at index 39152\n",
      "Saved the embedding for spacing.\n",
      "spastic is at index 2292\n",
      "Saved the embedding for spastic.\n",
      "speaking is at index 2686\n",
      "Saved the embedding for speaking.\n",
      "specious is at index 12002\n",
      "Saved the embedding for specious.\n",
      "speculative is at index 21779\n",
      "Saved the embedding for speculative.\n",
      "speechless is at index 1901\n",
      "Saved the embedding for speechless.\n",
      "spent is at index 1240\n",
      "Saved the embedding for spent.\n",
      "spirited is at index 27206\n",
      "Saved the embedding for spirited.\n",
      "spiritless is at index 4780\n",
      "Saved the embedding for spiritless.\n",
      "spite is at index 14117\n",
      "Saved the embedding for spite.\n",
      "spiteful is at index 14117\n",
      "Saved the embedding for spiteful.\n",
      "spoiled is at index 29136\n",
      "Saved the embedding for spoiled.\n",
      "spooked is at index 2292\n",
      "Saved the embedding for spooked.\n",
      "squeamish is at index 33380\n",
      "Saved the embedding for squeamish.\n",
      "staggered is at index 37646\n",
      "Saved the embedding for staggered.\n",
      "stalker is at index 1690\n",
      "Saved the embedding for stalker.\n",
      "stare is at index 27655\n",
      "Saved the embedding for stare.\n",
      "staring is at index 19311\n",
      "Saved the embedding for staring.\n",
      "starstruck is at index 999\n",
      "Saved the embedding for starstruck.\n",
      "started is at index 554\n",
      "Saved the embedding for started.\n",
      "startled is at index 37747\n",
      "Saved the embedding for startled.\n",
      "stately is at index 194\n",
      "Saved the embedding for stately.\n",
      "steadfast is at index 25781\n",
      "Saved the embedding for steadfast.\n",
      "steady is at index 5204\n",
      "Saved the embedding for steady.\n",
      "stealthy is at index 27026\n",
      "Saved the embedding for stealthy.\n",
      "steamed is at index 11235\n",
      "Saved the embedding for steamed.\n",
      "steaming is at index 11235\n",
      "Saved the embedding for steaming.\n",
      "steeling is at index 3689\n",
      "Saved the embedding for steeling.\n",
      "steely is at index 1690\n",
      "Saved the embedding for steely.\n",
      "stern is at index 23427\n",
      "Saved the embedding for stern.\n",
      "stiff is at index 13116\n",
      "Saved the embedding for stiff.\n",
      "stifled is at index 1690\n",
      "Saved the embedding for stifled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stifling is at index 1690\n",
      "Saved the embedding for stifling.\n",
      "still is at index 202\n",
      "Saved the embedding for still.\n",
      "stillness is at index 202\n",
      "Saved the embedding for stillness.\n",
      "stimulated is at index 42040\n",
      "Saved the embedding for stimulated.\n",
      "stinky is at index 1690\n",
      "Saved the embedding for stinky.\n",
      "stirred is at index 26158\n",
      "Saved the embedding for stirred.\n",
      "stoic is at index 20572\n",
      "Saved the embedding for stoic.\n",
      "stoical is at index 20572\n",
      "Saved the embedding for stoical.\n",
      "stolid is at index 1690\n",
      "Saved the embedding for stolid.\n",
      "stoned is at index 1690\n",
      "Saved the embedding for stoned.\n",
      "storming is at index 2130\n",
      "Saved the embedding for storming.\n",
      "stormy is at index 2130\n",
      "Saved the embedding for stormy.\n",
      "stout is at index 34636\n",
      "Saved the embedding for stout.\n",
      "straight is at index 1359\n",
      "Saved the embedding for straight.\n",
      "strained is at index 15718\n",
      "Saved the embedding for strained.\n",
      "strange is at index 7782\n",
      "Saved the embedding for strange.\n",
      "stressed is at index 5882\n",
      "Saved the embedding for stressed.\n",
      "stricken is at index 35876\n",
      "Saved the embedding for stricken.\n",
      "strict is at index 8414\n",
      "Saved the embedding for strict.\n",
      "strong is at index 670\n",
      "Saved the embedding for strong.\n",
      "struck is at index 2322\n",
      "Saved the embedding for struck.\n",
      "stubborn is at index 20476\n",
      "Saved the embedding for stubborn.\n",
      "stubbornness is at index 20476\n",
      "Saved the embedding for stubbornness.\n",
      "studious is at index 15863\n",
      "Saved the embedding for studious.\n",
      "studying is at index 7739\n",
      "Saved the embedding for studying.\n",
      "stumped is at index 1690\n",
      "Saved the embedding for stumped.\n",
      "stung is at index 1690\n",
      "Saved the embedding for stung.\n",
      "stunned is at index 12144\n",
      "Saved the embedding for stunned.\n",
      "stupefaction is at index 1690\n",
      "Saved the embedding for stupefaction.\n",
      "stupefied is at index 1690\n",
      "Saved the embedding for stupefied.\n",
      "stupefy is at index 1690\n",
      "Saved the embedding for stupefy.\n",
      "stupid is at index 12103\n",
      "Saved the embedding for stupid.\n",
      "stuporous is at index 1690\n",
      "Saved the embedding for stuporous.\n",
      "suave is at index 2628\n",
      "Saved the embedding for suave.\n",
      "subdued is at index 20247\n",
      "Saved the embedding for subdued.\n",
      "sublime is at index 32477\n",
      "Saved the embedding for sublime.\n",
      "submissive is at index 2849\n",
      "Saved the embedding for submissive.\n",
      "suffering is at index 3606\n",
      "Saved the embedding for suffering.\n",
      "suggestive is at index 38907\n",
      "Saved the embedding for suggestive.\n",
      "sulking is at index 26648\n",
      "Saved the embedding for sulking.\n",
      "sulky is at index 26648\n",
      "Saved the embedding for sulky.\n",
      "sullen is at index 2628\n",
      "Saved the embedding for sullen.\n",
      "sullenness is at index 2628\n",
      "Saved the embedding for sullenness.\n",
      "sunny is at index 5419\n",
      "Saved the embedding for sunny.\n",
      "superior is at index 10295\n",
      "Saved the embedding for superior.\n",
      "superiority is at index 32951\n",
      "Saved the embedding for superiority.\n",
      "suppressed is at index 31683\n",
      "Saved the embedding for suppressed.\n",
      "suppressing is at index 38919\n",
      "Saved the embedding for suppressing.\n",
      "suppression is at index 25276\n",
      "Saved the embedding for suppression.\n",
      "sure is at index 686\n",
      "Saved the embedding for sure.\n",
      "surly is at index 8113\n",
      "Saved the embedding for surly.\n",
      "surprise is at index 2755\n",
      "Saved the embedding for surprise.\n",
      "surprised is at index 3911\n",
      "Saved the embedding for surprised.\n",
      "surprising is at index 6167\n",
      "Saved the embedding for surprising.\n",
      "surprisingly is at index 10262\n",
      "Saved the embedding for surprisingly.\n",
      "surreptitious is at index 8113\n",
      "Saved the embedding for surreptitious.\n",
      "suspect is at index 1985\n",
      "Saved the embedding for suspect.\n",
      "suspecting is at index 1985\n",
      "Saved the embedding for suspecting.\n",
      "suspense is at index 31803\n",
      "Saved the embedding for suspense.\n",
      "suspicion is at index 8551\n",
      "Saved the embedding for suspicion.\n",
      "suspicious is at index 7775\n",
      "Saved the embedding for suspicious.\n",
      "suspiciously is at index 7775\n",
      "Saved the embedding for suspiciously.\n",
      "suspiciousness is at index 7775\n",
      "Saved the embedding for suspiciousness.\n",
      "swaggering is at index 3514\n",
      "Saved the embedding for swaggering.\n",
      "swearing is at index 21854\n",
      "Saved the embedding for swearing.\n",
      "sympathetic is at index 22869\n",
      "Saved the embedding for sympathetic.\n",
      "sympathizing is at index 19023\n",
      "Saved the embedding for sympathizing.\n",
      "sympathy is at index 16554\n",
      "Saved the embedding for sympathy.\n",
      "taciturn is at index 36502\n",
      "Saved the embedding for taciturn.\n",
      "talkative is at index 1067\n",
      "Saved the embedding for talkative.\n",
      "talking is at index 1686\n",
      "Saved the embedding for talking.\n",
      "tantalized is at index 33496\n",
      "Saved the embedding for tantalized.\n",
      "tart is at index 27468\n",
      "Saved the embedding for tart.\n",
      "tasteful is at index 24867\n",
      "Saved the embedding for tasteful.\n",
      "tattling is at index 45951\n",
      "Saved the embedding for tattling.\n",
      "taunt is at index 44048\n",
      "Saved the embedding for taunt.\n",
      "taunting is at index 326\n",
      "Saved the embedding for taunting.\n",
      "taut is at index 326\n",
      "Saved the embedding for taut.\n",
      "tearful is at index 7366\n",
      "Saved the embedding for tearful.\n",
      "teary is at index 7366\n",
      "Saved the embedding for teary.\n",
      "tease is at index 29993\n",
      "Saved the embedding for tease.\n",
      "teasing is at index 29752\n",
      "Saved the embedding for teasing.\n",
      "tempered is at index 31380\n",
      "Saved the embedding for tempered.\n",
      "tempest is at index 32196\n",
      "Saved the embedding for tempest.\n",
      "tempestuous is at index 32196\n",
      "Saved the embedding for tempestuous.\n",
      "tempted is at index 23448\n",
      "Saved the embedding for tempted.\n",
      "tenacious is at index 2724\n",
      "Saved the embedding for tenacious.\n",
      "tender is at index 8780\n",
      "Saved the embedding for tender.\n",
      "tenderness is at index 8780\n",
      "Saved the embedding for tenderness.\n",
      "tense is at index 13554\n",
      "Saved the embedding for tense.\n",
      "tensed is at index 7281\n",
      "Saved the embedding for tensed.\n",
      "tension is at index 8556\n",
      "Saved the embedding for tension.\n",
      "tentative is at index 22948\n",
      "Saved the embedding for tentative.\n",
      "terrified is at index 19419\n",
      "Saved the embedding for terrified.\n",
      "terror is at index 5231\n",
      "Saved the embedding for terror.\n",
      "terrorized is at index 5231\n",
      "Saved the embedding for terrorized.\n",
      "terrorizing is at index 5231\n",
      "Saved the embedding for terrorizing.\n",
      "terse is at index 8470\n",
      "Saved the embedding for terse.\n",
      "testy is at index 1296\n",
      "Saved the embedding for testy.\n",
      "tetchy is at index 326\n",
      "Saved the embedding for tetchy.\n",
      "thankful is at index 12025\n",
      "Saved the embedding for thankful.\n",
      "thinking is at index 2053\n",
      "Saved the embedding for thinking.\n",
      "thought is at index 802\n",
      "Saved the embedding for thought.\n",
      "thoughtful is at index 16801\n",
      "Saved the embedding for thoughtful.\n",
      "thoughtfulness is at index 802\n",
      "Saved the embedding for thoughtfulness.\n",
      "threat is at index 1856\n",
      "Saved the embedding for threat.\n",
      "threatened is at index 3711\n",
      "Saved the embedding for threatened.\n",
      "threatening is at index 5608\n",
      "Saved the embedding for threatening.\n",
      "thrilled is at index 8689\n",
      "Saved the embedding for thrilled.\n",
      "thrown is at index 5629\n",
      "Saved the embedding for thrown.\n",
      "thunderstruck is at index 4775\n",
      "Saved the embedding for thunderstruck.\n",
      "thwarted is at index 28299\n",
      "Saved the embedding for thwarted.\n",
      "ticked is at index 10457\n",
      "Saved the embedding for ticked.\n",
      "tickled is at index 10457\n",
      "Saved the embedding for tickled.\n",
      "tied is at index 3016\n",
      "Saved the embedding for tied.\n",
      "tiered is at index 3318\n",
      "Saved the embedding for tiered.\n",
      "tight is at index 3229\n",
      "Saved the embedding for tight.\n",
      "tightlipped is at index 3229\n",
      "Saved the embedding for tightlipped.\n",
      "timid is at index 39649\n",
      "Saved the embedding for timid.\n",
      "timidly is at index 39649\n",
      "Saved the embedding for timidly.\n",
      "timidness is at index 39649\n",
      "Saved the embedding for timidness.\n",
      "tired is at index 7428\n",
      "Saved the embedding for tired.\n",
      "tiredly is at index 7428\n",
      "Saved the embedding for tiredly.\n",
      "tiredness is at index 7428\n",
      "Saved the embedding for tiredness.\n",
      "titillated is at index 13515\n",
      "Saved the embedding for titillated.\n",
      "tolerant is at index 32836\n",
      "Saved the embedding for tolerant.\n",
      "tongue is at index 15686\n",
      "Saved the embedding for tongue.\n",
      "tormented is at index 16535\n",
      "Saved the embedding for tormented.\n",
      "touched is at index 6699\n",
      "Saved the embedding for touched.\n",
      "tough is at index 1828\n",
      "Saved the embedding for tough.\n",
      "toying is at index 7\n",
      "Saved the embedding for toying.\n",
      "tragic is at index 8805\n",
      "Saved the embedding for tragic.\n",
      "tragical is at index 2664\n",
      "Saved the embedding for tragical.\n",
      "tranquil is at index 33535\n",
      "Saved the embedding for tranquil.\n",
      "tranquility is at index 36474\n",
      "Saved the embedding for tranquility.\n",
      "transfixed is at index 30387\n",
      "Saved the embedding for transfixed.\n",
      "traumatized is at index 25178\n",
      "Saved the embedding for traumatized.\n",
      "trembling is at index 44912\n",
      "Saved the embedding for trembling.\n",
      "trepid is at index 6110\n",
      "Saved the embedding for trepid.\n",
      "trepidation is at index 6110\n",
      "Saved the embedding for trepidation.\n",
      "trickster is at index 7610\n",
      "Saved the embedding for trickster.\n",
      "tricky is at index 12792\n",
      "Saved the embedding for tricky.\n",
      "triumphant is at index 32025\n",
      "Saved the embedding for triumphant.\n",
      "troubled is at index 9895\n",
      "Saved the embedding for troubled.\n",
      "troublesome is at index 34056\n",
      "Saved the embedding for troublesome.\n",
      "troubling is at index 15554\n",
      "Saved the embedding for troubling.\n",
      "trusting is at index 28969\n",
      "Saved the embedding for trusting.\n",
      "trustworthy is at index 32101\n",
      "Saved the embedding for trustworthy.\n",
      "tumultuous is at index 23787\n",
      "Saved the embedding for tumultuous.\n",
      "turbulent is at index 23415\n",
      "Saved the embedding for turbulent.\n",
      "twinkly is at index 11901\n",
      "Saved the embedding for twinkly.\n",
      "umbrage is at index 7252\n",
      "Saved the embedding for umbrage.\n",
      "umbrageous is at index 7252\n",
      "Saved the embedding for umbrageous.\n",
      "unaffected is at index 32512\n",
      "Saved the embedding for unaffected.\n",
      "unagitated is at index 542\n",
      "Saved the embedding for unagitated.\n",
      "unamused is at index 542\n",
      "Saved the embedding for unamused.\n",
      "unappreciative is at index 542\n",
      "Saved the embedding for unappreciative.\n",
      "unapproachable is at index 542\n",
      "Saved the embedding for unapproachable.\n",
      "unassertive is at index 542\n",
      "Saved the embedding for unassertive.\n",
      "unassuming is at index 542\n",
      "Saved the embedding for unassuming.\n",
      "unaware is at index 14021\n",
      "Saved the embedding for unaware.\n",
      "unbelief is at index 46646\n",
      "Saved the embedding for unbelief.\n",
      "unbelievable is at index 14011\n",
      "Saved the embedding for unbelievable.\n",
      "unbelieving is at index 46646\n",
      "Saved the embedding for unbelieving.\n",
      "unbothered is at index 542\n",
      "Saved the embedding for unbothered.\n",
      "uncaring is at index 16511\n",
      "Saved the embedding for uncaring.\n",
      "uncertain is at index 9684\n",
      "Saved the embedding for uncertain.\n",
      "uncertainly is at index 9684\n",
      "Saved the embedding for uncertainly.\n",
      "uncertainty is at index 4983\n",
      "Saved the embedding for uncertainty.\n",
      "uncivil is at index 16511\n",
      "Saved the embedding for uncivil.\n",
      "uncomfortable is at index 9800\n",
      "Saved the embedding for uncomfortable.\n",
      "uncommitted is at index 32275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for uncommitted.\n",
      "uncommunicative is at index 32275\n",
      "Saved the embedding for uncommunicative.\n",
      "uncomprehending is at index 32275\n",
      "Saved the embedding for uncomprehending.\n",
      "uncompromising is at index 32213\n",
      "Saved the embedding for uncompromising.\n",
      "unconcerned is at index 28198\n",
      "Saved the embedding for unconcerned.\n",
      "unconfident is at index 542\n",
      "Saved the embedding for unconfident.\n",
      "unconvinced is at index 28198\n",
      "Saved the embedding for unconvinced.\n",
      "uncooperative is at index 542\n",
      "Saved the embedding for uncooperative.\n",
      "uncurious is at index 16511\n",
      "Saved the embedding for uncurious.\n",
      "undecided is at index 28598\n",
      "Saved the embedding for undecided.\n",
      "underhanded is at index 223\n",
      "Saved the embedding for underhanded.\n",
      "understanding is at index 2969\n",
      "Saved the embedding for understanding.\n",
      "undesirable is at index 39028\n",
      "Saved the embedding for undesirable.\n",
      "unease is at index 12515\n",
      "Saved the embedding for unease.\n",
      "uneasily is at index 12515\n",
      "Saved the embedding for uneasily.\n",
      "uneasiness is at index 12515\n",
      "Saved the embedding for uneasiness.\n",
      "uneasy is at index 29569\n",
      "Saved the embedding for uneasy.\n",
      "unemotional is at index 542\n",
      "Saved the embedding for unemotional.\n",
      "unenthusiastic is at index 542\n",
      "Saved the embedding for unenthusiastic.\n",
      "unexcited is at index 39432\n",
      "Saved the embedding for unexcited.\n",
      "unexpected is at index 7152\n",
      "Saved the embedding for unexpected.\n",
      "unfamiliar is at index 21942\n",
      "Saved the embedding for unfamiliar.\n",
      "unfathomable is at index 9515\n",
      "Saved the embedding for unfathomable.\n",
      "unfazed is at index 9515\n",
      "Saved the embedding for unfazed.\n",
      "unfeeling is at index 9515\n",
      "Saved the embedding for unfeeling.\n",
      "unfocused is at index 47306\n",
      "Saved the embedding for unfocused.\n",
      "unforeseen is at index 33257\n",
      "Saved the embedding for unforeseen.\n",
      "unforgiving is at index 34262\n",
      "Saved the embedding for unforgiving.\n",
      "unforthcoming is at index 9515\n",
      "Saved the embedding for unforthcoming.\n",
      "unfortunate is at index 9327\n",
      "Saved the embedding for unfortunate.\n",
      "unfriendly is at index 9515\n",
      "Saved the embedding for unfriendly.\n",
      "unhappy is at index 13865\n",
      "Saved the embedding for unhappy.\n",
      "unhinged is at index 542\n",
      "Saved the embedding for unhinged.\n",
      "unimpressed is at index 542\n",
      "Saved the embedding for unimpressed.\n",
      "uninformed is at index 21969\n",
      "Saved the embedding for uninformed.\n",
      "uninspired is at index 542\n",
      "Saved the embedding for uninspired.\n",
      "uninterested is at index 542\n",
      "Saved the embedding for uninterested.\n",
      "uninvolved is at index 542\n",
      "Saved the embedding for uninvolved.\n",
      "unique is at index 2216\n",
      "Saved the embedding for unique.\n",
      "unlikeable is at index 7328\n",
      "Saved the embedding for unlikeable.\n",
      "unmoved is at index 30780\n",
      "Saved the embedding for unmoved.\n",
      "unnerved is at index 31550\n",
      "Saved the embedding for unnerved.\n",
      "unpleasant is at index 26262\n",
      "Saved the embedding for unpleasant.\n",
      "unprepared is at index 35578\n",
      "Saved the embedding for unprepared.\n",
      "unquiet is at index 542\n",
      "Saved the embedding for unquiet.\n",
      "unreactive is at index 21153\n",
      "Saved the embedding for unreactive.\n",
      "unresolved is at index 29909\n",
      "Saved the embedding for unresolved.\n",
      "unrestrained is at index 12254\n",
      "Saved the embedding for unrestrained.\n",
      "unruffled is at index 542\n",
      "Saved the embedding for unruffled.\n",
      "unsatisfied is at index 36010\n",
      "Saved the embedding for unsatisfied.\n",
      "unsettled is at index 30933\n",
      "Saved the embedding for unsettled.\n",
      "unsociable is at index 9977\n",
      "Saved the embedding for unsociable.\n",
      "unspeaking is at index 542\n",
      "Saved the embedding for unspeaking.\n",
      "unspoken is at index 542\n",
      "Saved the embedding for unspoken.\n",
      "unstrung is at index 542\n",
      "Saved the embedding for unstrung.\n",
      "unsuccessful is at index 15943\n",
      "Saved the embedding for unsuccessful.\n",
      "unsure is at index 17118\n",
      "Saved the embedding for unsure.\n",
      "unsurprised is at index 36637\n",
      "Saved the embedding for unsurprised.\n",
      "unsuspecting is at index 32276\n",
      "Saved the embedding for unsuspecting.\n",
      "unswayed is at index 9977\n",
      "Saved the embedding for unswayed.\n",
      "unsympathetic is at index 542\n",
      "Saved the embedding for unsympathetic.\n",
      "untouched is at index 29929\n",
      "Saved the embedding for untouched.\n",
      "untroubled is at index 7587\n",
      "Saved the embedding for untroubled.\n",
      "untrusting is at index 7587\n",
      "Saved the embedding for untrusting.\n",
      "unwanted is at index 15067\n",
      "Saved the embedding for unwanted.\n",
      "unwavering is at index 10963\n",
      "Saved the embedding for unwavering.\n",
      "unwelcoming is at index 10963\n",
      "Saved the embedding for unwelcoming.\n",
      "unwell is at index 542\n",
      "Saved the embedding for unwell.\n",
      "unwilling is at index 20656\n",
      "Saved the embedding for unwilling.\n",
      "unyielding is at index 542\n",
      "Saved the embedding for unyielding.\n",
      "up is at index 62\n",
      "Saved the embedding for up.\n",
      "upbeat is at index 14899\n",
      "Saved the embedding for upbeat.\n",
      "uplifting is at index 17627\n",
      "Saved the embedding for uplifting.\n",
      "uppity is at index 1717\n",
      "Saved the embedding for uppity.\n",
      "upset is at index 4904\n",
      "Saved the embedding for upset.\n",
      "uptight is at index 18256\n",
      "Saved the embedding for uptight.\n",
      "useless is at index 23584\n",
      "Saved the embedding for useless.\n",
      "vacant is at index 11042\n",
      "Saved the embedding for vacant.\n",
      "vacuous is at index 18721\n",
      "Saved the embedding for vacuous.\n",
      "vanquished is at index 44400\n",
      "Saved the embedding for vanquished.\n",
      "vehement is at index 45373\n",
      "Saved the embedding for vehement.\n",
      "vengeful is at index 748\n",
      "Saved the embedding for vengeful.\n",
      "venomous is at index 32051\n",
      "Saved the embedding for venomous.\n",
      "vex is at index 37894\n",
      "Saved the embedding for vex.\n",
      "vexation is at index 37894\n",
      "Saved the embedding for vexation.\n",
      "vexed is at index 37894\n",
      "Saved the embedding for vexed.\n",
      "vicious is at index 16339\n",
      "Saved the embedding for vicious.\n",
      "victorious is at index 22518\n",
      "Saved the embedding for victorious.\n",
      "vigilant is at index 17258\n",
      "Saved the embedding for vigilant.\n",
      "vile is at index 32359\n",
      "Saved the embedding for vile.\n",
      "villainous is at index 17031\n",
      "Saved the embedding for villainous.\n",
      "vindictive is at index 21339\n",
      "Saved the embedding for vindictive.\n",
      "violence is at index 1476\n",
      "Saved the embedding for violence.\n",
      "violent is at index 4153\n",
      "Saved the embedding for violent.\n",
      "viperous is at index 748\n",
      "Saved the embedding for viperous.\n",
      "vituperative is at index 14306\n",
      "Saved the embedding for vituperative.\n",
      "vocal is at index 7578\n",
      "Saved the embedding for vocal.\n",
      "vocalized is at index 7578\n",
      "Saved the embedding for vocalized.\n",
      "vulgar is at index 28792\n",
      "Saved the embedding for vulgar.\n",
      "vulnerability is at index 15661\n",
      "Saved the embedding for vulnerability.\n",
      "vulnerable is at index 4478\n",
      "Saved the embedding for vulnerable.\n",
      "wacky is at index 885\n",
      "Saved the embedding for wacky.\n",
      "waiting is at index 2445\n",
      "Saved the embedding for waiting.\n",
      "wanted is at index 770\n",
      "Saved the embedding for wanted.\n",
      "wanting is at index 6923\n",
      "Saved the embedding for wanting.\n",
      "wanton is at index 236\n",
      "Saved the embedding for wanton.\n",
      "wariness is at index 997\n",
      "Saved the embedding for wariness.\n",
      "warm is at index 3279\n",
      "Saved the embedding for warm.\n",
      "wary is at index 13441\n",
      "Saved the embedding for wary.\n",
      "wasted is at index 14260\n",
      "Saved the embedding for wasted.\n",
      "watch is at index 1183\n",
      "Saved the embedding for watch.\n",
      "watchful is at index 1183\n",
      "Saved the embedding for watchful.\n",
      "watching is at index 2494\n",
      "Saved the embedding for watching.\n",
      "wavering is at index 13332\n",
      "Saved the embedding for wavering.\n",
      "weariness is at index 3568\n",
      "Saved the embedding for weariness.\n",
      "weary is at index 31554\n",
      "Saved the embedding for weary.\n",
      "weeping is at index 39423\n",
      "Saved the embedding for weeping.\n",
      "weird is at index 7735\n",
      "Saved the embedding for weird.\n",
      "welcome is at index 2814\n",
      "Saved the embedding for welcome.\n",
      "welcoming is at index 10423\n",
      "Saved the embedding for welcoming.\n",
      "whatever is at index 3046\n",
      "Saved the embedding for whatever.\n",
      "whimpering is at index 31754\n",
      "Saved the embedding for whimpering.\n",
      "whimsical is at index 29363\n",
      "Saved the embedding for whimsical.\n",
      "whisper is at index 37539\n",
      "Saved the embedding for whisper.\n",
      "whistle is at index 16867\n",
      "Saved the embedding for whistle.\n",
      "white is at index 1104\n",
      "Saved the embedding for white.\n",
      "wicked is at index 28418\n",
      "Saved the embedding for wicked.\n",
      "wild is at index 3418\n",
      "Saved the embedding for wild.\n",
      "willful is at index 40960\n",
      "Saved the embedding for willful.\n",
      "willing is at index 2882\n",
      "Saved the embedding for willing.\n",
      "wily is at index 885\n",
      "Saved the embedding for wily.\n",
      "wink is at index 39422\n",
      "Saved the embedding for wink.\n",
      "wired is at index 26977\n",
      "Saved the embedding for wired.\n",
      "wishful is at index 2813\n",
      "Saved the embedding for wishful.\n",
      "wistful is at index 885\n",
      "Saved the embedding for wistful.\n",
      "wistfully is at index 885\n",
      "Saved the embedding for wistfully.\n",
      "withdraw is at index 8202\n",
      "Saved the embedding for withdraw.\n",
      "withdrawn is at index 13375\n",
      "Saved the embedding for withdrawn.\n",
      "withheld is at index 22292\n",
      "Saved the embedding for withheld.\n",
      "withholding is at index 25661\n",
      "Saved the embedding for withholding.\n",
      "woe is at index 885\n",
      "Saved the embedding for woe.\n",
      "woeful is at index 19958\n",
      "Saved the embedding for woeful.\n",
      "wonder is at index 5170\n",
      "Saved the embedding for wonder.\n",
      "wondering is at index 8020\n",
      "Saved the embedding for wondering.\n",
      "wonderment is at index 5170\n",
      "Saved the embedding for wonderment.\n",
      "wooly is at index 24815\n",
      "Saved the embedding for wooly.\n",
      "woozy is at index 24815\n",
      "Saved the embedding for woozy.\n",
      "worn is at index 10610\n",
      "Saved the embedding for worn.\n",
      "worried is at index 3915\n",
      "Saved the embedding for worried.\n",
      "worrisome is at index 29611\n",
      "Saved the embedding for worrisome.\n",
      "worry is at index 4022\n",
      "Saved the embedding for worry.\n",
      "worrying is at index 12648\n",
      "Saved the embedding for worrying.\n",
      "worryingly is at index 4022\n",
      "Saved the embedding for worryingly.\n",
      "wounded is at index 5424\n",
      "Saved the embedding for wounded.\n",
      "wow is at index 26388\n",
      "Saved the embedding for wow.\n",
      "wrathful is at index 30220\n",
      "Saved the embedding for wrathful.\n",
      "wrathfully is at index 30220\n",
      "Saved the embedding for wrathfully.\n",
      "wrecked is at index 30090\n",
      "Saved the embedding for wrecked.\n",
      "wretched is at index 42824\n",
      "Saved the embedding for wretched.\n",
      "wronged is at index 1593\n",
      "Saved the embedding for wronged.\n",
      "wroth is at index 885\n",
      "Saved the embedding for wroth.\n",
      "wry is at index 885\n",
      "Saved the embedding for wry.\n",
      "yawn is at index 39654\n",
      "Saved the embedding for yawn.\n",
      "yawning is at index 39654\n",
      "Saved the embedding for yawning.\n",
      "yearning is at index 76\n",
      "Saved the embedding for yearning.\n",
      "yell is at index 28930\n",
      "Saved the embedding for yell.\n",
      "yelling is at index 16600\n",
      "Saved the embedding for yelling.\n",
      "yielding is at index 25438\n",
      "Saved the embedding for yielding.\n",
      "yuck is at index 1423\n",
      "Saved the embedding for yuck.\n",
      "zany is at index 992\n",
      "Saved the embedding for zany.\n",
      "zealous is at index 992\n",
      "Saved the embedding for zealous.\n",
      "zen is at index 992\n",
      "Saved the embedding for zen.\n",
      "zoned is at index 992\n",
      "Saved the embedding for zoned.\n"
     ]
    }
   ],
   "source": [
    "################################################\n",
    "# This cell will write out input embeddings    #\n",
    "# for all the words in my vocabulary, using    #\n",
    "# RoBERTa fine-tuned on wiki-103 training text.#\n",
    "################################################\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = RobertaTokenizer.from_pretrained('./output_wiki-103/')\n",
    "\n",
    "model = RobertaForMaskedLM.from_pretrained('./output_wiki-103/', config=config)\n",
    "\n",
    "config = RobertaConfig.from_pretrained('./output_wiki-103/')\n",
    "config.output_hidden_states = True\n",
    "input_embeddings = model.get_input_embeddings()\n",
    "embeddings_file = '/home/jupyter/Notebooks/crystal/NLP/nlp_testing/embeddings_context_vocab/roberta_input_wiki-103.txt'\n",
    "for v in vocab:\n",
    "    v_tensor = torch.tensor([tokenizer.encode(v)])\n",
    "    # Print the index of the test word.\n",
    "    print(f'{v} is at index {v_tensor[0][1].item()}')\n",
    "#     print(input_embeddings_test(torch.LongTensor([v_tensor[0][1].item()])))\n",
    "    v_embed = input_embeddings(torch.LongTensor([v_tensor[0][1].item()]))\n",
    "#     for n in range(v_embed.size()[1])\n",
    "    try:\n",
    "        with open(embeddings_file, 'a') as f:\n",
    "            f.write(v)\n",
    "            for value in v_embed[0]:\n",
    "                f.write(' ' + str(value.item()))\n",
    "            f.write('\\n')\n",
    "        print(f'Saved the embedding for {v}.')\n",
    "    except:\n",
    "        print('Oh no! Unable to write to the embeddings file.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aback is at index 36347\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1933,  0.2200,  0.0831,  ..., -0.0753, -0.0857, -0.1703],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for aback.\n",
      "abashed is at index 4091\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1475,  0.1399,  0.4928,  ...,  0.0418, -0.2483,  0.0081],\n",
      "         [-0.1704,  0.3353,  0.0577,  ..., -0.3183, -0.2601,  0.1997],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for abashed.\n",
      "abhor is at index 35350\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.5060,  0.0363, -0.0173,  ...,  0.1436,  0.1771,  0.1344],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for abhor.\n",
      "abhorred is at index 35350\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.5060,  0.0363, -0.0173,  ...,  0.1436,  0.1771,  0.1344],\n",
      "         [ 0.3309,  0.2068, -0.1227,  ...,  0.1026, -0.0409,  0.0010],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for abhorred.\n",
      "abhorrence is at index 35350\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.5060,  0.0363, -0.0173,  ...,  0.1436,  0.1771,  0.1344],\n",
      "         [ 0.1362,  0.1037,  0.1765,  ...,  0.0914,  0.1407,  0.3693],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for abhorrence.\n",
      "abhorrent is at index 35350\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [ 5.0605e-01,  3.6306e-02, -1.7294e-02,  ...,  1.4364e-01,\n",
      "           1.7705e-01,  1.3435e-01],\n",
      "         [ 1.1946e-04,  1.8297e-01,  2.4901e-01,  ..., -1.0183e-01,\n",
      "          -7.6961e-01, -4.4653e-02],\n",
      "         [ 1.9912e-01, -1.5637e-01, -7.9924e-02,  ...,  3.5773e-01,\n",
      "          -8.6763e-02,  2.1586e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for abhorrent.\n",
      "abominable is at index 4091\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1475,  0.1399,  0.4928,  ...,  0.0418, -0.2483,  0.0081],\n",
      "         [ 0.5156,  0.0202, -0.0747,  ..., -0.2013, -0.5465,  0.3410],\n",
      "         [ 0.5674, -0.2207,  0.0994,  ...,  0.1118,  0.1132,  0.2356],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for abominable.\n",
      "abound is at index 32937\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1023,  0.0546,  0.0013,  ...,  0.0019,  0.1345,  0.5578],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for abound.\n",
      "absent is at index 11640\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2409, -0.1964, -0.0551,  ..., -0.0678,  0.2844, -0.0879],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for absent.\n",
      "absorbed is at index 22416\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0351,  0.2792,  0.7183,  ..., -0.3407, -0.3610,  0.3012],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for absorbed.\n",
      "acceptance is at index 10502\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1390,  0.1489,  0.0401,  ...,  0.3191,  0.1244,  0.1907],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for acceptance.\n",
      "accepted is at index 3903\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0828,  0.2418,  0.1442,  ...,  0.0736, -0.2023,  0.3222],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for accepted.\n",
      "accepting is at index 8394\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1087,  0.2046,  0.2503,  ...,  0.2022, -0.0367,  0.0336],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for accepting.\n",
      "accommodating is at index 33681\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0768,  0.0160,  0.3111,  ..., -0.0308,  0.0529, -0.1500],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for accommodating.\n",
      "accomplished is at index 9370\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0531,  0.3732, -0.0753,  ...,  0.1131, -0.1065,  0.0307],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for accomplished.\n",
      "accordant is at index 10170\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0470, -0.2059, -0.5375,  ...,  0.1221,  0.0929,  0.1415],\n",
      "         [-0.0978, -0.6161,  0.4288,  ..., -0.2426,  0.1850, -0.0844],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for accordant.\n",
      "accursed is at index 7678\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.4927,  0.2873,  0.2267,  ..., -0.1570, -0.4495, -0.4392],\n",
      "         [-0.4246,  0.1411,  0.5739,  ...,  0.0851, -0.0877, -0.1865],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for accursed.\n",
      "accusatory is at index 23123\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0800, -0.5086, -0.0028,  ...,  0.0860, -0.0284, -0.1520],\n",
      "         [-0.2759, -0.2099, -0.0074,  ...,  0.0886, -0.0460,  0.0378],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for accusatory.\n",
      "accused is at index 1238\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3295, -0.6653, -0.2071,  ..., -0.1554, -0.7189, -0.2158],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for accused.\n",
      "accusing is at index 8601\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3186, -0.5605, -0.1728,  ...,  0.0575, -0.3538,  0.0360],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for accusing.\n",
      "acerbic is at index 4285\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-1.7855e-02,  1.4865e-02, -1.2054e-01,  ..., -4.3581e-01,\n",
      "          -5.6217e-01, -4.1441e-01],\n",
      "         [ 2.8738e-02,  5.2570e-01, -1.1831e-02,  ...,  3.5120e-02,\n",
      "          -1.3351e-01,  6.9800e-01],\n",
      "         [ 2.8527e-01,  3.6146e-01,  9.8728e-02,  ...,  1.0066e-01,\n",
      "          -1.2082e-01,  6.6317e-02],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for acerbic.\n",
      "acidic is at index 41314\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2146,  0.1157, -0.0045,  ...,  0.0453,  0.4614, -0.4345],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for acidic.\n",
      "active is at index 2171\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1082, -0.7906, -0.0132,  ..., -0.0189, -0.3132,  0.2632],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for active.\n",
      "acute is at index 13827\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1041,  0.0036,  0.1854,  ...,  0.0184,  0.3055,  0.3794],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for acute.\n",
      "adamant is at index 22668\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2111,  0.1397, -0.0155,  ...,  0.2958,  0.2245, -0.4049],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for adamant.\n",
      "addled is at index 1606\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3402, -0.0924,  0.5841,  ..., -0.2394, -0.1107, -0.0882],\n",
      "         [-0.0402, -0.1098,  0.1399,  ..., -0.2213, -0.1115,  0.2467],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for addled.\n",
      "admiration is at index 24287\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2784, -0.0581, -0.1368,  ...,  0.4917,  0.1334,  0.3510],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for admiration.\n",
      "admit is at index 8109\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0477, -0.2471, -0.0038,  ..., -0.1329, -0.2711,  0.0567],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for admit.\n",
      "adoration is at index 2329\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1289,  0.0190, -0.0155,  ...,  0.0487,  0.3188,  0.0234],\n",
      "         [ 0.2028,  0.3211,  0.4867,  ...,  0.3004,  0.1121,  0.2702],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for adoration.\n",
      "adoring is at index 2329\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1289,  0.0190, -0.0155,  ...,  0.0487,  0.3188,  0.0234],\n",
      "         [-0.2449,  0.1567, -0.4582,  ...,  0.3038,  0.0327,  0.2458],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for adoring.\n",
      "adrift is at index 2329\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1289,  0.0190, -0.0155,  ...,  0.0487,  0.3188,  0.0234],\n",
      "         [ 0.2429, -0.1576,  0.5751,  ..., -0.1698,  0.3648,  0.3320],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for adrift.\n",
      "adversarial is at index 37930\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2004,  0.1657,  0.1634,  ...,  0.5169,  0.2707, -0.2436],\n",
      "         [-0.0697,  0.5667,  0.0419,  ..., -0.7302, -0.3667,  0.0860],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for adversarial.\n",
      "affability is at index 11129\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0988,  0.0627,  0.4388,  ..., -0.0220,  0.0655, -0.5661],\n",
      "         [ 0.0665, -0.2547,  0.0943,  ..., -0.0250,  0.4171, -0.1098],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for affability.\n",
      "affected is at index 2132\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1226,  0.4764,  0.3767,  ..., -0.1467,  0.2225,  0.2227],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for affected.\n",
      "affectionate is at index 15955\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1111, -0.3447,  0.1843,  ...,  0.3421,  0.3744,  0.2769],\n",
      "         [-0.3462,  0.2802, -0.0972,  ...,  0.2098, -0.1504,  0.2755],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for affectionate.\n",
      "afflicted is at index 39234\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0478,  0.1720,  0.3670,  ...,  0.0570, -0.1153, -0.1132],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for afflicted.\n",
      "affronted is at index 11129\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [ 9.8776e-02,  6.2653e-02,  4.3880e-01,  ..., -2.1984e-02,\n",
      "           6.5535e-02, -5.6613e-01],\n",
      "         [ 3.7706e-01, -2.8436e-01, -5.8371e-02,  ..., -3.1412e-01,\n",
      "          -9.0653e-01,  6.5078e-02],\n",
      "         [-7.6293e-02,  8.2298e-02,  3.7151e-01,  ...,  3.9176e-01,\n",
      "          -5.2446e-01,  1.9090e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for affronted.\n",
      "aflutter is at index 10\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-3.4255e-01, -1.8128e-01,  1.8741e-01,  ...,  2.3911e-01,\n",
      "          -1.4931e-01,  4.2797e-01],\n",
      "         [ 1.1907e-01,  4.8629e-01,  3.6980e-01,  ..., -2.7187e-01,\n",
      "          -5.6087e-01,  4.5725e-01],\n",
      "         [-1.1708e-01, -7.6808e-02, -1.1052e-01,  ..., -8.4777e-01,\n",
      "           7.7282e-03,  5.9359e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for aflutter.\n",
      "afraid is at index 6023\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2115, -0.0168,  0.2869,  ..., -0.2915, -0.1033,  0.3821],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for afraid.\n",
      "agape is at index 5951\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3362,  0.0874, -0.0383,  ..., -0.0372,  0.0240,  0.2215],\n",
      "         [-0.2269,  0.1259, -0.0978,  ..., -0.3679, -0.3261, -0.0202],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for agape.\n",
      "aggravated is at index 10040\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0558,  0.1866,  0.2645,  ...,  0.1865, -0.4157, -0.3908],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for aggravated.\n",
      "aggravation is at index 29223\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.7114,  0.2839, -0.2450,  ...,  0.5198, -0.1507, -0.0615],\n",
      "         [ 0.1896,  0.6529,  0.2115,  ...,  0.5904, -0.0469,  0.0362],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for aggravation.\n",
      "aggression is at index 14227\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2992, -0.0261,  0.0445,  ..., -0.1116,  0.3869,  0.3457],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for aggression.\n",
      "aggressive is at index 4353\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.5191, -0.2222,  0.0041,  ...,  0.0787,  0.1479,  0.5176],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for aggressive.\n",
      "aggrieve is at index 28940\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0101, -0.1290,  0.2554,  ..., -0.0584, -0.5064, -0.3676],\n",
      "         [ 0.8336,  0.5449,  0.0942,  ...,  0.3034, -0.4783,  0.3832],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for aggrieve.\n",
      "aggrieved is at index 28940\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0101, -0.1290,  0.2554,  ..., -0.0584, -0.5064, -0.3676],\n",
      "         [ 0.3461,  0.5858,  0.3646,  ..., -0.3560, -0.5193,  0.1936],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for aggrieved.\n",
      "aghast is at index 10\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3425, -0.1813,  0.1874,  ...,  0.2391, -0.1493,  0.4280],\n",
      "         [ 0.1034, -0.1018,  0.2360,  ..., -0.3582, -0.5462,  0.1377],\n",
      "         [ 0.1627,  0.0060,  0.4403,  ..., -0.3156,  0.2326,  0.4222],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for aghast.\n",
      "agitated is at index 33426\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0033,  0.1646,  0.5097,  ..., -0.0950,  0.1146,  0.3803],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for agitated.\n",
      "agog is at index 5951\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3362,  0.0874, -0.0383,  ..., -0.0372,  0.0240,  0.2215],\n",
      "         [ 0.2728,  0.1774,  0.4404,  ..., -0.1182,  0.1261,  0.4940],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for agog.\n",
      "agonized is at index 27497\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1535, -0.0872,  0.6724,  ..., -0.2086,  0.1093,  0.1812],\n",
      "         [-0.0545,  0.4248,  0.1878,  ...,  0.0940, -0.2454,  0.3326],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for agonized.\n",
      "agreeable is at index 43359\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0685,  0.6068,  0.4413,  ...,  0.5503, -0.0142, -0.4021],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for agreeable.\n",
      "agressive is at index 5951\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3362,  0.0874, -0.0383,  ..., -0.0372,  0.0240,  0.2215],\n",
      "         [ 0.1153,  0.3402, -0.1710,  ..., -0.1718,  0.3420,  0.7256],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for agressive.\n",
      "airhead is at index 935\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2318,  0.0454,  0.6743,  ..., -0.2832, -0.1716, -0.2246],\n",
      "         [-0.4606, -0.0086, -0.2200,  ..., -0.2949, -0.2364, -0.2281],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for airhead.\n",
      "alarm is at index 8054\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0508,  0.3033, -0.0576,  ...,  0.1338,  0.4975,  0.4033],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for alarm.\n",
      "alarmed is at index 23438\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0150,  0.2074,  0.1115,  ...,  0.0193,  0.1799,  0.2692],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for alarmed.\n",
      "alarming is at index 16156\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1312,  0.2593, -0.2836,  ...,  0.2730,  0.1358,  0.1664],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for alarming.\n",
      "alert is at index 5439\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0056, -0.3777,  0.1223,  ..., -0.3287, -0.0029,  0.5106],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for alert.\n",
      "alerted is at index 14588\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1858, -0.0156, -0.0960,  ..., -0.1461, -0.1879,  0.3287],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for alerted.\n",
      "alienated is at index 36462\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1760, -0.2123,  0.2368,  ..., -0.4140,  0.0945, -0.0129],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for alienated.\n",
      "allergic is at index 28349\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2483,  0.3656,  0.1020,  ..., -0.4486,  0.5615, -0.0173],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for allergic.\n",
      "alleviated is at index 32216\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2423, -0.2742,  0.0406,  ..., -0.0568, -0.0069,  0.0933],\n",
      "         [-0.0259,  0.4460,  0.2169,  ...,  0.0611, -0.0919,  0.5177],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for alleviated.\n",
      "alluring is at index 70\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1615, -0.4482,  0.1608,  ...,  0.0834, -0.1533,  0.1677],\n",
      "         [-0.2070,  0.1855,  0.2401,  ..., -0.2010,  0.2415,  0.1745],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for alluring.\n",
      "aloof is at index 1076\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0966, -0.2599,  0.4926,  ..., -0.0855, -0.0958, -0.3909],\n",
      "         [ 0.1014,  0.6782, -0.1610,  ..., -0.2202, -0.1842, -0.3921],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for aloof.\n",
      "amatory is at index 524\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1394,  0.0866,  0.1162,  ...,  0.1771,  0.0375,  0.1449],\n",
      "         [-0.2759, -0.2099, -0.0074,  ...,  0.0886, -0.0460,  0.0378],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for amatory.\n",
      "amazed is at index 22431\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-1.7991e-01,  1.2518e-01,  2.3629e-01,  ..., -2.2717e-02,\n",
      "           1.3673e-01,  2.3994e-04],\n",
      "         [ 9.2431e-02, -2.9484e-02, -1.2872e-02,  ...,  3.0573e-01,\n",
      "          -1.1492e-01,  1.8911e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for amazed.\n",
      "amazement is at index 42402\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0473,  0.3030,  0.2537,  ..., -0.1566,  0.3523, -0.2061],\n",
      "         [-0.2372, -0.2709, -0.2547,  ..., -0.3685, -0.1200,  0.1339],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for amazement.\n",
      "amazing is at index 2770\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0143,  0.2973,  0.0761,  ...,  0.1615,  0.3187, -0.0499],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for amazing.\n",
      "ambition is at index 12831\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.6263, -0.3976, -0.1093,  ...,  0.0164,  0.4765, -0.0280],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for ambition.\n",
      "ambitious is at index 8263\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2045, -0.2513, -0.2112,  ...,  0.3956,  0.3585,  0.0823],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for ambitious.\n",
      "ambivalence is at index 13569\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [ 9.2847e-02, -1.5346e-01,  8.4384e-02,  ..., -2.6614e-01,\n",
      "          -4.9905e-01,  3.6538e-01],\n",
      "         [ 1.0443e-01,  6.8622e-01,  1.7174e-01,  ...,  1.6618e-02,\n",
      "          -1.7295e-01, -2.3462e-01],\n",
      "         [ 9.3340e-02,  1.2822e-01, -7.3889e-02,  ...,  1.1709e-02,\n",
      "           1.0633e-01,  2.4044e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for ambivalence.\n",
      "ambivalent is at index 13569\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0928, -0.1535,  0.0844,  ..., -0.2661, -0.4991,  0.3654],\n",
      "         [ 0.0343,  1.1645, -0.0423,  ..., -0.1530, -0.1426, -0.3754],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for ambivalent.\n",
      "amenable is at index 524\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1394,  0.0866,  0.1162,  ...,  0.1771,  0.0375,  0.1449],\n",
      "         [ 0.1898,  0.2692,  0.0034,  ...,  0.0098, -0.2619,  0.1852],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for amenable.\n",
      "amiable is at index 524\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1394,  0.0866,  0.1162,  ...,  0.1771,  0.0375,  0.1449],\n",
      "         [ 0.0837,  0.6270,  0.2283,  ..., -0.2682, -0.0916,  0.0955],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for amiable.\n",
      "amicable is at index 524\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1394,  0.0866,  0.1162,  ...,  0.1771,  0.0375,  0.1449],\n",
      "         [-0.4071,  0.5874,  0.1903,  ..., -0.3120,  0.1416,  0.5668],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for amicable.\n",
      "amused is at index 36530\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1049,  0.1946,  0.4059,  ...,  0.3025,  0.0685,  0.0565],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for amused.\n",
      "amusement is at index 28445\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0780,  0.3671, -0.1606,  ...,  0.0426,  0.3989,  0.0170],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for amusement.\n",
      "analytical is at index 23554\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2477,  0.4695,  0.2721,  ...,  0.2130, -0.0287, -0.0328],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for analytical.\n",
      "analyzing is at index 18999\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1138,  0.3406,  0.2919,  ...,  0.0976, -0.0790,  0.3147],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for analyzing.\n",
      "anger is at index 6378\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2962, -0.3629, -0.0619,  ..., -0.1794,  0.3361,  0.0556],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for anger.\n",
      "angered is at index 20166\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0145, -0.1485,  0.2759,  ..., -0.1042,  0.1691,  0.2114],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for angered.\n",
      "angrily is at index 30302\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1332,  0.0858, -0.1426,  ...,  0.3160, -0.0841,  0.0448],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for angrily.\n",
      "angry is at index 5800\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0426, -0.0603, -0.0544,  ..., -0.1335, -0.0806, -0.0307],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for angry.\n",
      "angst is at index 33010\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0929,  0.4043,  0.3763,  ..., -0.4771,  0.3743,  0.1515],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for angst.\n",
      "anguish is at index 32446\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0802,  0.4996,  0.4211,  ..., -0.0813, -0.0512,  0.2261],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for anguish.\n",
      "anguished is at index 5667\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2036,  0.0628,  0.2230,  ...,  0.2172, -0.2692, -0.0440],\n",
      "         [ 0.3237, -0.0217,  0.2328,  ..., -0.4661, -0.4461,  0.0846],\n",
      "         [ 0.0482,  0.3376,  0.0024,  ...,  0.2005, -0.0491,  0.3149],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for anguished.\n",
      "animated is at index 12847\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0510,  0.3774,  0.3870,  ...,  0.0468,  0.2205,  0.0698],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for animated.\n",
      "animosity is at index 34351\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2328,  0.0256,  0.2873,  ..., -0.0653,  0.5074,  0.1429],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for animosity.\n",
      "annoyance is at index 39341\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0517,  0.1988, -0.0099,  ...,  0.0374,  0.5116,  0.1566],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for annoyance.\n",
      "annoyed is at index 26678\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1398,  0.1184,  0.5449,  ..., -0.0603,  0.0256, -0.2940],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for annoyed.\n",
      "annoying is at index 19887\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1550,  0.3865,  0.1874,  ...,  0.2742, -0.2834, -0.3371],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for annoying.\n",
      "antagonistic is at index 32726\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1194,  0.0146, -0.1070,  ..., -0.1183,  0.2426,  0.2226],\n",
      "         [ 0.1147,  0.1744, -0.4991,  ...,  0.4511,  0.0892,  0.2464],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for antagonistic.\n",
      "antagonized is at index 32726\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1194,  0.0146, -0.1070,  ..., -0.1183,  0.2426,  0.2226],\n",
      "         [-0.0545,  0.4248,  0.1878,  ...,  0.0940, -0.2454,  0.3326],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for antagonized.\n",
      "anticipated is at index 5291\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1155,  0.2220,  0.1506,  ...,  0.2760,  0.1173, -0.1772],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for anticipated.\n",
      "anticipating is at index 22535\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0084, -0.2041,  0.3380,  ...,  0.0333,  0.1580,  0.0268],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for anticipating.\n",
      "anticipation is at index 14714\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2058,  0.0981,  0.1176,  ..., -0.2756,  0.4860, -0.1257],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for anticipation.\n",
      "anticipative is at index 21428\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.4099, -0.4061, -0.1711,  ...,  0.0113,  0.1527,  0.0038],\n",
      "         [ 0.0452,  0.3078, -0.1904,  ..., -0.2063,  0.4188,  0.0517],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for anticipative.\n",
      "anticipatory is at index 21428\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.4099, -0.4061, -0.1711,  ...,  0.0113,  0.1527,  0.0038],\n",
      "         [-0.2759, -0.2099, -0.0074,  ...,  0.0886, -0.0460,  0.0378],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for anticipatory.\n",
      "antipathy is at index 37554\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0114, -0.0625,  0.1711,  ..., -0.0138,  0.1669, -0.0252],\n",
      "         [ 0.4423,  0.3915,  0.8312,  ..., -0.2921, -0.2428,  0.3214],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for antipathy.\n",
      "antsy is at index 32855\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2003, -0.6058,  0.6974,  ..., -0.2965, -0.0213,  0.3111],\n",
      "         [ 0.1311, -0.1715,  0.0534,  ..., -0.0509, -0.4687, -0.2923],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for antsy.\n",
      "anxiety is at index 6882\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1429,  0.6555,  0.5965,  ..., -0.6166,  0.4486,  0.0678],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for anxiety.\n",
      "anxious is at index 13473\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0984,  0.3546,  0.8504,  ..., -0.2553,  0.0462,  0.1159],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for anxious.\n",
      "anxiously is at index 27442\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [ 5.8545e-02,  6.9485e-01,  3.1796e-04,  ...,  8.1285e-02,\n",
      "          -3.6089e-01, -1.8635e-02],\n",
      "         [-1.5685e-01,  6.9284e-01, -1.2101e-01,  ...,  1.1654e-02,\n",
      "          -4.5280e-01, -7.0703e-02],\n",
      "         [ 1.9912e-01, -1.5637e-01, -7.9924e-02,  ...,  3.5773e-01,\n",
      "          -8.6763e-02,  2.1586e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for anxiously.\n",
      "apathetic is at index 6256\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2950, -0.2718,  0.2387,  ..., -0.2692,  0.0223, -0.3755],\n",
      "         [ 0.0879,  0.4539,  0.5002,  ..., -0.3756,  0.4817,  0.4803],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for apathetic.\n",
      "apathy is at index 6256\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2950, -0.2718,  0.2387,  ..., -0.2692,  0.0223, -0.3755],\n",
      "         [ 0.4423,  0.3915,  0.8312,  ..., -0.2921, -0.2428,  0.3214],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for apathy.\n",
      "apologetic is at index 23842\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1403,  0.0755,  0.2998,  ..., -0.3577, -0.3889, -0.1931],\n",
      "         [-0.5189, -0.1800,  0.4117,  ..., -0.0667, -0.2868,  0.1824],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for apologetic.\n",
      "appalled is at index 31514\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1162,  0.0656,  0.0276,  ..., -0.1217,  0.1216,  0.2532],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for appalled.\n",
      "appallingly is at index 1553\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0550,  0.0503, -0.3052,  ..., -0.0669, -0.4877, -0.1398],\n",
      "         [ 0.0053, -0.3714,  0.1366,  ..., -0.1070, -0.1093,  0.0447],\n",
      "         [ 0.1573,  0.1742, -0.2868,  ...,  0.0256, -0.0949,  0.3700],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for appallingly.\n",
      "appeased is at index 44151\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1087, -0.5317, -0.2561,  ..., -0.1869,  0.2688, -0.0927],\n",
      "         [-0.3413,  0.2097, -0.0392,  ..., -0.4061,  0.2151, -0.1586],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for appeased.\n",
      "appeasing is at index 44151\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1087, -0.5317, -0.2561,  ..., -0.1869,  0.2688, -0.0927],\n",
      "         [-0.2930,  0.3248, -0.1258,  ..., -0.4215,  0.5778, -0.0395],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for appeasing.\n",
      "appreciative is at index 14137\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.4088, -0.3738,  0.3361,  ...,  0.4298,  0.5139,  0.0515],\n",
      "         [ 0.0452,  0.3078, -0.1904,  ..., -0.2063,  0.4188,  0.0517],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for appreciative.\n",
      "apprehension is at index 34640\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0866,  0.3324,  0.3929,  ..., -0.0969,  0.5276,  0.3350],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for apprehension.\n",
      "apprehensive is at index 33655\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2082,  0.2744,  0.5919,  ..., -0.0832,  0.0527,  0.2327],\n",
      "         [ 0.1941,  0.3173,  0.1725,  ...,  0.0227, -0.1611,  0.4399],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for apprehensive.\n",
      "approve is at index 7244\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2776,  0.6767, -0.0106,  ...,  0.0816, -0.2245, -0.3411],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for approve.\n",
      "approved is at index 2033\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0389,  0.5201, -0.0967,  ...,  0.3636, -0.5890, -0.4551],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for approved.\n",
      "approving is at index 20499\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2459,  0.5313,  0.1136,  ...,  0.4180, -0.0377, -0.4694],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for approving.\n",
      "argue is at index 5848\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1702,  0.3956, -0.2406,  ...,  0.2514,  0.2119,  0.5546],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for argue.\n",
      "argumentative is at index 4795\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0554, -0.0788,  0.2126,  ...,  0.4197,  0.1639,  0.0744],\n",
      "         [ 0.0452,  0.3078, -0.1904,  ..., -0.2063,  0.4188,  0.0517],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for argumentative.\n",
      "aroused is at index 42941\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1022, -0.2074,  0.1884,  ..., -0.1698, -0.1509,  0.2318],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for aroused.\n",
      "arrogance is at index 32818\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0055,  0.1256,  0.2317,  ..., -0.3904,  0.1510, -0.2672],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for arrogance.\n",
      "arrogant is at index 30967\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3491, -0.1728,  0.1687,  ..., -0.2851, -0.0178, -0.3332],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for arrogant.\n",
      "arrogantly is at index 46553\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0077,  0.0601, -0.0333,  ..., -0.1109, -0.1338, -0.3754],\n",
      "         [ 0.1203,  0.2636, -0.1958,  ..., -0.3596,  0.0988, -0.1268],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for arrogantly.\n",
      "artificial is at index 7350\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0645,  0.1368,  0.2420,  ..., -0.3232, -0.1846,  0.5880],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for artificial.\n",
      "ashamed is at index 20085\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0318, -0.5717, -0.0029,  ..., -0.1996,  0.2936,  0.1547],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for ashamed.\n",
      "aspiring is at index 18885\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0344, -0.3726, -0.4033,  ..., -0.1214, -0.4253, -0.0417],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for aspiring.\n",
      "assertive is at index 18088\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1434,  0.1615,  0.0435,  ..., -0.2978,  0.0640,  0.0935],\n",
      "         [ 0.1941,  0.3173,  0.1725,  ...,  0.0227, -0.1611,  0.4399],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for assertive.\n",
      "assertively is at index 18088\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1434,  0.1615,  0.0435,  ..., -0.2978,  0.0640,  0.0935],\n",
      "         [ 0.2512,  0.2734, -0.0256,  ...,  0.0393, -0.2657,  0.5681],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for assertively.\n",
      "assessing is at index 16629\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1900,  0.1018,  0.2051,  ..., -0.0959, -0.0346,  0.2703],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for assessing.\n",
      "assured is at index 7189\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2513,  0.0638,  0.6533,  ..., -0.6892,  0.1543, -0.0381],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for assured.\n",
      "astonished is at index 40788\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.4778, -0.0564,  0.0853,  ..., -0.0182,  0.0830,  0.2459],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for astonished.\n",
      "astonishment is at index 44434\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1164,  0.0009, -0.1317,  ..., -0.0581, -0.1153,  0.1955],\n",
      "         [-0.2600,  0.1408, -0.1883,  ...,  0.0056, -0.0882,  0.2172],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for astonishment.\n",
      "astounded is at index 12976\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2571, -0.0358,  0.4140,  ..., -0.0978,  0.0822,  0.3037],\n",
      "         [-0.8611,  0.7814,  0.0060,  ..., -0.2269,  0.0823,  0.0056],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for astounded.\n",
      "attempting is at index 6475\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0120, -0.4175,  0.0985,  ...,  0.3076, -0.3756, -0.0187],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for attempting.\n",
      "attentive is at index 36670\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1051, -0.0384,  0.1013,  ...,  0.4816,  0.1724,  0.3213],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for attentive.\n",
      "attentiveness is at index 39879\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1131, -0.1303,  0.0036,  ...,  0.1452, -0.0656,  0.7426],\n",
      "         [ 0.3393,  0.2342,  0.1175,  ..., -0.0257,  0.4384,  0.4985],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for attentiveness.\n",
      "attracted is at index 7671\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0065, -0.0373,  0.0821,  ..., -0.0342,  0.1732,  0.2581],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for attracted.\n",
      "avenging is at index 38796\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1505, -0.0508, -0.3932,  ..., -0.1897, -0.5518, -0.4372],\n",
      "         [-0.1019,  0.1050, -0.2707,  ...,  0.2250, -0.1715, -0.2717],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for avenging.\n",
      "averse is at index 10\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3425, -0.1813,  0.1874,  ...,  0.2391, -0.1493,  0.4280],\n",
      "         [-0.0728,  0.3828, -0.5245,  ..., -0.2863, -0.1929, -0.1441],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for averse.\n",
      "aversion is at index 33814\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1645, -0.0252,  0.1196,  ..., -0.1692,  0.4632, -0.1058],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for aversion.\n",
      "aversive is at index 10\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3425, -0.1813,  0.1874,  ...,  0.2391, -0.1493,  0.4280],\n",
      "         [-0.3882,  1.2482, -0.4311,  ..., -0.1022, -0.1959,  0.4542],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for aversive.\n",
      "avid is at index 20137\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1832,  0.0887, -0.3799,  ..., -0.0092, -0.4468,  0.2763],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for avid.\n",
      "avoiding is at index 11473\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2789, -0.0909,  0.2321,  ...,  0.0852, -0.2549,  0.1390],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for avoiding.\n",
      "awaiting is at index 10254\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2030, -0.0745, -0.0711,  ..., -0.3879,  0.0466, -0.4260],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for awaiting.\n",
      "awakened is at index 40593\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0901, -0.3616, -0.0676,  ...,  0.0608,  0.2068, -0.2836],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for awakened.\n",
      "aware is at index 2542\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3167, -0.0695, -0.2455,  ..., -0.2955, -0.0768,  0.2597],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for aware.\n",
      "awareness is at index 4199\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1428, -0.3666,  0.0266,  ..., -0.1353,  0.5158,  0.0881],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for awareness.\n",
      "awe is at index 21531\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2529, -0.3167,  0.2648,  ...,  0.1580,  0.1287, -0.2844],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for awe.\n",
      "awed is at index 19267\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0571,  0.2198,  0.1613,  ..., -0.2110,  0.5265, -0.7189],\n",
      "         [-0.1786,  0.2013,  0.4345,  ...,  0.3394, -0.5501,  0.1632],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for awed.\n",
      "awestruck is at index 19267\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-5.7141e-02,  2.1983e-01,  1.6133e-01,  ..., -2.1103e-01,\n",
      "           5.2650e-01, -7.1892e-01],\n",
      "         [-1.2120e-02, -1.0135e-02,  1.9057e-01,  ..., -3.9804e-01,\n",
      "          -3.2055e-01,  6.8503e-01],\n",
      "         [ 2.7782e-01, -2.7443e-01,  2.6804e-01,  ..., -5.6766e-01,\n",
      "           2.7784e-02, -4.4740e-02],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for awestruck.\n",
      "awful is at index 11522\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1026,  0.1671,  0.0298,  ...,  0.1545, -0.1060, -0.2246],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for awful.\n",
      "awkward is at index 11789\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0307, -0.3494,  0.1904,  ..., -0.0915,  0.1292, -0.1411],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for awkward.\n",
      "awkwardness is at index 11789\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0307, -0.3494,  0.1904,  ..., -0.0915,  0.1292, -0.1411],\n",
      "         [-0.1231,  0.1777,  0.1255,  ..., -0.4542,  0.0778,  0.0067],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for awkwardness.\n",
      "axed is at index 18884\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3238,  0.4658,  0.1092,  ...,  0.1985, -0.2093,  0.0947],\n",
      "         [-0.1786,  0.2013,  0.4345,  ...,  0.3394, -0.5501,  0.1632],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for axed.\n",
      "backhanded is at index 124\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1760, -0.1183,  0.3271,  ...,  0.1649,  0.0894,  0.3951],\n",
      "         [-0.3785, -0.1858, -0.0753,  ..., -0.1790, -0.1432,  0.2136],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for backhanded.\n",
      "badly is at index 7340\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0158, -0.0483, -0.1091,  ..., -0.1740, -0.0895, -0.2376],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for badly.\n",
      "baffle is at index 33139\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0102, -0.0776, -0.0679,  ...,  0.1966,  0.1773,  0.4317],\n",
      "         [-0.2066,  0.0911,  0.1720,  ...,  0.1381,  0.3392,  0.2400],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for baffle.\n",
      "baffled is at index 33396\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2359,  0.1908,  0.2292,  ...,  0.1433,  0.0765, -0.0467],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for baffled.\n",
      "baffling is at index 33139\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0102, -0.0776, -0.0679,  ...,  0.1966,  0.1773,  0.4317],\n",
      "         [-0.0505, -0.0944,  0.4063,  ..., -0.3282, -0.1252,  0.2769],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for baffling.\n",
      "baked is at index 17241\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1268, -0.0782,  0.1495,  ...,  0.1118, -0.2470, -0.3078],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for baked.\n",
      "banal is at index 2020\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3054,  0.2493,  0.0067,  ...,  0.3671, -0.2517, -0.0615],\n",
      "         [ 0.0758, -0.0494,  0.4151,  ...,  0.1255, -0.5114,  0.3248],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for banal.\n",
      "barking is at index 35828\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.4301,  0.0680, -0.1324,  ..., -0.1586, -0.1217,  0.3045],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for barking.\n",
      "bashful is at index 12882\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3563, -0.5381,  0.1038,  ...,  0.1139, -0.2096, -0.0433],\n",
      "         [ 0.3025,  0.1036, -0.3624,  ...,  0.1536, -0.4041, -0.2558],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for bashful.\n",
      "beaming is at index 28\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.4305, -0.3520,  0.2453,  ...,  0.7052, -0.0727,  0.1980],\n",
      "         [-0.0629,  0.0570,  0.2557,  ..., -0.3957, -0.1494, -0.4727],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for beaming.\n",
      "bearish is at index 4649\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1701, -0.3967,  0.5016,  ...,  0.0291,  0.1031,  0.1427],\n",
      "         [ 0.4075, -0.2999,  0.2436,  ..., -0.0861, -0.1961,  0.0055],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for bearish.\n",
      "beat is at index 1451\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3556, -0.4063,  0.1664,  ...,  0.0752, -0.2618,  0.3721],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for beat.\n",
      "beaten is at index 6432\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1106, -0.9919,  0.3929,  ..., -0.0509, -0.3352,  0.7090],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for beaten.\n",
      "bedeviled is at index 3267\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [ 2.6147e-02, -3.5771e-01,  1.5396e-02,  ...,  4.8714e-02,\n",
      "          -1.7425e-01,  3.5064e-01],\n",
      "         [ 1.9626e-01, -6.8401e-02,  8.7034e-02,  ...,  6.4264e-02,\n",
      "          -9.5382e-01,  6.3970e-01],\n",
      "         [ 2.6155e-01,  4.5031e-01, -1.0643e-01,  ..., -5.4123e-01,\n",
      "           4.1338e-02,  6.5498e-02],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for bedeviled.\n",
      "befuddled is at index 28\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-4.3045e-01, -3.5196e-01,  2.4530e-01,  ...,  7.0523e-01,\n",
      "          -7.2744e-02,  1.9798e-01],\n",
      "         [-1.1769e-02,  1.9539e-01,  1.3389e-01,  ...,  8.5156e-02,\n",
      "           9.0932e-02,  4.0722e-01],\n",
      "         [-4.7292e-02,  2.6370e-01, -1.3658e-01,  ..., -3.6463e-02,\n",
      "          -2.4190e-01,  5.4483e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for befuddled.\n",
      "begging is at index 22901\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0488, -0.5512, -0.1285,  ...,  0.4154,  0.0539,  0.4585],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for begging.\n",
      "begrudge is at index 28\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-4.3045e-01, -3.5196e-01,  2.4530e-01,  ...,  7.0523e-01,\n",
      "          -7.2744e-02,  1.9798e-01],\n",
      "         [-8.3294e-02, -2.4349e-01,  1.3294e-01,  ...,  4.1088e-01,\n",
      "           3.8169e-01,  3.3068e-01],\n",
      "         [ 1.2530e-01, -7.0976e-02, -2.6388e-01,  ...,  1.0900e-02,\n",
      "          -2.6033e-01, -5.1691e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for begrudge.\n",
      "begrudging is at index 28\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-4.3045e-01, -3.5196e-01,  2.4530e-01,  ...,  7.0523e-01,\n",
      "          -7.2744e-02,  1.9798e-01],\n",
      "         [-8.3294e-02, -2.4349e-01,  1.3294e-01,  ...,  4.1088e-01,\n",
      "           3.8169e-01,  3.3068e-01],\n",
      "         [-5.7484e-02,  3.1784e-01, -2.1649e-02,  ...,  3.4305e-02,\n",
      "           1.8887e-01, -8.5006e-02],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for begrudging.\n",
      "begrudgingly is at index 28\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.4305, -0.3520,  0.2453,  ...,  0.7052, -0.0727,  0.1980],\n",
      "         [-0.0833, -0.2435,  0.1329,  ...,  0.4109,  0.3817,  0.3307],\n",
      "         [-0.0575,  0.3178, -0.0216,  ...,  0.0343,  0.1889, -0.0850],\n",
      "         [ 0.4864,  0.1639, -0.0570,  ..., -0.0095, -0.4545,  0.1739],\n",
      "         [ 0.2760, -0.1979, -0.1075,  ...,  0.4037,  0.0583,  0.1964]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for begrudgingly.\n",
      "beguiled is at index 21422\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0403,  0.0999, -0.4876,  ...,  0.5092,  0.1633,  0.5818],\n",
      "         [ 0.3237, -0.0217,  0.2328,  ..., -0.4661, -0.4461,  0.0846],\n",
      "         [ 0.2616,  0.4503, -0.1064,  ..., -0.5412,  0.0413,  0.0655],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for beguiled.\n",
      "belated is at index 12138\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.4343, -0.6047,  0.2496,  ...,  0.7894,  0.0438,  0.4432],\n",
      "         [-0.0291,  1.0262,  0.5924,  ..., -0.1654,  0.0214,  0.4920],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for belated.\n",
      "belittling is at index 12138\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [ 4.3435e-01, -6.0474e-01,  2.4961e-01,  ...,  7.8945e-01,\n",
      "           4.3775e-02,  4.4321e-01],\n",
      "         [ 7.9732e-02,  4.4871e-01,  4.0982e-01,  ...,  5.3150e-01,\n",
      "          -1.4552e-01,  7.9736e-01],\n",
      "         [ 4.9880e-02, -2.1098e-01,  3.4535e-01,  ..., -2.7677e-01,\n",
      "          -1.0062e-01,  3.0451e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for belittling.\n",
      "belligerence is at index 35756\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2101, -0.0047,  0.2233,  ...,  0.0544,  0.1539,  0.0044],\n",
      "         [-0.0570,  0.0427, -0.0210,  ...,  0.1206, -0.1938,  0.0395],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for belligerence.\n",
      "belligerent is at index 35756\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2101, -0.0047,  0.2233,  ...,  0.0544,  0.1539,  0.0044],\n",
      "         [-0.2246,  0.3662, -0.0470,  ..., -0.2413, -0.6209, -0.1371],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for belligerent.\n",
      "belonging is at index 11441\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1978, -0.1883, -0.4876,  ..., -0.0789, -0.2433,  0.6411],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for belonging.\n",
      "bemused is at index 28\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-4.3045e-01, -3.5196e-01,  2.4530e-01,  ...,  7.0523e-01,\n",
      "          -7.2744e-02,  1.9798e-01],\n",
      "         [ 8.8937e-02,  1.8038e-01, -9.8231e-02,  ...,  1.5956e-01,\n",
      "           1.7243e-01,  3.0574e-01],\n",
      "         [ 1.2342e-01,  5.8174e-01, -1.8776e-01,  ..., -6.1117e-01,\n",
      "          -1.5881e-01,  1.2933e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for bemused.\n",
      "bemusement is at index 28\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.4305, -0.3520,  0.2453,  ...,  0.7052, -0.0727,  0.1980],\n",
      "         [ 0.0889,  0.1804, -0.0982,  ...,  0.1596,  0.1724,  0.3057],\n",
      "         [ 0.0364,  0.0021, -0.3918,  ..., -0.5100,  0.0445,  0.3461],\n",
      "         [ 0.1459,  0.3916, -0.1364,  ...,  0.2828,  0.1278,  0.5493],\n",
      "         [ 0.2760, -0.1979, -0.1075,  ...,  0.4037,  0.0583,  0.1964]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for bemusement.\n",
      "benevolence is at index 42364\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-6.9851e-02, -4.6797e-01,  2.7155e-01,  ...,  3.0540e-01,\n",
      "           4.9834e-01,  1.2724e-01],\n",
      "         [-2.0768e-01,  4.5593e-01, -2.1821e-01,  ..., -6.6072e-01,\n",
      "           6.5226e-02, -1.9288e-01],\n",
      "         [ 9.3340e-02,  1.2822e-01, -7.3889e-02,  ...,  1.1709e-02,\n",
      "           1.0633e-01,  2.4044e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for benevolence.\n",
      "benevolent is at index 43186\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0135, -0.0136, -0.2972,  ...,  0.5124,  0.1771,  0.2989],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for benevolent.\n",
      "benumbed is at index 21576\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1412, -0.4361,  0.1506,  ...,  0.3387, -0.0083, -0.1083],\n",
      "         [-0.2254,  0.5057,  0.1997,  ...,  0.1793, -0.4944,  0.2856],\n",
      "         [-0.0763,  0.0823,  0.3715,  ...,  0.3918, -0.5245,  0.1909],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for benumbed.\n",
      "berate is at index 14719\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2765, -0.3230,  0.0949,  ...,  0.1427, -0.0043,  0.1400],\n",
      "         [-0.3462,  0.2802, -0.0972,  ...,  0.2098, -0.1504,  0.2755],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for berate.\n",
      "berating is at index 14719\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2765, -0.3230,  0.0949,  ...,  0.1427, -0.0043,  0.1400],\n",
      "         [ 0.1687,  0.8291,  0.4266,  ..., -0.1742,  0.2603,  0.0939],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for berating.\n",
      "bereaved is at index 17738\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1423, -0.5660, -0.1341,  ..., -0.0143,  0.0418,  0.0707],\n",
      "         [-0.0822,  0.8926,  0.8575,  ..., -0.7443,  0.1901, -0.3320],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for bereaved.\n",
      "bereft is at index 17738\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1423, -0.5660, -0.1341,  ..., -0.0143,  0.0418,  0.0707],\n",
      "         [-0.2958,  0.0442,  0.2338,  ..., -0.5126, -0.1326,  0.2853],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for bereft.\n",
      "beseeching is at index 9988\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0855, -0.0857, -0.1644,  ...,  0.0207, -0.0609,  0.1862],\n",
      "         [ 0.4007, -0.3046, -0.0053,  ...,  0.1608, -0.0959,  0.3963],\n",
      "         [-0.3909,  0.3142,  0.2973,  ..., -0.1891, -0.2294,  0.0541],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for beseeching.\n",
      "bested is at index 275\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2898, -0.0664, -0.2711,  ...,  0.1179, -0.5070, -0.0055],\n",
      "         [-0.1786,  0.2013,  0.4345,  ...,  0.3394, -0.5501,  0.1632],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for bested.\n",
      "betrayal is at index 26760\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1088, -0.2871, -0.2378,  ...,  0.0063,  0.5453,  0.2642],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for betrayal.\n",
      "betrayed is at index 26913\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.6868, -0.4910, -0.4096,  ..., -0.1907,  0.3168,  0.0637],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for betrayed.\n",
      "bewildered is at index 33304\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3171, -0.0447, -0.0925,  ..., -0.0561, -0.2575,  0.1997],\n",
      "         [ 0.1771,  0.1589,  0.0945,  ...,  0.1806, -0.3288,  0.3249],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for bewildered.\n",
      "bewilderment is at index 33304\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3171, -0.0447, -0.0925,  ..., -0.0561, -0.2575,  0.1997],\n",
      "         [ 0.4303,  0.2150, -0.2271,  ..., -0.0656, -0.3551,  0.0153],\n",
      "         [ 0.1172,  0.4227, -0.1042,  ...,  0.2411,  0.0541,  0.5336],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for bewilderment.\n",
      "bi is at index 4003\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0827,  0.1671,  0.1792,  ..., -0.1842,  0.0370,  0.2760],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for bi.\n",
      "bilious is at index 31617\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.4025,  0.2430, -0.1254,  ..., -0.0529,  0.0117,  0.1814],\n",
      "         [-0.0583,  0.2461,  0.3175,  ..., -0.0270, -0.2839, -0.2945],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for bilious.\n",
      "bit is at index 828\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3081,  0.4348, -0.0825,  ...,  0.6861, -0.2669, -0.1234],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for bit.\n",
      "biting is at index 25609\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2236,  0.1072, -0.1521,  ...,  0.8628,  0.0899,  0.7299],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for biting.\n",
      "bitter is at index 10513\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1209, -0.0096,  0.4048,  ...,  0.2228,  0.4998,  0.1304],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for bitter.\n",
      "bittersweet is at index 28609\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3650,  0.4623,  0.2932,  ...,  0.0391,  0.9198,  0.4251],\n",
      "         [ 0.3826,  0.6687, -0.1358,  ..., -0.1935, -0.0872, -0.2954],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for bittersweet.\n",
      "blaming is at index 15249\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1004, -0.5362,  0.1997,  ...,  0.0996, -0.2259, -0.2186],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for blaming.\n",
      "bland is at index 35063\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.4791, -0.5380,  0.1720,  ...,  0.0265, -0.5114, -0.1781],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for bland.\n",
      "blank is at index 15818\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.4817, -0.6994,  0.0656,  ...,  0.0551, -0.2743, -0.2161],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for blank.\n",
      "blase is at index 3089\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1877, -0.6761,  0.0794,  ..., -0.0395, -0.2780, -0.1590],\n",
      "         [-0.1660,  0.0600,  0.3686,  ..., -0.7509,  0.1465, -0.1595],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for blase.\n",
      "blazed is at index 3089\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1877, -0.6761,  0.0794,  ..., -0.0395, -0.2780, -0.1590],\n",
      "         [ 0.0665,  0.0330,  0.4868,  ..., -0.1887,  0.0429,  0.3282],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for blazed.\n",
      "bleak is at index 23530\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0703,  0.0609,  0.1730,  ...,  0.2510,  0.2867, -0.0671],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for bleak.\n",
      "bleary is at index 13819\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0773,  0.0579,  0.1676,  ...,  0.4075, -0.1357,  0.0615],\n",
      "         [ 0.1577,  0.0254, -0.0304,  ...,  0.2235,  0.0405,  0.4374],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for bleary.\n",
      "blessed is at index 12230\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1324, -0.2051,  0.3051,  ...,  0.3673,  0.0475, -0.1897],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for blessed.\n",
      "blew is at index 10879\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2928,  0.4932, -0.2253,  ...,  0.2170,  0.1713, -0.5855],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for blew.\n",
      "blinded is at index 40094\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1096, -0.1102,  0.2411,  ...,  0.0487, -0.0856, -0.5630],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for blinded.\n",
      "blindsided is at index 7709\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0091, -0.3505,  0.2661,  ..., -0.1019, -0.3360, -0.0390],\n",
      "         [ 0.0859,  0.9324, -0.2320,  ..., -0.5579,  0.0777, -0.3025],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for blindsided.\n",
      "bliss is at index 30299\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1581, -0.6401,  0.2632,  ...,  0.0693,  0.0432, -0.6107],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for bliss.\n",
      "blissful is at index 30299\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1581, -0.6401,  0.2632,  ...,  0.0693,  0.0432, -0.6107],\n",
      "         [ 0.3025,  0.1036, -0.3624,  ...,  0.1536, -0.4041, -0.2558],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for blissful.\n",
      "blissfully is at index 30299\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1581, -0.6401,  0.2632,  ...,  0.0693,  0.0432, -0.6107],\n",
      "         [-0.0888,  0.0999, -0.3792,  ...,  0.0177, -0.7239,  0.2116],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for blissfully.\n",
      "blithe is at index 3089\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1877, -0.6761,  0.0794,  ..., -0.0395, -0.2780, -0.1590],\n",
      "         [ 0.0250, -0.0520,  0.2269,  ..., -0.3300, -0.0145,  0.3031],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for blithe.\n",
      "blown is at index 12315\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2019, -0.2702, -0.3189,  ...,  0.2170,  0.3274, -0.3200],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for blown.\n",
      "blue is at index 2440\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0383, -0.3151,  0.4023,  ...,  0.3413, -0.2738, -0.2182],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for blue.\n",
      "blues is at index 15629\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1466,  0.1635,  0.2236,  ..., -0.0533,  0.0807, -0.0355],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for blues.\n",
      "bluffing is at index 37372\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0713,  0.3956, -0.0671,  ..., -0.2986,  0.1343,  0.3886],\n",
      "         [ 0.1383,  0.3796,  0.1368,  ...,  0.2405, -0.3453,  0.0233],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for bluffing.\n",
      "blunt is at index 18720\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1858,  0.2849,  0.0884,  ..., -0.0893,  0.1033,  0.0173],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for blunt.\n",
      "blushing is at index 3089\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1877, -0.6761,  0.0794,  ..., -0.0395, -0.2780, -0.1590],\n",
      "         [ 0.1384,  0.3386,  0.3438,  ..., -0.4737, -0.2944,  0.1733],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for blushing.\n",
      "blustering is at index 3089\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [ 1.8766e-01, -6.7611e-01,  7.9381e-02,  ..., -3.9499e-02,\n",
      "          -2.7804e-01, -1.5899e-01],\n",
      "         [-1.7246e-01, -1.3852e-01,  3.2591e-01,  ..., -1.0450e-01,\n",
      "           1.5661e-01,  2.3199e-01],\n",
      "         [ 3.2813e-01,  2.0755e-01, -7.7806e-02,  ...,  5.3696e-01,\n",
      "          -2.5786e-01,  3.7482e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for blustering.\n",
      "boastful is at index 18639\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0102, -0.1853, -0.1097,  ..., -0.1763,  0.1543,  0.3033],\n",
      "         [ 0.3025,  0.1036, -0.3624,  ...,  0.1536, -0.4041, -0.2558],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for boastful.\n",
      "boggled is at index 741\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [ 3.8340e-01,  3.7594e-01,  2.6817e-02,  ...,  1.6899e-01,\n",
      "          -2.7568e-01,  7.1504e-02],\n",
      "         [ 2.2565e-01,  3.5651e-01, -1.5736e-01,  ...,  8.3176e-01,\n",
      "          -2.5169e-01,  3.8485e-01],\n",
      "         [ 5.8872e-02, -2.2500e-01,  7.9825e-02,  ..., -1.7086e-01,\n",
      "          -8.7378e-02,  2.7442e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for boggled.\n",
      "boiling is at index 27513\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2378, -0.8254,  0.2469,  ...,  0.6721,  0.0462, -0.3256],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for boiling.\n",
      "boisterous is at index 5276\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [ 7.2223e-02,  2.4438e-01,  2.1384e-01,  ...,  1.9484e-01,\n",
      "          -2.7599e-01,  2.9608e-01],\n",
      "         [ 7.5640e-01,  1.5740e-01,  4.2119e-02,  ..., -3.7569e-01,\n",
      "          -1.7230e-01,  3.6508e-01],\n",
      "         [ 6.2312e-03, -3.8450e-01,  1.2523e-01,  ...,  3.1559e-01,\n",
      "          -3.8559e-01, -2.4341e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for boisterous.\n",
      "bold is at index 7457\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3389, -0.7936, -0.0168,  ..., -0.1183, -0.4531,  0.2338],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for bold.\n",
      "bored is at index 23809\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1221, -0.0279,  0.2201,  ..., -0.0221, -0.4927, -0.3153],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for bored.\n",
      "boredom is at index 40326\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.4139,  0.1646,  0.0714,  ...,  0.0692, -0.0408,  0.0997],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for boredom.\n",
      "boring is at index 15305\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0167, -0.0561, -0.2313,  ...,  0.0351, -0.3697, -0.0935],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for boring.\n",
      "bothered is at index 18523\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0136,  0.4998,  0.5525,  ..., -0.0454,  0.0645,  0.2175],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for bothered.\n",
      "bounder is at index 8191\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0327, -0.2272,  0.0311,  ...,  0.2262, -0.4614,  0.1449],\n",
      "         [ 0.4303,  0.2150, -0.2271,  ..., -0.0656, -0.3551,  0.0153],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for bounder.\n",
      "brashness is at index 5378\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0075, -0.1138,  0.1299,  ..., -0.0272, -0.1805,  0.1898],\n",
      "         [-0.1051, -0.2144, -0.3385,  ..., -0.5691, -0.2581,  0.0159],\n",
      "         [-0.0261,  0.0648,  0.0660,  ..., -0.4037,  0.1015,  0.0331],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for brashness.\n",
      "bratty is at index 5378\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0075, -0.1138,  0.1299,  ..., -0.0272, -0.1805,  0.1898],\n",
      "         [ 0.1051, -0.2202, -0.0654,  ..., -0.6205, -0.2806, -0.1741],\n",
      "         [ 0.1435,  0.1202, -0.2999,  ..., -0.1916,  0.0954, -0.2514],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for bratty.\n",
      "brave is at index 10025\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.4295,  0.2017,  0.4391,  ..., -0.0977, -0.1476,  0.2876],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for brave.\n",
      "bright is at index 4520\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1066, -0.1500, -0.6335,  ..., -0.1173, -0.5711, -0.4294],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for bright.\n",
      "bristling is at index 37135\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3499,  0.1722,  0.0632,  ...,  0.1619, -0.1074,  0.0450],\n",
      "         [-0.0505, -0.0944,  0.4063,  ..., -0.3282, -0.1252,  0.2769],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for bristling.\n",
      "broken is at index 3187\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2418, -0.2876, -0.0328,  ...,  0.3319,  0.0099, -0.3306],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for broken.\n",
      "brokenhearted is at index 3187\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2418, -0.2876, -0.0328,  ...,  0.3319,  0.0099, -0.3306],\n",
      "         [-0.1408,  0.2934, -0.1141,  ...,  0.0744,  0.0680,  0.7601],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for brokenhearted.\n",
      "brokenheartedly is at index 3187\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2418, -0.2876, -0.0328,  ...,  0.3319,  0.0099, -0.3306],\n",
      "         [ 0.0899,  0.0900, -0.0768,  ..., -0.2744, -0.6974,  0.3391],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for brokenheartedly.\n",
      "brooding is at index 11051\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.5877,  0.3743,  0.4774,  ..., -0.0398, -0.1157,  0.3615],\n",
      "         [ 0.0193,  0.8056, -0.0324,  ..., -0.1929, -0.2519, -0.2192],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for brooding.\n",
      "broody is at index 11051\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.5877,  0.3743,  0.4774,  ..., -0.0398, -0.1157,  0.3615],\n",
      "         [-0.2041,  0.2176, -0.0808,  ..., -0.0969, -0.2114,  0.5330],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for broody.\n",
      "bruised is at index 26360\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0367,  0.0482,  0.5748,  ..., -0.2812,  0.0067,  0.1885],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for bruised.\n",
      "brusque is at index 5378\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0075, -0.1138,  0.1299,  ..., -0.0272, -0.1805,  0.1898],\n",
      "         [ 0.1537, -0.1257,  0.4566,  ..., -0.0650, -0.1153,  0.5475],\n",
      "         [-0.0130, -0.0322,  0.5613,  ...,  0.4493, -0.6099, -0.0785],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for brusque.\n",
      "bug is at index 13673\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0548,  0.2287,  0.3124,  ...,  0.3100,  0.1238, -0.0087],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for bug.\n",
      "bulging is at index 22382\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0127, -0.2932,  0.0274,  ..., -0.2167,  0.1964, -0.0091],\n",
      "         [-0.1019,  0.1050, -0.2707,  ...,  0.2250, -0.1715, -0.2717],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for bulging.\n",
      "bully is at index 23934\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3866, -0.1139, -0.1959,  ..., -0.1968, -0.2402,  0.1982],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for bully.\n",
      "bullying is at index 11902\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0906, -0.2341,  0.3072,  ..., -0.1430, -0.4878,  0.6570],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for bullying.\n",
      "bummed is at index 29673\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1101, -0.3088,  0.7585,  ..., -0.3120,  0.4967, -0.4712],\n",
      "         [ 0.2060,  0.4758,  0.4269,  ..., -0.1902, -0.6361,  0.0991],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for bummed.\n",
      "buoyant is at index 15980\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3855, -0.4208,  0.6451,  ...,  0.2721,  0.0207,  0.1787],\n",
      "         [-0.0978, -0.6161,  0.4288,  ..., -0.2426,  0.1850, -0.0844],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for buoyant.\n",
      "burdened is at index 32875\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0108, -0.1082,  0.1790,  ..., -0.2891,  0.0439,  0.0446],\n",
      "         [-0.0674, -0.2683,  0.6696,  ..., -0.0751, -0.2735,  0.6508],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for burdened.\n",
      "burn is at index 7403\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.4757, -0.4395, -0.0181,  ...,  0.2966, -0.3133,  0.0280],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for burn.\n",
      "bursting is at index 28548\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1136, -0.0437,  0.1970,  ...,  0.3145, -0.1885,  0.2253],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for bursting.\n",
      "bushed is at index 2353\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0009,  0.3071,  0.1849,  ..., -0.4281, -0.6466,  0.2581],\n",
      "         [-0.1477, -0.2185, -0.0201,  ..., -0.2697,  0.0681,  0.0602],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for bushed.\n",
      "cagey is at index 16051\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3299,  0.2078,  0.3933,  ..., -0.2223, -0.2426,  0.2273],\n",
      "         [ 0.1311, -0.1715,  0.0534,  ..., -0.0509, -0.4687, -0.2923],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for cagey.\n",
      "cagy is at index 740\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0761, -0.0491,  0.5377,  ...,  0.0450, -0.2771, -0.1752],\n",
      "         [ 0.0538,  0.1540,  0.2739,  ...,  0.1590, -0.4682,  0.5028],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for cagy.\n",
      "calculating is at index 29770\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0694,  0.0669,  0.2485,  ..., -0.1431,  0.1073,  0.2197],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for calculating.\n",
      "callous is at index 486\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2789,  0.0355, -0.1685,  ...,  0.0695, -0.3118,  0.3611],\n",
      "         [-0.0881, -0.2759,  0.1838,  ...,  0.2681, -0.4104, -0.2701],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for callous.\n",
      "callused is at index 486\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2789,  0.0355, -0.1685,  ...,  0.0695, -0.3118,  0.3611],\n",
      "         [ 0.0305,  0.6891, -0.1309,  ..., -0.6586, -0.1815,  0.1039],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for callused.\n",
      "calm is at index 6327\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0240, -0.0130,  0.4747,  ...,  0.0039, -0.2869, -0.1725],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for calm.\n",
      "calming is at index 31220\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1163,  0.4597,  0.1336,  ...,  0.0169, -0.4753,  0.2958],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for calming.\n",
      "calmness is at index 6327\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0240, -0.0130,  0.4747,  ...,  0.0039, -0.2869, -0.1725],\n",
      "         [-0.1231,  0.1777,  0.1255,  ..., -0.4542,  0.0778,  0.0067],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for calmness.\n",
      "canny is at index 64\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1149, -0.2863,  0.4727,  ...,  0.0887, -0.3983,  0.1376],\n",
      "         [ 0.0071,  0.9003,  0.5055,  ...,  0.0488, -0.6240,  0.4384],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for canny.\n",
      "cantankerous is at index 17672\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2923, -0.1207,  0.2156,  ..., -0.0856, -0.1273, -0.0366],\n",
      "         [-0.0482,  0.2532, -0.0248,  ..., -0.2848, -0.1947, -0.0389],\n",
      "         [ 0.4927,  0.0564, -0.3434,  ..., -0.3574,  0.1590,  0.0100],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for cantankerous.\n",
      "capable is at index 4453\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1597, -0.1065, -0.1208,  ...,  0.0219, -0.5153,  0.0090],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for capable.\n",
      "capricious is at index 2927\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-2.0529e-01, -7.5179e-02,  8.3207e-01,  ..., -3.5775e-02,\n",
      "          -6.8091e-01, -6.1380e-01],\n",
      "         [ 3.0664e-01,  2.3273e-02, -3.5081e-01,  ...,  2.2096e-01,\n",
      "          -5.1479e-01, -4.9293e-01],\n",
      "         [ 3.3982e-02,  1.3871e-01,  2.6086e-01,  ...,  2.0632e-02,\n",
      "          -2.6103e-01, -2.6917e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for capricious.\n",
      "captivated is at index 13363\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3201,  0.3865, -0.2160,  ..., -0.0479, -0.1263,  0.3647],\n",
      "         [ 0.1816,  0.4343, -0.6001,  ..., -0.0551, -0.5880, -0.2798],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for captivated.\n",
      "captive is at index 24145\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0283, -0.4725,  0.0279,  ..., -0.0965, -0.1729,  0.2473],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for captive.\n",
      "carefree is at index 575\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2052,  0.2258, -0.0366,  ..., -0.0192, -0.0204,  0.5237],\n",
      "         [ 0.0871, -0.3580,  0.1668,  ...,  0.0802, -0.0297,  0.1569],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for carefree.\n",
      "careful is at index 7316\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1282,  0.1627,  0.3222,  ...,  0.1098, -0.3381,  0.4345],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for careful.\n",
      "careless is at index 29399\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0350, -0.2497,  0.4088,  ..., -0.0998, -0.2163,  0.2681],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for careless.\n",
      "caring is at index 10837\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0864,  0.1751, -0.1627,  ..., -0.0982,  0.4664,  0.2349],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for caring.\n",
      "catty is at index 4758\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.4876, -0.0685,  0.4317,  ..., -0.1935, -0.0953,  0.0501],\n",
      "         [ 0.0507,  0.2282, -0.2432,  ..., -0.2395,  0.0726, -0.2768],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for catty.\n",
      "caustic is at index 6056\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1330,  0.1255, -0.0032,  ..., -0.1335, -0.3868, -0.0376],\n",
      "         [-0.1725, -0.1385,  0.3259,  ..., -0.1045,  0.1566,  0.2320],\n",
      "         [ 0.2853,  0.3615,  0.0987,  ...,  0.1007, -0.1208,  0.0663],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for caustic.\n",
      "cautionary is at index 8038\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3836,  0.1165,  0.0524,  ...,  0.2014, -0.0511,  0.2035],\n",
      "         [ 0.1577,  0.0254, -0.0304,  ...,  0.2235,  0.0405,  0.4374],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for cautionary.\n",
      "cautious is at index 9420\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0489,  0.1283,  0.2087,  ...,  0.1555, -0.3056,  0.4178],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for cautious.\n",
      "cavalier is at index 41869\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1251, -0.2389,  0.3090,  ..., -0.0620, -0.0871, -0.0732],\n",
      "         [-0.0479,  0.0969, -0.0692,  ..., -0.1569, -0.3009,  0.1434],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for cavalier.\n",
      "celebrating is at index 6146\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3596, -0.3286,  0.0102,  ...,  0.1918,  0.1953,  0.2728],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for celebrating.\n",
      "celebration is at index 4821\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2735, -0.0056, -0.0703,  ...,  0.1922,  0.3194,  0.6732],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for celebration.\n",
      "censure is at index 26489\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2801,  0.1260, -0.3007,  ...,  0.4318, -0.6892,  0.1225],\n",
      "         [ 0.0432,  0.0270,  0.1464,  ..., -0.1014,  0.2977, -0.1121],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for censure.\n",
      "centered is at index 14889\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0929,  0.3707,  0.2874,  ...,  0.0837, -0.2074, -0.4233],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for centered.\n",
      "certain is at index 1402\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0419,  0.0541,  0.4752,  ..., -0.0664, -0.0948, -0.0096],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for certain.\n",
      "chafed is at index 1855\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3101, -0.2237,  0.1505,  ...,  0.2899,  0.1971,  0.5207],\n",
      "         [ 0.2818,  0.1240, -0.0765,  ..., -0.3350,  0.1079, -0.0711],\n",
      "         [-0.0763,  0.0823,  0.3715,  ...,  0.3918, -0.5245,  0.1909],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for chafed.\n",
      "chagrin is at index 1855\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3101, -0.2237,  0.1505,  ...,  0.2899,  0.1971,  0.5207],\n",
      "         [ 0.3773,  0.3764,  0.6317,  ..., -0.2165,  0.2533,  0.1200],\n",
      "         [ 0.5358,  0.0369, -0.3369,  ..., -0.3095, -0.4843,  0.2047],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for chagrin.\n",
      "chagrined is at index 1855\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3101, -0.2237,  0.1505,  ...,  0.2899,  0.1971,  0.5207],\n",
      "         [ 0.3773,  0.3764,  0.6317,  ..., -0.2165,  0.2533,  0.1200],\n",
      "         [ 0.5522, -0.2355, -0.0396,  ...,  0.2374, -0.0143,  0.0048],\n",
      "         [ 0.2769,  0.3843,  0.2157,  ..., -0.2105,  0.1265,  0.6264],\n",
      "         [ 0.2760, -0.1979, -0.1075,  ...,  0.4037,  0.0583,  0.1964]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for chagrined.\n",
      "chagrinned is at index 1855\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3101, -0.2237,  0.1505,  ...,  0.2899,  0.1971,  0.5207],\n",
      "         [ 0.3773,  0.3764,  0.6317,  ..., -0.2165,  0.2533,  0.1200],\n",
      "         [ 0.5358,  0.0369, -0.3369,  ..., -0.3095, -0.4843,  0.2047],\n",
      "         [-0.1197, -0.4144,  0.0403,  ...,  0.1716, -0.5948, -0.0206],\n",
      "         [ 0.2760, -0.1979, -0.1075,  ...,  0.4037,  0.0583,  0.1964]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for chagrinned.\n",
      "challenge is at index 1539\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.4720, -0.1289,  0.2339,  ...,  0.2514, -0.0650,  0.2596],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for challenge.\n",
      "challenged is at index 6835\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.6791, -0.1204,  0.4161,  ...,  0.0338, -0.0515, -0.1427],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for challenged.\n",
      "challenging is at index 4087\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.6995,  0.0129, -0.0845,  ...,  0.2702, -0.0713,  0.0373],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for challenging.\n",
      "chaotic is at index 16529\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1757,  0.0374, -0.2267,  ..., -0.0252, -0.1314, -0.0404],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for chaotic.\n",
      "charged is at index 1340\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0338,  0.2939,  0.3231,  ..., -0.0624, -0.9234,  0.2783],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for charged.\n",
      "charmed is at index 16224\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0709,  0.1653,  0.6502,  ..., -0.2939, -0.6353, -0.2093],\n",
      "         [ 0.2060,  0.4758,  0.4269,  ..., -0.1902, -0.6361,  0.0991],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for charmed.\n",
      "charming is at index 18452\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2475,  0.0977,  0.0579,  ...,  0.4207, -0.3872, -0.0409],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for charming.\n",
      "chary is at index 1855\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3101, -0.2237,  0.1505,  ...,  0.2899,  0.1971,  0.5207],\n",
      "         [ 0.1577,  0.0254, -0.0304,  ...,  0.2235,  0.0405,  0.4374],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for chary.\n",
      "cheated is at index 25177\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0663,  0.0450,  0.1377,  ..., -0.1942,  0.0422,  0.4173],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for cheated.\n",
      "cheeky is at index 15401\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2743,  0.1061,  0.0425,  ..., -0.3354, -0.0405,  0.2462],\n",
      "         [ 0.1311, -0.1715,  0.0534,  ..., -0.0509, -0.4687, -0.2923],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for cheeky.\n",
      "cheered is at index 18643\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1867,  0.1707,  0.3842,  ...,  0.3575, -0.3502,  0.1373],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for cheered.\n",
      "cheerful is at index 33928\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0922,  0.2526,  0.2512,  ...,  0.5579, -0.1026,  0.1023],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for cheerful.\n",
      "cheering is at index 16765\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0180, -0.1746,  0.1874,  ...,  0.6581, -0.4061, -0.0155],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for cheering.\n",
      "cheerless is at index 9450\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0937,  0.0588,  0.5386,  ...,  0.4403, -0.2596,  0.1987],\n",
      "         [-0.0646, -0.7736,  0.2078,  ...,  0.1990, -0.4643, -0.1719],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for cheerless.\n",
      "cheery is at index 5851\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0882,  0.1604,  0.3574,  ...,  0.2630, -0.1186,  0.2223],\n",
      "         [-0.1645,  0.1921, -0.3187,  ..., -0.2029, -0.1886,  0.1188],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for cheery.\n",
      "cheesy is at index 36331\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1078, -0.2216,  0.2409,  ..., -0.0157,  0.0841, -0.0984],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for cheesy.\n",
      "chesty is at index 7050\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0910, -0.1615,  0.6620,  ..., -0.5561, -0.0868, -0.2410],\n",
      "         [ 0.1311, -0.1715,  0.0534,  ..., -0.0509, -0.4687, -0.2923],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for chesty.\n",
      "chide is at index 1855\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3101, -0.2237,  0.1505,  ...,  0.2899,  0.1971,  0.5207],\n",
      "         [-0.2467,  0.6990,  0.0891,  ..., -0.3310, -0.2731,  0.3602],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for chide.\n",
      "chiding is at index 1855\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3101, -0.2237,  0.1505,  ...,  0.2899,  0.1971,  0.5207],\n",
      "         [-0.3089,  0.8814, -0.2127,  ..., -0.3277, -0.0050,  0.4172],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for chiding.\n",
      "childish is at index 40531\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2472, -0.2034,  0.0251,  ..., -0.1036, -0.0541, -0.1306],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for childish.\n",
      "childishly is at index 920\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3920, -0.1187,  0.2120,  ..., -0.2594, -0.1002, -0.1848],\n",
      "         [ 0.2796, -0.0197, -0.4107,  ...,  0.0650, -0.4153,  0.3996],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for childishly.\n",
      "childlike is at index 920\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3920, -0.1187,  0.2120,  ..., -0.2594, -0.1002, -0.1848],\n",
      "         [ 0.2989, -0.4439, -0.4761,  ..., -0.1166,  0.2157,  0.3290],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for childlike.\n",
      "chill is at index 13146\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3393,  0.3542,  0.5014,  ...,  0.2634, -0.0436,  0.2418],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for chill.\n",
      "chilled is at index 32338\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0511,  0.1068,  0.5147,  ...,  0.2743,  0.1796,  0.3592],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for chilled.\n",
      "chilling is at index 22577\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.4830,  0.5080,  0.3790,  ...,  0.8014, -0.0260,  0.5048],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for chilling.\n",
      "chipper is at index 1855\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3101, -0.2237,  0.1505,  ...,  0.2899,  0.1971,  0.5207],\n",
      "         [ 0.2330,  0.6986, -0.1797,  ...,  0.4946, -0.2164,  0.4476],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for chipper.\n",
      "chirpy is at index 1855\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-3.1014e-01, -2.2368e-01,  1.5054e-01,  ...,  2.8995e-01,\n",
      "           1.9709e-01,  5.2066e-01],\n",
      "         [ 5.0110e-01,  3.2309e-01,  9.7804e-01,  ..., -1.0649e-01,\n",
      "          -6.7823e-02,  7.7963e-01],\n",
      "         [-8.1415e-02,  5.6889e-01,  5.6564e-01,  ..., -2.9892e-01,\n",
      "          -3.5616e-01, -4.1879e-02],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for chirpy.\n",
      "choleric is at index 1855\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3101, -0.2237,  0.1505,  ...,  0.2899,  0.1971,  0.5207],\n",
      "         [ 0.5957,  0.0883, -0.1406,  ...,  0.5413, -0.1653,  0.3049],\n",
      "         [ 0.2853,  0.3615,  0.0987,  ...,  0.1007, -0.1208,  0.0663],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for choleric.\n",
      "chortling is at index 1855\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3101, -0.2237,  0.1505,  ...,  0.2899,  0.1971,  0.5207],\n",
      "         [-0.4040, -0.0564,  0.5574,  ..., -0.3967,  0.0151,  0.3760],\n",
      "         [ 0.0499, -0.2110,  0.3453,  ..., -0.2768, -0.1006,  0.3045],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for chortling.\n",
      "chuckle is at index 37496\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.4197,  0.3619,  0.3590,  ..., -0.3379,  0.0162,  0.1876],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for chuckle.\n",
      "chuckling is at index 34600\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0174, -0.2535,  0.6783,  ...,  0.0986, -0.1313, -0.2030],\n",
      "         [-0.0505, -0.0944,  0.4063,  ..., -0.3282, -0.1252,  0.2769],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for chuckling.\n",
      "churlish is at index 1855\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3101, -0.2237,  0.1505,  ...,  0.2899,  0.1971,  0.5207],\n",
      "         [-0.0512, -0.0761,  0.0085,  ..., -0.2011,  0.4813, -0.2538],\n",
      "         [ 0.1187,  0.2951, -0.2445,  ...,  0.0785, -0.0014,  0.1393],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for churlish.\n",
      "circumspect is at index 38529\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0453,  0.1250,  0.7246,  ...,  0.2143, -0.0400,  0.0392],\n",
      "         [ 0.3306,  0.3038, -0.0324,  ..., -0.1424, -0.1171,  0.7134],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for circumspect.\n",
      "clamorous is at index 24045\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2455,  0.0193,  0.5365,  ...,  0.1901, -0.4298, -0.2660],\n",
      "         [ 0.1864,  0.2010, -0.5071,  ...,  0.2052, -0.1649,  0.2339],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for clamorous.\n",
      "clash is at index 6064\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.5147,  0.1731, -0.2657,  ...,  0.1470,  0.0992,  0.5188],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for clash.\n",
      "clear is at index 699\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3610, -0.2909,  0.3276,  ..., -0.0413, -0.2139,  0.1421],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for clear.\n",
      "clenched is at index 44646\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0949, -0.2123, -0.1224,  ..., -0.3510,  0.0057,  0.2434],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for clenched.\n",
      "clever is at index 13074\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0593,  0.2145, -0.1907,  ...,  0.4133, -0.1942,  0.1594],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for clever.\n",
      "close is at index 593\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3408,  0.0055,  0.1738,  ...,  0.4163, -0.8939, -0.0061],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for close.\n",
      "closed is at index 1367\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0327, -0.2777,  0.0751,  ..., -0.0627, -0.3413, -0.0241],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for closed.\n",
      "closemouthed is at index 593\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3408,  0.0055,  0.1738,  ...,  0.4163, -0.8939, -0.0061],\n",
      "         [ 0.0889,  0.1804, -0.0982,  ...,  0.1596,  0.1724,  0.3057],\n",
      "         [-0.0471, -0.4785, -0.2044,  ..., -0.3562, -0.6360,  0.3498],\n",
      "         [-0.0279, -0.3569, -0.1079,  ..., -0.1819,  0.1631,  0.1000],\n",
      "         [ 0.2760, -0.1979, -0.1075,  ...,  0.4037,  0.0583,  0.1964]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for closemouthed.\n",
      "cloy is at index 3741\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3091,  0.1379,  0.2666,  ...,  0.3452, -0.4528, -0.0876],\n",
      "         [ 0.2223,  0.2522,  0.1665,  ..., -0.6101, -0.1394,  0.1217],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for cloy.\n",
      "clueless is at index 36776\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0069,  0.0386,  0.1937,  ..., -0.1647,  0.2178, -0.3228],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for clueless.\n",
      "clutched is at index 29409\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.4442,  0.0051,  0.0634,  ..., -0.2464, -0.6295,  0.4768],\n",
      "         [-0.4913,  0.3303,  0.0863,  ..., -0.1675, -0.1343, -0.2704],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for clutched.\n",
      "cluttered is at index 29409\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.4442,  0.0051,  0.0634,  ..., -0.2464, -0.6295,  0.4768],\n",
      "         [ 0.1090,  0.1862, -0.0721,  ...,  0.0564, -0.0326,  0.0966],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for cluttered.\n",
      "cockeyed is at index 740\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [ 7.6077e-02, -4.9108e-02,  5.3775e-01,  ...,  4.5011e-02,\n",
      "          -2.7709e-01, -1.7525e-01],\n",
      "         [ 4.0265e-01,  2.5979e-01,  6.5434e-01,  ..., -5.9182e-01,\n",
      "          -4.0795e-01,  2.5973e-01],\n",
      "         [-7.6293e-02,  8.2298e-02,  3.7151e-01,  ...,  3.9176e-01,\n",
      "          -5.2446e-01,  1.9090e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for cockeyed.\n",
      "cockiness is at index 24231\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.4129, -0.1409,  0.1788,  ..., -0.1839,  0.3096, -0.4166],\n",
      "         [-0.2111,  0.2981, -0.1767,  ..., -0.0285,  0.2131, -0.4322],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for cockiness.\n",
      "cocksure is at index 740\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [ 7.6077e-02, -4.9108e-02,  5.3775e-01,  ...,  4.5011e-02,\n",
      "          -2.7709e-01, -1.7525e-01],\n",
      "         [-3.2278e-01,  8.9257e-01, -8.3426e-02,  ..., -2.4174e-01,\n",
      "          -2.3834e-01, -2.3957e-01],\n",
      "         [ 1.3932e-01, -8.4328e-02,  8.8077e-02,  ..., -5.2191e-02,\n",
      "           3.2186e-01, -8.6095e-02],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for cocksure.\n",
      "cocky is at index 24231\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.4129, -0.1409,  0.1788,  ..., -0.1839,  0.3096, -0.4166],\n",
      "         [ 0.1311, -0.1715,  0.0534,  ..., -0.0509, -0.4687, -0.2923],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for cocky.\n",
      "cognizant is at index 28105\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-5.1960e-02, -4.2402e-01,  6.2261e-01,  ..., -9.6289e-02,\n",
      "          -2.2594e-01,  3.1367e-03],\n",
      "         [ 2.3487e-01,  4.8086e-01, -2.6044e-01,  ..., -1.1364e-01,\n",
      "          -1.4859e-01,  4.2543e-01],\n",
      "         [-1.7943e-03, -7.2241e-01,  3.6607e-01,  ..., -1.9104e-01,\n",
      "           2.0683e-01, -5.7756e-02],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for cognizant.\n",
      "cold is at index 2569\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0422, -0.1145,  0.2199,  ...,  0.2875, -0.2915,  0.1528],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for cold.\n",
      "collected is at index 4786\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1766,  0.1981,  0.6013,  ...,  0.1164, -0.4685, -0.1939],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for collected.\n",
      "collusive is at index 9843\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2971, -0.5067, -0.2773,  ...,  0.3626, -0.9616,  0.0761],\n",
      "         [-0.0436,  0.6806, -0.3090,  ...,  0.1173,  0.1579,  0.2195],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for collusive.\n",
      "colonized is at index 17735\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2683, -0.1802,  0.4084,  ..., -0.0107, -0.1546, -0.3973],\n",
      "         [-0.0545,  0.4248,  0.1878,  ...,  0.0940, -0.2454,  0.3326],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for colonized.\n",
      "combative is at index 14960\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.7236, -0.2106, -0.1656,  ...,  0.1485,  0.2245,  0.1056],\n",
      "         [ 0.0452,  0.3078, -0.1904,  ..., -0.2063,  0.4188,  0.0517],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for combative.\n",
      "comedic is at index 29045\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-3.4551e-01,  6.4965e-01,  3.5912e-04,  ..., -1.8390e-01,\n",
      "           4.7345e-01, -3.4677e-01],\n",
      "         [ 9.2431e-02, -2.9484e-02, -1.2872e-02,  ...,  3.0573e-01,\n",
      "          -1.1492e-01,  1.8911e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for comedic.\n",
      "comfort is at index 5863\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2323,  0.2735,  0.0934,  ..., -0.1272, -0.1433,  0.0182],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for comfort.\n",
      "comfortable is at index 3473\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1205, -0.0206,  0.8908,  ..., -0.2248, -0.1100,  0.3117],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for comfortable.\n",
      "comforted is at index 5863\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2323,  0.2735,  0.0934,  ..., -0.1272, -0.1433,  0.0182],\n",
      "         [-0.1786,  0.2013,  0.4345,  ...,  0.3394, -0.5501,  0.1632],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for comforted.\n",
      "comical is at index 3137\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1362,  0.1403,  0.5310,  ..., -0.2105, -0.2356,  0.1517],\n",
      "         [-0.3909,  0.5831,  0.0951,  ...,  0.2938,  0.2165, -0.0992],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for comical.\n",
      "commanding is at index 20510\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0163,  0.1523,  0.2225,  ...,  0.1602, -0.0091,  0.2313],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for commanding.\n",
      "commiserating is at index 7034\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-1.1978e-01,  1.0524e-01,  6.0842e-02,  ...,  3.4193e-02,\n",
      "          -2.1757e-01, -3.0938e-02],\n",
      "         [ 1.0798e-01,  1.1742e-01, -1.0132e-01,  ..., -4.0846e-01,\n",
      "           3.7869e-01,  8.1115e-01],\n",
      "         [ 2.6927e-01,  7.0658e-01,  3.6206e-01,  ..., -1.2090e-01,\n",
      "           2.8401e-01,  1.2105e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for commiserating.\n",
      "commiserative is at index 7034\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-1.1978e-01,  1.0524e-01,  6.0842e-02,  ...,  3.4193e-02,\n",
      "          -2.1757e-01, -3.0938e-02],\n",
      "         [ 1.0798e-01,  1.1742e-01, -1.0132e-01,  ..., -4.0846e-01,\n",
      "           3.7869e-01,  8.1115e-01],\n",
      "         [ 1.4141e-01,  1.9555e-01, -2.4921e-01,  ..., -1.5649e-01,\n",
      "           4.4205e-01,  7.7889e-02],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for commiserative.\n",
      "communicative is at index 16759\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1491, -0.5592, -0.0611,  ..., -0.2471, -0.2948,  0.6412],\n",
      "         [-0.0529,  0.6225, -0.5696,  ..., -0.2476, -0.2144,  0.3368],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for communicative.\n",
      "compassion is at index 14736\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0674, -0.1163,  0.3491,  ...,  0.0576,  0.0837,  0.2032],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for compassion.\n",
      "compassionate is at index 23303\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2203,  0.0994,  0.1918,  ...,  0.2910, -0.0787,  0.4520],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for compassionate.\n",
      "competent is at index 17451\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.6058,  0.1434,  0.2596,  ...,  0.3968, -0.9635,  0.2662],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for competent.\n",
      "competitive is at index 2695\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2518,  0.1152,  0.4359,  ..., -0.1672,  0.2922,  0.1544],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for competitive.\n",
      "complacence is at index 13000\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1477, -0.1490, -0.3718,  ...,  0.1761, -0.0134, -0.4308],\n",
      "         [ 0.2710,  0.1755, -0.1227,  ..., -0.3227, -0.2315,  0.1875],\n",
      "         [ 0.0933,  0.1282, -0.0739,  ...,  0.0117,  0.1063,  0.2404],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for complacence.\n",
      "complacency is at index 13000\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [ 1.4774e-01, -1.4905e-01, -3.7183e-01,  ...,  1.7611e-01,\n",
      "          -1.3373e-02, -4.3085e-01],\n",
      "         [ 2.7102e-01,  1.7546e-01, -1.2273e-01,  ..., -3.2271e-01,\n",
      "          -2.3147e-01,  1.8755e-01],\n",
      "         [ 2.7783e-01, -5.5999e-01, -2.4313e-01,  ..., -2.5632e-01,\n",
      "           2.2675e-01,  8.4540e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for complacency.\n",
      "complacent is at index 13000\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1477, -0.1490, -0.3718,  ...,  0.1761, -0.0134, -0.4308],\n",
      "         [-0.2344,  0.4253,  0.2548,  ..., -0.9594,  0.1253,  0.3056],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for complacent.\n",
      "complacently is at index 13000\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [ 1.4774e-01, -1.4905e-01, -3.7183e-01,  ...,  1.7611e-01,\n",
      "          -1.3373e-02, -4.3085e-01],\n",
      "         [ 2.7102e-01,  1.7546e-01, -1.2273e-01,  ..., -3.2271e-01,\n",
      "          -2.3147e-01,  1.8755e-01],\n",
      "         [ 3.4200e-01, -1.3810e-01, -2.4102e-01,  ...,  2.9614e-01,\n",
      "          -4.8194e-01,  7.3892e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for complacently.\n",
      "complain is at index 11316\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0491, -0.0259,  0.3804,  ...,  0.0723, -0.2284,  0.0404],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for complain.\n",
      "complaining is at index 13689\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2117, -0.1905,  0.5900,  ...,  0.0525,  0.0805,  0.2132],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for complaining.\n",
      "composed is at index 14092\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3029,  0.1408,  0.0898,  ..., -0.0421, -0.4404, -0.3328],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for composed.\n",
      "comprehending is at index 30030\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.6712, -0.1027, -0.2911,  ...,  0.0777, -0.2089,  0.0905],\n",
      "         [ 0.1383,  0.3796,  0.1368,  ...,  0.2405, -0.3453,  0.0233],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for comprehending.\n",
      "compulsive is at index 7753\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0012,  0.0814, -0.0429,  ...,  0.2329, -0.2438, -0.3577],\n",
      "         [ 0.3380,  0.6912, -0.0372,  ..., -0.0503,  0.0016,  0.5383],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for compulsive.\n",
      "concealed is at index 17180\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.6789,  0.2118, -0.3874,  ..., -0.2516, -0.1670, -0.3530],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for concealed.\n",
      "conceding is at index 24647\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1245, -0.2461,  0.4480,  ..., -0.0717, -0.1798,  0.2806],\n",
      "         [ 0.1383,  0.3796,  0.1368,  ...,  0.2405, -0.3453,  0.0233],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for conceding.\n",
      "conceited is at index 21177\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.5320,  0.2497, -0.2054,  ...,  0.1149,  0.3427,  0.1367],\n",
      "         [ 0.4064,  0.8840,  0.1087,  ..., -0.0376,  0.1923,  0.0776],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for conceited.\n",
      "concentrated is at index 15450\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2085,  0.0495, -0.0312,  ..., -0.0351, -0.0041,  0.0967],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for concentrated.\n",
      "concentrating is at index 28619\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0188,  0.1580, -0.1630,  ..., -0.2227,  0.0800, -0.0334],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for concentrating.\n",
      "concentration is at index 11772\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0834,  0.1480,  0.3931,  ..., -0.2605,  0.3331,  0.0028],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for concentration.\n",
      "concern is at index 2212\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0591,  0.2526,  0.1740,  ..., -0.1147,  0.5379,  0.3389],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for concern.\n",
      "concerned is at index 2273\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.4450,  0.3549,  0.4092,  ..., -0.2351,  0.3562,  0.1052],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for concerned.\n",
      "conciliatory is at index 10146\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-9.4536e-02,  2.8680e-01,  1.0136e-01,  ...,  1.1488e-01,\n",
      "          -7.2824e-01, -4.8122e-01],\n",
      "         [-8.6418e-02,  4.0692e-01,  6.3039e-03,  ..., -2.6043e-01,\n",
      "           3.3239e-01,  4.7113e-01],\n",
      "         [-1.8555e-01, -3.1370e-01, -6.2384e-02,  ...,  1.3454e-01,\n",
      "          -2.3793e-02,  6.2098e-02],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for conciliatory.\n",
      "conclusive is at index 37847\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.4046,  0.1839, -0.7770,  ...,  0.0935,  0.0148, -0.0925],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for conclusive.\n",
      "condemning is at index 21856\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0884,  0.0260,  0.0110,  ...,  0.4091, -0.3036, -0.0050],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for condemning.\n",
      "condescending is at index 40742\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.4242,  0.0327,  0.4827,  ..., -0.1532,  0.0241, -0.2410],\n",
      "         [ 0.3157,  0.1324,  0.2893,  ..., -0.0994,  0.8110,  0.0177],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for condescending.\n",
      "condoling is at index 35279\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0367,  0.0628, -0.2455,  ..., -0.4293, -0.1810,  0.4520],\n",
      "         [ 0.1383,  0.3796,  0.1368,  ...,  0.2405, -0.3453,  0.0233],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for condoling.\n",
      "confidence is at index 2123\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0029,  0.3921,  0.4357,  ..., -0.7137,  0.0996, -0.0937],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for confidence.\n",
      "confident is at index 3230\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1278,  0.2129,  0.3830,  ..., -0.4542, -0.2631,  0.1811],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for confident.\n",
      "confidently is at index 27447\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0195,  0.0197,  0.4566,  ..., -0.2849, -0.9068,  0.1842],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for confidently.\n",
      "conflicted is at index 34428\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3036,  0.8843, -0.0399,  ..., -0.0620,  0.0693, -0.6190],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for conflicted.\n",
      "confound is at index 7856\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2000,  0.1205, -0.2097,  ..., -0.1188, -0.2680, -0.0290],\n",
      "         [-0.8512,  0.6415, -0.3188,  ..., -0.3318,  0.1079, -0.3183],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for confound.\n",
      "confounded is at index 7856\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2000,  0.1205, -0.2097,  ..., -0.1188, -0.2680, -0.0290],\n",
      "         [-0.8611,  0.7814,  0.0060,  ..., -0.2269,  0.0823,  0.0056],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for confounded.\n",
      "confrontational is at index 10749\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0843, -0.3267,  0.1540,  ..., -0.2313,  0.0763,  0.1236],\n",
      "         [ 0.0015,  0.8869, -0.3079,  ...,  0.0908,  0.0704, -0.1345],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for confrontational.\n",
      "confused is at index 10985\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3789,  0.2313,  0.2402,  ..., -0.2795, -0.2195, -0.3592],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for confused.\n",
      "confusion is at index 9655\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1130,  0.3810,  0.2447,  ..., -0.4546,  0.1118, -0.2551],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for confusion.\n",
      "congenial is at index 36764\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0037,  0.2823,  0.3489,  ..., -0.0193, -0.1875,  0.1596],\n",
      "         [-0.1138,  0.2129, -0.0623,  ...,  0.2614, -0.4726,  0.1944],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for congenial.\n",
      "congratulatory is at index 26303\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0068, -0.1480, -0.2363,  ...,  0.2533, -0.2414,  0.1386],\n",
      "         [-0.0440,  0.3413,  0.2101,  ..., -0.2771,  0.1404,  0.5219],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for congratulatory.\n",
      "conniving is at index 39277\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3194,  0.1024,  0.0903,  ..., -0.0375,  0.0963,  0.2515],\n",
      "         [ 0.6389,  0.8547, -0.0406,  ...,  0.1180,  0.0874,  0.2479],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for conniving.\n",
      "conscious is at index 13316\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3439, -0.2131,  0.0497,  ...,  0.1925, -0.0849, -0.0946],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for conscious.\n",
      "conservative is at index 3354\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0378, -0.2155, -0.2729,  ...,  0.1668, -0.3645, -0.0585],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for conservative.\n",
      "considerate is at index 1701\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1279, -0.2386,  0.3152,  ...,  0.2183,  0.1676,  0.2844],\n",
      "         [-0.3462,  0.2802, -0.0972,  ...,  0.2098, -0.1504,  0.2755],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for considerate.\n",
      "considering is at index 2811\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1407, -0.0774,  0.5191,  ...,  0.2619,  0.4923,  0.0495],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for considering.\n",
      "consoling is at index 7407\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3687, -0.0844, -0.3678,  ..., -0.3237, -0.5071, -0.2190],\n",
      "         [ 0.0694,  0.3380,  0.0133,  ...,  0.1607, -0.4590, -0.0710],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for consoling.\n",
      "conspiratorial is at index 31150\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2127,  0.2174, -0.1964,  ..., -0.1678, -0.3191,  0.0183],\n",
      "         [ 0.3905,  0.0847,  0.0055,  ...,  0.1685, -0.3958,  0.1527],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for conspiratorial.\n",
      "conspiring is at index 27230\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2145, -0.1007, -0.5172,  ..., -0.2216,  0.0786, -0.0788],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for conspiring.\n",
      "consternation is at index 10759\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0850, -0.0734,  0.1139,  ...,  0.0904,  0.3105,  0.1391],\n",
      "         [ 0.2762,  0.3560,  0.5480,  ...,  0.4431, -0.6270,  0.4175],\n",
      "         [ 0.2885,  0.5321,  0.1486,  ...,  0.6387, -0.0220,  0.0633],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for consternation.\n",
      "constipated is at index 10759\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-8.4958e-02, -7.3386e-02,  1.1393e-01,  ...,  9.0440e-02,\n",
      "           3.1049e-01,  1.3910e-01],\n",
      "         [ 5.3512e-02,  4.9525e-01,  5.1928e-02,  ..., -1.3412e-01,\n",
      "          -9.3671e-02,  2.9904e-01],\n",
      "         [ 7.0715e-02,  9.0628e-01,  5.2908e-01,  ..., -1.1324e-01,\n",
      "           4.5858e-02,  5.1753e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for constipated.\n",
      "constrained is at index 26525\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1708, -0.3134, -0.1551,  ...,  0.0849, -0.1035, -0.6346],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for constrained.\n",
      "consumed is at index 13056\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2925,  0.1760,  0.4006,  ..., -0.0501, -0.1602, -0.0390],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for consumed.\n",
      "consuming is at index 16997\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3511,  0.0477,  0.6063,  ...,  0.1993, -0.3713, -0.0770],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for consuming.\n",
      "contained is at index 5558\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1050,  0.0402, -0.3193,  ..., -0.0357, -0.3138, -0.0437],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for contained.\n",
      "contemplate is at index 32848\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1205,  0.1314,  0.1484,  ..., -0.3370,  0.0757,  0.1860],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for contemplate.\n",
      "contemplating is at index 27744\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2184, -0.0102,  0.1051,  ..., -0.2081,  0.0143, -0.1131],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for contemplating.\n",
      "contemplation is at index 44072\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0317,  0.1148,  0.5776,  ...,  0.0152, -0.0805,  0.0327],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for contemplation.\n",
      "contemplative is at index 43580\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3027, -0.3209,  0.0791,  ...,  0.0038,  0.1022,  0.2321],\n",
      "         [ 0.0452,  0.3078, -0.1904,  ..., -0.2063,  0.4188,  0.0517],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for contemplative.\n",
      "contempt is at index 16176\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0075, -0.5855,  0.2250,  ..., -0.0253,  0.2840,  0.2418],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for contempt.\n",
      "contemptuous is at index 16176\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0075, -0.5855,  0.2250,  ..., -0.0253,  0.2840,  0.2418],\n",
      "         [ 0.1306, -0.0317,  0.2685,  ..., -0.0785, -0.3928, -0.3087],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for contemptuous.\n",
      "content is at index 1383\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.5402, -0.6773,  0.3641,  ...,  0.0233,  0.0594,  0.0979],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for content.\n",
      "contented is at index 1383\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.5402, -0.6773,  0.3641,  ...,  0.0233,  0.0594,  0.0979],\n",
      "         [-0.1786,  0.2013,  0.4345,  ...,  0.3394, -0.5501,  0.1632],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for contented.\n",
      "contentious is at index 14883\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0798,  0.6682,  0.1968,  ...,  0.2619,  0.1124,  0.1460],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for contentious.\n",
      "contently is at index 8541\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0228, -0.3346,  0.3756,  ..., -0.8295, -0.5004, -0.1775],\n",
      "         [ 0.2502, -0.0295, -0.1846,  ...,  0.2492, -0.5073,  0.7170],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for contently.\n",
      "contentment is at index 1383\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.5402, -0.6773,  0.3641,  ...,  0.0233,  0.0594,  0.0979],\n",
      "         [ 0.0237,  0.5318, -0.0470,  ...,  0.1930,  0.0311,  0.5084],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for contentment.\n",
      "contradictory is at index 31515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0639,  0.4641, -0.4009,  ..., -0.0121,  0.1834, -0.4090],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for contradictory.\n",
      "contrary is at index 11159\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0226,  0.0179,  0.1748,  ...,  0.3009, -0.1227,  0.1077],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for contrary.\n",
      "contrite is at index 17035\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3629, -0.3292, -0.0709,  ...,  0.0751,  0.3227, -0.0541],\n",
      "         [-0.0219,  0.3283, -0.4917,  ..., -0.2443,  0.2092, -0.0387],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for contrite.\n",
      "controlled is at index 4875\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0523,  0.2303,  0.3376,  ..., -0.0568, -0.5540,  0.3513],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for controlled.\n",
      "controlling is at index 10568\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1471,  0.0727,  0.3394,  ...,  0.2123,  0.2475,  0.0054],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for controlling.\n",
      "controversial is at index 4456\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3051,  0.4396,  0.0213,  ...,  0.1845, -0.1141,  0.1214],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for controversial.\n",
      "contumacious is at index 8541\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-2.2820e-02, -3.3462e-01,  3.7561e-01,  ..., -8.2953e-01,\n",
      "          -5.0037e-01, -1.7749e-01],\n",
      "         [ 9.4204e-03, -1.3914e-01,  4.2542e-01,  ..., -7.1778e-02,\n",
      "           2.7751e-01, -3.5878e-02],\n",
      "         [ 1.0461e-01, -1.3921e-01, -4.0359e-01,  ..., -1.5967e-01,\n",
      "          -3.0924e-01, -3.0879e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for contumacious.\n",
      "convinced is at index 7013\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2063, -0.1454,  0.1572,  ..., -0.0104,  0.1722, -0.0299],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for convinced.\n",
      "cool is at index 3035\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2281,  0.1446,  0.3641,  ...,  0.0542,  0.0388, -0.0803],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for cool.\n",
      "cooperative is at index 18777\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2678, -0.4022, -0.0427,  ...,  0.0121, -0.2292,  0.2707],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for cooperative.\n",
      "cordial is at index 13051\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2249, -0.0474,  0.2608,  ..., -0.4913, -0.2992, -0.5633],\n",
      "         [-0.1138,  0.2129, -0.0623,  ...,  0.2614, -0.4726,  0.1944],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for cordial.\n",
      "courageous is at index 24219\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0358,  0.0550,  0.2871,  ...,  0.0290, -0.2810,  0.2243],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for courageous.\n",
      "covert is at index 25523\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0590, -0.2660, -0.3835,  ..., -0.2424, -0.0883,  0.3477],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for covert.\n",
      "cowardly is at index 36881\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1762, -0.2469, -0.3819,  ..., -0.1974, -0.4360,  0.2163],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for cowardly.\n",
      "coy is at index 20176\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.4031,  0.0318,  0.2906,  ..., -0.6761, -0.2600, -0.2623],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for coy.\n",
      "crabby is at index 23320\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0258,  0.0310,  0.9955,  ...,  0.2142,  0.3684,  0.2034],\n",
      "         [-0.1758,  0.6642, -0.4225,  ...,  0.1293, -0.3372,  0.4302],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for crabby.\n",
      "crafty is at index 6306\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3270, -0.1722,  0.2121,  ...,  0.1240, -0.2194,  0.1278],\n",
      "         [ 0.1311, -0.1715,  0.0534,  ..., -0.0509, -0.4687, -0.2923],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for crafty.\n",
      "cranky is at index 30952\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3834, -0.0238, -0.1155,  ...,  0.5737,  0.0741, -0.2799],\n",
      "         [ 0.1311, -0.1715,  0.0534,  ..., -0.0509, -0.4687, -0.2923],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for cranky.\n",
      "crazed is at index 26002\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0899, -0.0246, -0.0953,  ...,  0.2248, -0.1826, -0.3698],\n",
      "         [-0.1786,  0.2013,  0.4345,  ...,  0.3394, -0.5501,  0.1632],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for crazed.\n",
      "crazy is at index 5373\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0052, -0.1190,  0.0170,  ...,  0.4232, -0.0252, -0.4743],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for crazy.\n",
      "credulous is at index 18994\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.4028,  0.1949,  0.1491,  ..., -0.2567, -0.1779, -0.3742],\n",
      "         [ 0.0855,  0.7959,  0.5674,  ..., -0.1975, -0.1550, -0.2803],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for credulous.\n",
      "creepy is at index 23814\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0162,  0.1090,  0.3741,  ...,  0.2838, -0.3383,  0.0579],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for creepy.\n",
      "crestfallen is at index 32220\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-7.4871e-02,  2.2460e-01,  4.0417e-01,  ...,  3.2678e-01,\n",
      "          -3.2721e-01,  8.5894e-02],\n",
      "         [ 6.2515e-03, -4.5136e-01, -2.0865e-01,  ...,  3.9414e-01,\n",
      "           2.9007e-01, -1.7469e-01],\n",
      "         [ 3.4456e-01, -7.0675e-02,  5.6877e-01,  ...,  1.8837e-01,\n",
      "          -4.8098e-01,  7.0811e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for crestfallen.\n",
      "cringing is at index 3977\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2916, -0.2629, -0.5359,  ...,  0.4484, -0.4556, -0.1693],\n",
      "         [ 0.1304,  1.0441,  0.2365,  ...,  0.4641,  0.1736, -0.1488],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for cringing.\n",
      "critical is at index 2008\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3675,  0.3366,  0.3457,  ...,  0.5966, -0.4775,  0.0686],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for critical.\n",
      "cross is at index 2116\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1827,  0.2239,  1.2862,  ...,  0.3481,  0.0328,  0.2509],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for cross.\n",
      "crotchety is at index 11398\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1863,  0.4271, -0.4150,  ..., -0.5021, -0.4262, -0.0186],\n",
      "         [ 0.1047, -0.0191,  0.1024,  ...,  0.0027, -0.4629,  0.3404],\n",
      "         [-0.2232, -0.0186,  0.0650,  ..., -0.5523,  0.2182,  0.1047],\n",
      "         [ 0.1714,  0.0887, -0.3315,  ..., -0.1505,  0.1682, -0.2366],\n",
      "         [ 0.2760, -0.1979, -0.1075,  ...,  0.4037,  0.0583,  0.1964]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for crotchety.\n",
      "crude is at index 2976\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2424,  0.2710, -0.0227,  ...,  0.0312, -0.7168, -0.1338],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for crude.\n",
      "cruel is at index 15939\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1292,  0.4571, -0.0420,  ...,  0.4581, -0.1844,  0.4764],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for cruel.\n",
      "crushed is at index 14045\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0526, -0.1095,  0.1921,  ...,  0.4303, -0.2175,  0.2989],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for crushed.\n",
      "cry is at index 8930\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2651,  0.5610, -0.0282,  ...,  0.6739, -0.4895,  0.0739],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for cry.\n",
      "crying is at index 9701\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0222,  0.2436,  0.2908,  ...,  0.4570, -0.2202,  0.1472],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for crying.\n",
      "cryptic is at index 35916\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2954, -0.1614, -0.7889,  ..., -0.0043, -0.3583, -0.4012],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for cryptic.\n",
      "culpable is at index 29410\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3218, -0.4224,  0.0620,  ..., -0.1027, -0.0788, -0.0447],\n",
      "         [ 0.4713, -0.1066,  0.1604,  ...,  0.0613,  0.0895,  0.2098],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for culpable.\n",
      "cunning is at index 41526\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0791, -0.0114, -0.3857,  ...,  0.1956, -0.1383,  0.2618],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for cunning.\n",
      "curios is at index 5350\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3768,  0.0257,  0.1475,  ...,  0.2798,  0.0939, -0.4457],\n",
      "         [-0.1376,  0.5599, -0.2945,  ..., -0.0868, -0.1783,  0.2962],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for curios.\n",
      "curiosity is at index 20610\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1304,  0.0368, -0.2106,  ..., -0.0384,  0.3231, -0.3582],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for curiosity.\n",
      "curious is at index 10691\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1541, -0.0961,  0.1185,  ...,  0.4125, -0.1602, -0.2714],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for curious.\n",
      "cutting is at index 3931\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3199, -0.2198,  0.3129,  ...,  0.6922,  0.4492,  0.5007],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for cutting.\n",
      "cynic is at index 40240\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0734,  0.2774,  0.0380,  ...,  0.1739, -0.2999,  0.2034],\n",
      "         [ 0.1879,  0.4749,  0.1584,  ...,  0.0505, -0.1448,  0.0398],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for cynic.\n",
      "cynical is at index 27566\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0995,  0.2821,  0.3504,  ...,  0.1365,  0.3448,  0.1857],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for cynical.\n",
      "cynicism is at index 39245\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1118,  0.1328,  0.3485,  ..., -0.0879,  0.6504,  0.1389],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for cynicism.\n",
      "dalliance is at index 385\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1079,  0.0539,  0.1122,  ...,  0.3283,  0.0679,  0.1026],\n",
      "         [ 0.0053, -0.3714,  0.1366,  ..., -0.1070, -0.1093,  0.0447],\n",
      "         [ 0.0460,  0.4915, -0.3238,  ..., -0.3370,  0.1893, -0.1624],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for dalliance.\n",
      "dandy is at index 385\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1079,  0.0539,  0.1122,  ...,  0.3283,  0.0679,  0.1026],\n",
      "         [-0.1330,  0.7225, -0.0665,  ...,  0.0050, -0.1650,  0.1351],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for dandy.\n",
      "dangerous is at index 2702\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0806,  0.3594,  0.2101,  ...,  0.4178, -0.0812,  0.1617],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for dangerous.\n",
      "darkly is at index 2933\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1117, -0.2726, -0.0775,  ...,  0.4096,  0.1368, -0.4672],\n",
      "         [ 0.3543,  0.3169,  0.0401,  ..., -0.1069, -0.5598,  0.1301],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for darkly.\n",
      "daunted is at index 385\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1079,  0.0539,  0.1122,  ...,  0.3283,  0.0679,  0.1026],\n",
      "         [-0.2919,  0.4680, -0.1489,  ...,  0.0544,  0.5094,  0.3133],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for daunted.\n",
      "daydream is at index 183\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2898,  0.4807,  0.4882,  ..., -0.0938, -0.6651, -0.1238],\n",
      "         [ 0.2755,  0.3019, -0.1960,  ..., -0.4059, -0.2240,  0.1547],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for daydream.\n",
      "daydreaming is at index 183\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [ 2.8975e-01,  4.8069e-01,  4.8818e-01,  ..., -9.3779e-02,\n",
      "          -6.6506e-01, -1.2377e-01],\n",
      "         [ 2.7548e-01,  3.0188e-01, -1.9600e-01,  ..., -4.0590e-01,\n",
      "          -2.2401e-01,  1.5466e-01],\n",
      "         [ 2.4069e-01,  2.5581e-01,  7.2026e-02,  ...,  2.9232e-01,\n",
      "          -3.1740e-01,  5.1260e-02],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for daydreaming.\n",
      "dazed is at index 385\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1079,  0.0539,  0.1122,  ...,  0.3283,  0.0679,  0.1026],\n",
      "         [ 0.0665,  0.0330,  0.4868,  ..., -0.1887,  0.0429,  0.3282],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for dazed.\n",
      "dazzled is at index 32614\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0909, -0.2542, -0.0288,  ..., -0.1527, -0.0173,  0.2397],\n",
      "         [-0.0402, -0.1098,  0.1399,  ..., -0.2213, -0.1115,  0.2467],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for dazzled.\n",
      "deadly is at index 4847\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1176,  0.0593, -0.0462,  ...,  0.6045, -0.1276,  0.6101],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for deadly.\n",
      "deadpan is at index 1462\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2826, -0.1631,  0.4769,  ...,  0.7179, -0.0160,  0.7345],\n",
      "         [ 0.0010,  0.9408,  0.6759,  ..., -0.2727, -0.2402, -0.2257],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for deadpan.\n",
      "debate is at index 2625\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0604,  0.0119,  0.1182,  ..., -0.0503, -0.4968,  0.1138],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for debate.\n",
      "debating is at index 24996\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2854, -0.0388,  0.0114,  ...,  0.0301, -0.2474, -0.2156],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for debating.\n",
      "debauched is at index 10189\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [ 8.1439e-02,  2.3259e-01,  1.5395e-01,  ...,  6.3276e-02,\n",
      "          -1.4348e-01,  8.0529e-02],\n",
      "         [-6.7149e-02, -1.6884e-01,  8.4361e-01,  ...,  9.3112e-02,\n",
      "          -2.3726e-01,  7.3127e-01],\n",
      "         [-3.9790e-01,  2.2115e-01,  2.8493e-02,  ..., -1.1910e-01,\n",
      "          -1.1143e-01, -2.4574e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for debauched.\n",
      "deceitful is at index 35049\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0877, -0.1281,  0.2466,  ..., -0.2631,  0.5269,  0.4096],\n",
      "         [ 0.3025,  0.1036, -0.3624,  ...,  0.1536, -0.4041, -0.2558],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for deceitful.\n",
      "deceived is at index 38079\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2329,  0.1254,  0.1435,  ..., -0.0993,  0.1084,  0.1423],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for deceived.\n",
      "deceiving is at index 34575\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2394,  0.1288, -0.2405,  ...,  0.0948,  0.3103,  0.3755],\n",
      "         [ 0.6389,  0.8547, -0.0406,  ...,  0.1180,  0.0874,  0.2479],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for deceiving.\n",
      "deceivingly is at index 34575\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-2.3941e-01,  1.2878e-01, -2.4047e-01,  ...,  9.4768e-02,\n",
      "           3.1029e-01,  3.7547e-01],\n",
      "         [ 6.3890e-01,  8.5467e-01, -4.0568e-02,  ...,  1.1804e-01,\n",
      "           8.7438e-02,  2.4787e-01],\n",
      "         [ 4.5286e-01,  1.9752e-01, -2.2084e-02,  ..., -5.4241e-02,\n",
      "          -5.3192e-01,  1.5678e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for deceivingly.\n",
      "deception is at index 29244\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1928,  0.1625, -0.2643,  ..., -0.3903,  0.4435,  0.3097],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for deception.\n",
      "deceptive is at index 31405\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2209,  0.1456,  0.0391,  ..., -0.1252, -0.0830, -0.1268],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for deceptive.\n",
      "deciding is at index 8997\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0521,  0.2276,  0.1120,  ..., -0.1477,  0.0601, -0.0831],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for deciding.\n",
      "decisive is at index 12703\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1496,  0.0705,  0.0194,  ...,  0.0943,  0.1177,  0.2976],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for decisive.\n",
      "dedicated is at index 3688\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3073,  0.3071, -0.2156,  ...,  0.4380, -0.3491, -0.1143],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for dedicated.\n",
      "defeat is at index 3002\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0255, -0.7581,  0.3092,  ...,  0.4976,  0.0552,  0.0781],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for defeat.\n",
      "defeated is at index 5125\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1986, -0.2904,  0.6142,  ...,  0.0995, -0.0627,  0.2802],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for defeated.\n",
      "defenseless is at index 3816\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-2.0617e-01,  2.8731e-01,  6.1997e-01,  ..., -1.2649e-01,\n",
      "          -3.5375e-01,  3.6668e-01],\n",
      "         [ 2.4538e-01,  4.4398e-02,  6.2909e-01,  ...,  1.3726e-01,\n",
      "          -5.0517e-01,  6.8084e-01],\n",
      "         [ 9.1010e-04,  1.3410e-01, -2.9809e-01,  ...,  3.5900e-02,\n",
      "          -4.1020e-01,  2.8053e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for defenseless.\n",
      "defensive is at index 2465\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1335,  0.0761,  0.2679,  ..., -0.0813, -0.2426, -0.1576],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for defensive.\n",
      "defiance is at index 25442\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0855,  0.0583, -0.5770,  ...,  0.0714,  0.3947,  0.3309],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for defiance.\n",
      "defiant is at index 23802\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2372, -0.2699, -0.1013,  ...,  0.0756, -0.1019,  0.2754],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for defiant.\n",
      "deflated is at index 3816\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2062,  0.2873,  0.6200,  ..., -0.1265, -0.3537,  0.3667],\n",
      "         [-0.4716,  0.6964,  0.3374,  ..., -0.1694, -0.1214, -0.6006],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for deflated.\n",
      "degage is at index 31295\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.4633,  0.2082,  0.3153,  ...,  0.7761,  0.1289,  0.0332],\n",
      "         [-0.2347, -0.2227,  0.1567,  ..., -0.0535,  0.2938,  0.1961],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for degage.\n",
      "degrading is at index 36892\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1148,  0.2922,  0.2022,  ...,  0.8974, -0.1440, -0.3170],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for degrading.\n",
      "dejected is at index 263\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2988, -0.3032,  0.0028,  ...,  0.0924, -0.2585,  0.7741],\n",
      "         [ 0.1329,  0.7311,  0.3638,  ...,  0.0667,  0.0089,  0.2398],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for dejected.\n",
      "dejection is at index 263\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2988, -0.3032,  0.0028,  ...,  0.0924, -0.2585,  0.7741],\n",
      "         [ 0.0762,  0.6454,  0.2416,  ...,  0.1537,  0.5437, -0.1051],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for dejection.\n",
      "deliberate is at index 14775\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0628,  0.2950, -0.1980,  ...,  0.2585, -0.1097,  0.1239],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for deliberate.\n",
      "deliberating is at index 21614\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1461,  0.0850, -0.3055,  ...,  0.2746,  0.0274,  0.2171],\n",
      "         [ 0.1687,  0.8291,  0.4266,  ..., -0.1742,  0.2603,  0.0939],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for deliberating.\n",
      "delight is at index 13213\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3144,  0.0561, -0.2852,  ...,  0.0119, -0.0582,  0.2998],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for delight.\n",
      "delighted is at index 7808\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1927, -0.0131,  0.1492,  ..., -0.0211, -0.0088,  0.3320],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for delighted.\n",
      "delightful is at index 24897\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0440,  0.4652,  0.2587,  ...,  0.5983, -0.0919,  0.1034],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for delightful.\n",
      "delirious is at index 2424\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [ 3.4273e-01, -4.7777e-01,  1.5855e-01,  ...,  3.4530e-01,\n",
      "           1.2091e-01, -2.0777e-01],\n",
      "         [ 5.0110e-01,  3.2309e-01,  9.7804e-01,  ..., -1.0649e-01,\n",
      "          -6.7823e-02,  7.7963e-01],\n",
      "         [ 3.3982e-02,  1.3871e-01,  2.6086e-01,  ...,  2.0632e-02,\n",
      "          -2.6103e-01, -2.6917e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for delirious.\n",
      "delirium is at index 2424\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [ 3.4273e-01, -4.7777e-01,  1.5855e-01,  ...,  3.4530e-01,\n",
      "           1.2091e-01, -2.0777e-01],\n",
      "         [ 5.0110e-01,  3.2309e-01,  9.7804e-01,  ..., -1.0649e-01,\n",
      "          -6.7823e-02,  7.7963e-01],\n",
      "         [-2.9973e-01, -1.1638e-01,  3.1140e-01,  ..., -4.7391e-02,\n",
      "          -8.5579e-02,  1.8314e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for delirium.\n",
      "delude is at index 2424\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3427, -0.4778,  0.1586,  ...,  0.3453,  0.1209, -0.2078],\n",
      "         [-0.2562,  0.6456, -0.0069,  ..., -0.1257, -0.3054, -0.0778],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for delude.\n",
      "delusional is at index 40160\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2610,  0.2428,  0.1920,  ..., -0.0576,  0.3593, -0.3647],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for delusional.\n",
      "demanding is at index 5783\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2544, -0.0741, -0.4801,  ...,  0.3145, -0.3201, -0.0151],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for demanding.\n",
      "demeaning is at index 4410\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-3.1748e-02,  3.5199e-02,  2.9204e-01,  ...,  2.9833e-01,\n",
      "           1.7455e-01,  6.4771e-02],\n",
      "         [ 4.7673e-01, -5.9472e-01, -5.1142e-01,  ...,  4.0435e-01,\n",
      "          -5.8217e-01,  5.3225e-01],\n",
      "         [-2.3089e-01,  3.7482e-01,  6.6191e-01,  ...,  1.4798e-01,\n",
      "           2.6582e-01,  1.0864e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for demeaning.\n",
      "demented is at index 44202\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2415,  0.1954, -0.0701,  ..., -0.2172,  0.0999, -0.3045],\n",
      "         [-0.1786,  0.2013,  0.4345,  ...,  0.3394, -0.5501,  0.1632],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for demented.\n",
      "demised is at index 4410\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0317,  0.0352,  0.2920,  ...,  0.2983,  0.1746,  0.0648],\n",
      "         [-0.0435, -0.0017,  0.0690,  ..., -0.5014, -0.3110,  0.5179],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for demised.\n",
      "demoralized is at index 36810\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0940, -0.5432,  0.0995,  ..., -0.0922,  0.4552, -0.0572],\n",
      "         [-0.0545,  0.4248,  0.1878,  ...,  0.0940, -0.2454,  0.3326],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for demoralized.\n",
      "demure is at index 4410\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0317,  0.0352,  0.2920,  ...,  0.2983,  0.1746,  0.0648],\n",
      "         [ 0.0432,  0.0270,  0.1464,  ..., -0.1014,  0.2977, -0.1121],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for demure.\n",
      "denied is at index 2296\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1971,  0.0891,  0.4835,  ...,  0.0558,  0.0180, -0.2138],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for denied.\n",
      "denouncing is at index 32439\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1286, -0.5510, -0.4002,  ...,  0.2406, -0.1832, -0.4082],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for denouncing.\n",
      "depleted is at index 26391\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0098,  0.1046,  0.1839,  ..., -0.2689,  0.0509, -0.1000],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for depleted.\n",
      "deplorable is at index 28156\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0266,  0.3875, -0.0796,  ...,  0.5206,  0.0637,  0.2158],\n",
      "         [ 0.1877,  0.9188, -0.3427,  ..., -0.0604, -0.3634,  0.3891],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for deplorable.\n",
      "deprecating is at index 8273\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [ 2.2020e-02,  8.7455e-02,  2.0612e-02,  ..., -6.2628e-02,\n",
      "          -5.8076e-01, -1.7623e-01],\n",
      "         [ 3.8480e-01,  4.5478e-02,  1.1182e-02,  ...,  8.5117e-02,\n",
      "           1.9176e-02, -1.0979e-01],\n",
      "         [ 2.6927e-01,  7.0658e-01,  3.6206e-01,  ..., -1.2090e-01,\n",
      "           2.8401e-01,  1.2105e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for deprecating.\n",
      "depressed is at index 16658\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1043,  0.4198,  0.9454,  ..., -0.0295,  0.2608,  0.0255],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for depressed.\n",
      "depression is at index 6943\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1308, -0.1117,  0.5238,  ...,  0.0009,  0.5553,  0.6355],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for depression.\n",
      "deprived is at index 22632\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1088, -0.5459,  0.3253,  ...,  0.4160, -0.0225, -0.4051],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for deprived.\n",
      "deranged is at index 1935\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1514,  0.1820,  0.2127,  ...,  0.3318, -0.0602,  0.1220],\n",
      "         [ 0.2301,  0.7065, -0.0855,  ..., -0.0077, -0.5560,  0.0503],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for deranged.\n",
      "derision is at index 1935\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1514,  0.1820,  0.2127,  ...,  0.3318, -0.0602,  0.1220],\n",
      "         [-0.1346,  0.4351,  0.1628,  ..., -0.0209, -0.0693,  0.3694],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for derision.\n",
      "derisive is at index 1935\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1514,  0.1820,  0.2127,  ...,  0.3318, -0.0602,  0.1220],\n",
      "         [-0.1359,  0.9133, -0.0822,  ...,  0.0316, -0.1752,  0.6281],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for derisive.\n",
      "derogatory is at index 30971\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0403,  0.2612,  0.2243,  ..., -0.0543,  0.0073, -0.0769],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for derogatory.\n",
      "desire is at index 4724\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.5540,  0.0896,  0.1191,  ..., -0.0137,  0.3135,  0.1619],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for desire.\n",
      "desiring is at index 2694\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1661, -0.2317,  0.4410,  ...,  0.6386, -0.1104,  0.4046],\n",
      "         [ 0.4555,  0.2160,  0.0374,  ..., -0.3311,  0.5541,  0.5424],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for desiring.\n",
      "desirous is at index 2694\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-1.6607e-01, -2.3170e-01,  4.4099e-01,  ...,  6.3864e-01,\n",
      "          -1.1040e-01,  4.0461e-01],\n",
      "         [ 5.0110e-01,  3.2309e-01,  9.7804e-01,  ..., -1.0649e-01,\n",
      "          -6.7823e-02,  7.7963e-01],\n",
      "         [ 6.2312e-03, -3.8450e-01,  1.2523e-01,  ...,  3.1559e-01,\n",
      "          -3.8559e-01, -2.4341e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for desirous.\n",
      "desolate is at index 43177\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1292,  0.1821,  0.2823,  ..., -0.0237,  0.3006,  0.0495],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for desolate.\n",
      "despair is at index 21508\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0746,  0.0875,  0.5930,  ...,  0.1017,  0.1605,  0.6198],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for despair.\n",
      "despaired is at index 2694\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1661, -0.2317,  0.4410,  ...,  0.6386, -0.1104,  0.4046],\n",
      "         [ 0.0524,  0.1843, -0.1839,  ...,  0.2928,  0.1484, -0.0784],\n",
      "         [ 0.4903,  0.4341, -0.0691,  ..., -0.3083, -0.0629,  0.5300],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for despaired.\n",
      "despairing is at index 21508\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0746,  0.0875,  0.5930,  ...,  0.1017,  0.1605,  0.6198],\n",
      "         [ 0.1383,  0.3796,  0.1368,  ...,  0.2405, -0.3453,  0.0233],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for despairing.\n",
      "desperate is at index 7764\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1164, -0.1376,  0.0759,  ...,  0.1048,  0.1233,  0.0230],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for desperate.\n",
      "desperation is at index 24278\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3741,  0.0782,  0.2228,  ..., -0.0703,  0.3374,  0.3354],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for desperation.\n",
      "despise is at index 43255\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0554,  0.2620,  0.0306,  ..., -0.1007,  0.4042,  0.2346],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for despise.\n",
      "despondent is at index 18690\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0799,  0.4230,  0.3025,  ..., -0.1565,  0.2977,  0.0638],\n",
      "         [ 0.0398,  0.5937,  0.3975,  ..., -0.5871, -0.0086,  0.5790],\n",
      "         [ 0.1843, -0.3705,  0.2203,  ...,  0.0498,  0.2812,  0.6431],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for despondent.\n",
      "destitute is at index 15357\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1085, -0.0600,  0.1244,  ..., -0.1373,  0.2709,  0.3605],\n",
      "         [-0.0537, -0.0219,  0.0844,  ..., -0.1766,  0.1595, -0.1337],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for destitute.\n",
      "destroyed is at index 4957\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0538,  0.1641,  0.3012,  ..., -0.0370, -0.2510, -0.0759],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for destroyed.\n",
      "detached is at index 27687\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2097,  0.4136,  0.3000,  ..., -0.0561, -0.1253,  0.1727],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for detached.\n",
      "determination is at index 8964\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.4418,  0.3997,  0.2641,  ...,  0.0040,  0.2246,  0.4982],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for determination.\n",
      "determined is at index 3030\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0587,  0.1797,  0.5565,  ..., -0.1416,  0.0070,  0.3323],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for determined.\n",
      "determining is at index 13684\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0162,  0.2561,  0.3616,  ..., -0.0377,  0.3658,  0.3918],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for determining.\n",
      "deterred is at index 10922\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2825, -0.0986, -0.0640,  ..., -0.0526,  0.3101,  0.3337],\n",
      "         [ 0.3309,  0.2068, -0.1227,  ...,  0.1026, -0.0409,  0.0010],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for deterred.\n",
      "detest is at index 6769\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1482,  0.3707, -0.2071,  ...,  0.2671, -0.2393,  0.2844],\n",
      "         [-0.0121, -0.0101,  0.1906,  ..., -0.3980, -0.3205,  0.6850],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for detest.\n",
      "detestable is at index 6769\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [ 1.4823e-01,  3.7071e-01, -2.0706e-01,  ...,  2.6709e-01,\n",
      "          -2.3933e-01,  2.8435e-01],\n",
      "         [-1.2120e-02, -1.0135e-02,  1.9057e-01,  ..., -3.9804e-01,\n",
      "          -3.2055e-01,  6.8503e-01],\n",
      "         [ 5.6745e-01, -2.2070e-01,  9.9365e-02,  ...,  1.1182e-01,\n",
      "           1.1322e-01,  2.3561e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for detestable.\n",
      "detesting is at index 6769\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1482,  0.3707, -0.2071,  ...,  0.2671, -0.2393,  0.2844],\n",
      "         [ 0.2469,  0.3832,  0.0079,  ..., -0.0837, -0.4373,  0.2286],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for detesting.\n",
      "detriment is at index 31969\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0225,  0.5292,  0.2689,  ..., -0.0578,  0.4070,  0.4023],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for detriment.\n",
      "devastated is at index 11521\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0371,  0.3373,  0.2589,  ..., -0.0133, -0.2257,  0.0170],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for devastated.\n",
      "deviant is at index 8709\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0133,  0.0524, -0.4125,  ...,  0.3605, -0.8404,  0.0469],\n",
      "         [-0.2093,  0.1216, -0.6925,  ..., -0.4027, -0.2113,  0.1260],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for deviant.\n",
      "devilish is at index 22406\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2032,  0.1056,  0.1680,  ..., -0.0435, -0.3510, -0.0500],\n",
      "         [ 0.4075, -0.2999,  0.2436,  ..., -0.0861, -0.1961,  0.0055],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for devilish.\n",
      "devious is at index 263\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2988, -0.3032,  0.0028,  ...,  0.0924, -0.2585,  0.7741],\n",
      "         [ 0.1044,  0.3820, -0.2167,  ..., -0.1594, -0.0214,  0.0120],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for devious.\n",
      "devising is at index 8709\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0133,  0.0524, -0.4125,  ...,  0.3605, -0.8404,  0.0469],\n",
      "         [-0.3147,  0.1039, -0.1990,  ..., -0.6578,  0.0103,  0.4787],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for devising.\n",
      "diffident is at index 25871\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2349,  0.2790,  0.4572,  ..., -0.1042, -0.1111,  0.2249],\n",
      "         [-0.1917,  0.8230,  0.1108,  ..., -0.5471, -0.1703,  0.0933],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for diffident.\n",
      "dilatory is at index 14632\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1616, -0.4980,  0.3330,  ...,  0.2153,  0.4812, -0.4003],\n",
      "         [-0.2759, -0.2099, -0.0074,  ...,  0.0886, -0.0460,  0.0378],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for dilatory.\n",
      "diligent is at index 33721\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3979,  0.0725,  0.1111,  ..., -0.0104,  0.0287,  0.3070],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for diligent.\n",
      "dimwitted is at index 14548\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [ 5.6088e-01, -5.1344e-01,  1.3725e-01,  ...,  2.7938e-01,\n",
      "          -5.1245e-01, -5.4531e-01],\n",
      "         [ 2.7159e-01, -5.5709e-02,  4.2908e-01,  ...,  1.5926e-01,\n",
      "           5.1120e-02, -3.9098e-03],\n",
      "         [-1.9892e-02,  7.0342e-01, -1.6611e-01,  ..., -3.6776e-01,\n",
      "          -1.4878e-01, -2.1853e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for dimwitted.\n",
      "dire is at index 10697\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0160,  0.0864, -0.3306,  ...,  0.1895,  0.3889,  0.1337],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for dire.\n",
      "disagree is at index 11967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0965,  0.2082,  0.1202,  ...,  0.2404, -0.0855, -0.3239],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for disagree.\n",
      "disagreeable is at index 11967\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0965,  0.2082,  0.1202,  ...,  0.2404, -0.0855, -0.3239],\n",
      "         [ 0.4713, -0.1066,  0.1604,  ...,  0.0613,  0.0895,  0.2098],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for disagreeable.\n",
      "disagreement is at index 20628\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2220,  0.1753, -0.0644,  ...,  0.0934, -0.1772, -0.2297],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for disagreement.\n",
      "disappointed is at index 5779\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0869, -0.5256,  0.2140,  ..., -0.1329, -0.0580, -0.0352],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for disappointed.\n",
      "disappointing is at index 6770\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1612, -0.0769, -0.2211,  ..., -0.1008, -0.1174, -0.1724],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for disappointing.\n",
      "disappointment is at index 10208\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3128, -0.1971, -0.2330,  ..., -0.2212,  0.3759, -0.0870],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for disappointment.\n",
      "disapproval is at index 32129\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1408,  0.0374, -0.2351,  ..., -0.0615,  0.3967, -0.0818],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for disapproval.\n",
      "disapproving is at index 36631\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0826,  0.4486, -0.3041,  ...,  0.2033,  0.3068, -0.2375],\n",
      "         [ 0.0437, -0.0243,  0.4522,  ...,  0.3294, -0.0960,  0.0235],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for disapproving.\n",
      "disbelief is at index 26440\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0769,  0.1691,  0.3074,  ..., -0.1096,  0.4860,  0.1497],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for disbelief.\n",
      "disbelieve is at index 45668\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1214, -0.4237, -0.0913,  ...,  0.2737, -0.1239, -0.4333],\n",
      "         [ 0.5093,  0.5753, -0.1677,  ...,  0.0549,  0.2756,  0.1786],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for disbelieve.\n",
      "disbelieving is at index 45668\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1214, -0.4237, -0.0913,  ...,  0.2737, -0.1239, -0.4333],\n",
      "         [-0.0295,  0.6889, -0.3564,  ...,  0.1062,  0.4223,  0.0153],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for disbelieving.\n",
      "discerning is at index 9553\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1015,  0.0373, -0.1755,  ...,  0.2175, -0.5680, -0.7527],\n",
      "         [-0.2479,  0.2286,  0.2796,  ...,  0.1247, -0.2775,  0.5368],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for discerning.\n",
      "discombobulated is at index 2982\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2225,  0.5796, -0.1104,  ...,  0.3329, -0.0538, -0.1306],\n",
      "         [ 0.2085,  0.1350,  0.0557,  ...,  0.1158, -0.1350, -0.1517],\n",
      "         [-0.1679,  0.7024,  0.6095,  ..., -0.2266,  0.2623, -0.0179],\n",
      "         [ 0.0797,  0.1301,  0.0448,  ...,  0.1112,  0.3241,  0.3119],\n",
      "         [ 0.2760, -0.1979, -0.1075,  ...,  0.4037,  0.0583,  0.1964]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for discombobulated.\n",
      "discomfited is at index 2982\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2225,  0.5796, -0.1104,  ...,  0.3329, -0.0538, -0.1306],\n",
      "         [-0.1839,  0.5192, -0.1258,  ..., -0.2125, -0.4305,  0.3751],\n",
      "         [ 0.0906,  0.0777,  0.0721,  ...,  0.1381,  0.1165,  0.4367],\n",
      "         [ 0.5275,  0.7351,  0.0168,  ...,  0.0540,  0.2895,  0.1181],\n",
      "         [ 0.2760, -0.1979, -0.1075,  ...,  0.4037,  0.0583,  0.1964]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for discomfited.\n",
      "discomfort is at index 19535\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0875,  0.0442,  0.7704,  ...,  0.0698, -0.0986,  0.3503],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for discomfort.\n",
      "discomforted is at index 19535\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0875,  0.0442,  0.7704,  ...,  0.0698, -0.0986,  0.3503],\n",
      "         [-0.1786,  0.2013,  0.4345,  ...,  0.3394, -0.5501,  0.1632],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for discomforted.\n",
      "disconcerted is at index 2982\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2225,  0.5796, -0.1104,  ...,  0.3329, -0.0538, -0.1306],\n",
      "         [ 0.0254,  0.0988,  0.0155,  ..., -0.2149, -0.1125, -0.2247],\n",
      "         [-0.0763,  0.0823,  0.3715,  ...,  0.3918, -0.5245,  0.1909],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for disconcerted.\n",
      "disconnected is at index 30005\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0571,  0.2683,  0.3087,  ...,  0.0762, -0.0081, -0.0324],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for disconnected.\n",
      "disconsolate is at index 9553\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-1.0145e-01,  3.7318e-02, -1.7546e-01,  ...,  2.1745e-01,\n",
      "          -5.6796e-01, -7.5273e-01],\n",
      "         [ 4.8075e-02,  4.3510e-02,  4.5876e-01,  ..., -1.2494e-01,\n",
      "           1.8034e-01, -7.3815e-02],\n",
      "         [ 5.8345e-01, -2.5581e-01, -9.4684e-02,  ...,  8.1505e-02,\n",
      "          -2.6278e-02, -3.5455e-02],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for disconsolate.\n",
      "discontent is at index 27478\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0673, -0.0634,  0.1772,  ..., -0.1135,  0.4727,  0.1716],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for discontent.\n",
      "discontented is at index 47772\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0462, -0.4840,  0.1500,  ..., -0.4067, -0.0410, -0.2838],\n",
      "         [-0.2727,  0.4556,  0.2024,  ...,  0.3433,  0.0765, -0.1249],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for discontented.\n",
      "discounted is at index 17533\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1081,  0.2090,  0.1605,  ...,  0.0510, -0.0355,  0.2487],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for discounted.\n",
      "discouraged is at index 25788\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1414, -0.1643,  0.9563,  ...,  0.4809, -0.1101, -0.0430],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for discouraged.\n",
      "discovery is at index 6953\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1191, -0.0033,  0.1156,  ...,  0.0090,  0.1130,  0.1095],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for discovery.\n",
      "discriminating is at index 38303\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0108,  0.1873,  0.1958,  ..., -0.0876,  0.1542,  0.4256],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for discriminating.\n",
      "discussed is at index 3373\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3913,  0.5264,  0.1577,  ..., -0.2502, -0.1875,  0.2510],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for discussed.\n",
      "disdain is at index 29512\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2311, -0.4307,  0.1882,  ...,  0.1382,  0.5093,  0.2553],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for disdain.\n",
      "disdained is at index 2982\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2225,  0.5796, -0.1104,  ...,  0.3329, -0.0538, -0.1306],\n",
      "         [-0.0445, -0.0307, -0.1699,  ...,  0.1606, -0.2926,  0.5322],\n",
      "         [ 0.1512,  0.4171, -0.2995,  ..., -0.0632, -0.3423, -0.0515],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for disdained.\n",
      "disdainful is at index 29512\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2311, -0.4307,  0.1882,  ...,  0.1382,  0.5093,  0.2553],\n",
      "         [ 0.3025,  0.1036, -0.3624,  ...,  0.1536, -0.4041, -0.2558],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for disdainful.\n",
      "disdainfully is at index 29512\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2311, -0.4307,  0.1882,  ...,  0.1382,  0.5093,  0.2553],\n",
      "         [-0.0888,  0.0999, -0.3792,  ...,  0.0177, -0.7239,  0.2116],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for disdainfully.\n",
      "disenchanted is at index 2982\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2225,  0.5796, -0.1104,  ...,  0.3329, -0.0538, -0.1306],\n",
      "         [ 0.6426, -0.0644,  0.0192,  ..., -0.4186, -0.0624,  0.4157],\n",
      "         [-0.1997, -0.2726, -0.1253,  ..., -0.5398,  0.1292,  0.1047],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for disenchanted.\n",
      "disengaged is at index 35170\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1256,  0.0331, -0.1285,  ..., -0.0955, -0.5187,  0.2849],\n",
      "         [-0.2992,  0.4179,  0.2010,  ..., -0.2848,  0.3272,  0.2091],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for disengaged.\n",
      "disgraced is at index 25425\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3438, -0.6391, -0.2889,  ..., -0.2097, -0.2842,  0.0349],\n",
      "         [ 0.0523,  0.2370, -0.2415,  ..., -0.3952, -0.5525,  0.1667],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for disgraced.\n",
      "disgruntled is at index 29412\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1521, -0.1930,  0.1697,  ..., -0.1004, -0.0339,  0.1941],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for disgruntled.\n",
      "disgruntlement is at index 25425\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3438, -0.6391, -0.2889,  ..., -0.2097, -0.2842,  0.0349],\n",
      "         [ 0.0808, -0.2141, -0.1046,  ..., -0.4486, -0.0924,  0.6040],\n",
      "         [-0.0965, -0.4661, -0.2343,  ...,  0.0776, -0.2298, -0.1936],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for disgruntlement.\n",
      "disgust is at index 30883\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1964, -0.2400,  0.0568,  ..., -0.0711,  0.0395,  0.4192],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for disgust.\n",
      "disgusted is at index 32759\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0982, -0.3758,  0.1873,  ..., -0.2205, -0.0786,  0.2975],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for disgusted.\n",
      "disgustedly is at index 32759\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0982, -0.3758,  0.1873,  ..., -0.2205, -0.0786,  0.2975],\n",
      "         [ 0.3543,  0.3169,  0.0401,  ..., -0.1069, -0.5598,  0.1301],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for disgustedly.\n",
      "disgusting is at index 21096\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3935, -0.1801, -0.0104,  ...,  0.5898, -0.3600, -0.2896],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for disgusting.\n",
      "disheartened is at index 2982\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-2.2246e-01,  5.7963e-01, -1.1038e-01,  ...,  3.3289e-01,\n",
      "          -5.3811e-02, -1.3058e-01],\n",
      "         [-2.0376e-01, -5.3116e-02,  1.7101e-01,  ..., -7.8103e-01,\n",
      "           4.3077e-01,  6.2287e-01],\n",
      "         [ 2.6623e-02, -3.7800e-01,  6.1400e-01,  ..., -2.6862e-02,\n",
      "          -2.5108e-01,  6.7815e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for disheartened.\n",
      "dishonest is at index 27820\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2132,  0.3856,  0.0124,  ..., -0.2029, -0.1547, -0.1748],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for dishonest.\n",
      "disillusioned is at index 33447\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0542, -0.4733,  0.0458,  ..., -0.2724,  0.3860, -0.0456],\n",
      "         [-0.1786,  0.2013,  0.4345,  ...,  0.3394, -0.5501,  0.1632],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for disillusioned.\n",
      "disinclined is at index 2982\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2225,  0.5796, -0.1104,  ...,  0.3329, -0.0538, -0.1306],\n",
      "         [ 0.2218,  0.0016,  0.2288,  ..., -0.3148, -0.1183,  0.2324],\n",
      "         [-0.1132, -0.1484, -0.0023,  ..., -0.0553, -0.4033, -0.3631],\n",
      "         [ 0.2769,  0.3843,  0.2157,  ..., -0.2105,  0.1265,  0.6264],\n",
      "         [ 0.2760, -0.1979, -0.1075,  ...,  0.4037,  0.0583,  0.1964]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for disinclined.\n",
      "disingenuous is at index 39622\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1482, -0.2260,  0.2184,  ...,  0.0356,  0.3975, -0.5090],\n",
      "         [ 0.1306, -0.0317,  0.2685,  ..., -0.0785, -0.3928, -0.3087],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for disingenuous.\n",
      "disinterest is at index 2982\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2225,  0.5796, -0.1104,  ...,  0.3329, -0.0538, -0.1306],\n",
      "         [ 0.0546,  0.6169,  0.0298,  ..., -0.7843, -0.0349,  0.2485],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for disinterest.\n",
      "disinterested is at index 2982\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2225,  0.5796, -0.1104,  ...,  0.3329, -0.0538, -0.1306],\n",
      "         [ 0.1845,  0.6920, -0.1450,  ..., -0.8040, -0.1258,  0.3181],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for disinterested.\n",
      "disjointed is at index 2982\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-2.2246e-01,  5.7963e-01, -1.1038e-01,  ...,  3.3289e-01,\n",
      "          -5.3811e-02, -1.3058e-01],\n",
      "         [ 8.9618e-02,  2.8542e-01, -1.1514e-01,  ..., -3.1937e-01,\n",
      "           1.4846e-01,  2.1588e-01],\n",
      "         [ 5.0971e-01,  4.1293e-01,  3.3559e-01,  ..., -9.4825e-01,\n",
      "          -1.5695e-01, -3.9538e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for disjointed.\n",
      "dislike is at index 28101\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.4741,  0.3228, -0.0077,  ..., -0.0335,  0.2700,  0.0567],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for dislike.\n",
      "disliked is at index 40891\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0122,  0.6327,  0.2721,  ..., -0.0073,  0.0675, -0.2314],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for disliked.\n",
      "disliking is at index 19131\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2406, -0.2004, -0.0282,  ..., -0.1716,  0.1045, -0.2753],\n",
      "         [ 0.0105,  0.6838, -0.0708,  ...,  0.1395,  0.1709,  0.1646],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for disliking.\n",
      "dismal is at index 23446\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3059,  0.1122, -0.2983,  ..., -0.0114,  0.1190,  0.2418],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for dismal.\n",
      "disman is at index 2982\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2225,  0.5796, -0.1104,  ...,  0.3329, -0.0538, -0.1306],\n",
      "         [ 0.2270,  0.0261,  0.2474,  ...,  0.0206,  0.4449,  0.1589],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for disman.\n",
      "dismay is at index 22135\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3260, -0.2413,  0.1342,  ..., -0.0351,  0.4360,  0.0821],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for dismay.\n",
      "dismayed is at index 22135\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3260, -0.2413,  0.1342,  ..., -0.0351,  0.4360,  0.0821],\n",
      "         [-0.1786,  0.2013,  0.4345,  ...,  0.3394, -0.5501,  0.1632],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for dismayed.\n",
      "dismissive is at index 37890\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0009,  0.1288,  0.0240,  ...,  0.1634,  0.0256,  0.2622],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for dismissive.\n",
      "disobedient is at index 43738\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1051,  0.2598, -0.1630,  ..., -0.0387,  0.0041,  0.1460],\n",
      "         [-0.3959,  0.6773, -0.1968,  ..., -0.4126,  0.0171,  0.3206],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for disobedient.\n",
      "disorderly is at index 23547\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2300,  0.3582, -0.5034,  ..., -0.3117, -0.1090, -0.2899],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for disorderly.\n",
      "disoriented is at index 2982\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2225,  0.5796, -0.1104,  ...,  0.3329, -0.0538, -0.1306],\n",
      "         [ 0.2596, -0.0359, -0.0596,  ..., -0.2759,  0.1256,  0.2478],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for disoriented.\n",
      "dispair is at index 11734\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0338,  0.9168,  0.2401,  ...,  0.4183, -0.5021,  0.8221],\n",
      "         [ 0.0889,  0.1041,  0.6073,  ..., -0.5907, -0.2013,  0.2147],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for dispair.\n",
      "disparaging is at index 24331\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1240,  0.0369,  0.0602,  ...,  0.1347, -0.2096,  0.3812],\n",
      "         [-0.1308,  0.3891,  0.3533,  ..., -0.3185,  0.1359,  0.3274],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for disparaging.\n",
      "dispassionate is at index 11734\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [ 3.3761e-02,  9.1682e-01,  2.4005e-01,  ...,  4.1827e-01,\n",
      "          -5.0214e-01,  8.2214e-01],\n",
      "         [ 1.7725e-01,  1.9135e-01,  6.6629e-01,  ...,  2.6275e-01,\n",
      "           1.9131e-01, -9.0712e-02],\n",
      "         [-2.4794e-01,  1.6602e-01, -1.5691e-01,  ...,  2.5994e-01,\n",
      "          -1.2617e-01,  3.0176e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for dispassionate.\n",
      "dispirited is at index 2982\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-2.2246e-01,  5.7963e-01, -1.1038e-01,  ...,  3.3289e-01,\n",
      "          -5.3811e-02, -1.3058e-01],\n",
      "         [ 5.0037e-01,  4.3663e-01,  3.6834e-01,  ..., -9.9128e-02,\n",
      "           1.0822e-01, -5.5525e-02],\n",
      "         [ 5.0011e-01,  7.6923e-01,  4.9628e-02,  ...,  1.1828e-02,\n",
      "           2.1502e-01,  1.0322e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for dispirited.\n",
      "dispiritedness is at index 2982\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2225,  0.5796, -0.1104,  ...,  0.3329, -0.0538, -0.1306],\n",
      "         [ 0.5004,  0.4366,  0.3683,  ..., -0.0991,  0.1082, -0.0555],\n",
      "         [ 0.5001,  0.7692,  0.0496,  ...,  0.0118,  0.2150,  0.1032],\n",
      "         [ 0.0038,  0.0321,  0.0331,  ..., -0.3626,  0.1786,  0.0489],\n",
      "         [ 0.2760, -0.1979, -0.1075,  ...,  0.4037,  0.0583,  0.1964]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for dispiritedness.\n",
      "displeased is at index 43709\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3973,  0.0521, -0.1415,  ..., -0.1870, -0.1378,  0.0938],\n",
      "         [-0.3413,  0.2097, -0.0392,  ..., -0.4061,  0.2151, -0.1586],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for displeased.\n",
      "displeasure is at index 30201\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0563,  0.1436,  0.0498,  ..., -0.0369,  0.5050,  0.1733],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for displeasure.\n",
      "disquiet is at index 2982\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2225,  0.5796, -0.1104,  ...,  0.3329, -0.0538, -0.1306],\n",
      "         [ 0.0660,  0.0401,  0.0242,  ..., -0.3747, -0.2477,  0.1395],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for disquiet.\n",
      "disquieted is at index 2982\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2225,  0.5796, -0.1104,  ...,  0.3329, -0.0538, -0.1306],\n",
      "         [ 0.0660,  0.0401,  0.0242,  ..., -0.3747, -0.2477,  0.1395],\n",
      "         [-0.0763,  0.0823,  0.3715,  ...,  0.3918, -0.5245,  0.1909],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for disquieted.\n",
      "disregard is at index 21034\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.4407, -0.3571, -0.0997,  ..., -0.1994,  0.1398,  0.2760],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for disregard.\n",
      "disrespectful is at index 26401\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0774, -0.1866, -0.0548,  ..., -0.0576, -0.0834, -0.0255],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for disrespectful.\n",
      "disrupted is at index 15902\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1780,  0.2613, -0.2510,  ..., -0.1423,  0.1998, -0.0034],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for disrupted.\n",
      "disruptive is at index 17561\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1836,  0.4754, -0.4431,  ...,  0.0312, -0.0478,  0.3172],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for disruptive.\n",
      "dissatisfaction is at index 31776\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0130, -0.0127,  0.0262,  ..., -0.1485,  0.1862, -0.0082],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for dissatisfaction.\n",
      "dissatisfied is at index 37278\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1725,  0.0808,  0.4095,  ..., -0.1934, -0.3126, -0.3779],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for dissatisfied.\n",
      "dissatisfy is at index 48830\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3994,  0.1075,  0.0012,  ..., -0.0910,  0.1962,  0.1039],\n",
      "         [ 0.1311, -0.1715,  0.0534,  ..., -0.0509, -0.4687, -0.2923],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for dissatisfy.\n",
      "dissecting is at index 33562\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.4403,  0.1220,  0.1779,  ...,  0.0916, -0.5997,  0.2539],\n",
      "         [ 0.1383,  0.3796,  0.1368,  ...,  0.2405, -0.3453,  0.0233],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for dissecting.\n",
      "dissociated is at index 14863\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1921,  0.2861, -0.3537,  ...,  0.2633,  0.2223, -0.6695],\n",
      "         [ 0.0165,  0.7947, -0.3843,  ..., -0.2629, -0.2333, -0.2426],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for dissociated.\n",
      "dissonant is at index 43162\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3359,  0.0496,  0.1772,  ..., -0.0953,  0.4192, -0.3267],\n",
      "         [-0.0978, -0.6161,  0.4288,  ..., -0.2426,  0.1850, -0.0844],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for dissonant.\n",
      "distain is at index 7018\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3259,  0.3390,  0.0177,  ...,  0.1033,  0.2622, -0.0472],\n",
      "         [ 0.3861, -0.0435,  0.1063,  ..., -0.2341, -0.6253,  0.3723],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for distain.\n",
      "distant is at index 13258\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0433, -0.1754, -0.1959,  ..., -0.2196,  0.0852,  0.2338],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for distant.\n",
      "distaste is at index 7018\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3259,  0.3390,  0.0177,  ...,  0.1033,  0.2622, -0.0472],\n",
      "         [-0.0452,  0.0988,  0.3512,  ...,  0.2760,  0.6586,  0.5190],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for distaste.\n",
      "distasteful is at index 7018\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-3.2591e-01,  3.3905e-01,  1.7685e-02,  ...,  1.0332e-01,\n",
      "           2.6220e-01, -4.7178e-02],\n",
      "         [ 7.0757e-02,  1.1254e-01,  4.9600e-01,  ..., -3.6258e-01,\n",
      "           2.0984e-01,  3.9677e-01],\n",
      "         [ 3.0977e-01,  3.5881e-01,  3.9610e-02,  ...,  4.6165e-01,\n",
      "          -6.6985e-01,  1.2103e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for distasteful.\n",
      "distracted is at index 16573\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1966,  0.1527,  0.2595,  ..., -0.1007, -0.0583, -0.1339],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for distracted.\n",
      "distraught is at index 30719\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0512,  0.5371,  0.2230,  ..., -0.1527, -0.2097,  0.4431],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for distraught.\n",
      "distress is at index 13250\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1866,  0.6054,  0.6061,  ..., -0.2777,  0.6705,  0.3388],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for distress.\n",
      "distressed is at index 21460\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.4815,  0.4098,  0.3702,  ..., -0.2021,  0.0484,  0.1181],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for distressed.\n",
      "distressing is at index 7018\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3259,  0.3390,  0.0177,  ...,  0.1033,  0.2622, -0.0472],\n",
      "         [ 0.5598,  0.4052, -0.1791,  ..., -0.3968,  0.0101,  0.0946],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for distressing.\n",
      "distrust is at index 27948\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1859, -0.1606,  0.0953,  ..., -0.0350, -0.1444,  0.0447],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for distrust.\n",
      "distrustful is at index 27948\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1859, -0.1606,  0.0953,  ..., -0.0350, -0.1444,  0.0447],\n",
      "         [ 0.3025,  0.1036, -0.3624,  ...,  0.1536, -0.4041, -0.2558],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for distrustful.\n",
      "distrusting is at index 27948\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1859, -0.1606,  0.0953,  ..., -0.0350, -0.1444,  0.0447],\n",
      "         [ 0.1383,  0.3796,  0.1368,  ...,  0.2405, -0.3453,  0.0233],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for distrusting.\n",
      "disturbed is at index 22938\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3130,  0.4163,  0.3545,  ..., -0.0989,  0.4240, -0.1160],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for disturbed.\n",
      "diverted is at index 19070\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0729,  0.1255,  0.0155,  ...,  0.0151,  0.0396,  0.0638],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for diverted.\n",
      "dodgy is at index 25744\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3473, -0.3957,  0.0606,  ..., -0.0842, -0.0215,  0.3471],\n",
      "         [-0.2171,  0.2084, -0.0842,  ..., -0.1712, -0.4832,  0.0053],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for dodgy.\n",
      "doleful is at index 109\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1513, -0.1517,  0.3122,  ...,  0.2894, -0.3602,  0.3092],\n",
      "         [-0.2066,  0.0911,  0.1720,  ...,  0.1381,  0.3392,  0.2400],\n",
      "         [ 0.3990, -0.0088, -0.4213,  ...,  0.2034, -0.3800, -0.2293],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for doleful.\n",
      "doltish is at index 385\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1079,  0.0539,  0.1122,  ...,  0.3283,  0.0679,  0.1026],\n",
      "         [-0.0342,  0.6281,  0.1067,  ...,  0.2093,  0.1461,  0.2590],\n",
      "         [ 0.5003, -0.4079,  0.1863,  ..., -0.0380, -0.1729,  0.0309],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for doltish.\n",
      "dominant is at index 7353\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1843,  0.4857,  0.0695,  ..., -0.2506,  0.0783,  0.4579],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for dominant.\n",
      "dominating is at index 17349\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2794,  0.2860, -0.0474,  ..., -0.0791,  0.0978,  0.3357],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for dominating.\n",
      "domineering is at index 13567\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2610, -0.0138,  0.1196,  ...,  0.0227,  0.0786, -0.4471],\n",
      "         [-0.0109,  0.1890,  0.4828,  ..., -0.0399, -0.2730,  0.3625],\n",
      "         [ 0.3281,  0.2076, -0.0778,  ...,  0.5370, -0.2579,  0.3748],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for domineering.\n",
      "done is at index 626\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0841,  0.1388,  0.4178,  ...,  0.1117, -0.7042, -0.1404],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for done.\n",
      "doomed is at index 23326\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0141, -0.0558,  0.1778,  ...,  0.6162,  0.0453, -0.0155],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for doomed.\n",
      "dopey is at index 32331\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3499,  0.2946,  0.1277,  ..., -0.2086,  0.1980, -0.3674],\n",
      "         [ 0.2900,  0.2699,  0.0942,  ..., -0.2311, -0.6692,  0.4580],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for dopey.\n",
      "doting is at index 385\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1079,  0.0539,  0.1122,  ...,  0.3283,  0.0679,  0.1026],\n",
      "         [-0.2703,  0.3502,  0.1611,  ...,  0.4540,  0.0623,  0.2554],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for doting.\n",
      "doubt is at index 2980\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1886,  0.0301,  0.2942,  ...,  0.0319,  0.0597,  0.2783],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for doubt.\n",
      "doubter is at index 26463\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3567,  0.0852,  0.0741,  ..., -0.0333,  0.3652,  0.0060],\n",
      "         [-0.2654,  0.5443,  0.2868,  ...,  0.2839,  0.3104,  0.2832],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for doubter.\n",
      "doubtful is at index 26645\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0342,  0.0027,  0.5849,  ...,  0.4846,  0.0428, -0.0455],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for doubtful.\n",
      "doubtfully is at index 2980\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1886,  0.0301,  0.2942,  ...,  0.0319,  0.0597,  0.2783],\n",
      "         [-0.0888,  0.0999, -0.3792,  ...,  0.0177, -0.7239,  0.2116],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for doubtfully.\n",
      "doubtfulness is at index 2980\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1886,  0.0301,  0.2942,  ...,  0.0319,  0.0597,  0.2783],\n",
      "         [-0.2371,  0.1973, -0.2739,  ...,  0.0637,  0.1708,  0.2685],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for doubtfulness.\n",
      "doubting is at index 26463\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3567,  0.0852,  0.0741,  ..., -0.0333,  0.3652,  0.0060],\n",
      "         [-0.0710,  0.1900,  0.8213,  ...,  0.2001,  0.0973,  0.1731],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for doubting.\n",
      "dour is at index 385\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1079,  0.0539,  0.1122,  ...,  0.3283,  0.0679,  0.1026],\n",
      "         [ 0.0845, -0.3015, -0.0931,  ...,  0.0886,  0.2216, -0.1075],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for dour.\n",
      "down is at index 159\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2128, -0.2031,  0.5623,  ...,  0.3336, -0.4724,  0.2635],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for down.\n",
      "downcast is at index 159\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2128, -0.2031,  0.5623,  ...,  0.3336, -0.4724,  0.2635],\n",
      "         [-0.1427, -0.1389, -0.0756,  ..., -0.1416,  0.3128,  0.2756],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for downcast.\n",
      "downhearted is at index 159\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2128, -0.2031,  0.5623,  ...,  0.3336, -0.4724,  0.2635],\n",
      "         [-0.1408,  0.2934, -0.1141,  ...,  0.0744,  0.0680,  0.7601],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for downhearted.\n",
      "downheartedness is at index 159\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [ 2.1281e-01, -2.0310e-01,  5.6233e-01,  ...,  3.3357e-01,\n",
      "          -4.7236e-01,  2.6352e-01],\n",
      "         [-1.4082e-01,  2.9338e-01, -1.1410e-01,  ...,  7.4373e-02,\n",
      "           6.7973e-02,  7.6010e-01],\n",
      "         [-2.6148e-02,  6.4814e-02,  6.6042e-02,  ..., -4.0375e-01,\n",
      "           1.0154e-01,  3.3071e-02],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for downheartedness.\n",
      "downtrodden is at index 29407\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1361,  0.1208,  0.5042,  ..., -0.0322, -0.1126,  0.1923],\n",
      "         [ 0.2338,  0.4071,  0.3186,  ..., -0.1618, -0.6183, -0.0143],\n",
      "         [-0.2312, -0.1769,  0.0816,  ..., -0.3049, -0.2974,  0.3303],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for downtrodden.\n",
      "dozing is at index 109\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1513, -0.1517,  0.3122,  ...,  0.2894, -0.3602,  0.3092],\n",
      "         [-0.2299,  0.4548, -0.2874,  ..., -0.4790,  0.0298,  0.5656],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for dozing.\n",
      "drained is at index 23544\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0513, -0.2338,  0.7300,  ..., -0.2346, -0.3843, -0.3831],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for drained.\n",
      "dramatic is at index 5386\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2828,  0.5151,  0.1781,  ...,  0.3397,  0.1555,  0.0416],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for dramatic.\n",
      "drawn is at index 4777\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0020,  0.0059,  0.0382,  ..., -0.0755,  0.0932,  0.1778],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for drawn.\n",
      "dread is at index 24506\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3980,  0.1723,  0.6149,  ..., -0.3433,  0.0656,  0.0125],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for dread.\n",
      "dreadful is at index 31715\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2758,  0.1581,  0.0052,  ...,  0.1287, -0.0185, -0.4064],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for dreadful.\n",
      "dreading is at index 24506\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3980,  0.1723,  0.6149,  ..., -0.3433,  0.0656,  0.0125],\n",
      "         [ 0.1383,  0.3796,  0.1368,  ...,  0.2405, -0.3453,  0.0233],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for dreading.\n",
      "dreaming is at index 26240\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0900, -0.6135,  0.1278,  ...,  0.0225, -0.2222,  0.0049],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for dreaming.\n",
      "dreamy is at index 3366\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0358, -0.3210,  0.3505,  ..., -0.3815, -0.0992,  0.0126],\n",
      "         [ 0.1311, -0.1715,  0.0534,  ..., -0.0509, -0.4687, -0.2923],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for dreamy.\n",
      "dreary is at index 385\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1079,  0.0539,  0.1122,  ...,  0.3283,  0.0679,  0.1026],\n",
      "         [-0.2533, -0.1367, -0.1395,  ...,  0.4556,  0.2148,  0.0992],\n",
      "         [ 0.2496, -0.0823, -0.0870,  ...,  0.2706,  0.0631,  0.4615],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for dreary.\n",
      "driven is at index 3185\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0318, -0.0813,  0.0067,  ...,  0.1394, -0.0185, -0.2335],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for driven.\n",
      "drowsy is at index 385\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1079,  0.0539,  0.1122,  ...,  0.3283,  0.0679,  0.1026],\n",
      "         [ 0.4892, -0.1152,  0.1820,  ...,  0.1788, -0.3649, -0.0024],\n",
      "         [ 0.3008,  0.2734,  0.0646,  ..., -0.3844, -0.0724, -0.0279],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for drowsy.\n",
      "drugged is at index 385\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1079,  0.0539,  0.1122,  ...,  0.3283,  0.0679,  0.1026],\n",
      "         [-0.4194,  0.6675,  0.3458,  ...,  0.0699, -0.1612, -0.1234],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for drugged.\n",
      "drunk is at index 10789\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1532, -0.5423,  0.0710,  ...,  0.3932,  0.0215, -0.6134],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for drunk.\n",
      "drunkenness is at index 19835\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1548, -0.5125,  0.2607,  ...,  0.2721, -0.0634, -0.3200],\n",
      "         [-0.1231,  0.1777,  0.1255,  ..., -0.4542,  0.0778,  0.0067],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for drunkenness.\n",
      "dubiety is at index 30180\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1491,  0.5240,  0.2837,  ..., -0.0083, -0.5294, -0.3874],\n",
      "         [-0.2282,  0.7369, -0.0222,  ...,  0.3327,  0.1616, -0.2607],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for dubiety.\n",
      "dubious is at index 24381\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.4971,  0.1972,  0.3290,  ...,  0.4972, -0.1429, -0.3908],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for dubious.\n",
      "dubiously is at index 30180\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1491,  0.5240,  0.2837,  ..., -0.0083, -0.5294, -0.3874],\n",
      "         [-0.1569,  0.6928, -0.1210,  ...,  0.0117, -0.4528, -0.0707],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for dubiously.\n",
      "dull is at index 22018\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2407, -0.3521, -0.1085,  ...,  0.0026, -0.0518, -0.4675],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for dull.\n",
      "dumb is at index 16881\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0852, -0.3772, -0.5369,  ..., -0.0772,  0.0581, -0.4238],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for dumb.\n",
      "dumbfound is at index 16881\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [ 8.5248e-02, -3.7720e-01, -5.3695e-01,  ..., -7.7243e-02,\n",
      "           5.8105e-02, -4.2383e-01],\n",
      "         [-6.0516e-01,  1.8481e-01, -6.1439e-02,  ..., -2.3095e-01,\n",
      "           4.1427e-04,  5.5863e-01],\n",
      "         [ 1.9912e-01, -1.5637e-01, -7.9924e-02,  ...,  3.5773e-01,\n",
      "          -8.6763e-02,  2.1586e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for dumbfound.\n",
      "dumbfounded is at index 16881\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0852, -0.3772, -0.5369,  ..., -0.0772,  0.0581, -0.4238],\n",
      "         [-0.7253, -0.0418,  0.0464,  ..., -0.3449, -0.0462,  0.3285],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for dumbfounded.\n",
      "dumbstruck is at index 16881\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0852, -0.3772, -0.5369,  ..., -0.0772,  0.0581, -0.4238],\n",
      "         [ 0.1982, -0.3151, -0.2151,  ..., -0.3520, -0.0846,  0.2366],\n",
      "         [ 0.4102,  0.0215,  0.2072,  ..., -0.0231,  0.1642,  0.5378],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for dumbstruck.\n",
      "dumfounded is at index 385\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1079,  0.0539,  0.1122,  ...,  0.3283,  0.0679,  0.1026],\n",
      "         [ 0.0094, -0.1391,  0.4254,  ..., -0.0718,  0.2775, -0.0359],\n",
      "         [-0.6329, -0.1476, -0.0094,  ..., -0.2973, -0.0238,  0.3526],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for dumfounded.\n",
      "dupe is at index 4279\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2186, -0.0496,  0.4028,  ...,  0.2697, -0.3528,  0.0271],\n",
      "         [-0.2860,  0.3523, -0.1521,  ...,  0.3917, -0.0569,  0.3635],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for dupe.\n",
      "duplicitous is at index 30501\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [ 2.4018e-01,  5.4227e-02,  9.4180e-02,  ..., -1.0121e-01,\n",
      "          -2.8090e-01, -7.5901e-02],\n",
      "         [-2.7041e-01,  5.7306e-01, -5.2363e-01,  ..., -8.0940e-01,\n",
      "          -6.3308e-02, -1.0975e-02],\n",
      "         [ 6.2312e-03, -3.8450e-01,  1.2523e-01,  ...,  3.1559e-01,\n",
      "          -3.8559e-01, -2.4341e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for duplicitous.\n",
      "dysphoric is at index 44153\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0613,  0.3536,  0.1629,  ..., -0.1931,  0.4668, -0.1095],\n",
      "         [-0.1510,  0.6601,  0.2042,  ...,  0.1111, -0.2796, -0.2455],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for dysphoric.\n",
      "eager is at index 7921\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0013, -0.3891,  0.1224,  ...,  0.4829, -0.1465,  0.1289],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for eager.\n",
      "eagerness is at index 7921\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0013, -0.3891,  0.1224,  ...,  0.4829, -0.1465,  0.1289],\n",
      "         [-0.1231,  0.1777,  0.1255,  ..., -0.4542,  0.0778,  0.0067],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for eagerness.\n",
      "earnest is at index 22623\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1614,  0.2719, -0.0071,  ...,  0.1940, -0.3564,  0.3280],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for earnest.\n",
      "easy is at index 1365\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1734,  0.0409,  0.3261,  ...,  0.0181,  0.0338,  0.0081],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for easy.\n",
      "ebullient is at index 364\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-1.0711e-01,  3.5706e-01, -2.0875e-01,  ...,  5.8882e-01,\n",
      "          -2.1098e-01,  3.6958e-01],\n",
      "         [ 7.0040e-03, -2.6444e-01, -4.2475e-02,  ..., -2.6462e-01,\n",
      "          -4.8544e-03,  7.1712e-01],\n",
      "         [-5.2518e-01, -6.1813e-02,  5.2077e-01,  ..., -2.3502e-01,\n",
      "          -3.6357e-01, -1.6024e-02],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for ebullient.\n",
      "ecstasy is at index 37695\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1074,  0.1425,  0.1300,  ..., -0.1033, -0.0144, -0.0530],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for ecstasy.\n",
      "ecstatic is at index 30754\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3678,  0.2213,  0.3659,  ..., -0.0802,  0.0127, -0.2114],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for ecstatic.\n",
      "ecstatically is at index 20508\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-5.4299e-02, -2.2887e-02,  3.8499e-01,  ..., -9.0180e-02,\n",
      "          -7.6623e-01, -7.3476e-02],\n",
      "         [-3.2959e-01,  1.9305e-01,  1.3436e-02,  ..., -3.5159e-01,\n",
      "          -1.5365e-01,  5.6637e-01],\n",
      "         [ 2.4588e-01,  1.0527e-01, -2.8628e-01,  ..., -4.0008e-01,\n",
      "          -2.0866e-01,  1.3370e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for ecstatically.\n",
      "edgy is at index 4803\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.5496,  0.3631,  0.2126,  ...,  0.2871, -0.3357,  0.2221],\n",
      "         [-0.2171,  0.2084, -0.0842,  ..., -0.1712, -0.4832,  0.0053],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for edgy.\n",
      "eerie is at index 33960\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3119,  0.1778,  0.0431,  ...,  0.1303, -0.2445,  0.2210],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for eerie.\n",
      "effulgent is at index 22089\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2150, -0.1852,  0.4497,  ...,  0.0392, -0.1557, -0.4838],\n",
      "         [ 0.0953, -0.1035,  0.6037,  ...,  0.5088, -0.1986, -0.0593],\n",
      "         [ 0.1103,  0.0510, -0.4474,  ...,  0.2590,  0.0274,  0.6382],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for effulgent.\n",
      "egoistic is at index 21450\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3053,  0.1141,  0.7707,  ..., -0.6712,  0.4031, -0.4672],\n",
      "         [ 0.1147,  0.1744, -0.4991,  ...,  0.4511,  0.0892,  0.2464],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for egoistic.\n",
      "egotistical is at index 364\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-1.0711e-01,  3.5706e-01, -2.0875e-01,  ...,  5.8882e-01,\n",
      "          -2.1098e-01,  3.6958e-01],\n",
      "         [-2.4478e-01,  1.7483e-01, -1.5677e-01,  ..., -4.6439e-01,\n",
      "           2.5423e-01, -1.6154e-01],\n",
      "         [ 5.1091e-01,  1.1296e+00, -2.3759e-01,  ...,  1.1979e-01,\n",
      "          -6.9063e-02, -2.7516e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for egotistical.\n",
      "egregious is at index 28971\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0023,  0.4766,  0.0053,  ...,  0.1210, -0.4283,  0.1698],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for egregious.\n",
      "elated is at index 1615\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0658, -0.1823,  0.7260,  ..., -0.1195, -0.0264,  0.2395],\n",
      "         [-0.0291,  1.0262,  0.5924,  ..., -0.1654,  0.0214,  0.4920],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for elated.\n",
      "elation is at index 1615\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0658, -0.1823,  0.7260,  ..., -0.1195, -0.0264,  0.2395],\n",
      "         [ 0.1896,  0.6529,  0.2115,  ...,  0.5904, -0.0469,  0.0362],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for elation.\n",
      "electrified is at index 17995\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0642,  0.4505, -0.1645,  ..., -0.1847, -0.0307,  0.1984],\n",
      "         [-0.1058,  0.7447, -0.3643,  ..., -0.4003, -0.0682, -0.4061],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for electrified.\n",
      "elusive is at index 21483\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3964,  0.1117, -0.5421,  ..., -0.2387,  0.1581,  0.0470],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for elusive.\n",
      "embarrassed is at index 17319\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3170, -0.2780,  0.1039,  ..., -0.6351, -0.0512, -0.2265],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for embarrassed.\n",
      "embarrassment is at index 19124\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0030,  0.0528, -0.3107,  ..., -0.3305,  0.2013, -0.3000],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for embarrassment.\n",
      "embittered is at index 2841\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [ 1.1006e-01, -1.8708e-01,  3.3612e-01,  ...,  4.2205e-01,\n",
      "          -3.5349e-01,  8.5673e-02],\n",
      "         [-1.6694e-01,  8.3497e-01, -2.0158e-01,  ..., -5.4671e-02,\n",
      "          -5.7446e-01,  1.5423e-01],\n",
      "         [ 2.0081e-01,  8.0151e-02, -1.2805e-01,  ...,  1.0367e-01,\n",
      "          -1.0150e-02,  1.2168e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for embittered.\n",
      "embody is at index 33865\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2234,  0.0892,  0.2297,  ..., -0.0118,  0.0971,  0.2747],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for embody.\n",
      "emotional is at index 3722\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0838,  0.4068,  0.5528,  ..., -0.0422,  0.0214, -0.2521],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for emotional.\n",
      "emotionless is at index 11926\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0988,  0.2694,  0.1478,  ..., -0.0535,  0.2136, -0.1345],\n",
      "         [-0.0646, -0.7736,  0.2078,  ...,  0.1990, -0.4643, -0.1719],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for emotionless.\n",
      "empathetic is at index 2841\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1101, -0.1871,  0.3361,  ...,  0.4220, -0.3535,  0.0857],\n",
      "         [ 0.0026,  0.5509, -0.0114,  ..., -0.6052, -0.2750, -0.0101],\n",
      "         [-0.3732,  0.1718,  0.2622,  ...,  0.0017,  0.0437,  0.4082],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for empathetic.\n",
      "empathic is at index 2841\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1101, -0.1871,  0.3361,  ...,  0.4220, -0.3535,  0.0857],\n",
      "         [-0.4320,  1.2155, -0.2239,  ..., -0.3174,  0.6120,  0.0578],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for empathic.\n",
      "empathy is at index 17805\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1805, -0.3713,  0.3017,  ...,  0.0721,  0.4436,  0.3314],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for empathy.\n",
      "emptiness is at index 44480\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.4303, -0.3539,  0.1662,  ..., -0.0763,  0.0647, -0.0649],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for emptiness.\n",
      "empty is at index 5802\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.5875, -0.7736,  0.3475,  ..., -0.2796,  0.0352, -0.3158],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for empty.\n",
      "enamored is at index 1177\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1301, -0.0923,  0.2446,  ...,  0.1393, -0.5094, -0.2671],\n",
      "         [ 0.0517,  0.1733, -0.0684,  ..., -0.5554,  0.2448,  0.0999],\n",
      "         [-0.0055,  0.3150, -0.4091,  ...,  0.1554,  0.0958,  0.3146],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for enamored.\n",
      "enchanted is at index 44141\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0124, -0.1992,  0.3810,  ...,  0.5260,  0.2170, -0.3800],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for enchanted.\n",
      "encouraged is at index 4446\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1702, -0.4575,  0.6017,  ...,  0.2390, -0.3803, -0.1195],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for encouraged.\n",
      "encouragement is at index 18197\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0176,  0.0288,  0.3079,  ...,  0.4978,  0.0459,  0.3762],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for encouragement.\n",
      "encouraging is at index 5513\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1051, -0.0659,  0.4050,  ...,  0.6167, -0.5346, -0.2282],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for encouraging.\n",
      "endeared is at index 253\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0691, -0.1018,  0.1311,  ...,  0.5985, -0.1124,  0.0662],\n",
      "         [ 0.1314, -0.0561, -0.4988,  ..., -0.1927, -0.3366, -0.0256],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for endeared.\n",
      "endearing is at index 253\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0691, -0.1018,  0.1311,  ...,  0.5985, -0.1124,  0.0662],\n",
      "         [-0.2805,  0.1911, -0.5917,  ..., -0.2838,  0.0953,  0.0655],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for endearing.\n",
      "enduring is at index 16480\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0436,  0.2083,  0.0276,  ...,  0.4446,  0.5156,  0.5427],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for enduring.\n",
      "energetic is at index 20425\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0461,  0.3350,  0.2877,  ...,  0.1028, -0.1376,  0.1906],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for energetic.\n",
      "energized is at index 15957\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0070,  0.2286,  0.3711,  ..., -0.2250,  0.5390,  0.2657],\n",
      "         [-0.0545,  0.4248,  0.1878,  ...,  0.0940, -0.2454,  0.3326],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for energized.\n",
      "engaged is at index 4009\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1608, -0.1818, -0.1494,  ..., -0.2295, -0.2295,  0.3872],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for engaged.\n",
      "engrossed is at index 20407\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [ 2.4223e-01,  9.3870e-02,  3.8401e-01,  ...,  6.3308e-02,\n",
      "          -9.6119e-01,  3.0776e-01],\n",
      "         [ 2.1287e-01,  2.9744e-01,  3.1501e-01,  ..., -2.1253e-01,\n",
      "          -4.1325e-01,  9.2323e-02],\n",
      "         [-7.6293e-02,  8.2298e-02,  3.7151e-01,  ...,  3.9176e-01,\n",
      "          -5.2446e-01,  1.9090e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for engrossed.\n",
      "engrossment is at index 20407\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [ 2.4223e-01,  9.3870e-02,  3.8401e-01,  ...,  6.3308e-02,\n",
      "          -9.6119e-01,  3.0776e-01],\n",
      "         [ 2.1287e-01,  2.9744e-01,  3.1501e-01,  ..., -2.1253e-01,\n",
      "          -4.1325e-01,  9.2323e-02],\n",
      "         [ 1.1722e-01,  4.2273e-01, -1.0415e-01,  ...,  2.4107e-01,\n",
      "           5.4125e-02,  5.3358e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for engrossment.\n",
      "enigmatic is at index 38910\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1607,  0.0559, -0.5942,  ..., -0.0462, -0.0982, -0.3928],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for enigmatic.\n",
      "enjoy is at index 2254\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.5061, -0.0037,  0.4099,  ...,  0.2513,  0.0748,  0.4067],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for enjoy.\n",
      "enjoying is at index 6218\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3813, -0.1442,  0.5484,  ...,  0.0447,  0.1020,  0.2927],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for enjoying.\n",
      "enjoyment is at index 26611\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3839,  0.4349,  0.3542,  ...,  0.0492,  0.1075, -0.0372],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for enjoyment.\n",
      "enlightened is at index 38853\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2381, -0.2966,  0.1359,  ...,  0.1653,  0.2574, -0.6856],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for enlightened.\n",
      "enmity is at index 1177\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1301, -0.0923,  0.2446,  ...,  0.1393, -0.5094, -0.2671],\n",
      "         [ 0.0889,  0.1804, -0.0982,  ...,  0.1596,  0.1724,  0.3057],\n",
      "         [ 0.2334,  0.3192,  0.2969,  ..., -0.5207, -0.0139, -0.2105],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for enmity.\n",
      "ennui is at index 1177\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1301, -0.0923,  0.2446,  ...,  0.1393, -0.5094, -0.2671],\n",
      "         [ 0.4332, -0.3587, -0.0185,  ...,  0.1673, -0.3373,  0.4497],\n",
      "         [-0.2372,  0.1982,  0.2538,  ..., -0.2625,  0.0273,  0.4158],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for ennui.\n",
      "enraged is at index 33415\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.4194,  0.0022,  0.1463,  ..., -0.1965,  0.1082,  0.1869],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for enraged.\n",
      "enraging is at index 1177\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1301, -0.0923,  0.2446,  ...,  0.1393, -0.5094, -0.2671],\n",
      "         [ 0.4529, -0.1199,  0.0213,  ...,  0.1861, -0.0388, -0.0224],\n",
      "         [-0.0399,  0.2839,  0.2982,  ..., -0.2721,  0.1585,  0.3526],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for enraging.\n",
      "enraptured is at index 1177\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1301, -0.0923,  0.2446,  ...,  0.1393, -0.5094, -0.2671],\n",
      "         [-0.0172, -0.2498, -0.0510,  ..., -0.4622, -0.5217,  0.0758],\n",
      "         [ 0.1843, -0.0356, -0.1994,  ..., -0.6613, -0.3206,  0.3108],\n",
      "         [-0.1238, -0.4793,  0.1919,  ..., -0.3769, -0.0059, -0.0941],\n",
      "         [ 0.2760, -0.1979, -0.1075,  ...,  0.4037,  0.0583,  0.1964]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for enraptured.\n",
      "entertained is at index 23979\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3825,  0.1251, -0.0063,  ..., -0.0726, -0.0054,  0.2713],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for entertained.\n",
      "enthralled is at index 3838\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0595,  0.1414,  0.2934,  ...,  0.0040, -0.3855,  0.6093],\n",
      "         [ 0.2088,  0.1287, -0.0968,  ..., -0.6506,  0.0812,  0.1472],\n",
      "         [ 0.2059, -0.2971,  0.1064,  ..., -0.1479, -0.0572,  0.2253],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for enthralled.\n",
      "enthused is at index 3838\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0595,  0.1414,  0.2934,  ...,  0.0040, -0.3855,  0.6093],\n",
      "         [ 0.6197, -0.2601, -0.1312,  ..., -0.0867,  0.2086,  0.3222],\n",
      "         [ 0.1234,  0.5817, -0.1878,  ..., -0.6112, -0.1588,  0.1293],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for enthused.\n",
      "enthusiasm is at index 11240\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1364,  0.1819,  0.3683,  ..., -0.1084,  0.1449, -0.1382],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for enthusiasm.\n",
      "enthusiastic is at index 15947\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2640,  0.2508,  0.1366,  ...,  0.1922, -0.0868, -0.0648],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for enthusiastic.\n",
      "enticed is at index 3838\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0595,  0.1414,  0.2934,  ...,  0.0040, -0.3855,  0.6093],\n",
      "         [-0.4012,  0.2121,  0.3380,  ..., -0.3584, -0.2318, -0.3762],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for enticed.\n",
      "entranced is at index 3838\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [ 5.9528e-02,  1.4140e-01,  2.9343e-01,  ...,  3.9694e-03,\n",
      "          -3.8555e-01,  6.0931e-01],\n",
      "         [ 5.6368e-02,  4.2636e-02,  2.2834e-01,  ..., -5.8814e-02,\n",
      "          -3.0121e-01,  1.0749e-01],\n",
      "         [-1.7364e-01,  5.1629e-01, -8.1892e-02,  ..., -1.7145e-01,\n",
      "          -7.2258e-01,  2.6829e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for entranced.\n",
      "envious is at index 1177\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1301, -0.0923,  0.2446,  ...,  0.1393, -0.5094, -0.2671],\n",
      "         [ 0.1044,  0.3820, -0.2167,  ..., -0.1594, -0.0214,  0.0120],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for envious.\n",
      "envy is at index 29778\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.5142, -0.4498,  0.2876,  ..., -0.0455, -0.0954, -0.0871],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for envy.\n",
      "erotically is at index 3335\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-1.3939e-01, -3.8693e-01,  6.5570e-02,  ...,  4.2519e-02,\n",
      "           1.7815e-01,  2.0352e-01],\n",
      "         [ 1.0451e-01, -7.5795e-02,  2.8391e-01,  ..., -4.3262e-01,\n",
      "          -7.8964e-01,  2.0736e-01],\n",
      "         [-2.7380e-01,  4.6765e-01, -4.6583e-01,  ..., -1.3346e-02,\n",
      "           4.5258e-03,  2.0682e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for erotically.\n",
      "estranged is at index 20599\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2281,  0.1188, -0.7214,  ..., -0.1913,  0.2055,  0.2988],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for estranged.\n",
      "etched is at index 35542\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2661,  0.1498,  0.1280,  ...,  0.0088,  0.0766,  0.2636],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for etched.\n",
      "euphoric is at index 30882\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0184,  0.6106,  0.2041,  ...,  0.3730,  0.2033, -0.0861],\n",
      "         [-0.1510,  0.6601,  0.2042,  ...,  0.1111, -0.2796, -0.2455],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for euphoric.\n",
      "evaluating is at index 15190\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1165,  0.0115,  0.3292,  ...,  0.2860, -0.0033,  0.4211],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for evaluating.\n",
      "evasive is at index 7630\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1458, -0.0733,  0.2132,  ...,  0.0882, -0.2214,  0.5965],\n",
      "         [ 0.4553,  0.6516,  0.0883,  ..., -0.5253, -0.1966,  0.1976],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for evasive.\n",
      "evil is at index 9247\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1365,  0.4100, -0.2058,  ...,  0.1386,  0.2205, -0.3312],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for evil.\n",
      "evoke is at index 35334\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0664,  0.0369,  0.2683,  ..., -0.1020,  0.0539,  0.2395],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for evoke.\n",
      "exacerbated is at index 24961\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0644,  0.2505, -0.0478,  ...,  0.0040,  0.0071, -0.4009],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for exacerbated.\n",
      "exalted is at index 45514\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0666,  0.4038,  0.1969,  ...,  0.0172,  0.3977, -0.4584],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for exalted.\n",
      "examining is at index 14951\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1785,  0.0848,  0.1727,  ...,  0.4344, -0.3766,  0.1298],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for examining.\n",
      "exasperate is at index 1931\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0952,  0.1526, -0.0940,  ..., -0.0114,  0.2232,  0.3121],\n",
      "         [-0.1685,  0.0648,  0.0112,  ..., -0.5343, -0.2791, -0.1257],\n",
      "         [ 0.3865,  0.1343, -0.2976,  ...,  0.0919,  0.0884,  0.3420],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for exasperate.\n",
      "exasperated is at index 34698\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1253, -0.0430,  0.0629,  ...,  0.4013,  0.1774,  0.0179],\n",
      "         [-0.0291,  1.0262,  0.5924,  ..., -0.1654,  0.0214,  0.4920],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for exasperated.\n",
      "exasperation is at index 34698\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1253, -0.0430,  0.0629,  ...,  0.4013,  0.1774,  0.0179],\n",
      "         [ 0.1896,  0.6529,  0.2115,  ...,  0.5904, -0.0469,  0.0362],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for exasperation.\n",
      "excited is at index 2283\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2045,  0.3450,  0.4285,  ..., -0.0217,  0.1979, -0.1276],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for excited.\n",
      "excitedly is at index 2283\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2045,  0.3450,  0.4285,  ..., -0.0217,  0.1979, -0.1276],\n",
      "         [ 0.3543,  0.3169,  0.0401,  ..., -0.1069, -0.5598,  0.1301],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for excitedly.\n",
      "excitement is at index 8354\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0487,  0.3419, -0.0295,  ..., -0.1123,  0.3535, -0.1319],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for excitement.\n",
      "exclamation is at index 1931\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0952,  0.1526, -0.0940,  ..., -0.0114,  0.2232,  0.3121],\n",
      "         [-0.0360,  0.9122, -0.1805,  ..., -0.0533, -0.0678,  0.0347],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for exclamation.\n",
      "exclamatory is at index 1931\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0952,  0.1526, -0.0940,  ..., -0.0114,  0.2232,  0.3121],\n",
      "         [-0.2054, -0.0410,  0.0540,  ..., -0.1027, -0.4250, -0.3874],\n",
      "         [ 0.1497,  0.0580, -0.1285,  ..., -0.5026,  0.2681,  0.1263],\n",
      "         [-0.1584, -0.3442, -0.0931,  ...,  0.1743,  0.0467,  0.0764],\n",
      "         [ 0.2760, -0.1979, -0.1075,  ...,  0.4037,  0.0583,  0.1964]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for exclamatory.\n",
      "exhausted is at index 17067\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1516, -0.2622,  0.5639,  ...,  0.1515,  0.3315, -0.1581],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for exhausted.\n",
      "exhaustion is at index 30567\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0372,  0.0607,  0.4380,  ...,  0.0252,  0.4924,  0.0290],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for exhaustion.\n",
      "exhaustive is at index 29180\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1410,  0.4182, -0.0240,  ...,  0.4802,  0.2208,  0.3580],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for exhaustive.\n",
      "exhilarated is at index 32749\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.4092,  0.0941,  0.0282,  ...,  0.4623,  0.0169,  0.3507],\n",
      "         [-0.0291,  1.0262,  0.5924,  ..., -0.1654,  0.0214,  0.4920],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for exhilarated.\n",
      "exhilaration is at index 32749\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.4092,  0.0941,  0.0282,  ...,  0.4623,  0.0169,  0.3507],\n",
      "         [ 0.1896,  0.6529,  0.2115,  ...,  0.5904, -0.0469,  0.0362],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for exhilaration.\n",
      "exited is at index 17469\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0248,  0.0314,  0.6451,  ..., -0.3726, -0.0482,  0.0144],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for exited.\n",
      "expectant is at index 1057\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1909, -0.7767,  0.2733,  ...,  0.1092,  0.1625,  0.3502],\n",
      "         [-0.0978, -0.6161,  0.4288,  ..., -0.2426,  0.1850, -0.0844],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for expectant.\n",
      "expectation is at index 9250\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.4133, -0.1740,  0.0731,  ..., -0.0487,  0.1975,  0.1755],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for expectation.\n",
      "expecting is at index 4804\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1003, -0.3691,  0.0130,  ..., -0.1358,  0.1247, -0.0088],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for expecting.\n",
      "explain is at index 3922\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0659,  0.0139, -0.1527,  ..., -0.2003,  0.0152,  0.1846],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for explain.\n",
      "explaining is at index 8926\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2629,  0.0459,  0.1639,  ..., -0.1707,  0.0809, -0.4005],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for explaining.\n",
      "exploitive is at index 38984\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1370,  0.1806,  0.5121,  ...,  0.5039, -0.0552,  0.1075],\n",
      "         [-0.1481,  0.3011, -0.2696,  ...,  0.3333, -0.0977, -0.3498],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for exploitive.\n",
      "explosive is at index 8560\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3591,  0.4724, -0.3711,  ...,  0.0066,  0.4815,  0.2573],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for explosive.\n",
      "exposure is at index 4895\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2281, -0.2264,  0.0092,  ..., -0.3465,  0.0365,  0.0886],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for exposure.\n",
      "expressive is at index 36340\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1055,  0.1116, -0.2365,  ..., -0.0426, -0.2247,  0.3760],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for expressive.\n",
      "exuberant is at index 1931\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [ 9.5182e-02,  1.5259e-01, -9.4028e-02,  ..., -1.1449e-02,\n",
      "           2.2325e-01,  3.1215e-01],\n",
      "         [ 2.4840e-01, -1.2940e-01,  5.1422e-01,  ..., -3.7862e-03,\n",
      "           5.4586e-01, -1.2641e-01],\n",
      "         [-1.7943e-03, -7.2241e-01,  3.6607e-01,  ..., -1.9104e-01,\n",
      "           2.0683e-01, -5.7756e-02],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for exuberant.\n",
      "exultant is at index 1931\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [ 9.5182e-02,  1.5259e-01, -9.4028e-02,  ..., -1.1449e-02,\n",
      "           2.2325e-01,  3.1215e-01],\n",
      "         [-3.7399e-01, -1.0950e-02,  3.7421e-02,  ..., -4.9450e-01,\n",
      "          -9.8216e-02,  7.8910e-01],\n",
      "         [-1.7943e-03, -7.2241e-01,  3.6607e-01,  ..., -1.9104e-01,\n",
      "           2.0683e-01, -5.7756e-02],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for exultant.\n",
      "exulted is at index 1931\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [ 9.5182e-02,  1.5259e-01, -9.4028e-02,  ..., -1.1449e-02,\n",
      "           2.2325e-01,  3.1215e-01],\n",
      "         [-3.7399e-01, -1.0950e-02,  3.7421e-02,  ..., -4.9450e-01,\n",
      "          -9.8216e-02,  7.8910e-01],\n",
      "         [-7.6293e-02,  8.2298e-02,  3.7151e-01,  ...,  3.9176e-01,\n",
      "          -5.2446e-01,  1.9090e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for exulted.\n",
      "eye is at index 2295\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2191, -0.1122,  0.4140,  ..., -0.0840, -0.2102,  0.1156],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for eye.\n",
      "eyed is at index 36235\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2042,  0.4761,  0.3543,  ..., -0.2182, -0.4272, -0.2091],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for eyed.\n",
      "faced is at index 2713\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3855, -0.3815,  0.4261,  ..., -0.6978, -0.4292, -0.0041],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for faced.\n",
      "facetious is at index 34407\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2328,  0.3194,  0.0965,  ...,  0.2951,  0.0819, -0.1695],\n",
      "         [-0.0583,  0.2461,  0.3175,  ..., -0.0270, -0.2839, -0.2945],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for facetious.\n",
      "failure is at index 2988\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3617, -0.3997,  0.1175,  ...,  0.3978,  0.2236,  0.5448],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for failure.\n",
      "faint is at index 27922\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0428, -0.5570,  0.0226,  ...,  0.1848,  0.0837,  0.1392],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for faint.\n",
      "fair is at index 2105\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2006, -0.0712,  0.2899,  ...,  0.5301, -0.4533,  0.1285],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for fair.\n",
      "fake is at index 4486\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0409,  0.0113,  0.3835,  ..., -0.4814, -0.2295, -0.0878],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for fake.\n",
      "faking is at index 856\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0556,  0.0471,  0.4430,  ...,  0.0909, -0.0159, -0.1068],\n",
      "         [-0.2203,  0.1312, -0.2695,  ..., -0.7442, -0.1591, -0.2997],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for faking.\n",
      "falter is at index 14848\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2365,  0.1473,  0.0015,  ..., -0.0950,  0.0929,  0.4788],\n",
      "         [-0.2654,  0.5443,  0.2868,  ...,  0.2839,  0.3104,  0.2832],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for falter.\n",
      "famished is at index 13403\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0496, -0.1894, -0.0634,  ..., -0.1457,  0.4478,  0.2128],\n",
      "         [-0.0435,  0.4447,  0.0586,  ...,  0.1533, -0.0717,  0.2901],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for famished.\n",
      "fanatic is at index 38604\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-9.0479e-02, -3.7984e-02, -2.4740e-01,  ..., -2.6150e-04,\n",
      "          -2.7169e-01, -4.7155e-02],\n",
      "         [ 9.2431e-02, -2.9484e-02, -1.2872e-02,  ...,  3.0573e-01,\n",
      "          -1.1492e-01,  1.8911e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for fanatic.\n",
      "fanciful is at index 33639\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3046,  0.2563,  0.1027,  ...,  0.4563,  0.0456, -0.4234],\n",
      "         [ 0.2073,  0.3928, -0.2104,  ..., -0.0912, -0.3504, -0.2985],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for fanciful.\n",
      "fart is at index 36762\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3921, -0.5675,  0.1978,  ..., -0.1023, -0.1613, -0.2689],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for fart.\n",
      "fascinated is at index 27025\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0277,  0.3395,  0.1025,  ..., -0.1530, -0.1056,  0.2067],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for fascinated.\n",
      "fastidious is at index 1769\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0064,  0.1402, -0.1982,  ..., -0.3251,  0.0223,  0.1650],\n",
      "         [-0.1270,  0.3223,  0.5620,  ..., -0.2738, -0.2282,  0.1413],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for fastidious.\n",
      "fatigue is at index 16069\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1318, -0.1433,  0.5568,  ...,  0.1099,  0.2124,  0.1349],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for fatigue.\n",
      "fatigued is at index 36239\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3348, -0.3551,  0.6156,  ...,  0.2182, -0.2028,  0.2737],\n",
      "         [ 0.1319,  0.0611,  0.8054,  ..., -0.0837, -0.3481, -0.1203],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for fatigued.\n",
      "faultfinding is at index 7684\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0364,  0.2549,  0.0088,  ...,  0.0997, -0.4005, -0.1716],\n",
      "         [ 0.0812,  0.1902,  0.0392,  ..., -0.0086,  0.1157,  0.2774],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for faultfinding.\n",
      "favorable is at index 9879\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0219,  0.5848,  0.5869,  ...,  0.8856, -0.1566, -0.2524],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for favorable.\n",
      "fawning is at index 856\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0556,  0.0471,  0.4430,  ...,  0.0909, -0.0159, -0.1068],\n",
      "         [ 0.3060,  0.3086,  0.2436,  ..., -0.5461, -0.0419,  0.0792],\n",
      "         [ 0.2407,  0.2558,  0.0720,  ...,  0.2923, -0.3174,  0.0513],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for fawning.\n",
      "fazed is at index 856\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0556,  0.0471,  0.4430,  ...,  0.0909, -0.0159, -0.1068],\n",
      "         [ 0.0665,  0.0330,  0.4868,  ..., -0.1887,  0.0429,  0.3282],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for fazed.\n",
      "fear is at index 2490\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0721,  0.2739,  0.3367,  ..., -0.1944,  0.3668,  0.3734],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for fear.\n",
      "feared is at index 9741\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1188,  0.4246,  0.1059,  ..., -0.2305, -0.1720,  0.5553],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for feared.\n",
      "fearful is at index 23526\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0906,  0.3492,  0.2712,  ..., -0.0752,  0.1531,  0.2747],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for fearful.\n",
      "fearing is at index 21510\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0566,  0.0709, -0.2011,  ..., -0.2543,  0.4404,  0.1193],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for fearing.\n",
      "fearless is at index 29107\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3965, -0.1716,  0.2623,  ..., -0.0217, -0.0393,  0.4224],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for fearless.\n",
      "fearsome is at index 39185\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1615,  0.3962, -0.3732,  ...,  0.5181,  0.2701,  0.2526],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for fearsome.\n",
      "feckless is at index 10668\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-1.5236e-01, -5.4666e-01, -1.1085e-01,  ...,  3.0110e-02,\n",
      "          -2.3416e-01,  2.6281e-02],\n",
      "         [ 3.1751e-01,  1.3049e-01,  2.6496e-01,  ..., -7.1447e-02,\n",
      "           1.4151e-01,  5.1340e-01],\n",
      "         [ 2.9923e-02, -8.8255e-01,  1.4969e-01,  ...,  2.4745e-01,\n",
      "          -4.4044e-01, -1.4588e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for feckless.\n",
      "fed is at index 9789\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1102, -0.2706,  0.4765,  ...,  0.3954, -0.3137,  0.1155],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for fed.\n",
      "feeble is at index 42217\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0018, -0.5866, -0.2397,  ...,  0.0309,  0.3953,  0.3639],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for feeble.\n",
      "feign is at index 10668\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1524, -0.5467, -0.1109,  ...,  0.0301, -0.2342,  0.0263],\n",
      "         [-0.2116,  0.7146,  0.4587,  ..., -0.3284,  0.0425, -0.0779],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for feign.\n",
      "felicitous is at index 14383\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [ 3.0600e-02, -5.7446e-02,  5.8058e-01,  ...,  4.4191e-01,\n",
      "          -1.2082e-01,  1.0571e-01],\n",
      "         [-2.7041e-01,  5.7306e-01, -5.2363e-01,  ..., -8.0940e-01,\n",
      "          -6.3308e-02, -1.0975e-02],\n",
      "         [ 6.2312e-03, -3.8450e-01,  1.2523e-01,  ...,  3.1559e-01,\n",
      "          -3.8559e-01, -2.4341e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for felicitous.\n",
      "ferocious is at index 31429\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0812,  0.0601, -0.3410,  ...,  0.1833,  0.0652,  0.2983],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for ferocious.\n",
      "ferocity is at index 16022\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1177,  0.2274,  0.3137,  ...,  0.2768, -0.0177, -0.1364],\n",
      "         [ 0.5049,  1.1287, -0.3783,  ...,  0.1131, -0.3811,  0.0262],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for ferocity.\n",
      "festive is at index 12298\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1048, -0.1024, -0.0980,  ...,  0.8073,  0.1941, -0.0706],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for festive.\n",
      "fidgety is at index 856\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-5.5600e-02,  4.7067e-02,  4.4295e-01,  ...,  9.0935e-02,\n",
      "          -1.5919e-02, -1.0682e-01],\n",
      "         [ 2.9073e-01,  6.1934e-01, -4.4477e-01,  ..., -9.3663e-01,\n",
      "          -1.6847e-01,  3.8990e-01],\n",
      "         [ 2.3049e-01, -2.8769e-01, -8.6994e-03,  ...,  1.2940e-03,\n",
      "          -4.4119e-01, -2.6326e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for fidgety.\n",
      "fiendish is at index 13383\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3691, -0.4028, -0.0907,  ..., -0.4776, -0.1880, -0.2070],\n",
      "         [ 0.2775,  0.8327, -0.3412,  ..., -0.2443, -0.7085,  0.2795],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for fiendish.\n",
      "fierce is at index 11039\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0494, -0.1257, -0.4470,  ...,  0.1424, -0.0307,  0.5903],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for fierce.\n",
      "fiery is at index 19068\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2778, -0.0664,  0.0370,  ...,  0.0947, -0.0189,  0.1188],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for fiery.\n",
      "fighting is at index 2190\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1801, -0.7719,  0.2448,  ..., -0.0515,  0.2027,  0.3582],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for fighting.\n",
      "fine is at index 2051\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0821,  0.5697, -0.0259,  ...,  0.3102, -0.6046,  0.4421],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for fine.\n",
      "finished is at index 1550\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.4647, -0.4369,  0.0613,  ...,  0.1224, -0.3617, -0.3519],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for finished.\n",
      "firm is at index 933\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2501,  0.1685,  0.1612,  ..., -0.0272, -0.1851,  0.2851],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for firm.\n",
      "fishy is at index 3539\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2052, -0.2433,  0.6673,  ..., -0.0837,  0.2752,  0.6544],\n",
      "         [ 0.1311, -0.1715,  0.0534,  ..., -0.0509, -0.4687, -0.2923],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for fishy.\n",
      "fixated is at index 4190\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3056, -0.2869,  0.1222,  ...,  0.0951, -0.3530, -0.4918],\n",
      "         [-0.0291,  1.0262,  0.5924,  ..., -0.1654,  0.0214,  0.4920],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for fixated.\n",
      "fixed is at index 4460\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1393, -0.1662,  0.1125,  ...,  0.2748, -0.1775, -0.5183],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for fixed.\n",
      "flabbergasted is at index 2342\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0681, -0.1047, -0.1443,  ...,  0.2139, -0.2678,  0.5587],\n",
      "         [ 0.3799,  0.2690,  0.2880,  ..., -0.2679, -0.0293,  0.1745],\n",
      "         [-0.1649,  0.3021,  0.2733,  ..., -0.2090, -0.0981,  0.0643],\n",
      "         [ 0.0856,  0.3255,  0.2063,  ...,  0.0185,  0.4875, -0.0235],\n",
      "         [ 0.2760, -0.1979, -0.1075,  ...,  0.4037,  0.0583,  0.1964]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for flabbergasted.\n",
      "flaming is at index 37222\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1506, -0.6127, -0.1639,  ...,  0.0703, -0.0498, -0.6998],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for flaming.\n",
      "flat is at index 3269\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2524, -0.1232,  0.5029,  ..., -0.2455, -0.5675, -0.4241],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for flat.\n",
      "flaunting is at index 2342\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0681, -0.1047, -0.1443,  ...,  0.2139, -0.2678,  0.5587],\n",
      "         [-0.1436,  1.0278, -0.0541,  ..., -0.4806,  0.1120,  0.2544],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for flaunting.\n",
      "flighty is at index 2524\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2451,  0.6555, -0.1419,  ..., -0.1021, -0.1352,  0.2110],\n",
      "         [ 0.1311, -0.1715,  0.0534,  ..., -0.0509, -0.4687, -0.2923],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for flighty.\n",
      "flippant is at index 2342\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [ 6.8108e-02, -1.0470e-01, -1.4435e-01,  ...,  2.1394e-01,\n",
      "          -2.6784e-01,  5.5869e-01],\n",
      "         [-1.1780e-02,  4.0410e-01, -6.8300e-02,  ..., -1.5071e-01,\n",
      "          -4.2254e-01,  2.7342e-01],\n",
      "         [-1.7943e-03, -7.2241e-01,  3.6607e-01,  ..., -1.9104e-01,\n",
      "           2.0683e-01, -5.7756e-02],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for flippant.\n",
      "flipped is at index 18626\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2419,  0.3818,  0.0768,  ...,  0.0495,  0.0663, -0.6335],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for flipped.\n",
      "flirtation is at index 33743\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.9187, -0.3660, -0.2402,  ...,  0.1046, -0.2174,  0.7426],\n",
      "         [ 0.1896,  0.6529,  0.2115,  ...,  0.5904, -0.0469,  0.0362],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for flirtation.\n",
      "flirtatious is at index 33743\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [ 9.1869e-01, -3.6603e-01, -2.4025e-01,  ...,  1.0464e-01,\n",
      "          -2.1739e-01,  7.4255e-01],\n",
      "         [ 1.0510e-01, -2.2017e-01, -6.5369e-02,  ..., -6.2051e-01,\n",
      "          -2.8061e-01, -1.7415e-01],\n",
      "         [ 3.3982e-02,  1.3871e-01,  2.6086e-01,  ...,  2.0632e-02,\n",
      "          -2.6103e-01, -2.6917e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for flirtatious.\n",
      "flirty is at index 2342\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0681, -0.1047, -0.1443,  ...,  0.2139, -0.2678,  0.5587],\n",
      "         [ 0.0570,  0.5913, -0.3993,  ..., -0.5458, -0.5680, -0.1427],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for flirty.\n",
      "floored is at index 27325\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1431, -0.2890, -0.1325,  ..., -0.2836,  0.0823,  0.2742],\n",
      "         [-0.0981,  0.4244, -0.3538,  ...,  0.1082,  0.0734,  0.2906],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for floored.\n",
      "flummoxed is at index 2342\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0681, -0.1047, -0.1443,  ...,  0.2139, -0.2678,  0.5587],\n",
      "         [ 0.1486,  0.1457, -0.5618,  ...,  0.1205,  0.2462,  0.4309],\n",
      "         [ 0.3016, -0.3740, -0.0104,  ..., -0.1606,  0.1195,  0.0958],\n",
      "         [-0.0451,  0.0478,  0.3378,  ...,  0.4386, -0.4458,  0.2081],\n",
      "         [ 0.2760, -0.1979, -0.1075,  ...,  0.4037,  0.0583,  0.1964]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for flummoxed.\n",
      "flustered is at index 2342\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0681, -0.1047, -0.1443,  ...,  0.2139, -0.2678,  0.5587],\n",
      "         [-0.1725, -0.1385,  0.3259,  ..., -0.1045,  0.1566,  0.2320],\n",
      "         [ 0.2722,  0.0471,  0.0356,  ...,  0.2295, -0.3044,  0.3501],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for flustered.\n",
      "focus is at index 1056\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2487,  0.3806, -0.3149,  ...,  0.3943,  0.0207,  0.3341],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for focus.\n",
      "focused is at index 2061\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1128,  0.3147, -0.3099,  ...,  0.2298, -0.1545,  0.2389],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for focused.\n",
      "focusing is at index 5650\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1626,  0.2467, -0.3312,  ...,  0.2808,  0.1946,  0.2231],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for focusing.\n",
      "foiled is at index 9565\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1768, -0.3501,  0.0351,  ...,  0.0958, -0.4785, -0.5132],\n",
      "         [ 0.1684,  0.5575, -0.0496,  ..., -0.5884,  0.0185,  0.0401],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for foiled.\n",
      "foolish is at index 22789\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1555, -0.2860,  0.3616,  ...,  0.3720, -0.0828, -0.0333],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for foolish.\n",
      "forbearing is at index 34550\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0010,  0.0378,  0.0555,  ...,  0.5086,  0.0516,  0.4112],\n",
      "         [-0.2805,  0.1911, -0.5917,  ..., -0.2838,  0.0953,  0.0655],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for forbearing.\n",
      "forbidding is at index 34550\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0010,  0.0378,  0.0555,  ...,  0.5086,  0.0516,  0.4112],\n",
      "         [ 0.0682, -0.0455, -0.1927,  ...,  0.0875, -0.0666,  0.4266],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for forbidding.\n",
      "forced is at index 1654\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2754, -0.4565,  0.1627,  ...,  0.3000,  0.2176, -0.0027],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for forced.\n",
      "forceful is at index 32165\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0390,  0.1439, -0.2555,  ..., -0.0654,  0.0705,  0.3378],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for forceful.\n",
      "forfeited is at index 31844\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.4161, -0.2304,  0.0727,  ..., -0.6135,  0.1254,  0.3276],\n",
      "         [ 0.4064,  0.8840,  0.1087,  ..., -0.0376,  0.1923,  0.0776],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for forfeited.\n",
      "forlorn is at index 13\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1466, -0.0321,  0.4941,  ...,  0.4490, -0.1976,  0.2421],\n",
      "         [ 0.1232,  0.0721,  0.0478,  ...,  0.2697, -0.1203,  0.1628],\n",
      "         [-0.1417, -0.0351,  0.3785,  ..., -0.0876,  0.1882,  0.0487],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for forlorn.\n",
      "fortunate is at index 10583\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1051, -0.4420,  0.4475,  ...,  0.5331,  0.2734, -0.0665],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for fortunate.\n",
      "forward is at index 556\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2698, -0.0919,  0.2433,  ...,  0.1137, -0.2766,  0.0994],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for forward.\n",
      "foul is at index 6962\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1975,  0.1126,  0.4989,  ...,  0.1960, -0.5230, -0.2928],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for foul.\n",
      "fractious is at index 38251\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3137,  0.2076, -0.1754,  ..., -0.1744,  0.4708, -0.0405],\n",
      "         [-0.0583,  0.2461,  0.3175,  ..., -0.0270, -0.2839, -0.2945],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for fractious.\n",
      "fragile is at index 14283\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0477,  0.5370, -0.0386,  ..., -0.0835,  0.5910, -0.0252],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for fragile.\n",
      "frantic is at index 27396\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0426,  0.3916, -0.1324,  ...,  0.0631,  0.0173,  0.4784],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for frantic.\n",
      "fraudulent is at index 15381\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0070,  0.1954,  0.3662,  ..., -0.1847, -0.3815,  0.2535],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for fraudulent.\n",
      "fraught is at index 25481\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1384,  0.0031,  0.1182,  ...,  0.1051,  0.2556,  0.4588],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for fraught.\n",
      "frazzled is at index 26830\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1626,  0.0877,  0.3039,  ..., -0.2154,  0.4718,  0.1020],\n",
      "         [-0.0440, -0.2659, -0.0130,  ...,  0.0659,  0.2587, -0.0173],\n",
      "         [ 0.0589, -0.2250,  0.0798,  ..., -0.1709, -0.0874,  0.2744],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for frazzled.\n",
      "freaked is at index 7619\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1189,  0.2193,  0.1171,  ..., -0.2763,  0.2320, -0.4155],\n",
      "         [-0.0185,  0.3825, -0.3778,  ..., -0.5825, -0.0706, -0.3325],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for freaked.\n",
      "frenzied is at index 26908\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1336,  0.2388, -0.0765,  ..., -0.5153, -0.1537,  0.0707],\n",
      "         [ 0.0310, -0.2013,  0.5224,  ..., -0.3017,  0.0045,  0.0680],\n",
      "         [-0.5649,  0.5122,  0.1362,  ...,  0.2446, -0.3121,  0.0768],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for frenzied.\n",
      "fretful is at index 31391\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2242,  0.1835,  0.1208,  ..., -0.1654,  0.0623,  0.3999],\n",
      "         [ 0.3025,  0.1036, -0.3624,  ...,  0.1536, -0.4041, -0.2558],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for fretful.\n",
      "friendliness is at index 1441\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0533, -0.4284, -0.0352,  ...,  0.1291, -0.0977,  0.6398],\n",
      "         [-0.1671,  0.2610, -0.0677,  ..., -0.4525,  0.2214, -0.0660],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for friendliness.\n",
      "friendly is at index 5192\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1302, -0.1625,  0.0386,  ...,  0.5196, -0.5000,  0.2889],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for friendly.\n",
      "fright is at index 32580\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0687, -0.0605, -0.1667,  ..., -0.2142, -0.1925,  0.1481],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for fright.\n",
      "frightened is at index 26851\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0511,  0.1274,  0.4779,  ..., -0.0669, -0.1117,  0.0908],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for frightened.\n",
      "frightening is at index 21111\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1215,  0.4060,  0.2081,  ..., -0.0718, -0.1675,  0.0701],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for frightening.\n",
      "frigid is at index 25805\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.6539, -0.4460,  0.1756,  ..., -0.0821, -0.0945,  0.2822],\n",
      "         [ 0.1995,  0.1890,  0.1638,  ..., -0.3835, -0.2360,  0.6759],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for frigid.\n",
      "frisky is at index 6664\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1029, -0.1852,  0.1852,  ..., -0.3306,  0.2261,  0.1839],\n",
      "         [-0.0586,  0.0888,  0.0997,  ..., -0.2723, -0.0962,  0.6306],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for frisky.\n",
      "frolicker is at index 856\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-5.5600e-02,  4.7067e-02,  4.4295e-01,  ...,  9.0935e-02,\n",
      "          -1.5919e-02, -1.0682e-01],\n",
      "         [ 1.3939e-01,  6.5667e-03,  4.3180e-01,  ..., -1.1429e-01,\n",
      "          -5.6957e-01,  1.1363e-01],\n",
      "         [ 1.3929e-01,  9.0472e-01, -3.8250e-01,  ..., -9.0218e-02,\n",
      "          -1.5864e-01,  1.7048e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for frolicker.\n",
      "frown is at index 41588\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1221,  0.2943,  0.2487,  ...,  0.5413, -0.2887,  0.0234],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for frown.\n",
      "frowning is at index 41588\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1221,  0.2943,  0.2487,  ...,  0.5413, -0.2887,  0.0234],\n",
      "         [ 0.1383,  0.3796,  0.1368,  ...,  0.2405, -0.3453,  0.0233],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for frowning.\n",
      "frozen is at index 9214\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1079, -0.4861,  0.3708,  ..., -0.0993,  0.1362,  0.0139],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for frozen.\n",
      "frumpy is at index 6664\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1029, -0.1852,  0.1852,  ..., -0.3306,  0.2261,  0.1839],\n",
      "         [-0.1138,  0.3547,  0.2720,  ..., -0.0545,  0.2651, -0.0593],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for frumpy.\n",
      "frustrated is at index 8164\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1723,  0.2017,  0.6270,  ..., -0.0553, -0.0563,  0.0795],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for frustrated.\n",
      "frustration is at index 8413\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0476,  0.0408,  0.2241,  ..., -0.4097,  0.0443,  0.1004],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for frustration.\n",
      "fulfilled is at index 20218\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1683, -0.6604,  0.1177,  ..., -0.0384,  0.5675, -0.0948],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for fulfilled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fumed is at index 856\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0556,  0.0471,  0.4430,  ...,  0.0909, -0.0159, -0.1068],\n",
      "         [ 0.1790, -0.0735,  0.4160,  ..., -0.3656, -0.8290,  0.3504],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for fumed.\n",
      "fuming is at index 856\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0556,  0.0471,  0.4430,  ...,  0.0909, -0.0159, -0.1068],\n",
      "         [ 0.2294, -0.0047,  0.4010,  ...,  0.0095, -0.4009,  0.1320],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for fuming.\n",
      "fun is at index 1531\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0135,  0.2989,  0.2610,  ...,  0.0743, -0.2207,  0.4365],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for fun.\n",
      "funny is at index 6269\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2611,  0.1332,  0.4451,  ..., -0.0317,  0.2136, -0.1921],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for funny.\n",
      "furious is at index 15940\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0785, -0.0929, -0.1892,  ..., -0.1594, -0.0964,  0.0282],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for furious.\n",
      "furiously is at index 39202\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1467, -0.2556, -0.4108,  ..., -0.1126, -0.0770, -0.0753],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for furiously.\n",
      "furiousness is at index 15940\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0785, -0.0929, -0.1892,  ..., -0.1594, -0.0964,  0.0282],\n",
      "         [-0.1231,  0.1777,  0.1255,  ..., -0.4542,  0.0778,  0.0067],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for furiousness.\n",
      "furrowed is at index 15503\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1250,  0.1202,  0.5750,  ...,  0.1226, -0.0475,  0.1151],\n",
      "         [ 0.4892, -0.1152,  0.1820,  ...,  0.1788, -0.3649, -0.0024],\n",
      "         [-0.0763,  0.0823,  0.3715,  ...,  0.3918, -0.5245,  0.1909],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for furrowed.\n",
      "furtive is at index 856\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0556,  0.0471,  0.4430,  ...,  0.0909, -0.0159, -0.1068],\n",
      "         [-0.2747, -0.1038,  0.4443,  ...,  0.1652, -0.2446,  0.0667],\n",
      "         [ 0.2886,  0.2062,  0.1140,  ...,  0.0716, -0.1374,  0.4649],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for furtive.\n",
      "fury is at index 22228\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.5611, -0.2778, -0.4139,  ..., -0.0830,  0.4945,  0.4533],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for fury.\n",
      "fussy is at index 856\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0556,  0.0471,  0.4430,  ...,  0.0909, -0.0159, -0.1068],\n",
      "         [-0.0739,  0.2924,  0.1395,  ..., -0.0281,  0.0775, -0.0939],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for fussy.\n",
      "galled is at index 821\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0662, -0.1866,  0.4628,  ...,  0.3143,  0.2821, -0.1666],\n",
      "         [ 0.1165, -0.1933,  0.1609,  ..., -0.1938, -0.0791,  0.2009],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for galled.\n",
      "galling is at index 19869\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0554, -0.1584,  0.4324,  ...,  0.2220,  0.1729, -0.0137],\n",
      "         [ 0.1383,  0.3796,  0.1368,  ...,  0.2405, -0.3453,  0.0233],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for galling.\n",
      "gasp is at index 41681\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1986, -0.2468,  0.0353,  ..., -0.1624, -0.2366,  0.0354],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for gasp.\n",
      "gasped is at index 44918\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1759,  0.3717,  0.0998,  ..., -0.0647, -0.2231,  0.0862],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for gasped.\n",
      "gasping is at index 1123\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.4581, -0.0159,  0.4136,  ...,  0.0093, -0.1592, -0.2006],\n",
      "         [-0.1036,  0.2815,  0.0207,  ..., -0.0869, -0.2940, -0.0597],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for gasping.\n",
      "gay is at index 5100\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3313, -0.4749,  0.2455,  ..., -0.4251, -0.1994,  0.1260],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for gay.\n",
      "gazing is at index 40804\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0095, -0.5799, -0.2139,  ...,  0.4468, -0.3034,  0.1149],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for gazing.\n",
      "genial is at index 12358\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2033,  0.0436,  0.4179,  ...,  0.1989, -0.5183, -0.0774],\n",
      "         [-0.1138,  0.2129, -0.0623,  ...,  0.2614, -0.4726,  0.1944],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for genial.\n",
      "gentle is at index 16634\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3498,  0.1847,  0.1389,  ...,  0.4213,  0.0379,  0.5813],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for gentle.\n",
      "genuine is at index 8916\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2337,  0.1926,  0.2449,  ...,  0.1338,  0.2196,  0.0073],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for genuine.\n",
      "ghastly is at index 34648\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0014, -0.1442, -0.0026,  ..., -0.2538, -0.3786, -0.1110],\n",
      "         [ 0.0708,  0.1125,  0.4960,  ..., -0.3626,  0.2098,  0.3968],\n",
      "         [ 0.4529,  0.1975, -0.0221,  ..., -0.0542, -0.5319,  0.1568],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for ghastly.\n",
      "giddy is at index 821\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0662, -0.1866,  0.4628,  ...,  0.3143,  0.2821, -0.1666],\n",
      "         [ 0.3751,  0.5648, -0.1441,  ..., -0.2389,  0.0623,  0.2681],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for giddy.\n",
      "giggle is at index 821\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0662, -0.1866,  0.4628,  ...,  0.3143,  0.2821, -0.1666],\n",
      "         [ 0.2389,  0.6492,  0.4789,  ..., -0.2538, -0.0526,  0.0632],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for giggle.\n",
      "giggling is at index 33786\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2042, -0.2587,  0.2558,  ..., -0.0626, -0.0083, -0.0490],\n",
      "         [-0.0505, -0.0944,  0.4063,  ..., -0.3282, -0.1252,  0.2769],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for giggling.\n",
      "glad is at index 7785\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3126, -0.2433,  0.7312,  ...,  0.2459,  0.0364,  0.2551],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for glad.\n",
      "gladdened is at index 5921\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-3.4028e-01, -3.2449e-01,  5.1474e-01,  ...,  5.8789e-01,\n",
      "          -8.2110e-02,  3.3093e-01],\n",
      "         [ 3.1033e-01,  4.5573e-01,  1.2322e-01,  ..., -4.6085e-01,\n",
      "          -9.1687e-02,  2.0571e-01],\n",
      "         [ 2.6623e-02, -3.7800e-01,  6.1400e-01,  ..., -2.6862e-02,\n",
      "          -2.5108e-01,  6.7815e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for gladdened.\n",
      "gladiola is at index 7785\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3126, -0.2433,  0.7312,  ...,  0.2459,  0.0364,  0.2551],\n",
      "         [-0.0203,  0.0632, -0.0862,  ...,  0.2286, -0.9327,  0.9527],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for gladiola.\n",
      "gladness is at index 7785\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3126, -0.2433,  0.7312,  ...,  0.2459,  0.0364,  0.2551],\n",
      "         [-0.1231,  0.1777,  0.1255,  ..., -0.4542,  0.0778,  0.0067],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for gladness.\n",
      "gladsome is at index 5921\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3403, -0.3245,  0.5147,  ...,  0.5879, -0.0821,  0.3309],\n",
      "         [-0.4940,  0.6509,  0.0599,  ..., -0.2386, -0.2937,  0.1899],\n",
      "         [-0.6451,  0.3439,  0.1125,  ..., -0.1229, -0.6441,  0.0512],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for gladsome.\n",
      "glare is at index 37355\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0895, -0.3907,  0.0744,  ...,  0.3352, -0.2342,  0.2129],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for glare.\n",
      "glaring is at index 26077\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0838, -0.3806,  0.0598,  ...,  0.2575, -0.4702,  0.4416],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for glaring.\n",
      "glazed is at index 5921\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3403, -0.3245,  0.5147,  ...,  0.5879, -0.0821,  0.3309],\n",
      "         [ 0.0665,  0.0330,  0.4868,  ..., -0.1887,  0.0429,  0.3282],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for glazed.\n",
      "glee is at index 821\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0662, -0.1866,  0.4628,  ...,  0.3143,  0.2821, -0.1666],\n",
      "         [ 0.0870, -0.2333, -0.2465,  ..., -0.3798,  0.0185,  0.4025],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for glee.\n",
      "gleeful is at index 22460\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1691,  0.4457,  0.0617,  ...,  0.3515, -0.0963, -0.1934],\n",
      "         [ 0.2202,  0.4626,  0.0943,  ...,  0.4154, -0.6916,  0.0966],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for gleeful.\n",
      "gleefully is at index 22460\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1691,  0.4457,  0.0617,  ...,  0.3515, -0.0963, -0.1934],\n",
      "         [ 0.1145,  0.3267,  0.0174,  ...,  0.1538, -0.5103,  0.3054],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for gleefully.\n",
      "glib is at index 5921\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3403, -0.3245,  0.5147,  ...,  0.5879, -0.0821,  0.3309],\n",
      "         [ 0.7301,  0.8928,  0.2414,  ...,  0.2321, -0.1133,  0.6000],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for glib.\n",
      "gloating is at index 5921\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-3.4028e-01, -3.2449e-01,  5.1474e-01,  ...,  5.8789e-01,\n",
      "          -8.2110e-02,  3.3093e-01],\n",
      "         [ 6.8538e-01, -1.3212e-01,  1.9097e-01,  ..., -9.0910e-02,\n",
      "          -4.9989e-01, -2.1041e-01],\n",
      "         [ 2.6927e-01,  7.0658e-01,  3.6206e-01,  ..., -1.2090e-01,\n",
      "           2.8401e-01,  1.2105e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for gloating.\n",
      "gloom is at index 31752\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0478,  0.0556,  0.2842,  ...,  0.2655,  0.2098,  0.0998],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for gloom.\n",
      "gloomy is at index 32627\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2735,  0.1546,  0.2639,  ...,  0.3087,  0.2193, -0.0527],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for gloomy.\n",
      "glowering is at index 5921\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3403, -0.3245,  0.5147,  ...,  0.5879, -0.0821,  0.3309],\n",
      "         [ 0.4346,  0.0056,  0.2863,  ..., -0.4455, -0.1775,  0.4263],\n",
      "         [ 0.2407,  0.2558,  0.0720,  ...,  0.2923, -0.3174,  0.0513],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for glowering.\n",
      "glowing is at index 22285\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3097,  0.0610,  0.4378,  ...,  0.5815,  0.2227,  0.0692],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for glowing.\n",
      "glum is at index 5921\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3403, -0.3245,  0.5147,  ...,  0.5879, -0.0821,  0.3309],\n",
      "         [ 0.0094, -0.1391,  0.4254,  ..., -0.0718,  0.2775, -0.0359],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for glum.\n",
      "gnarl is at index 31021\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1190,  0.0838,  0.2385,  ...,  0.0261,  0.0860,  0.5401],\n",
      "         [ 0.1298,  0.6738, -0.1278,  ..., -0.7942, -0.1010,  0.2759],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for gnarl.\n",
      "gobsmacked is at index 213\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0879, -0.2291,  0.2397,  ...,  0.0510, -0.4789,  0.0072],\n",
      "         [-0.1441,  0.8255,  0.0994,  ...,  0.0946, -0.2258,  0.3471],\n",
      "         [ 0.1924,  0.0612, -0.1614,  ...,  0.2130,  0.1982,  0.3346],\n",
      "         [ 0.3478,  0.4613, -0.3090,  ...,  0.1517, -0.1586, -0.2393],\n",
      "         [ 0.2760, -0.1979, -0.1075,  ...,  0.4037,  0.0583,  0.1964]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for gobsmacked.\n",
      "good is at index 205\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0865,  0.5702,  0.2019,  ...,  0.1356, -0.1242, -0.0877],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for good.\n",
      "goofy is at index 36302\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3299,  0.1400,  0.1765,  ...,  0.0873, -0.0364,  0.1455],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for goofy.\n",
      "gossipy is at index 20445\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.4793, -0.3615, -0.0831,  ..., -0.3327, -0.3256,  0.4035],\n",
      "         [ 0.1311, -0.1715,  0.0534,  ..., -0.0509, -0.4687, -0.2923],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for gossipy.\n",
      "grandiose is at index 2821\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [ 6.9564e-02, -2.1857e-02,  3.7543e-02,  ...,  5.7084e-02,\n",
      "          -1.0581e-01, -2.7766e-02],\n",
      "         [ 7.1795e-01,  2.5539e-03,  2.4265e-03,  ..., -2.9053e-01,\n",
      "          -2.3969e-01,  2.8924e-01],\n",
      "         [-4.2622e-01,  4.6043e-02,  9.3834e-02,  ..., -1.1357e-01,\n",
      "           1.9634e-01,  7.8366e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for grandiose.\n",
      "grateful is at index 6161\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0937, -0.5381,  0.4958,  ...,  0.1898,  0.1473, -0.1086],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for grateful.\n",
      "gratified is at index 20153\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1493, -0.8059,  0.3658,  ...,  0.3126, -0.2017, -0.0805],\n",
      "         [-0.1058,  0.7447, -0.3643,  ..., -0.4003, -0.0682, -0.4061],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for gratified.\n",
      "grave is at index 9753\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0151,  0.3063,  0.4607,  ...,  0.0009, -0.2648,  0.2893],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for grave.\n",
      "great is at index 372\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2722,  0.3682,  0.1676,  ...,  0.3026, -0.0053,  0.1050],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for great.\n",
      "greedy is at index 34405\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0017, -0.2965,  0.1514,  ..., -0.1060,  0.1287,  0.2576],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for greedy.\n",
      "greeting is at index 25801\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.4625, -0.0815, -0.6646,  ...,  0.0272, -0.6271,  0.3516],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for greeting.\n",
      "grief is at index 12903\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0543,  0.2141,  0.4184,  ..., -0.1273, -0.4772,  0.1815],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for grief.\n",
      "grieved is at index 821\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0662, -0.1866,  0.4628,  ...,  0.3143,  0.2821, -0.1666],\n",
      "         [ 0.3461,  0.5858,  0.3646,  ..., -0.3560, -0.5193,  0.1936],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for grieved.\n",
      "grieving is at index 22567\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0109,  0.1758,  0.2785,  ..., -0.0598, -0.2305,  0.3456],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for grieving.\n",
      "grim is at index 17081\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0594,  0.1243,  0.4409,  ...,  0.3216, -0.1704, -0.1370],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for grim.\n",
      "grimace is at index 17081\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0594,  0.1243,  0.4409,  ...,  0.3216, -0.1704, -0.1370],\n",
      "         [-0.1934, -0.0508, -0.1597,  ..., -0.2852, -0.1542,  0.4662],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for grimace.\n",
      "grimacing is at index 17081\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0594,  0.1243,  0.4409,  ...,  0.3216, -0.1704, -0.1370],\n",
      "         [-0.2570,  0.1459, -0.0142,  ..., -0.7281,  0.0774,  0.3583],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for grimacing.\n",
      "grin is at index 30986\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1438, -0.2032,  0.5342,  ..., -0.0179, -0.4240,  0.0388],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for grin.\n",
      "grinning is at index 39662\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0930, -0.4147,  0.0307,  ...,  0.3877, -0.5239,  0.2470],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for grinning.\n",
      "griping is at index 11155\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2393,  0.4376,  0.2201,  ..., -0.6166, -0.0533,  0.7751],\n",
      "         [ 0.1383,  0.3796,  0.1368,  ...,  0.2405, -0.3453,  0.0233],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for griping.\n",
      "gross is at index 4200\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2524, -0.1281,  0.3523,  ...,  0.2735, -0.2084, -0.1935],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for gross.\n",
      "grossed is at index 4200\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2524, -0.1281,  0.3523,  ...,  0.2735, -0.2084, -0.1935],\n",
      "         [-0.1786,  0.2013,  0.4345,  ...,  0.3394, -0.5501,  0.1632],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for grossed.\n",
      "grouchy is at index 22970\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0924,  0.0457,  0.5110,  ..., -0.1114,  0.0292, -0.3900],\n",
      "         [-0.4184,  0.4744,  0.4257,  ..., -0.4343, -0.5698,  0.0550],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for grouchy.\n",
      "growl is at index 1733\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2781, -0.2791,  0.2904,  ..., -0.0386, -0.2136,  0.4365],\n",
      "         [ 0.1232,  0.0721,  0.0478,  ...,  0.2697, -0.1203,  0.1628],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for growl.\n",
      "growling is at index 1733\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2781, -0.2791,  0.2904,  ..., -0.0386, -0.2136,  0.4365],\n",
      "         [-0.0505, -0.0944,  0.4063,  ..., -0.3282, -0.1252,  0.2769],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for growling.\n",
      "grudge is at index 4435\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1545, -0.5047,  0.1362,  ...,  0.2144,  0.5964,  0.3315],\n",
      "         [ 0.0370,  0.0319, -0.2101,  ..., -0.0347, -0.2825, -0.5418],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for grudge.\n",
      "grudging is at index 4435\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1545, -0.5047,  0.1362,  ...,  0.2144,  0.5964,  0.3315],\n",
      "         [-0.1464,  0.4237,  0.0329,  ..., -0.0114,  0.1683, -0.1097],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for grudging.\n",
      "gruff is at index 15551\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3104,  0.3472,  0.2390,  ..., -0.1501,  0.4528,  0.2228],\n",
      "         [-0.3942,  0.5264,  0.2781,  ..., -0.2957,  0.1259,  0.4703],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for gruff.\n",
      "grumbling is at index 4435\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1545, -0.5047,  0.1362,  ...,  0.2144,  0.5964,  0.3315],\n",
      "         [-0.2282,  0.5899, -0.3619,  ..., -0.4189,  0.2522,  0.2405],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for grumbling.\n",
      "grumpy is at index 4435\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1545, -0.5047,  0.1362,  ...,  0.2144,  0.5964,  0.3315],\n",
      "         [-0.1138,  0.3547,  0.2720,  ..., -0.0545,  0.2651, -0.0593],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for grumpy.\n",
      "grunt is at index 44376\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2193, -0.4637,  0.2257,  ..., -0.0701, -0.4132,  0.1885],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for grunt.\n",
      "grunting is at index 39204\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3267, -0.8772,  0.2355,  ...,  0.0049, -0.0414,  0.1828],\n",
      "         [-0.0710,  0.1900,  0.8213,  ...,  0.2001,  0.0973,  0.1731],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for grunting.\n",
      "guarded is at index 25853\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0910,  0.5196,  0.2003,  ..., -0.1404, -0.2624, -0.2325],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for guarded.\n",
      "guilty is at index 2181\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.4171, -0.0972,  0.0371,  ...,  0.1780, -0.5682, -0.5604],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for guilty.\n",
      "gulp is at index 821\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0662, -0.1866,  0.4628,  ...,  0.3143,  0.2821, -0.1666],\n",
      "         [ 0.3156, -0.2416,  0.4049,  ...,  0.1976, -0.5947,  0.3700],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for gulp.\n",
      "haggard is at index 1368\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0159, -0.2682,  0.5717,  ...,  0.3633, -0.0530,  0.3527],\n",
      "         [-0.0158,  0.0628, -0.1135,  ...,  0.0403, -0.4167,  0.3035],\n",
      "         [ 0.1852,  0.0085, -0.3370,  ..., -0.0605,  0.1814,  0.5082],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for haggard.\n",
      "halfhearted is at index 457\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3067, -0.4180,  0.1521,  ...,  0.0061, -0.3223,  0.0277],\n",
      "         [-0.1408,  0.2934, -0.1141,  ...,  0.0744,  0.0680,  0.7601],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for halfhearted.\n",
      "halted is at index 12856\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0915,  0.1200,  0.1631,  ...,  0.4176, -0.1247, -0.2445],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for halted.\n",
      "hapless is at index 2489\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1287, -0.4380,  0.0338,  ...,  0.0544,  0.1569, -0.3741],\n",
      "         [ 0.0895,  0.0022,  0.1615,  ..., -0.8777, -0.3354, -0.1106],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for hapless.\n",
      "happiness is at index 11098\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3854,  0.4386,  0.3093,  ..., -0.0685,  0.3035, -0.2186],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for happiness.\n",
      "happy is at index 1372\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0636,  0.2531,  0.5812,  ...,  0.2055, -0.1985, -0.1437],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for happy.\n",
      "harassed is at index 16835\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2425, -0.4857,  0.3029,  ...,  0.0635, -0.5415,  0.2927],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for harassed.\n",
      "hard is at index 543\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1988, -0.1312, -0.2993,  ..., -0.1000, -0.3335,  0.0653],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for hard.\n",
      "hardened is at index 33631\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0567, -0.0697, -0.3543,  ...,  0.3663,  0.0639,  0.1060],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for hardened.\n",
      "harmful is at index 11190\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1895,  0.4425,  0.0439,  ...,  0.5179, -0.0293,  0.4139],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for harmful.\n",
      "harried is at index 12280\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2118,  0.2939,  0.3799,  ...,  0.0843, -0.0882, -0.2547],\n",
      "         [-0.4501,  0.8347,  0.0744,  ..., -0.0632, -0.3284,  0.4755],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for harried.\n",
      "harsh is at index 9776\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2531,  0.2639, -0.0620,  ...,  0.3138, -0.3455,  0.6790],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for harsh.\n",
      "hate is at index 4157\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2737, -0.0873,  0.3997,  ...,  0.0157,  0.0518, -0.1887],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for hate.\n",
      "hateful is at index 26393\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2161,  0.1028, -0.1274,  ...,  0.1047, -0.0558,  0.2628],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for hateful.\n",
      "hating is at index 40873\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1076, -0.2021,  0.3824,  ..., -0.1404, -0.0969, -0.3505],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for hating.\n",
      "hatred is at index 13453\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2958, -0.4220,  0.3747,  ..., -0.0273, -0.1465, -0.0147],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for hatred.\n",
      "haughty is at index 2489\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1287, -0.4380,  0.0338,  ...,  0.0544,  0.1569, -0.3741],\n",
      "         [ 0.3768, -0.0680,  0.5245,  ..., -0.2853, -0.0152,  0.5205],\n",
      "         [ 0.1435,  0.1202, -0.2999,  ..., -0.1916,  0.0954, -0.2514],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for haughty.\n",
      "haunted is at index 22717\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0102,  0.0597,  0.2695,  ...,  0.0961,  0.3531, -0.0235],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for haunted.\n",
      "hazy is at index 2489\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1287, -0.4380,  0.0338,  ...,  0.0544,  0.1569, -0.3741],\n",
      "         [-0.0577,  0.5858,  0.1074,  ..., -0.6844, -0.2767,  0.0738],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for hazy.\n",
      "headshake is at index 471\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.4189, -0.3451,  0.4644,  ..., -0.0880, -0.1078,  0.3330],\n",
      "         [-0.0524,  0.2561, -0.4352,  ..., -0.5555,  0.7113, -0.1941],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for headshake.\n",
      "heartache is at index 1144\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1888,  0.0788,  0.7145,  ..., -0.2274,  0.0503,  0.4668],\n",
      "         [ 0.0876, -0.2296, -0.0613,  ..., -0.7254, -0.3180, -0.2264],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for heartache.\n",
      "heartbroken is at index 1144\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1888,  0.0788,  0.7145,  ..., -0.2274,  0.0503,  0.4668],\n",
      "         [-0.2875,  0.0309, -0.0421,  ...,  0.2124, -0.0511, -0.0096],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for heartbroken.\n",
      "hearted is at index 1144\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1888,  0.0788,  0.7145,  ..., -0.2274,  0.0503,  0.4668],\n",
      "         [-0.1786,  0.2013,  0.4345,  ...,  0.3394, -0.5501,  0.1632],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for hearted.\n",
      "heartsick is at index 7754\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1080,  0.1757,  0.4773,  ..., -0.2657, -0.1340,  0.6579],\n",
      "         [-0.1118,  0.3405,  0.3984,  ...,  0.4437,  0.4347, -0.0613],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for heartsick.\n",
      "heated is at index 10819\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0337,  0.2512,  0.2151,  ...,  0.2696,  0.1707,  0.0397],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for heated.\n",
      "heavyhearted is at index 2016\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2659, -0.1154, -0.3196,  ...,  0.3270, -0.0612, -0.0434],\n",
      "         [-0.1408,  0.2934, -0.1141,  ...,  0.0744,  0.0680,  0.7601],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for heavyhearted.\n",
      "heckle is at index 17835\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1674, -0.1818,  0.4298,  ...,  0.0254, -0.4423,  0.1486],\n",
      "         [-0.2066,  0.0911,  0.1720,  ...,  0.1381,  0.3392,  0.2400],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for heckle.\n",
      "heedful is at index 25432\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1666, -0.3851, -0.1022,  ..., -0.2119,  0.0458,  0.2509],\n",
      "         [ 0.3025,  0.1036, -0.3624,  ...,  0.1536, -0.4041, -0.2558],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for heedful.\n",
      "heinous is at index 30091\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2694,  0.6353, -0.4507,  ...,  0.2756, -0.0681,  0.0987],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for heinous.\n",
      "helpful is at index 7163\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2242,  0.0437,  0.4875,  ...,  0.5880, -0.4331,  0.1418],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for helpful.\n",
      "helpless is at index 22445\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0652, -0.4148,  0.5055,  ..., -0.2160,  0.0621,  0.0281],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for helpless.\n",
      "hesitant is at index 24668\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3334,  0.0230,  0.3593,  ..., -0.1189,  0.0250,  0.0743],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for hesitant.\n",
      "hesitantly is at index 36279\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3531, -0.3517,  0.0065,  ..., -0.0842,  0.3211,  0.2614],\n",
      "         [ 0.2052,  0.3978,  0.1051,  ..., -0.2637, -0.3355,  0.0147],\n",
      "         [ 0.2111,  0.1548, -0.2511,  ..., -0.3100,  0.1207, -0.1011],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for hesitantly.\n",
      "hesitating is at index 36279\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3531, -0.3517,  0.0065,  ..., -0.0842,  0.3211,  0.2614],\n",
      "         [ 0.2360,  0.4257,  0.1191,  ...,  0.0325,  0.5004,  0.2153],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for hesitating.\n",
      "hesitation is at index 28946\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0175,  0.1624,  0.2559,  ..., -0.4021, -0.1035,  0.0212],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for hesitation.\n",
      "high is at index 239\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1283,  0.2562,  0.2116,  ...,  0.0523, -0.3689, -0.1317],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for high.\n",
      "hollering is at index 1368\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [ 1.5933e-02, -2.6822e-01,  5.7166e-01,  ...,  3.6329e-01,\n",
      "          -5.2968e-02,  3.5275e-01],\n",
      "         [-3.8871e-03,  1.7191e-01,  6.8320e-01,  ...,  8.6269e-02,\n",
      "          -2.0757e-01, -9.1664e-03],\n",
      "         [ 3.2813e-01,  2.0755e-01, -7.7806e-02,  ...,  5.3696e-01,\n",
      "          -2.5786e-01,  3.7482e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for hollering.\n",
      "homicidal is at index 9486\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0398, -0.3242, -0.1791,  ...,  0.1839, -0.4151, -0.4330],\n",
      "         [ 0.6041, -0.0360, -0.2511,  ..., -0.0975,  0.1443,  0.6042],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for homicidal.\n",
      "honest is at index 5322\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2481, -0.0143,  0.5151,  ..., -0.2115, -0.0965, -0.0798],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for honest.\n",
      "honorable is at index 28537\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0387,  0.4234, -0.1792,  ...,  0.1182, -0.2606, -0.0686],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for honorable.\n",
      "hope is at index 1034\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.4499, -0.1924,  0.0232,  ...,  0.3368,  0.1444,  0.3355],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for hope.\n",
      "hopeful is at index 7917\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1084,  0.0712,  0.1641,  ...,  0.4145, -0.1036, -0.0631],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for hopeful.\n",
      "hopefulness is at index 7917\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1084,  0.0712,  0.1641,  ...,  0.4145, -0.1036, -0.0631],\n",
      "         [-0.1231,  0.1777,  0.1255,  ..., -0.4542,  0.0778,  0.0067],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for hopefulness.\n",
      "hopeless is at index 24418\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1563, -0.2794, -0.0224,  ...,  0.0928, -0.0013,  0.0553],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for hopeless.\n",
      "hoping is at index 2818\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.4513, -0.4764,  0.0245,  ...,  0.2550,  0.1057,  0.1650],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for hoping.\n",
      "horny is at index 46216\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.4344, -0.1902,  0.0811,  ...,  0.2137,  0.1491, -0.3793],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for horny.\n",
      "horrible is at index 11385\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0346,  0.3626, -0.0069,  ...,  0.2057, -0.1961, -0.1908],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for horrible.\n",
      "horrified is at index 27807\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0933,  0.0749, -0.0426,  ...,  0.0818, -0.1018,  0.1605],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for horrified.\n",
      "horrify is at index 48067\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.4774,  0.1368, -0.3757,  ...,  0.2499, -0.1106,  0.2523],\n",
      "         [ 0.6081,  0.7832, -0.3257,  ..., -0.3761, -0.2217,  0.0296],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for horrify.\n",
      "horrifying is at index 28242\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0955,  0.3186,  0.0368,  ..., -0.0522, -0.2723,  0.2862],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for horrifying.\n",
      "horror is at index 8444\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1518,  0.0977, -0.2610,  ..., -0.1149,  0.1347, -0.0238],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for horror.\n",
      "hostile is at index 11928\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2149, -0.2067, -0.1609,  ...,  0.1832, -0.1180, -0.0940],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for hostile.\n",
      "hostility is at index 22069\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0951, -0.0858, -0.0390,  ...,  0.0889,  0.3837,  0.3273],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for hostility.\n",
      "hot is at index 2131\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1562, -0.3820,  0.1870,  ..., -0.0144, -0.3400, -0.5543],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for hot.\n",
      "hotshot is at index 2131\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1562, -0.3820,  0.1870,  ..., -0.0144, -0.3400, -0.5543],\n",
      "         [-0.1983, -0.0425, -0.2736,  ..., -0.0140,  0.1355,  0.1154],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for hotshot.\n",
      "huffiness is at index 1368\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [ 1.5933e-02, -2.6822e-01,  5.7166e-01,  ...,  3.6329e-01,\n",
      "          -5.2968e-02,  3.5275e-01],\n",
      "         [ 3.0661e-01,  6.9952e-01, -4.5631e-02,  ...,  3.7726e-02,\n",
      "          -2.8382e-01,  9.3385e-02],\n",
      "         [-1.1555e-01,  1.8699e-01, -2.3497e-01,  ...,  2.0679e-02,\n",
      "           2.3643e-01, -4.0586e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for huffiness.\n",
      "huffy is at index 1368\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0159, -0.2682,  0.5717,  ...,  0.3633, -0.0530,  0.3527],\n",
      "         [-0.0682,  0.7046,  0.2141,  ...,  0.1037, -0.3775, -0.0055],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for huffy.\n",
      "humble is at index 14083\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.5033, -0.0991,  0.3506,  ..., -0.0363, -0.0065, -0.8135],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for humble.\n",
      "humbled is at index 10080\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.5350,  0.0496,  0.6811,  ..., -0.0239,  0.2051, -0.5203],\n",
      "         [-0.4297,  0.2474, -0.2384,  ..., -0.1220, -0.0718,  0.0871],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for humbled.\n",
      "humdrum is at index 10080\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [ 5.3504e-01,  4.9596e-02,  6.8106e-01,  ..., -2.3916e-02,\n",
      "           2.0506e-01, -5.2034e-01],\n",
      "         [-4.4508e-02, -3.0696e-02, -1.6995e-01,  ...,  1.6061e-01,\n",
      "          -2.9257e-01,  5.3225e-01],\n",
      "         [ 1.4243e-01,  1.1748e-01, -4.3146e-01,  ..., -8.2075e-02,\n",
      "          -4.5740e-01, -1.0991e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for humdrum.\n",
      "humiliated is at index 32386\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [ 7.8003e-02, -1.8567e-04,  1.2105e-01,  ..., -2.5092e-01,\n",
      "          -2.4583e-01,  2.1776e-01],\n",
      "         [ 9.2431e-02, -2.9484e-02, -1.2872e-02,  ...,  3.0573e-01,\n",
      "          -1.1492e-01,  1.8911e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for humiliated.\n",
      "humility is at index 27352\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1249, -0.4313,  0.3056,  ..., -0.1507,  0.4371,  0.0554],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for humility.\n",
      "humming is at index 35774\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2506,  0.0295,  0.0764,  ...,  0.0034, -0.0891, -0.3986],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for humming.\n",
      "humor is at index 12073\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0410, -0.1913,  0.4732,  ...,  0.0130,  0.4241,  0.4232],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for humor.\n",
      "humored is at index 10080\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.5350,  0.0496,  0.6811,  ..., -0.0239,  0.2051, -0.5203],\n",
      "         [-0.0981,  0.4244, -0.3538,  ...,  0.1082,  0.0734,  0.2906],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for humored.\n",
      "humorous is at index 31214\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1894,  0.0815,  0.2216,  ...,  0.4010,  0.3369, -0.0448],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for humorous.\n",
      "hunger is at index 12226\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1406, -0.6822, -0.1035,  ...,  0.2020,  0.2428,  0.2539],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for hunger.\n",
      "hungry is at index 11130\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2282, -0.7849,  0.3094,  ...,  0.6334,  0.2878, -0.0538],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for hungry.\n",
      "hunted is at index 32602\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0319, -0.5388, -0.5635,  ...,  0.2597, -0.1235,  0.1379],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for hunted.\n",
      "hurt is at index 2581\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0603, -0.1507,  0.7790,  ...,  0.1406,  0.1621, -0.1515],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for hurt.\n",
      "hurtful is at index 2581\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0603, -0.1507,  0.7790,  ...,  0.1406,  0.1621, -0.1515],\n",
      "         [ 0.3025,  0.1036, -0.3624,  ...,  0.1536, -0.4041, -0.2558],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for hurtful.\n",
      "hurting is at index 12780\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0722, -0.0022,  0.3161,  ...,  0.2466,  0.1075,  0.0701],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for hurting.\n",
      "hush is at index 1368\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0159, -0.2682,  0.5717,  ...,  0.3633, -0.0530,  0.3527],\n",
      "         [-0.1372, -0.5072,  0.6010,  ..., -0.4859, -0.6282,  0.0414],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for hush.\n",
      "hushed is at index 33476\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1819,  0.2070, -0.0139,  ..., -0.0497,  0.0651,  0.4733],\n",
      "         [-0.1477, -0.2185, -0.0201,  ..., -0.2697,  0.0681,  0.0602],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for hushed.\n",
      "hyper is at index 8944\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0247,  0.1366,  0.0808,  ...,  0.0975, -0.1415,  0.1596],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for hyper.\n",
      "hyperactive is at index 8944\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0247,  0.1366,  0.0808,  ...,  0.0975, -0.1415,  0.1596],\n",
      "         [-0.1872,  0.1475,  0.0291,  ..., -0.3139,  0.0372,  0.2490],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for hyperactive.\n",
      "hypnotized is at index 39040\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0085, -0.0594, -0.0833,  ..., -0.0392,  0.4349,  0.3023],\n",
      "         [-0.0545,  0.4248,  0.1878,  ...,  0.0940, -0.2454,  0.3326],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for hypnotized.\n",
      "hypocritical is at index 37769\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1440, -0.1857, -0.1140,  ...,  0.5295,  0.2077, -0.0690],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for hypocritical.\n",
      "hysteria is at index 35099\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0903,  0.5641,  0.1323,  ...,  0.0329,  0.0460,  0.1072],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for hysteria.\n",
      "hysterical is at index 38561\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0405,  0.5387,  0.1594,  ...,  0.0177,  0.1625, -0.2343],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for hysterical.\n",
      "idiotic is at index 13561\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0258,  0.4132,  0.5032,  ...,  0.0562, -0.0941, -0.1815],\n",
      "         [-0.2016,  0.4301,  0.1551,  ..., -0.1968, -0.1900,  0.1816],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for idiotic.\n",
      "ignorant is at index 27726\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1573,  0.1022, -0.0875,  ...,  0.0067,  0.0988, -0.8137],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for ignorant.\n",
      "ignoring is at index 15515\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1159, -0.2395, -0.0808,  ..., -0.0814,  0.2856,  0.2303],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for ignoring.\n",
      "ill is at index 4812\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0081, -0.0165,  0.0529,  ...,  0.3285,  0.0580, -0.4163],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for ill.\n",
      "imaginative is at index 35026\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1358,  0.1027,  0.3128,  ...,  0.0027,  0.1446,  0.1431],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for imaginative.\n",
      "immature is at index 39001\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0091, -0.2045,  0.0845,  ..., -0.1747,  0.2512, -0.2853],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for immature.\n",
      "immersed is at index 31971\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0962, -0.2421,  0.3001,  ..., -0.0210,  0.0276,  0.2379],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for immersed.\n",
      "impacted is at index 7284\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0641,  0.5637,  0.2939,  ..., -0.0595,  0.1075,  0.2365],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for impacted.\n",
      "impartial is at index 24283\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2137, -0.1342,  0.1553,  ...,  0.5056,  0.1004, -0.2789],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for impartial.\n",
      "impassioned is at index 4023\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-1.5603e-01,  6.1846e-02,  5.4477e-02,  ...,  5.3232e-01,\n",
      "           3.0015e-01, -1.4220e-01],\n",
      "         [ 1.7725e-01,  1.9135e-01,  6.6629e-01,  ...,  2.6275e-01,\n",
      "           1.9131e-01, -9.0712e-02],\n",
      "         [-7.6293e-02,  8.2298e-02,  3.7151e-01,  ...,  3.9176e-01,\n",
      "          -5.2446e-01,  1.9090e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for impassioned.\n",
      "impassive is at index 4023\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1560,  0.0618,  0.0545,  ...,  0.5323,  0.3002, -0.1422],\n",
      "         [ 0.1080, -0.1133,  0.1955,  ..., -0.5776, -0.2019, -0.1954],\n",
      "         [ 0.2886,  0.2062,  0.1140,  ...,  0.0716, -0.1374,  0.4649],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for impassive.\n",
      "impatience is at index 43635\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2309,  0.1230,  0.2753,  ..., -0.2353, -0.0602, -0.1974],\n",
      "         [-0.0602,  0.3119,  0.1890,  ..., -0.1302,  0.3309, -0.6296],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for impatience.\n",
      "impatient is at index 32601\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2654, -0.1796,  0.2683,  ..., -0.1841,  0.1649, -0.2761],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for impatient.\n",
      "imperious is at index 21245\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1224,  0.1339,  0.4612,  ...,  0.2272,  0.4898,  0.2590],\n",
      "         [-0.0583,  0.2461,  0.3175,  ..., -0.0270, -0.2839, -0.2945],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for imperious.\n",
      "impersonal is at index 23153\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2540,  0.1239,  0.1470,  ..., -0.2451, -0.0917,  0.1209],\n",
      "         [ 0.0758, -0.0494,  0.4151,  ...,  0.1255, -0.5114,  0.3248],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for impersonal.\n",
      "impertinent is at index 21245\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1224,  0.1339,  0.4612,  ...,  0.2272,  0.4898,  0.2590],\n",
      "         [ 0.1047, -0.0191,  0.1024,  ...,  0.0027, -0.4629,  0.3404],\n",
      "         [ 0.2140, -0.0617,  0.1462,  ..., -0.4583, -0.0130,  0.5562],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for impertinent.\n",
      "impish is at index 4023\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1560,  0.0618,  0.0545,  ...,  0.5323,  0.3002, -0.1422],\n",
      "         [ 0.4075, -0.2999,  0.2436,  ..., -0.0861, -0.1961,  0.0055],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for impish.\n",
      "implicated is at index 23316\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2290, -0.3856, -0.3555,  ..., -0.4646, -0.1497, -0.0895],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for implicated.\n",
      "imploring is at index 12956\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2514, -0.0915, -0.5580,  ...,  0.0973, -0.1288,  0.1547],\n",
      "         [-0.2449,  0.1567, -0.4582,  ...,  0.3038,  0.0327,  0.2458],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for imploring.\n",
      "important is at index 505\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0256,  0.7622,  0.2045,  ...,  0.0190,  0.0461, -0.0361],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for important.\n",
      "impressed is at index 6889\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1783, -0.1029,  0.2994,  ...,  0.0297,  0.1292, -0.0295],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for impressed.\n",
      "impulsive is at index 4023\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1560,  0.0618,  0.0545,  ...,  0.5323,  0.3002, -0.1422],\n",
      "         [ 0.3380,  0.6912, -0.0372,  ..., -0.0503,  0.0016,  0.5383],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for impulsive.\n",
      "inactive is at index 25986\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1039, -0.6803,  0.0352,  ..., -0.2044,  0.0176,  0.3264],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for inactive.\n",
      "inadequate is at index 15650\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0447,  0.0923, -0.1030,  ..., -0.2295,  0.3389,  0.2463],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for inadequate.\n",
      "inarticulate is at index 11\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1197, -0.1600,  0.3583,  ...,  0.4136, -0.0771,  0.2119],\n",
      "         [ 0.4045,  0.0604, -0.0937,  ..., -0.1509,  0.1479,  0.5144],\n",
      "         [ 0.2853,  0.3615,  0.0987,  ...,  0.1007, -0.1208,  0.0663],\n",
      "         [ 0.2148,  0.4770, -0.0866,  ...,  0.4353,  0.3689,  0.3042],\n",
      "         [ 0.2760, -0.1979, -0.1075,  ...,  0.4037,  0.0583,  0.1964]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for inarticulate.\n",
      "inattentive is at index 11\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1197, -0.1600,  0.3583,  ...,  0.4136, -0.0771,  0.2119],\n",
      "         [ 0.0026,  0.0612,  0.2497,  ..., -0.4297,  0.0061,  0.1590],\n",
      "         [ 0.1843, -0.3705,  0.2203,  ...,  0.0498,  0.2812,  0.6431],\n",
      "         [ 0.3177,  0.1741,  0.0816,  ...,  0.1137, -0.0629,  0.4805],\n",
      "         [ 0.2760, -0.1979, -0.1075,  ...,  0.4037,  0.0583,  0.1964]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for inattentive.\n",
      "inaudible is at index 11\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-1.1969e-01, -1.6003e-01,  3.5830e-01,  ...,  4.1359e-01,\n",
      "          -7.7141e-02,  2.1191e-01],\n",
      "         [ 1.7281e-01,  1.1146e-01,  6.2423e-01,  ...,  2.4091e-01,\n",
      "          -7.8419e-01,  6.6966e-02],\n",
      "         [-1.8025e-01,  9.8702e-02,  1.5913e-01,  ...,  3.9013e-01,\n",
      "          -7.0480e-01,  4.4639e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for inaudible.\n",
      "inauthentic is at index 11\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1197, -0.1600,  0.3583,  ...,  0.4136, -0.0771,  0.2119],\n",
      "         [-0.0252,  0.1918,  0.1024,  ..., -0.0956, -0.3460,  0.0644],\n",
      "         [ 0.2853,  0.3615,  0.0987,  ...,  0.1007, -0.1208,  0.0663],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for inauthentic.\n",
      "incapable is at index 30256\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1345, -0.1800, -0.0938,  ..., -0.0920, -0.2818, -0.1404],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for incapable.\n",
      "incensed is at index 5853\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.5086, -0.3447,  0.4136,  ...,  0.0091, -0.4071,  0.0286],\n",
      "         [-0.3646,  0.8972,  0.0376,  ..., -0.3977, -0.1300, -0.1805],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for incensed.\n",
      "incertain is at index 5853\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.5086, -0.3447,  0.4136,  ...,  0.0091, -0.4071,  0.0286],\n",
      "         [ 0.3601, -0.1440, -0.0106,  ..., -0.5567, -0.3193, -0.0713],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for incertain.\n",
      "incertitude is at index 5853\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-5.0860e-01, -3.4470e-01,  4.1358e-01,  ...,  9.0665e-03,\n",
      "          -4.0712e-01,  2.8578e-02],\n",
      "         [ 2.7854e-01, -2.6822e-01,  1.6342e-01,  ..., -2.3723e-01,\n",
      "          -1.6074e-01,  5.9265e-01],\n",
      "         [-1.1713e-01, -3.4759e-01,  9.1116e-02,  ..., -2.5890e-01,\n",
      "           6.5766e-01, -2.7283e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for incertitude.\n",
      "incited is at index 5853\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.5086, -0.3447,  0.4136,  ...,  0.0091, -0.4071,  0.0286],\n",
      "         [ 0.4064,  0.8840,  0.1087,  ..., -0.0376,  0.1923,  0.0776],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for incited.\n",
      "incomprehensible is at index 42494\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2002,  0.0961, -0.3514,  ..., -0.0398, -0.1023, -0.0756],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for incomprehensible.\n",
      "inconspicuous is at index 40817\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2572, -0.3690, -0.1339,  ..., -0.1288, -0.3007,  0.1874],\n",
      "         [ 0.4709, -0.1523, -0.1825,  ...,  0.0243, -0.3822,  0.3098],\n",
      "         [ 0.2217, -0.1388,  0.2106,  ..., -0.0306, -0.3683, -0.2822],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for inconspicuous.\n",
      "incredulity is at index 38366\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.4029,  0.1545,  0.0009,  ...,  0.2945,  0.4524, -0.4013],\n",
      "         [ 0.0953, -0.1035,  0.6037,  ...,  0.5088, -0.1986, -0.0593],\n",
      "         [ 0.2334,  0.3192,  0.2969,  ..., -0.5207, -0.0139, -0.2105],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for incredulity.\n",
      "incredulous is at index 38366\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.4029,  0.1545,  0.0009,  ...,  0.2945,  0.4524, -0.4013],\n",
      "         [ 0.0855,  0.7959,  0.5674,  ..., -0.1975, -0.1550, -0.2803],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for incredulous.\n",
      "incredulously is at index 38366\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-4.0286e-01,  1.5453e-01,  9.0124e-04,  ...,  2.9455e-01,\n",
      "           4.5235e-01, -4.0127e-01],\n",
      "         [-2.6545e-04,  6.6862e-01,  2.3869e-01,  ...,  8.0970e-02,\n",
      "          -1.6677e-01,  3.3854e-01],\n",
      "         [ 1.9912e-01, -1.5637e-01, -7.9924e-02,  ...,  3.5773e-01,\n",
      "          -8.6763e-02,  2.1586e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for incredulously.\n",
      "inculpate is at index 5853\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.5086, -0.3447,  0.4136,  ...,  0.0091, -0.4071,  0.0286],\n",
      "         [ 0.3156, -0.2416,  0.4049,  ...,  0.1976, -0.5947,  0.3700],\n",
      "         [-0.2479,  0.1660, -0.1569,  ...,  0.2599, -0.1262,  0.3018],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for inculpate.\n",
      "incurious is at index 5853\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.5086, -0.3447,  0.4136,  ...,  0.0091, -0.4071,  0.0286],\n",
      "         [ 0.0674,  0.2586, -0.0345,  ...,  0.1410,  0.0100,  0.0963],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for incurious.\n",
      "indecipherable is at index 32227\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [ 3.6142e-01, -1.7447e-01,  2.2929e-01,  ..., -1.1369e-01,\n",
      "          -2.7804e-01, -1.9601e-01],\n",
      "         [ 4.2118e-02,  1.1588e+00, -6.4333e-02,  ..., -1.3328e-01,\n",
      "          -2.9934e-01, -7.0144e-02],\n",
      "         [ 5.6745e-01, -2.2070e-01,  9.9365e-02,  ...,  1.1182e-01,\n",
      "           1.1322e-01,  2.3561e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for indecipherable.\n",
      "indecision is at index 32227\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3614, -0.1745,  0.2293,  ..., -0.1137, -0.2780, -0.1960],\n",
      "         [-0.1346,  0.4351,  0.1628,  ..., -0.0209, -0.0693,  0.3694],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for indecision.\n",
      "indecisive is at index 32227\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3614, -0.1745,  0.2293,  ..., -0.1137, -0.2780, -0.1960],\n",
      "         [-0.1359,  0.9133, -0.0822,  ...,  0.0316, -0.1752,  0.6281],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for indecisive.\n",
      "indifferent is at index 34657\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0435,  0.1213,  0.1011,  ..., -0.1002, -0.0620,  0.0435],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for indifferent.\n",
      "indifferently is at index 34657\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0435,  0.1213,  0.1011,  ..., -0.1002, -0.0620,  0.0435],\n",
      "         [ 0.3543,  0.3169,  0.0401,  ..., -0.1069, -0.5598,  0.1301],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for indifferently.\n",
      "indignant is at index 9473\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3380, -0.3358,  0.2404,  ...,  0.1692,  0.0224,  0.3511],\n",
      "         [-0.1351,  0.6704,  0.1272,  ..., -0.0643, -0.4017, -0.3534],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for indignant.\n",
      "indolent is at index 9473\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3380, -0.3358,  0.2404,  ...,  0.1692,  0.0224,  0.3511],\n",
      "         [ 0.1950,  0.0413, -0.0030,  ...,  0.1406, -0.2731, -0.0433],\n",
      "         [ 0.1843, -0.3705,  0.2203,  ...,  0.0498,  0.2812,  0.6431],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for indolent.\n",
      "inebriated is at index 11\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1197, -0.1600,  0.3583,  ...,  0.4136, -0.0771,  0.2119],\n",
      "         [ 0.2764,  0.6513,  0.2970,  ..., -0.1405, -0.3072,  0.5041],\n",
      "         [ 0.6316,  0.1095,  0.0510,  ...,  0.1579,  0.0515,  0.3860],\n",
      "         [ 0.1012,  0.8732,  0.4953,  ..., -0.0690,  0.1246,  0.5340],\n",
      "         [ 0.2760, -0.1979, -0.1075,  ...,  0.4037,  0.0583,  0.1964]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for inebriated.\n",
      "inert is at index 43783\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0524, -0.2956,  0.1400,  ..., -0.0349,  0.0027,  0.2846],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for inert.\n",
      "infatuating is at index 4047\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0104, -0.1022, -0.0194,  ...,  0.1140, -0.4357,  0.1621],\n",
      "         [ 0.1051, -0.2202, -0.0654,  ..., -0.6205, -0.2806, -0.1741],\n",
      "         [ 0.1610,  0.5453, -0.3474,  ...,  0.1878,  0.0934,  0.0757],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for infatuating.\n",
      "inferior is at index 28510\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0649, -0.0453, -0.1287,  ..., -0.1484,  0.0890, -0.2346],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for inferior.\n",
      "inferiority is at index 28510\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0649, -0.0453, -0.1287,  ..., -0.1484,  0.0890, -0.2346],\n",
      "         [ 0.1406,  0.4309,  0.3565,  ..., -0.5722, -0.0371, -0.2373],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for inferiority.\n",
      "inflamed is at index 11411\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2972,  0.3145, -0.1778,  ..., -0.0216, -0.2049,  0.0076],\n",
      "         [ 0.0505,  0.0059,  0.1942,  ..., -0.4513, -0.3499,  0.0357],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for inflamed.\n",
      "informal is at index 14110\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1316, -0.0065,  0.1751,  ...,  0.1725, -0.0935,  0.4760],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for informal.\n",
      "informing is at index 21835\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.4398,  0.0926, -0.2065,  ..., -0.1133,  0.0051,  0.2595],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for informing.\n",
      "infuriated is at index 26974\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0724, -0.1479, -0.3759,  ..., -0.0618,  0.2580,  0.0672],\n",
      "         [-0.0291,  1.0262,  0.5924,  ..., -0.1654,  0.0214,  0.4920],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for infuriated.\n",
      "inhibited is at index 45427\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0440,  0.4597,  0.6196,  ...,  0.0040,  0.0909, -0.3614],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for inhibited.\n",
      "inhibiting is at index 38512\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.5819,  0.4040,  0.4920,  ..., -0.0546,  0.7304, -0.1565],\n",
      "         [ 0.3285,  0.6020, -0.2240,  ..., -0.1792,  0.2081,  0.3680],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for inhibiting.\n",
      "inimical is at index 11\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1197, -0.1600,  0.3583,  ...,  0.4136, -0.0771,  0.2119],\n",
      "         [ 0.2001,  0.3774, -0.1114,  ..., -0.0892,  0.1542,  0.3739],\n",
      "         [-0.2949,  0.4707,  0.0365,  ...,  0.3417,  0.2391, -0.0731],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for inimical.\n",
      "injured is at index 1710\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1806, -0.3951,  0.5771,  ...,  0.1406,  0.0149,  0.2864],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for injured.\n",
      "innocent is at index 7850\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1260,  0.1893, -0.2974,  ..., -0.0871, -0.2820, -0.1574],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for innocent.\n",
      "inpatient is at index 11\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1197, -0.1600,  0.3583,  ...,  0.4136, -0.0771,  0.2119],\n",
      "         [-0.3356, -0.2000,  0.3798,  ..., -0.2028, -0.1796,  0.1928],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for inpatient.\n",
      "inquiring is at index 27874\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1117,  0.0587,  0.0263,  ...,  0.2118, -0.4648,  0.2387],\n",
      "         [ 0.4555,  0.2160,  0.0374,  ..., -0.3311,  0.5541,  0.5424],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for inquiring.\n",
      "inquisitive is at index 27874\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-1.1167e-01,  5.8675e-02,  2.6348e-02,  ...,  2.1183e-01,\n",
      "          -4.6482e-01,  2.3873e-01],\n",
      "         [ 2.0866e-01,  2.6214e-02, -1.8820e-01,  ..., -1.7282e-01,\n",
      "           1.8477e-02,  8.8773e-01],\n",
      "         [-5.5411e-02,  1.9293e-01, -3.2570e-01,  ...,  3.8031e-01,\n",
      "          -7.4766e-02, -3.2389e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for inquisitive.\n",
      "insane is at index 18544\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2421, -0.0297,  0.0987,  ...,  0.5526, -0.1865, -0.3265],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for insane.\n",
      "inscrutable is at index 7540\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-5.0753e-01, -2.5048e-04,  5.8013e-01,  ...,  6.7034e-02,\n",
      "           1.3181e-01, -1.3560e-01],\n",
      "         [ 3.1095e-01,  3.5688e-01, -2.2511e-01,  ..., -3.7261e-03,\n",
      "          -2.3346e-01,  1.4553e-01],\n",
      "         [ 3.1002e-01,  5.4817e-01, -2.6137e-03,  ..., -5.8593e-02,\n",
      "          -1.8337e-01,  1.7066e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for inscrutable.\n",
      "insecure is at index 27810\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3058,  0.2602,  0.7152,  ..., -0.6232,  0.4184, -0.3901],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for insecure.\n",
      "insecurity is at index 19401\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0869,  0.3765,  0.4153,  ..., -0.4740,  0.8304, -0.2171],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for insecurity.\n",
      "insensitive is at index 29401\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0361,  0.1735,  0.1112,  ..., -0.0650, -0.0247,  0.3082],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for insensitive.\n",
      "insidious is at index 40012\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1681,  0.6246, -0.3857,  ..., -0.1531, -0.0210,  0.0632],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for insidious.\n",
      "insinuating is at index 32016\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0510, -0.1293, -0.1145,  ..., -0.1613,  0.2455,  0.3749],\n",
      "         [ 0.0755,  0.6490, -0.2960,  ...,  0.1440,  0.0726,  0.0526],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for insinuating.\n",
      "insistence is at index 24974\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.4411,  0.3070, -0.3200,  ...,  0.2891,  0.0633,  0.2435],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for insistence.\n",
      "insistent is at index 7540\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-5.0753e-01, -2.5048e-04,  5.8013e-01,  ...,  6.7034e-02,\n",
      "           1.3181e-01, -1.3560e-01],\n",
      "         [ 3.2650e-03,  1.2777e+00, -5.7432e-01,  ..., -3.2286e-01,\n",
      "          -8.4656e-03,  1.3731e-01],\n",
      "         [ 1.9912e-01, -1.5637e-01, -7.9924e-02,  ...,  3.5773e-01,\n",
      "          -8.6763e-02,  2.1586e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for insistent.\n",
      "insisting is at index 13875\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0493,  0.1084, -0.1079,  ...,  0.1730, -0.3895,  0.0279],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for insisting.\n",
      "insolent is at index 23799\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2558, -0.0343, -0.0070,  ...,  0.2590,  0.7631, -0.1471],\n",
      "         [ 0.0903, -0.2613,  0.2799,  ...,  0.0009,  0.2593,  0.6205],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for insolent.\n",
      "insouciance is at index 7540\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-5.0753e-01, -2.5048e-04,  5.8013e-01,  ...,  6.7034e-02,\n",
      "           1.3181e-01, -1.3560e-01],\n",
      "         [ 2.1231e-01,  2.2037e-02,  2.8720e-01,  ..., -1.4720e-01,\n",
      "          -4.6529e-01, -1.0170e-02],\n",
      "         [ 1.3503e-01,  2.4440e-01,  1.1919e-01,  ..., -6.0079e-01,\n",
      "          -4.9252e-01,  1.6700e-01],\n",
      "         [ 3.6531e-03,  5.4150e-01, -3.0774e-01,  ...,  5.1328e-02,\n",
      "          -5.9189e-02,  1.2510e-01],\n",
      "         [ 2.7604e-01, -1.9787e-01, -1.0754e-01,  ...,  4.0371e-01,\n",
      "           5.8283e-02,  1.9644e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for insouciance.\n",
      "insouciant is at index 7540\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-5.0753e-01, -2.5048e-04,  5.8013e-01,  ...,  6.7034e-02,\n",
      "           1.3181e-01, -1.3560e-01],\n",
      "         [ 2.1231e-01,  2.2037e-02,  2.8720e-01,  ..., -1.4720e-01,\n",
      "          -4.6529e-01, -1.0170e-02],\n",
      "         [ 1.3503e-01,  2.4440e-01,  1.1919e-01,  ..., -6.0079e-01,\n",
      "          -4.9252e-01,  1.6700e-01],\n",
      "         [ 2.6595e-02, -7.5166e-01,  3.3163e-01,  ..., -1.4798e-01,\n",
      "           2.8098e-01, -4.2452e-02],\n",
      "         [ 2.7604e-01, -1.9787e-01, -1.0754e-01,  ...,  4.0371e-01,\n",
      "           5.8283e-02,  1.9644e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for insouciant.\n",
      "inspired is at index 4083\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1352, -0.0450,  0.2503,  ...,  0.2261, -0.0959,  0.2342],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for inspired.\n",
      "inspiring is at index 11653\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1091,  0.1138, -0.0854,  ...,  0.4601,  0.1339,  0.0293],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for inspiring.\n",
      "instigating is at index 9084\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1067, -0.3891, -0.0044,  ...,  0.1984, -0.3509,  0.2947],\n",
      "         [ 0.3538,  0.8130,  0.1497,  ..., -0.1433, -0.2076,  0.1349],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for instigating.\n",
      "instructing is at index 20587\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3353,  0.0755, -0.3303,  ...,  0.3369, -0.5578,  0.3393],\n",
      "         [ 0.1383,  0.3796,  0.1368,  ...,  0.2405, -0.3453,  0.0233],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for instructing.\n",
      "insubordinate is at index 7540\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-5.0753e-01, -2.5048e-04,  5.8013e-01,  ...,  6.7034e-02,\n",
      "           1.3181e-01, -1.3560e-01],\n",
      "         [-1.0709e-01,  4.9865e-01,  3.3527e-01,  ..., -1.9993e-01,\n",
      "          -3.9629e-01, -3.5991e-01],\n",
      "         [ 2.6088e-01,  3.0240e-01,  1.2765e-01,  ..., -2.2951e-01,\n",
      "          -2.5444e-01,  6.7334e-02],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for insubordinate.\n",
      "insular is at index 7540\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-5.0753e-01, -2.5048e-04,  5.8013e-01,  ...,  6.7034e-02,\n",
      "           1.3181e-01, -1.3560e-01],\n",
      "         [ 5.8663e-02,  4.4787e-01,  3.1777e-01,  ...,  2.0542e-01,\n",
      "          -6.3074e-01, -1.9112e-02],\n",
      "         [ 1.9912e-01, -1.5637e-01, -7.9924e-02,  ...,  3.5773e-01,\n",
      "          -8.6763e-02,  2.1586e-01]]], grad_fn=<NativeLayerNormBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for insular.\n",
      "insulted is at index 32149\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.4652, -0.1605,  0.2457,  ..., -0.1013, -0.0464, -0.7363],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for insulted.\n",
      "insulting is at index 22602\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0835, -0.1907,  0.1660,  ...,  0.1997, -0.4180, -0.6131],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for insulting.\n",
      "intelligence is at index 2316\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0176,  0.5261,  0.0589,  ..., -0.1468,  0.4485,  0.2148],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for intelligence.\n",
      "intense is at index 5676\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0856,  0.2509, -0.2981,  ...,  0.4322,  0.3350,  0.2746],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for intense.\n",
      "intensely is at index 29727\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0590, -0.0299, -0.1186,  ...,  0.0524,  0.0064,  0.2988],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for intensely.\n",
      "intensity is at index 10603\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3710,  0.2255,  0.0656,  ..., -0.0603,  0.3987,  0.2200],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for intensity.\n",
      "intensive is at index 12296\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1114, -0.2383, -0.3436,  ...,  0.4751,  0.0809,  0.5151],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for intensive.\n",
      "intent is at index 5927\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0453, -0.4455, -0.1419,  ..., -0.0391, -0.0455,  0.1474],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for intent.\n",
      "intentional is at index 18797\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1241,  0.2034,  0.5378,  ...,  0.2559,  0.0496,  0.0569],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for intentional.\n",
      "interacting is at index 23140\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1068,  0.1640, -0.1425,  ..., -0.1223, -0.1765,  0.6243],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for interacting.\n",
      "interest is at index 773\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1625,  0.2882,  0.0680,  ..., -0.5104, -0.1748,  0.2374],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for interest.\n",
      "interested is at index 2509\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1871,  0.1544,  0.1547,  ..., -0.3467, -0.0872,  0.0421],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for interested.\n",
      "interjecting is at index 3222\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0210,  0.3417,  0.1678,  ..., -0.0197, -0.3159, -0.0627],\n",
      "         [-0.2296,  0.6447, -0.3114,  ...,  0.2270,  0.1539,  0.4013],\n",
      "         [ 0.2407,  0.2558,  0.0720,  ...,  0.2923, -0.3174,  0.0513],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for interjecting.\n",
      "internalizing is at index 3425\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1212,  0.1711,  0.0321,  ..., -0.0140,  0.1040,  0.7333],\n",
      "         [-0.0178,  0.5333,  0.0785,  ..., -0.2432, -0.0303,  0.2913],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for internalizing.\n",
      "interrogating is at index 28592\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0840,  0.0381, -0.5685,  ...,  0.1197, -0.3348,  0.2759],\n",
      "         [ 0.1687,  0.8291,  0.4266,  ..., -0.1742,  0.2603,  0.0939],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for interrogating.\n",
      "interrupting is at index 22749\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1348,  0.1067, -0.2434,  ...,  0.2691,  0.3215, -0.2296],\n",
      "         [ 0.1383,  0.3796,  0.1368,  ...,  0.2405, -0.3453,  0.0233],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for interrupting.\n",
      "intimidated is at index 25443\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0406,  0.2077,  0.4418,  ..., -0.1356, -0.2636,  0.1426],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for intimidated.\n",
      "intimidating is at index 23292\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2883,  0.0868,  0.1137,  ...,  0.3038, -0.0650,  0.1845],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for intimidating.\n",
      "intolerant is at index 39348\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1381, -0.5313,  0.2953,  ..., -0.1444,  0.2900,  0.1286],\n",
      "         [-0.0978, -0.6161,  0.4288,  ..., -0.2426,  0.1850, -0.0844],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for intolerant.\n",
      "intoxicated is at index 20600\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1062, -0.0263,  0.6156,  ...,  0.3967,  0.3969, -0.5454],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for intoxicated.\n",
      "intrigue is at index 30368\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1913,  0.0734, -0.0869,  ..., -0.2972,  0.1279,  0.0404],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for intrigue.\n",
      "intrigued is at index 28622\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0732,  0.1182,  0.0867,  ..., -0.1264, -0.1079, -0.2503],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for intrigued.\n",
      "intriguing is at index 14816\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0041,  0.6046,  0.1860,  ...,  0.1722, -0.0812,  0.3176],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for intriguing.\n",
      "introspective is at index 22845\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0550,  0.2433,  0.3278,  ..., -0.0634,  0.1841, -0.0384],\n",
      "         [ 0.0312,  0.3915, -0.0072,  ...,  0.1396,  0.0081,  0.0962],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for introspective.\n",
      "invested is at index 5221\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0621,  0.1625,  0.6419,  ..., -0.2247, -0.2282,  0.2555],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for invested.\n",
      "investigate is at index 4830\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1608,  0.0593, -0.0183,  ...,  0.0576, -0.6032,  0.5289],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for investigate.\n",
      "investigative is at index 13222\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2077, -0.0106, -0.4039,  ...,  0.2495, -0.2740,  0.4952],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for investigative.\n",
      "investigatory is at index 25463\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0257,  0.0598,  0.0477,  ...,  0.1648,  0.0087,  0.2064],\n",
      "         [-0.2759, -0.2099, -0.0074,  ...,  0.0886, -0.0460,  0.0378],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for investigatory.\n",
      "invigorated is at index 12259\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-2.9988e-01, -1.0184e-01,  1.7631e-01,  ...,  1.4825e-01,\n",
      "          -1.6764e-01,  2.7105e-01],\n",
      "         [ 3.8443e-01,  4.8789e-02,  5.0105e-01,  ...,  3.1058e-01,\n",
      "           2.3442e-01,  5.5200e-01],\n",
      "         [ 7.0715e-02,  9.0628e-01,  5.2908e-01,  ..., -1.1324e-01,\n",
      "           4.5858e-02,  5.1753e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for invigorated.\n",
      "involved is at index 963\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1688, -0.0979,  0.0892,  ..., -0.4198, -0.2186,  0.0909],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for involved.\n",
      "irascible is at index 10209\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [ 3.7147e-01,  1.3672e-01,  7.4729e-01,  ..., -1.6791e-01,\n",
      "          -1.4484e-01,  8.4555e-01],\n",
      "         [-1.6618e-01,  4.3802e-01,  3.8021e-01,  ..., -2.2851e-01,\n",
      "          -1.5763e-01,  1.2319e-02],\n",
      "         [-1.8025e-01,  9.8702e-02,  1.5913e-01,  ...,  3.9013e-01,\n",
      "          -7.0480e-01,  4.4639e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for irascible.\n",
      "irate is at index 10209\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3715,  0.1367,  0.7473,  ..., -0.1679, -0.1448,  0.8455],\n",
      "         [-0.3462,  0.2802, -0.0972,  ...,  0.2098, -0.1504,  0.2755],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for irate.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ire is at index 25509\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0883,  0.1516,  0.2811,  ...,  0.1242,  0.0998,  0.2175],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for ire.\n",
      "ireful is at index 25509\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0883,  0.1516,  0.2811,  ...,  0.1242,  0.0998,  0.2175],\n",
      "         [ 0.3025,  0.1036, -0.3624,  ...,  0.1536, -0.4041, -0.2558],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for ireful.\n",
      "irked is at index 10209\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3715,  0.1367,  0.7473,  ..., -0.1679, -0.1448,  0.8455],\n",
      "         [-0.1796,  0.6423, -0.0191,  ...,  0.0356,  0.1968,  0.0476],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for irked.\n",
      "ironic is at index 25553\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1230,  0.2530,  0.2452,  ...,  0.4398,  0.4472, -0.0608],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for ironic.\n",
      "irony is at index 21490\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1429,  0.2940,  0.2613,  ...,  0.0856,  0.7492,  0.1800],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for irony.\n",
      "irresolute is at index 10209\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [ 3.7147e-01,  1.3672e-01,  7.4729e-01,  ..., -1.6791e-01,\n",
      "          -1.4484e-01,  8.4555e-01],\n",
      "         [-2.3745e-01, -7.1657e-01,  3.4308e-01,  ..., -2.6809e-01,\n",
      "          -9.3543e-02,  3.6939e-01],\n",
      "         [ 3.1703e-01,  8.2800e-01, -8.6553e-02,  ..., -5.7365e-02,\n",
      "          -2.4974e-02,  5.6577e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for irresolute.\n",
      "irritable is at index 26570\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.4620,  0.0752,  0.2005,  ..., -0.0303,  0.4431,  0.0767],\n",
      "         [ 0.4713, -0.1066,  0.1604,  ...,  0.0613,  0.0895,  0.2098],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for irritable.\n",
      "irritably is at index 26570\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.4620,  0.0752,  0.2005,  ..., -0.0303,  0.4431,  0.0767],\n",
      "         [ 0.0748,  0.0923, -0.3015,  ...,  0.0551, -0.1260,  0.1143],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for irritably.\n",
      "irritated is at index 35270\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2971,  0.2179,  0.6829,  ...,  0.1279, -0.0928,  0.0732],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for irritated.\n",
      "irritation is at index 32776\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1157,  0.1419,  0.5517,  ...,  0.2881,  0.4763, -0.0627],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for irritation.\n",
      "isolated is at index 8067\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1872,  0.1220,  0.1187,  ...,  0.1051, -0.3010, -0.2263],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for isolated.\n",
      "jabbed is at index 27916\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1688,  0.1428,  0.6891,  ...,  0.1211,  0.0259, -0.1991],\n",
      "         [ 0.1750,  0.4346,  0.2629,  ..., -0.0678, -0.4538,  0.3048],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for jabbed.\n",
      "jaded is at index 1236\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2115, -0.1256,  0.1216,  ...,  0.5844,  0.0245, -0.0983],\n",
      "         [ 0.3116,  0.7421,  0.3203,  ..., -0.4082,  0.5106, -0.2575],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for jaded.\n",
      "jarred is at index 25413\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0300,  0.0588,  0.3980,  ..., -0.2881, -0.1052, -0.2460],\n",
      "         [ 0.3309,  0.2068, -0.1227,  ...,  0.1026, -0.0409,  0.0010],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for jarred.\n",
      "jarring is at index 35659\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3266,  0.5914,  0.3427,  ...,  0.5602, -0.1324,  0.0653],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for jarring.\n",
      "jaunty is at index 1236\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2115, -0.1256,  0.1216,  ...,  0.5844,  0.0245, -0.0983],\n",
      "         [ 0.1619, -0.4539, -0.0742,  ..., -0.0947,  0.4414,  0.1759],\n",
      "         [ 0.1435,  0.1202, -0.2999,  ..., -0.1916,  0.0954, -0.2514],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for jaunty.\n",
      "jawed is at index 15345\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1903,  0.1159,  0.0600,  ..., -0.1678,  0.1312,  0.4227],\n",
      "         [-0.1786,  0.2013,  0.4345,  ...,  0.3394, -0.5501,  0.1632],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for jawed.\n",
      "jealous is at index 27064\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3287, -0.1974,  0.1313,  ..., -0.0233, -0.1100, -0.2013],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for jealous.\n",
      "jeering is at index 4112\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2911,  0.3816,  0.0389,  ...,  0.5407, -0.1106, -0.0250],\n",
      "         [ 0.2306,  0.3185, -0.0189,  ...,  0.4856, -0.2807,  0.3472],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for jeering.\n",
      "jesting is at index 1236\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2115, -0.1256,  0.1216,  ...,  0.5844,  0.0245, -0.0983],\n",
      "         [ 0.2469,  0.3832,  0.0079,  ..., -0.0837, -0.4373,  0.2286],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for jesting.\n",
      "jilted is at index 1236\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-2.1151e-01, -1.2564e-01,  1.2162e-01,  ...,  5.8442e-01,\n",
      "           2.4450e-02, -9.8294e-02],\n",
      "         [ 4.0250e-01,  9.8885e-02,  1.9256e-01,  ...,  8.1197e-02,\n",
      "           1.3131e-01,  2.8066e-01],\n",
      "         [-1.3283e-02,  2.1458e-01,  1.1063e-01,  ...,  4.1645e-01,\n",
      "          -6.8313e-01, -1.3212e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for jilted.\n",
      "jittery is at index 1236\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-2.1151e-01, -1.2564e-01,  1.2162e-01,  ...,  5.8442e-01,\n",
      "           2.4450e-02, -9.8294e-02],\n",
      "         [-3.7792e-01,  2.8695e-01,  4.5814e-01,  ...,  5.1419e-02,\n",
      "           7.8500e-01,  4.9475e-01],\n",
      "         [ 2.3049e-01, -2.8769e-01, -8.6994e-03,  ...,  1.2940e-03,\n",
      "          -4.4119e-01, -2.6326e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for jittery.\n",
      "jocular is at index 1236\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2115, -0.1256,  0.1216,  ...,  0.5844,  0.0245, -0.0983],\n",
      "         [-0.0812,  1.0808,  0.8142,  ..., -0.1318, -0.2815,  0.7687],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for jocular.\n",
      "joking is at index 22024\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3213, -0.2472, -0.0396,  ..., -0.0551,  0.0876,  0.4387],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for joking.\n",
      "jolly is at index 1236\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2115, -0.1256,  0.1216,  ...,  0.5844,  0.0245, -0.0983],\n",
      "         [ 0.3501,  0.9703,  0.6661,  ...,  0.1152, -0.0228,  0.2927],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for jolly.\n",
      "jolted is at index 1236\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-2.1151e-01, -1.2564e-01,  1.2162e-01,  ...,  5.8442e-01,\n",
      "           2.4450e-02, -9.8294e-02],\n",
      "         [ 1.9504e-01,  4.1292e-02, -3.0450e-03,  ...,  1.4063e-01,\n",
      "          -2.7313e-01, -4.3342e-02],\n",
      "         [-1.3283e-02,  2.1458e-01,  1.1063e-01,  ...,  4.1645e-01,\n",
      "          -6.8313e-01, -1.3212e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for jolted.\n",
      "jovial is at index 1236\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-2.1151e-01, -1.2564e-01,  1.2162e-01,  ...,  5.8442e-01,\n",
      "           2.4450e-02, -9.8294e-02],\n",
      "         [-9.6826e-02,  1.3680e-02,  7.1637e-01,  ...,  2.3402e-01,\n",
      "          -1.5307e-02,  4.3127e-01],\n",
      "         [-2.0754e-02,  1.0472e-01, -1.1916e-01,  ...,  3.0937e-01,\n",
      "          -4.4973e-01,  2.1976e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for jovial.\n",
      "joy is at index 5823\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2421,  0.5080,  0.4443,  ..., -0.1993, -0.1478,  0.0558],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for joy.\n",
      "joyful is at index 32076\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1510,  0.5759,  0.2345,  ...,  0.5743, -0.1146,  0.3117],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for joyful.\n",
      "joyfulness is at index 5823\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2421,  0.5080,  0.4443,  ..., -0.1993, -0.1478,  0.0558],\n",
      "         [-0.2371,  0.1973, -0.2739,  ...,  0.0637,  0.1708,  0.2685],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for joyfulness.\n",
      "joyless is at index 5823\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2421,  0.5080,  0.4443,  ..., -0.1993, -0.1478,  0.0558],\n",
      "         [-0.0646, -0.7736,  0.2078,  ...,  0.1990, -0.4643, -0.1719],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for joyless.\n",
      "joyous is at index 5823\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2421,  0.5080,  0.4443,  ..., -0.1993, -0.1478,  0.0558],\n",
      "         [-0.0881, -0.2759,  0.1838,  ...,  0.2681, -0.4104, -0.2701],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for joyous.\n",
      "jubilant is at index 1236\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-2.1151e-01, -1.2564e-01,  1.2162e-01,  ...,  5.8442e-01,\n",
      "           2.4450e-02, -9.8294e-02],\n",
      "         [-1.0709e-01,  4.9865e-01,  3.3527e-01,  ..., -1.9993e-01,\n",
      "          -3.9629e-01, -3.5991e-01],\n",
      "         [ 5.1574e-01,  2.6643e-01,  4.2836e-01,  ...,  3.1026e-01,\n",
      "          -6.7255e-01,  5.2856e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for jubilant.\n",
      "jubilation is at index 1236\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2115, -0.1256,  0.1216,  ...,  0.5844,  0.0245, -0.0983],\n",
      "         [-0.1071,  0.4987,  0.3353,  ..., -0.1999, -0.3963, -0.3599],\n",
      "         [ 0.2274,  0.5362,  0.1805,  ...,  0.5548,  0.3117,  0.1573],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for jubilation.\n",
      "judgemental is at index 17219\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3677,  0.0301,  0.0113,  ...,  0.1128,  0.2236, -0.0088],\n",
      "         [ 0.0758, -0.0494,  0.4151,  ...,  0.1255, -0.5114,  0.3248],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for judgemental.\n",
      "judging is at index 17298\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0856, -0.3777,  0.1041,  ...,  0.4697, -0.3658,  0.3442],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for judging.\n",
      "judgmental is at index 7579\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3095,  0.0499,  0.0622,  ...,  0.2616,  0.1783,  0.0361],\n",
      "         [ 0.0758, -0.0494,  0.4151,  ...,  0.1255, -0.5114,  0.3248],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for judgmental.\n",
      "judicious is at index 21392\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1547, -0.0341,  0.3560,  ...,  0.1482, -0.1551,  0.4924],\n",
      "         [ 0.2852,  0.6089,  0.1796,  ...,  0.0688, -0.0198,  0.1196],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for judicious.\n",
      "jumpy is at index 3704\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3013,  0.1017,  0.4351,  ..., -0.0057, -0.3441,  0.1996],\n",
      "         [ 0.1311, -0.1715,  0.0534,  ..., -0.0509, -0.4687, -0.2923],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for jumpy.\n",
      "justified is at index 14267\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.4929,  0.2615,  0.4899,  ...,  0.1696, -0.1436, -0.0925],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for justified.\n",
      "keen is at index 5609\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1454, -0.0664,  0.0720,  ...,  0.1766, -0.0712,  0.6119],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for keen.\n",
      "kind is at index 761\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0350,  0.1884,  0.1879,  ...,  0.3021, -0.0771,  0.3368],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for kind.\n",
      "kindhearted is at index 761\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0350,  0.1884,  0.1879,  ...,  0.3021, -0.0771,  0.3368],\n",
      "         [-0.1408,  0.2934, -0.1141,  ...,  0.0744,  0.0680,  0.7601],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for kindhearted.\n",
      "kiss is at index 13301\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0412, -0.0161,  0.3187,  ..., -0.1463,  0.0770,  0.0823],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for kiss.\n",
      "knowing is at index 4730\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1955, -0.1846, -0.0723,  ..., -0.1971,  0.5517, -0.2325],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for knowing.\n",
      "knowledgable is at index 216\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1265, -0.2575, -0.2113,  ..., -0.0241, -0.0838,  0.5004],\n",
      "         [-0.0402, -0.1098,  0.1399,  ..., -0.2213, -0.1115,  0.2467],\n",
      "         [ 0.2834, -0.1570, -0.0408,  ...,  0.3090,  0.3349,  0.4842],\n",
      "         [ 0.5987, -0.2547,  0.0658,  ...,  0.1557,  0.1910,  0.2519],\n",
      "         [ 0.2760, -0.1979, -0.1075,  ...,  0.4037,  0.0583,  0.1964]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for knowledgable.\n",
      "knowledgeable is at index 26782\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.4846,  0.1441,  0.4896,  ..., -0.1767, -0.4960, -0.0490],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for knowledgeable.\n",
      "kosher is at index 36930\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1736, -0.0870,  0.0779,  ...,  0.2100,  0.0032,  0.0723],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for kosher.\n",
      "lackadaisical is at index 1762\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1996, -0.4747, -0.1484,  ...,  0.5590,  0.2319, -0.0293],\n",
      "         [ 0.1274,  0.3448,  0.4591,  ..., -0.1919, -0.3500,  0.1126],\n",
      "         [ 0.3069, -0.0902, -0.2484,  ..., -0.1204,  0.0428,  0.9098],\n",
      "         [-0.2662,  0.4385,  0.0040,  ...,  0.3838,  0.3137, -0.0580],\n",
      "         [ 0.2760, -0.1979, -0.1075,  ...,  0.4037,  0.0583,  0.1964]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for lackadaisical.\n",
      "lackluster is at index 28369\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0291,  0.1163, -0.2601,  ...,  0.0728, -0.0299,  0.2829],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for lackluster.\n",
      "laconic is at index 784\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0497, -0.0139,  0.0576,  ...,  0.1354, -0.1139,  0.0267],\n",
      "         [-0.0788, -0.3512,  0.2431,  ..., -0.1225, -0.1500,  0.5236],\n",
      "         [ 0.2853,  0.3615,  0.0987,  ...,  0.1007, -0.1208,  0.0663],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for laconic.\n",
      "lambaste is at index 17988\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1025, -0.5096,  0.4072,  ..., -0.6071,  0.0875,  0.3260],\n",
      "         [-0.0452,  0.0988,  0.3512,  ...,  0.2760,  0.6586,  0.5190],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for lambaste.\n",
      "lamentable is at index 25532\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0011,  0.2514,  0.2967,  ...,  0.1748,  0.1175,  0.2775],\n",
      "         [ 0.4713, -0.1066,  0.1604,  ...,  0.0613,  0.0895,  0.2098],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for lamentable.\n",
      "lamenting is at index 25532\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0011,  0.2514,  0.2967,  ...,  0.1748,  0.1175,  0.2775],\n",
      "         [ 0.1383,  0.3796,  0.1368,  ...,  0.2405, -0.3453,  0.0233],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for lamenting.\n",
      "lascivious is at index 784\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0497, -0.0139,  0.0576,  ...,  0.1354, -0.1139,  0.0267],\n",
      "         [-0.1662,  0.4380,  0.3802,  ..., -0.2285, -0.1576,  0.0123],\n",
      "         [ 0.5693, -0.4779,  0.2833,  ..., -0.0714,  0.0631,  0.2883],\n",
      "         [ 0.0621,  0.1076,  0.2296,  ...,  0.0615, -0.1888, -0.2548],\n",
      "         [ 0.2760, -0.1979, -0.1075,  ...,  0.4037,  0.0583,  0.1964]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for lascivious.\n",
      "laugh is at index 7923\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3136,  0.1688,  0.4583,  ..., -0.3835, -0.1654,  0.3097],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for laugh.\n",
      "laughing is at index 11339\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1192, -0.2616,  0.2613,  ..., -0.0243, -0.0085,  0.1596],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for laughing.\n",
      "laughter is at index 16805\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.4192,  0.0402,  0.2346,  ...,  0.0721,  0.1651,  0.1815],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for laughter.\n",
      "lazy is at index 22414\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0927, -0.4634,  0.1963,  ..., -0.1453, -0.1108,  0.1122],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for lazy.\n",
      "leaving is at index 1618\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0476, -0.7379,  0.1603,  ..., -0.2414, -0.0998,  0.0097],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for leaving.\n",
      "lecherous is at index 2084\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-6.9382e-01, -7.2731e-01,  9.2147e-01,  ...,  1.7670e-01,\n",
      "          -2.3969e-02,  2.0083e-01],\n",
      "         [ 3.1013e-01, -2.9921e-01,  1.9111e-02,  ..., -1.4111e-01,\n",
      "          -2.7656e-01,  6.8266e-03],\n",
      "         [ 6.2312e-03, -3.8450e-01,  1.2523e-01,  ...,  3.1559e-01,\n",
      "          -3.8559e-01, -2.4341e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for lecherous.\n",
      "lecturing is at index 25673\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3585, -0.1531, -0.5229,  ..., -0.1786, -0.2270, -0.2636],\n",
      "         [-0.2070,  0.1855,  0.2401,  ..., -0.2010,  0.2415,  0.1745],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for lecturing.\n",
      "leering is at index 2084\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.6938, -0.7273,  0.9215,  ...,  0.1767, -0.0240,  0.2008],\n",
      "         [ 0.2306,  0.3185, -0.0189,  ...,  0.4856, -0.2807,  0.3472],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for leering.\n",
      "leery is at index 2084\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.6938, -0.7273,  0.9215,  ...,  0.1767, -0.0240,  0.2008],\n",
      "         [-0.1645,  0.1921, -0.3187,  ..., -0.2029, -0.1886,  0.1188],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for leery.\n",
      "letdown is at index 905\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2741, -0.4059,  0.5379,  ..., -0.2632, -0.4881,  0.2389],\n",
      "         [ 0.0937,  0.2674, -0.1077,  ...,  0.0327, -0.3287,  0.2273],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for letdown.\n",
      "lethargic is at index 35370\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2559, -0.1532,  0.2151,  ...,  0.2465,  0.2961,  0.0093],\n",
      "         [ 0.3057,  0.2415, -0.0685,  ..., -0.0040, -0.0574,  0.2186],\n",
      "         [ 0.2853,  0.3615,  0.0987,  ...,  0.1007, -0.1208,  0.0663],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for lethargic.\n",
      "levelheaded is at index 672\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2050, -0.2356,  0.2321,  ..., -0.0062, -0.2602,  0.4313],\n",
      "         [-0.3560,  0.0823, -0.1026,  ..., -0.0136, -0.3141, -0.0938],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for levelheaded.\n",
      "lewd is at index 31942\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0197,  0.0933, -0.0461,  ...,  0.0225, -0.3138,  0.1455],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for lewd.\n",
      "libidinous is at index 21748\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-7.5270e-02,  1.4840e-01,  1.3550e-01,  ...,  3.5753e-01,\n",
      "          -3.7614e-01, -7.5534e-01],\n",
      "         [ 1.9947e-01,  1.8897e-01,  1.6384e-01,  ..., -3.8353e-01,\n",
      "          -2.3598e-01,  6.7589e-01],\n",
      "         [ 2.2488e-02,  2.2280e-01,  1.7688e-01,  ...,  2.0158e-01,\n",
      "          -9.6036e-02, -7.4842e-02],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for libidinous.\n",
      "lifeless is at index 37019\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1645, -0.1363, -0.0510,  ...,  0.1853, -0.1023,  0.3723],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for lifeless.\n",
      "lighthearted is at index 1109\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2369, -0.6426,  0.0452,  ...,  0.1937, -0.2965, -0.1384],\n",
      "         [-0.1408,  0.2934, -0.1141,  ...,  0.0744,  0.0680,  0.7601],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for lighthearted.\n",
      "lipped is at index 784\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0497, -0.0139,  0.0576,  ...,  0.1354, -0.1139,  0.0267],\n",
      "         [ 0.1139,  0.7057,  0.1929,  ..., -0.0204, -0.1724,  0.0147],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for lipped.\n",
      "listening is at index 6288\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1632, -0.5674, -0.1336,  ...,  0.0153, -0.0300,  0.0452],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for listening.\n",
      "listless is at index 889\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2298, -0.5597,  0.1014,  ..., -0.5476, -0.2054,  0.3952],\n",
      "         [-0.0646, -0.7736,  0.2078,  ...,  0.1990, -0.4643, -0.1719],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for listless.\n",
      "lively is at index 20902\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2319, -0.1142,  0.1968,  ...,  0.5065, -0.0878,  0.3426],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for lively.\n",
      "livid is at index 784\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0497, -0.0139,  0.0576,  ...,  0.1354, -0.1139,  0.0267],\n",
      "         [ 0.2006,  0.7263,  0.0956,  ...,  0.0402,  0.0223,  0.4437],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for livid.\n",
      "loaded is at index 7973\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0013, -0.1641, -0.1732,  ..., -0.2736, -0.2877, -0.4688],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for loaded.\n",
      "loath is at index 4600\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0063,  0.0963,  0.2457,  ...,  0.5426, -0.1644,  0.3364],\n",
      "         [-0.1091, -0.1735,  0.4317,  ..., -0.2917, -0.4455,  0.3185],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for loath.\n",
      "loathe is at index 4600\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0063,  0.0963,  0.2457,  ...,  0.5426, -0.1644,  0.3364],\n",
      "         [-0.3984, -0.1727,  0.2171,  ..., -0.1943, -0.3059,  0.0464],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for loathe.\n",
      "loathing is at index 4600\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0063,  0.0963,  0.2457,  ...,  0.5426, -0.1644,  0.3364],\n",
      "         [-0.1788,  0.4200, -0.0538,  ..., -0.3887,  0.0771, -0.1037],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for loathing.\n",
      "loathsome is at index 4600\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0063,  0.0963,  0.2457,  ...,  0.5426, -0.1644,  0.3364],\n",
      "         [-0.1091, -0.1735,  0.4317,  ..., -0.2917, -0.4455,  0.3185],\n",
      "         [ 0.1292,  0.2240, -0.4392,  ...,  0.1288, -0.5614,  0.3773],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for loathsome.\n",
      "locked is at index 5930\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2564, -0.3967, -0.4382,  ...,  0.0282, -0.5732,  0.1395],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for locked.\n",
      "loneliness is at index 27942\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2475, -0.1157,  0.4353,  ..., -0.1512, -0.0893,  0.4839],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for loneliness.\n",
      "lonely is at index 20100\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3600, -0.1078,  0.5557,  ...,  0.0206, -0.3229,  0.1379],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for lonely.\n",
      "longing is at index 36171\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.4643, -0.0762,  0.0316,  ..., -0.1238,  0.3617,  0.0348],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for longing.\n",
      "looking is at index 546\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.4918, -0.6602,  0.3219,  ...,  0.5232, -0.0254,  0.4180],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for looking.\n",
      "loony is at index 4600\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0063,  0.0963,  0.2457,  ...,  0.5426, -0.1644,  0.3364],\n",
      "         [-0.2487,  0.3130,  0.4924,  ..., -0.1290,  0.0341,  0.1614],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for loony.\n",
      "loss is at index 872\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0059,  0.0832,  0.3822,  ...,  0.3303,  0.2884,  0.0713],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for loss.\n",
      "lost is at index 685\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.4502,  0.1266,  0.3421,  ...,  0.2634,  0.1103, -0.2076],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for lost.\n",
      "loud is at index 7337\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0289, -0.1275,  0.0453,  ...,  0.2233, -0.5587, -0.7254],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for loud.\n",
      "lousy is at index 38909\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0246, -0.2307, -0.1378,  ..., -0.0655,  0.2776, -0.2032],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for lousy.\n",
      "love is at index 657\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2001, -0.1250,  0.3818,  ...,  0.3047,  0.1862,  0.2213],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for love.\n",
      "loving is at index 8520\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2734,  0.2111,  0.3420,  ...,  0.3980,  0.0064,  0.3207],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for loving.\n",
      "lowliness is at index 614\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3148, -0.2477,  0.4092,  ..., -0.1979, -0.1141, -0.0161],\n",
      "         [-0.1671,  0.2610, -0.0677,  ..., -0.4525,  0.2214, -0.0660],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for lowliness.\n",
      "lurid is at index 30461\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2469, -0.5104,  0.0175,  ..., -0.1716, -0.6632,  0.1832],\n",
      "         [ 0.1995,  0.1890,  0.1638,  ..., -0.3835, -0.2360,  0.6759],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for lurid.\n",
      "lustful is at index 30864\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1253, -0.1759,  0.1194,  ..., -0.1519,  0.7352,  0.3592],\n",
      "         [ 0.3025,  0.1036, -0.3624,  ...,  0.1536, -0.4041, -0.2558],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for lustful.\n",
      "lusting is at index 30864\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1253, -0.1759,  0.1194,  ..., -0.1519,  0.7352,  0.3592],\n",
      "         [ 0.1383,  0.3796,  0.1368,  ...,  0.2405, -0.3453,  0.0233],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for lusting.\n",
      "lusty is at index 30864\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1253, -0.1759,  0.1194,  ..., -0.1519,  0.7352,  0.3592],\n",
      "         [ 0.1311, -0.1715,  0.0534,  ..., -0.0509, -0.4687, -0.2923],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for lusty.\n",
      "lying is at index 6480\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.4844, -0.1032,  0.1513,  ..., -0.2570, -0.5845,  0.1115],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for lying.\n",
      "mad is at index 7758\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0796, -0.0758,  0.4532,  ..., -0.2489, -0.0710, -0.2909],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for mad.\n",
      "maddened is at index 475\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-2.1500e-01, -5.3820e-02,  2.3417e-01,  ...,  4.4651e-02,\n",
      "          -1.4075e-03, -1.1451e-03],\n",
      "         [ 3.1033e-01,  4.5573e-01,  1.2322e-01,  ..., -4.6085e-01,\n",
      "          -9.1687e-02,  2.0571e-01],\n",
      "         [ 2.6623e-02, -3.7800e-01,  6.1400e-01,  ..., -2.6862e-02,\n",
      "          -2.5108e-01,  6.7815e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for maddened.\n",
      "madness is at index 24714\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2118, -0.0919,  0.0823,  ...,  0.1108, -0.0248, -0.0306],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for madness.\n",
      "malcontent is at index 8196\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0352, -0.0717,  0.3200,  ...,  0.5882, -0.0662,  0.2428],\n",
      "         [-0.4087,  0.0541, -0.3753,  ...,  0.0384, -0.0649,  0.0584],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for malcontent.\n",
      "maleficent is at index 8196\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0352, -0.0717,  0.3200,  ...,  0.5882, -0.0662,  0.2428],\n",
      "         [ 0.1032,  0.5414, -0.1054,  ..., -0.4561, -0.1238,  0.3903],\n",
      "         [-0.0968,  0.5577, -0.3554,  ..., -0.5715,  0.1083,  0.1359],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for maleficent.\n",
      "malevolent is at index 2943\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0560, -0.3698,  0.0541,  ..., -0.3228,  0.0410,  0.1685],\n",
      "         [-0.2090,  1.0067, -0.5977,  ..., -0.2023, -0.2609, -0.1132],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for malevolent.\n",
      "malice is at index 39625\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0092,  0.1774,  0.1146,  ..., -0.0168, -0.1291, -0.3405],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for malice.\n",
      "malicious is at index 15237\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0357,  0.4900, -0.2086,  ...,  0.1538,  0.0103, -0.3035],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for malicious.\n",
      "malignant is at index 8196\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0352, -0.0717,  0.3200,  ...,  0.5882, -0.0662,  0.2428],\n",
      "         [-0.1351,  0.6704,  0.1272,  ..., -0.0643, -0.4017, -0.3534],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for malignant.\n",
      "maniacal is at index 41288\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0027,  0.0439, -0.2529,  ...,  0.0225, -0.0435, -0.0888],\n",
      "         [ 0.0758, -0.0494,  0.4151,  ...,  0.1255, -0.5114,  0.3248],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for maniacal.\n",
      "manipulative is at index 39802\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1112,  0.1768, -0.4018,  ..., -0.1686, -0.0718,  0.3607],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for manipulative.\n",
      "marveled is at index 25591\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1602,  0.1861,  0.1409,  ...,  0.1780,  0.0037,  0.2274],\n",
      "         [-0.1786,  0.2013,  0.4345,  ...,  0.3394, -0.5501,  0.1632],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for marveled.\n",
      "master is at index 4710\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0359, -0.0109, -0.3880,  ..., -0.3868, -0.3148,  0.2464],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for master.\n",
      "mean is at index 1266\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1021, -0.0279,  0.3676,  ...,  0.6998, -0.2759, -0.1809],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for mean.\n",
      "meaningful is at index 6667\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2266, -0.0128,  0.5021,  ...,  0.3427,  0.0496,  0.1984],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for meaningful.\n",
      "meditative is at index 5679\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2791,  0.6335,  0.4258,  ...,  0.2323,  0.0205,  0.3353],\n",
      "         [ 0.3081,  0.6572, -0.0495,  ...,  0.0764,  0.1560,  0.6251],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for meditative.\n",
      "meek is at index 162\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2573,  0.0607, -0.1241,  ...,  0.5602, -0.0192,  0.0520],\n",
      "         [ 0.1597,  0.0379,  0.3052,  ..., -0.6666, -0.5599,  0.6064],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for meek.\n",
      "melancholic is at index 45565\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1305,  0.1496, -0.0402,  ...,  0.3026,  0.6161,  0.1776],\n",
      "         [ 0.0320,  1.0086, -0.2411,  ...,  0.1745, -0.3134, -0.6512],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for melancholic.\n",
      "melancholy is at index 40602\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0812,  0.0152,  0.5884,  ...,  0.5611,  0.5166,  0.0578],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for melancholy.\n",
      "mellow is at index 34384\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1593,  0.0098,  0.0047,  ...,  0.2685,  0.3566,  0.0112],\n",
      "         [ 0.2556,  0.1262,  0.5201,  ...,  0.1277, -0.0635,  0.1048],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for mellow.\n",
      "menace is at index 24213\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0607,  0.2366,  0.2786,  ..., -0.0248, -0.2473,  0.3415],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for menace.\n",
      "menacing is at index 32002\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3811,  0.1294,  0.3899,  ..., -0.0844, -0.3590,  0.2257],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for menacing.\n",
      "mental is at index 2536\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1164,  0.3656,  0.3592,  ..., -0.1223,  0.1263, -0.1138],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for mental.\n",
      "merrily is at index 9374\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0810,  0.1435,  0.5934,  ..., -0.2886, -0.1790,  0.2629],\n",
      "         [ 0.1785,  0.5838, -0.2429,  ...,  0.2990, -0.5237,  0.2459],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for merrily.\n",
      "merry is at index 35814\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3267,  0.2103,  0.0596,  ...,  0.3375,  0.1345,  0.3890],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for merry.\n",
      "mesmerized is at index 31294\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1591, -0.1448, -0.0240,  ...,  0.1039, -0.0523,  0.2263],\n",
      "         [-0.0545,  0.4248,  0.1878,  ...,  0.0940, -0.2454,  0.3326],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for mesmerized.\n",
      "miffed is at index 475\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2150, -0.0538,  0.2342,  ...,  0.0447, -0.0014, -0.0011],\n",
      "         [-0.0887,  0.4996,  0.0025,  ...,  0.1635, -0.3445,  0.4425],\n",
      "         [-0.0763,  0.0823,  0.3715,  ...,  0.3918, -0.5245,  0.1909],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for miffed.\n",
      "mild is at index 10439\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0118, -0.1986, -0.2889,  ...,  0.7079, -0.0539,  0.0180],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for mild.\n",
      "mincing is at index 5251\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0208,  0.1305, -0.2782,  ..., -0.0023, -0.1952, -0.2117],\n",
      "         [-0.5482,  0.6752, -0.0416,  ..., -0.3848,  0.1347,  0.3388],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for mincing.\n",
      "mindful is at index 20807\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0331, -0.2386,  0.1419,  ...,  0.1450,  0.4546,  0.2578],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for mindful.\n",
      "mindless is at index 41406\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1837, -0.4435,  0.0382,  ...,  0.2957, -0.2018,  0.1273],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for mindless.\n",
      "mirrored is at index 31349\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1960,  0.0943, -0.0970,  ..., -0.0642,  0.0092,  0.1018],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for mirrored.\n",
      "mirth is at index 475\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2150, -0.0538,  0.2342,  ...,  0.0447, -0.0014, -0.0011],\n",
      "         [-0.0926,  0.3154,  0.8135,  ..., -0.6388,  0.1166,  0.7723],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for mirth.\n",
      "mirthful is at index 475\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-2.1500e-01, -5.3820e-02,  2.3417e-01,  ...,  4.4651e-02,\n",
      "          -1.4075e-03, -1.1451e-03],\n",
      "         [-9.2599e-02,  3.1537e-01,  8.1352e-01,  ..., -6.3885e-01,\n",
      "           1.1658e-01,  7.7232e-01],\n",
      "         [ 3.9899e-01, -8.8491e-03, -4.2134e-01,  ...,  2.0336e-01,\n",
      "          -3.8005e-01, -2.2930e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for mirthful.\n",
      "misanthropic is at index 3834\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0617,  0.3061,  0.0236,  ...,  0.1142, -0.3544,  0.1322],\n",
      "         [-0.2958, -0.0500,  0.0403,  ..., -0.1365,  0.3389,  0.2060],\n",
      "         [ 0.2853,  0.3615,  0.0987,  ...,  0.1007, -0.1208,  0.0663],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for misanthropic.\n",
      "mischief is at index 26245\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2489,  0.1847,  0.0130,  ...,  0.0448,  0.6088,  0.2251],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for mischief.\n",
      "mischievous is at index 3834\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0617,  0.3061,  0.0236,  ...,  0.1142, -0.3544,  0.1322],\n",
      "         [ 0.1157,  0.1933,  0.0037,  ..., -0.0786,  0.1192,  0.1822],\n",
      "         [ 0.2415, -0.0133, -0.5033,  ...,  0.2422, -0.2725,  0.1041],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for mischievous.\n",
      "mischievousness is at index 3834\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0617,  0.3061,  0.0236,  ...,  0.1142, -0.3544,  0.1322],\n",
      "         [ 0.1157,  0.1933,  0.0037,  ..., -0.0786,  0.1192,  0.1822],\n",
      "         [ 0.2415, -0.0133, -0.5033,  ...,  0.2422, -0.2725,  0.1041],\n",
      "         [ 0.0038,  0.0321,  0.0331,  ..., -0.3626,  0.1786,  0.0489],\n",
      "         [ 0.2760, -0.1979, -0.1075,  ...,  0.4037,  0.0583,  0.1964]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for mischievousness.\n",
      "miserable is at index 20161\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1483,  0.1401,  0.6047,  ...,  0.3991,  0.0235,  0.1187],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for miserable.\n",
      "misery is at index 23110\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2866,  0.3456,  0.6881,  ...,  0.4033,  0.4562,  0.5206],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for misery.\n",
      "misgiving is at index 3834\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0617,  0.3061,  0.0236,  ...,  0.1142, -0.3544,  0.1322],\n",
      "         [ 0.0584, -0.3741,  0.0604,  ..., -0.2394,  0.3973,  0.1999],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for misgiving.\n",
      "mislead is at index 34747\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1232,  0.0643,  0.0156,  ...,  0.0326, -0.3283,  0.2313],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for mislead.\n",
      "mistrust is at index 34873\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1811,  0.1031,  0.0336,  ..., -0.1576, -0.1294,  0.2904],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for mistrust.\n",
      "mistrustful is at index 34873\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1811,  0.1031,  0.0336,  ..., -0.1576, -0.1294,  0.2904],\n",
      "         [ 0.3025,  0.1036, -0.3624,  ...,  0.1536, -0.4041, -0.2558],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for mistrustful.\n",
      "mistrusting is at index 34873\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1811,  0.1031,  0.0336,  ..., -0.1576, -0.1294,  0.2904],\n",
      "         [ 0.1383,  0.3796,  0.1368,  ...,  0.2405, -0.3453,  0.0233],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for mistrusting.\n",
      "misunderstood is at index 32085\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.4727,  0.5908, -0.4964,  ...,  0.0051, -0.2214, -0.2971],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for misunderstood.\n",
      "mockery is at index 34641\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1723, -0.2359, -0.0433,  ...,  0.4208,  0.4284,  0.7443],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for mockery.\n",
      "mocking is at index 27813\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.4920,  0.0515,  0.0151,  ...,  0.2515, -0.3520, -0.2588],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for mocking.\n",
      "mockingly is at index 16177\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3009,  0.0533,  0.0715,  ..., -0.4040, -0.7633,  0.3196],\n",
      "         [ 0.0652,  0.2826, -0.2308,  ..., -0.0222, -0.1180,  0.3459],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for mockingly.\n",
      "modest is at index 6473\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.4912, -0.2316,  0.1222,  ...,  0.1244,  0.1217, -0.1264],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for modest.\n",
      "monotone is at index 6154\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-2.5869e-01,  2.8800e-01,  5.9923e-01,  ...,  4.3933e-02,\n",
      "          -3.0830e-01, -3.2313e-01],\n",
      "         [ 1.0451e-01, -7.5795e-02,  2.8391e-01,  ..., -4.3262e-01,\n",
      "          -7.8964e-01,  2.0736e-01],\n",
      "         [ 2.1637e-01, -3.3830e-01,  1.9026e-01,  ...,  4.2577e-02,\n",
      "          -9.2810e-02,  4.8180e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for monotone.\n",
      "monster is at index 13317\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0978, -0.3250, -0.2569,  ..., -0.1033, -0.2357, -0.0771],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for monster.\n",
      "moody is at index 6711\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.5154,  0.2513,  0.0998,  ...,  0.5105,  0.0312,  0.4125],\n",
      "         [ 0.1311, -0.1715,  0.0534,  ..., -0.0509, -0.4687, -0.2923],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for moody.\n",
      "mopey is at index 475\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2150, -0.0538,  0.2342,  ...,  0.0447, -0.0014, -0.0011],\n",
      "         [ 0.1079,  0.2775, -0.2426,  ..., -0.1311, -0.5012, -0.1575],\n",
      "         [ 0.3820,  0.1638,  0.0383,  ..., -0.1842, -0.6474,  0.4836],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for mopey.\n",
      "morose is at index 14628\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0253, -0.3526,  0.1765,  ...,  0.3313, -0.0574,  0.2443],\n",
      "         [-0.5170,  0.1509,  0.1492,  ..., -0.1602,  0.1746,  0.7607],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for morose.\n",
      "mortified is at index 18631\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1093, -0.4963,  0.2949,  ..., -0.2622, -0.3332,  0.1112],\n",
      "         [-0.1058,  0.7447, -0.3643,  ..., -0.4003, -0.0682, -0.4061],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for mortified.\n",
      "motivated is at index 7958\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2846,  0.0628,  0.1507,  ...,  0.1441,  0.0358, -0.0509],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for motivated.\n",
      "mournful is at index 15213\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2595,  0.1323, -0.0098,  ...,  0.1132, -0.4200,  0.6204],\n",
      "         [ 0.3025,  0.1036, -0.3624,  ...,  0.1536, -0.4041, -0.2558],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for mournful.\n",
      "mournfulness is at index 15213\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2595,  0.1323, -0.0098,  ...,  0.1132, -0.4200,  0.6204],\n",
      "         [-0.2371,  0.1973, -0.2739,  ...,  0.0637,  0.1708,  0.2685],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for mournfulness.\n",
      "mourning is at index 19293\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0908,  0.1771,  0.3000,  ...,  0.2688, -0.1069,  0.2243],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for mourning.\n",
      "mouthed is at index 475\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-2.1500e-01, -5.3820e-02,  2.3417e-01,  ...,  4.4651e-02,\n",
      "          -1.4075e-03, -1.1451e-03],\n",
      "         [-1.4614e-01, -3.6347e-01, -1.4388e-01,  ..., -4.0734e-01,\n",
      "          -6.6047e-01,  3.2287e-01],\n",
      "         [-5.5869e-02, -3.2498e-01, -7.6261e-02,  ..., -2.2209e-01,\n",
      "           9.0629e-02,  8.5119e-02],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for mouthed.\n",
      "moved is at index 1410\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0344,  0.4298,  0.0581,  ...,  0.0631,  0.2570,  0.2698],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for moved.\n",
      "muddled is at index 475\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2150, -0.0538,  0.2342,  ...,  0.0447, -0.0014, -0.0011],\n",
      "         [-0.1427,  0.3743, -0.0782,  ..., -0.0856, -0.2652,  0.5185],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for muddled.\n",
      "mum is at index 8562\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2407, -0.1417, -0.0608,  ..., -0.1935, -0.0932, -0.2391],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for mum.\n",
      "murderous is at index 32883\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1219, -0.2497,  0.1102,  ...,  0.4143,  0.0601,  0.3678],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for murderous.\n",
      "musical is at index 4388\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0435,  0.5156,  0.0809,  ...,  0.1136,  0.0629, -0.1119],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for musical.\n",
      "musing is at index 11721\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1648,  0.4775,  0.3722,  ..., -0.0439, -0.0433,  0.3126],\n",
      "         [ 0.1383,  0.3796,  0.1368,  ...,  0.2405, -0.3453,  0.0233],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for musing.\n",
      "muster is at index 27665\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0490, -0.0467, -0.0949,  ...,  0.1896, -0.6134,  0.0018],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for muster.\n",
      "mute is at index 33758\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0297, -0.4160,  0.0151,  ..., -0.3761, -0.1936, -0.3264],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for mute.\n",
      "muted is at index 21677\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0557, -0.1134,  0.1147,  ...,  0.2950, -0.1769, -0.0846],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for muted.\n",
      "muttering is at index 16119\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2647, -0.1677, -0.7057,  ..., -0.1638, -0.0552,  0.1132],\n",
      "         [ 0.2417,  0.7037, -0.3129,  ..., -0.1221,  0.2416,  0.3714],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for muttering.\n",
      "mysterious is at index 12754\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2870, -0.0325, -0.3664,  ..., -0.1809, -0.1227, -0.5997],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for mysterious.\n",
      "mystical is at index 39795\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0986,  0.5487,  0.2300,  ...,  0.1521,  0.1791, -0.7516],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for mystical.\n",
      "mystified is at index 37763\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2537,  0.3595,  0.1942,  ..., -0.1739,  0.3611, -0.2673],\n",
      "         [-0.1058,  0.7447, -0.3643,  ..., -0.4003, -0.0682, -0.4061],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for mystified.\n",
      "naive is at index 25672\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1795, -0.2086,  0.1579,  ...,  0.0041,  0.0386, -0.2174],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for naive.\n",
      "napping is at index 295\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1867, -0.0902,  0.6961,  ...,  0.1752,  0.0099,  0.1367],\n",
      "         [ 0.0965,  0.6192,  0.0822,  ...,  0.0284, -0.0321,  0.0117],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for napping.\n",
      "narrow is at index 6787\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3522, -0.1296,  0.4522,  ...,  0.0557, -0.6843, -0.5881],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for narrow.\n",
      "nasty is at index 15455\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0846,  0.2901,  0.0947,  ...,  0.1327,  0.0433,  0.0219],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for nasty.\n",
      "natural is at index 1632\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2485,  0.1283,  0.6556,  ..., -0.0981, -0.1383,  0.4222],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for natural.\n",
      "natured is at index 23577\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0582, -0.2778,  0.2143,  ...,  0.1656,  0.2073,  0.1183],\n",
      "         [-0.2489, -0.3336,  0.2829,  ..., -0.4678, -0.1050, -0.1354],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for natured.\n",
      "naughty is at index 38384\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1214, -0.3013, -0.4955,  ...,  0.0466,  0.0116, -0.0229],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for naughty.\n",
      "nausea is at index 27214\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0831, -0.0185,  0.3775,  ...,  0.1018,  0.4265,  0.2897],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for nausea.\n",
      "nauseated is at index 39117\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1734,  0.1024,  0.4590,  ...,  0.2402,  0.0681, -0.4759],\n",
      "         [-0.0291,  1.0262,  0.5924,  ..., -0.1654,  0.0214,  0.4920],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for nauseated.\n",
      "nauseous is at index 39117\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1734,  0.1024,  0.4590,  ...,  0.2402,  0.0681, -0.4759],\n",
      "         [-0.0881, -0.2759,  0.1838,  ...,  0.2681, -0.4104, -0.2701],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for nauseous.\n",
      "needy is at index 28166\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2012,  0.0394, -0.0568,  ..., -0.0853, -0.1180, -0.0239],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for needy.\n",
      "nefarious is at index 33952\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0301,  0.7022, -0.3687,  ...,  0.1607,  0.0336,  0.2631],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for nefarious.\n",
      "negating is at index 15183\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0721,  0.1463,  0.6370,  ...,  0.0508,  0.2052, -0.1747],\n",
      "         [ 0.1687,  0.8291,  0.4266,  ..., -0.1742,  0.2603,  0.0939],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for negating.\n",
      "negative is at index 2430\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2892,  0.3669,  0.3665,  ...,  0.3385, -0.1097, -0.4294],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for negative.\n",
      "negativity is at index 30269\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2494,  0.1699,  0.4001,  ...,  0.1871,  0.5016, -0.0199],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for negativity.\n",
      "neglected is at index 20428\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0570, -0.2721, -0.0083,  ...,  0.2329, -0.1591,  0.2822],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for neglected.\n",
      "nerdy is at index 38286\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2136,  0.0863,  0.4123,  ...,  0.0595,  0.4625, -0.4010],\n",
      "         [ 0.3635,  0.6980, -0.1820,  ..., -0.3928, -0.5754,  0.0413],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for nerdy.\n",
      "nerved is at index 295\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1867, -0.0902,  0.6961,  ...,  0.1752,  0.0099,  0.1367],\n",
      "         [-0.4216,  0.7628,  0.6954,  ..., -0.0713,  0.0912, -0.0121],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for nerved.\n",
      "nerves is at index 17358\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0634,  0.5294,  0.6057,  ..., -0.0354,  0.2120, -0.3013],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for nerves.\n",
      "nervous is at index 7464\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.5792,  0.3271,  0.8480,  ..., -0.2942, -0.0975,  0.1979],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for nervous.\n",
      "nervously is at index 40968\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0756,  0.0725,  0.0735,  ..., -0.0140, -0.6057,  0.3121],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for nervously.\n",
      "nervousness is at index 7464\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.5792,  0.3271,  0.8480,  ..., -0.2942, -0.0975,  0.1979],\n",
      "         [-0.1231,  0.1777,  0.1255,  ..., -0.4542,  0.0778,  0.0067],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for nervousness.\n",
      "nescient is at index 295\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-1.8673e-01, -9.0221e-02,  6.9611e-01,  ...,  1.7520e-01,\n",
      "           9.8965e-03,  1.3674e-01],\n",
      "         [-2.7248e-03, -2.4564e-02,  9.4908e-02,  ...,  1.2072e-01,\n",
      "          -2.4992e-01,  6.6296e-01],\n",
      "         [-3.5646e-01,  5.4691e-01, -3.8082e-03,  ..., -1.7357e-01,\n",
      "          -1.9105e-01, -1.9644e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for nescient.\n",
      "nettled is at index 1161\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.5180, -0.3735,  0.4460,  ..., -0.4172, -0.0726, -0.2286],\n",
      "         [ 0.1047, -0.0191,  0.1024,  ...,  0.0027, -0.4629,  0.3404],\n",
      "         [ 0.0589, -0.2250,  0.0798,  ..., -0.1709, -0.0874,  0.2744],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for nettled.\n",
      "neutral is at index 7974\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2268,  0.0057,  0.3629,  ...,  0.3326, -0.3452, -0.2677],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for neutral.\n",
      "neutrality is at index 18755\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1538, -0.0205,  0.2531,  ...,  0.2150,  0.2576, -0.1012],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for neutrality.\n",
      "nice is at index 2579\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0783,  0.2101,  0.5576,  ...,  0.2677, -0.2455, -0.3696],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for nice.\n",
      "noisy is at index 28269\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1614,  0.0154, -0.2449,  ...,  0.0371, -0.6388, -0.2645],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for noisy.\n",
      "nonbelief is at index 786\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-2.4794e-01, -5.0717e-01,  1.3930e-01,  ..., -2.5016e-01,\n",
      "          -3.0070e-01, -3.5461e-01],\n",
      "         [ 6.4768e-01, -2.6858e-01,  8.7154e-02,  ...,  1.6787e-01,\n",
      "          -8.5439e-02,  7.2690e-01],\n",
      "         [ 4.2981e-01,  4.8165e-01, -4.0582e-02,  ..., -1.2691e-01,\n",
      "          -1.8412e-01,  4.2551e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for nonbelief.\n",
      "nonchalance is at index 786\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2479, -0.5072,  0.1393,  ..., -0.2502, -0.3007, -0.3546],\n",
      "         [-0.1604,  0.2363,  0.6033,  ..., -0.5225, -0.1975,  0.5785],\n",
      "         [-0.0256,  0.5733, -0.2744,  ...,  0.0088, -0.1345,  0.1096],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for nonchalance.\n",
      "nonchalant is at index 786\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-2.4794e-01, -5.0717e-01,  1.3930e-01,  ..., -2.5016e-01,\n",
      "          -3.0070e-01, -3.5461e-01],\n",
      "         [-1.6039e-01,  2.3635e-01,  6.0329e-01,  ..., -5.2250e-01,\n",
      "          -1.9754e-01,  5.7848e-01],\n",
      "         [-1.7943e-03, -7.2241e-01,  3.6607e-01,  ..., -1.9104e-01,\n",
      "           2.0683e-01, -5.7756e-02],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for nonchalant.\n",
      "noncommittal is at index 786\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2479, -0.5072,  0.1393,  ..., -0.2502, -0.3007, -0.3546],\n",
      "         [-0.0097,  0.5043, -0.3272,  ...,  0.2667, -0.4917,  0.5503],\n",
      "         [ 0.2424,  0.3395, -0.5111,  ...,  0.1912, -0.2890,  0.5100],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for noncommittal.\n",
      "noncompliant is at index 786\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-2.4794e-01, -5.0717e-01,  1.3930e-01,  ..., -2.5016e-01,\n",
      "          -3.0070e-01, -3.5461e-01],\n",
      "         [ 3.9359e-02,  1.2315e-01, -2.4823e-01,  ..., -5.5450e-02,\n",
      "          -5.1481e-01, -2.7380e-02],\n",
      "         [-1.2218e-01,  2.0410e-02, -7.4672e-01,  ..., -3.5828e-01,\n",
      "          -1.9005e-01,  1.5003e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for noncompliant.\n",
      "nonplussed is at index 786\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-2.4794e-01, -5.0717e-01,  1.3930e-01,  ..., -2.5016e-01,\n",
      "          -3.0070e-01, -3.5461e-01],\n",
      "         [-4.1439e-01,  5.5768e-02,  1.6912e-01,  ..., -2.3178e-02,\n",
      "          -6.3082e-01,  6.8241e-01],\n",
      "         [-1.7480e-01,  5.3073e-01, -1.4494e-01,  ..., -1.3860e-01,\n",
      "          -1.5462e-01,  9.6293e-02],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for nonplussed.\n",
      "nonsensical is at index 42475\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3135,  0.1010, -0.1164,  ...,  0.0580,  0.0082,  0.0334],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for nonsensical.\n",
      "normal is at index 2340\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.4216, -0.2271, -0.1617,  ...,  0.2371,  0.0744, -0.1841],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for normal.\n",
      "nosey is at index 8658\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0186, -0.2197,  1.0355,  ..., -0.0396, -0.1024,  0.3951],\n",
      "         [ 0.1311, -0.1715,  0.0534,  ..., -0.0509, -0.4687, -0.2923],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for nosey.\n",
      "nostalgic is at index 28055\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2084,  0.0873,  0.1054,  ...,  0.4069,  0.4826, -0.5365],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for nostalgic.\n",
      "nosy is at index 13736\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.4472, -0.1563,  0.7965,  ...,  0.4619, -0.3727, -0.1868],\n",
      "         [ 0.1311, -0.1715,  0.0534,  ..., -0.0509, -0.4687, -0.2923],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for nosy.\n",
      "numb is at index 31086\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.4212, -0.0241,  0.8813,  ..., -0.2545,  0.0082, -0.2611],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for numb.\n",
      "obedient is at index 44729\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0210, -0.1905, -0.0876,  ..., -0.3041, -0.1951,  0.2268],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for obedient.\n",
      "objecting is at index 7626\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3150,  0.0685, -0.3102,  ...,  0.7096,  0.1126,  0.5732],\n",
      "         [ 0.1383,  0.3796,  0.1368,  ...,  0.2405, -0.3453,  0.0233],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for objecting.\n",
      "objection is at index 24763\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1280,  0.2194, -0.3159,  ...,  0.2721, -0.1434,  0.1185],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for objection.\n",
      "objective is at index 4554\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0249,  0.3631,  0.3739,  ...,  0.4037, -0.0775, -0.1736],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for objective.\n",
      "obliged is at index 23964\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1424, -0.4607,  0.0041,  ..., -0.1036,  0.0050, -0.0540],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for obliged.\n",
      "obliging is at index 23762\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2843, -0.4978,  0.2971,  ...,  0.0310,  0.1078,  0.1377],\n",
      "         [ 0.1383,  0.3796,  0.1368,  ...,  0.2405, -0.3453,  0.0233],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for obliging.\n",
      "oblivious is at index 35606\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0858, -0.1333,  0.0228,  ..., -0.2393,  0.4311,  0.2209],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for oblivious.\n",
      "observant is at index 20717\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0245, -0.3922, -0.0859,  ...,  0.3303, -0.2640,  0.5438],\n",
      "         [-0.0978, -0.6161,  0.4288,  ..., -0.2426,  0.1850, -0.0844],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for observant.\n",
      "observing is at index 21981\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1331, -0.3226,  0.0481,  ...,  0.1417, -0.0626,  0.0997],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for observing.\n",
      "obsessed is at index 17593\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2763,  0.2836,  0.0841,  ..., -0.0195, -0.1470, -0.0915],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for obsessed.\n",
      "obstinate is at index 30896\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2127,  0.0769, -0.0015,  ..., -0.3075,  0.1187,  0.1323],\n",
      "         [-0.0737,  0.4937,  0.1707,  ...,  0.0505, -0.2632,  0.2483],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for obstinate.\n",
      "occupied is at index 9533\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.4844, -0.7160,  0.7337,  ..., -0.3900, -0.6526,  0.0918],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for occupied.\n",
      "odd is at index 8372\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3886, -0.0051,  0.1699,  ...,  0.4596,  0.0133, -0.5966],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for odd.\n",
      "odious is at index 7452\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0844, -0.0235,  0.6126,  ...,  0.2763,  0.0068,  0.0470],\n",
      "         [-0.0583,  0.2461,  0.3175,  ..., -0.0270, -0.2839, -0.2945],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for odious.\n",
      "off is at index 160\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1662,  0.1227,  0.1045,  ..., -0.0659, -0.6478,  0.1934],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for off.\n",
      "offended is at index 22169\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0686, -0.0799,  0.3930,  ..., -0.1740, -0.0167, -0.2864],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for offended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offensive is at index 2555\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0032, -0.2576, -0.0560,  ..., -0.0097, -0.4125, -0.2493],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for offensive.\n",
      "ogling is at index 1021\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3279, -0.4441,  0.0033,  ...,  0.5435, -0.0449, -0.1642],\n",
      "         [ 0.1615, -0.0974, -0.1730,  ..., -0.3229, -0.5420,  0.4371],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for ogling.\n",
      "okay is at index 8578\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0547,  0.0687,  0.5094,  ...,  0.2577, -0.4935,  0.0061],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for okay.\n",
      "on is at index 15\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0245, -0.0542,  0.3088,  ...,  0.1958, -0.3856, -0.0110],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for on.\n",
      "open is at index 490\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1056, -0.3731,  0.1850,  ..., -0.0570, -0.6085,  0.2455],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for open.\n",
      "openness is at index 23163\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1474, -0.3975,  0.3005,  ...,  0.1553,  0.1547,  0.1634],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for openness.\n",
      "opposed is at index 4340\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0544,  0.2427,  0.3455,  ...,  0.0859, -0.1805, -0.5096],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for opposed.\n",
      "oppositional is at index 39734\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3907,  0.0714,  0.0193,  ..., -0.0280,  0.4420, -0.0729],\n",
      "         [ 0.0929,  0.1246, -0.4798,  ...,  0.1128, -0.0688, -0.5002],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for oppositional.\n",
      "oppressed is at index 32881\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2029,  0.2117,  0.1301,  ..., -0.1076,  0.1288, -0.3903],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for oppressed.\n",
      "optimism is at index 9743\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.4121,  0.6976,  0.5095,  ...,  0.2492,  0.5039, -0.0190],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for optimism.\n",
      "optimistic is at index 7168\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1310,  0.6406,  0.3738,  ...,  0.2573,  0.2516,  0.0710],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for optimistic.\n",
      "ordering is at index 12926\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0054, -0.1827, -0.0466,  ...,  0.3321, -0.7171, -0.4164],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for ordering.\n",
      "orgasmic is at index 39396\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0709, -0.1604,  0.2198,  ..., -0.0246,  0.4623, -0.1531],\n",
      "         [ 0.1879,  0.4749,  0.1584,  ...,  0.0505, -0.1448,  0.0398],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for orgasmic.\n",
      "ornery is at index 50\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2663, -0.2147, -0.0515,  ...,  0.5056, -0.2008,  0.0348],\n",
      "         [-0.2130,  0.5143, -0.5034,  ...,  0.0676, -0.3542,  0.0702],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for ornery.\n",
      "ouch is at index 1021\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3279, -0.4441,  0.0033,  ...,  0.5435, -0.0449, -0.1642],\n",
      "         [-0.1735, -0.1055,  0.6236,  ..., -0.2852, -0.0077,  0.3662],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for ouch.\n",
      "out is at index 66\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2005, -0.0818,  0.2816,  ..., -0.0753, -0.6845,  0.3528],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for out.\n",
      "outburst is at index 28999\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0188,  0.2439, -0.6225,  ...,  0.0510, -0.1690,  0.0471],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for outburst.\n",
      "outcry is at index 19900\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1347,  0.3111, -0.0241,  ...,  0.1454, -0.1471,  0.2660],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for outcry.\n",
      "outed is at index 66\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2005, -0.0818,  0.2816,  ..., -0.0753, -0.6845,  0.3528],\n",
      "         [-0.1786,  0.2013,  0.4345,  ...,  0.3394, -0.5501,  0.1632],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for outed.\n",
      "outlandish is at index 35785\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1367,  0.0661, -0.0378,  ...,  0.2989,  0.0692, -0.3007],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for outlandish.\n",
      "outrage is at index 10618\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0986, -0.3230, -0.3017,  ...,  0.1083,  0.1131, -0.2153],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for outrage.\n",
      "outraged is at index 22339\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1642, -0.2229,  0.0112,  ...,  0.2826, -0.0716, -0.1335],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for outraged.\n",
      "outspoken is at index 16120\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0351,  0.0376, -0.1005,  ..., -0.0807, -0.0187,  0.1737],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for outspoken.\n",
      "overbearing is at index 81\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0958,  0.1313,  0.5339,  ...,  0.3791, -0.0526,  0.5940],\n",
      "         [ 0.0405,  0.3254, -0.3596,  ...,  0.0119,  0.0724,  0.1354],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for overbearing.\n",
      "overexcited is at index 39919\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-2.6570e-01, -4.1509e-01, -3.6109e-02,  ..., -1.0335e-01,\n",
      "          -1.3354e-01,  1.7463e-01],\n",
      "         [ 5.3353e-01,  7.2707e-01,  3.4534e-01,  ...,  1.6879e-02,\n",
      "          -4.9851e-01, -2.0228e-01],\n",
      "         [ 5.0011e-01,  7.6923e-01,  4.9628e-02,  ...,  1.1828e-02,\n",
      "           2.1502e-01,  1.0322e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for overexcited.\n",
      "overjoyed is at index 81\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-9.5787e-02,  1.3129e-01,  5.3385e-01,  ...,  3.7912e-01,\n",
      "          -5.2644e-02,  5.9401e-01],\n",
      "         [ 3.7488e-01,  3.3265e-01,  4.9834e-01,  ...,  2.2795e-04,\n",
      "          -5.3503e-01, -3.6168e-01],\n",
      "         [-7.6293e-02,  8.2298e-02,  3.7151e-01,  ...,  3.9176e-01,\n",
      "          -5.2446e-01,  1.9090e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for overjoyed.\n",
      "overshadowed is at index 22140\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0497, -0.0192,  0.1449,  ..., -0.3778,  0.0913, -0.2633],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for overshadowed.\n",
      "overstrung is at index 81\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0958,  0.1313,  0.5339,  ...,  0.3791, -0.0526,  0.5940],\n",
      "         [ 0.0232,  0.0113, -0.4245,  ..., -0.2486,  0.2409,  0.4824],\n",
      "         [-0.4069,  0.4513,  0.5727,  ...,  0.1675,  0.1120, -0.3204],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for overstrung.\n",
      "overwhelmed is at index 13203\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1952, -0.3013,  0.2744,  ..., -0.3181,  0.0216,  0.1279],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for overwhelmed.\n",
      "overworked is at index 81\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0958,  0.1313,  0.5339,  ...,  0.3791, -0.0526,  0.5940],\n",
      "         [-0.1438,  0.4500, -0.3455,  ..., -0.2164,  0.1989,  0.4118],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for overworked.\n",
      "overwrought is at index 42674\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0278,  0.0789,  0.4102,  ...,  0.1455, -0.0406,  0.5417],\n",
      "         [-0.3547,  0.9883, -0.1185,  ..., -0.7280,  0.2133,  0.0444],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for overwrought.\n",
      "pain is at index 2400\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.4238,  0.2561,  0.4378,  ..., -0.2559, -0.2000, -0.1962],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for pain.\n",
      "pained is at index 181\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2570,  0.1398,  0.2694,  ...,  0.0402, -0.2035,  0.0750],\n",
      "         [ 0.0622,  0.5197, -0.2450,  ..., -0.1089, -0.3638, -0.0757],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for pained.\n",
      "painful is at index 8661\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1359,  0.2560,  0.3510,  ...,  0.0932,  0.0193,  0.2825],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for painful.\n",
      "painfully is at index 32020\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0172, -0.0765,  0.2859,  ...,  0.0736,  0.0913,  0.3488],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for painfully.\n",
      "panic is at index 9810\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0363,  0.3198, -0.0015,  ..., -0.2659, -0.0858,  0.0509],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for panic.\n",
      "panicked is at index 28604\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0701,  0.5473, -0.1196,  ..., -0.1897, -0.0021,  0.3475],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for panicked.\n",
      "panicky is at index 5730\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1557,  0.0571,  0.7104,  ...,  0.0557, -0.0863, -0.2036],\n",
      "         [-0.2022,  0.6835, -0.0189,  ..., -0.0649, -0.1161,  0.3882],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for panicky.\n",
      "paralyzed is at index 28582\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0643,  0.1575,  0.4242,  ..., -0.1744, -0.2739,  0.1590],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for paralyzed.\n",
      "paranoid is at index 33554\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0035,  0.1638,  0.0705,  ..., -0.2510, -0.1231,  0.2433],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for paranoid.\n",
      "passionate is at index 8840\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1860,  0.2700, -0.0822,  ...,  0.0912,  0.2519, -0.1846],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for passionate.\n",
      "passive is at index 18718\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3895, -0.6215,  0.3041,  ...,  0.4912, -0.1408,  0.0509],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for passive.\n",
      "patience is at index 11383\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2039,  0.3225,  0.1632,  ..., -0.4700,  0.3265, -0.2913],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for patience.\n",
      "patient is at index 3186\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.5207,  0.0811,  0.2941,  ...,  0.0965, -0.2566, -0.0733],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for patient.\n",
      "patronizing is at index 18528\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1642, -0.1558, -0.2514,  ...,  0.3990,  0.3393, -0.0310],\n",
      "         [-0.0178,  0.5333,  0.0785,  ..., -0.2432, -0.0303,  0.2913],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for patronizing.\n",
      "pause is at index 13787\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3988, -0.0841,  0.0636,  ...,  0.0249,  0.5109, -0.3288],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for pause.\n",
      "pausing is at index 6044\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0855,  0.1853,  0.8279,  ...,  0.0181,  0.5349, -0.2998],\n",
      "         [-0.1349,  0.4999, -0.2391,  ..., -0.4129, -0.1906,  0.3051],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for pausing.\n",
      "peaceful is at index 7053\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1646,  0.1462,  0.1991,  ...,  0.2133, -0.5056, -0.1848],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for peaceful.\n",
      "peculiar is at index 28178\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0962,  0.4689,  0.0016,  ...,  0.3844, -0.1263,  0.0185],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for peculiar.\n",
      "peering is at index 3723\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0581, -0.1058,  0.0341,  ...,  0.3178, -0.3839,  0.2120],\n",
      "         [ 0.2306,  0.3185, -0.0189,  ...,  0.4856, -0.2807,  0.3472],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for peering.\n",
      "peeved is at index 32734\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2736, -0.5577,  0.4478,  ..., -0.0799,  0.1555, -0.3601],\n",
      "         [-0.2920,  0.4201, -0.1039,  ...,  0.1972, -0.1771, -0.0647],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for peeved.\n",
      "peevish is at index 3723\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-5.8139e-02, -1.0575e-01,  3.4145e-02,  ...,  3.1778e-01,\n",
      "          -3.8389e-01,  2.1202e-01],\n",
      "         [ 1.9626e-01, -6.8401e-02,  8.7034e-02,  ...,  6.4264e-02,\n",
      "          -9.5382e-01,  6.3970e-01],\n",
      "         [ 5.0026e-01, -4.0793e-01,  1.8632e-01,  ..., -3.7958e-02,\n",
      "          -1.7293e-01,  3.0884e-02],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for peevish.\n",
      "pensive is at index 181\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2570,  0.1398,  0.2694,  ...,  0.0402, -0.2035,  0.0750],\n",
      "         [-0.1209,  0.3619,  0.0772,  ...,  0.0235, -0.0182, -0.2705],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for pensive.\n",
      "peppy is at index 3723\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0581, -0.1058,  0.0341,  ...,  0.3178, -0.3839,  0.2120],\n",
      "         [ 0.3121,  0.3653,  0.1482,  ..., -0.2074, -0.2926,  0.6856],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for peppy.\n",
      "perceptive is at index 228\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0404, -0.0842,  0.4611,  ...,  0.3965,  0.2288, -0.1556],\n",
      "         [-0.4272,  0.6801, -0.0244,  ...,  0.0169,  0.0993,  0.3735],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for perceptive.\n",
      "perfidious is at index 32168\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0161,  0.0716, -0.0034,  ..., -0.2192, -0.2725, -0.2910],\n",
      "         [-0.1270,  0.3223,  0.5620,  ..., -0.2738, -0.2282,  0.1413],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for perfidious.\n",
      "perky is at index 228\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0404, -0.0842,  0.4611,  ...,  0.3965,  0.2288, -0.1556],\n",
      "         [-0.4044,  0.8069, -0.0090,  ..., -0.1264, -0.3957, -0.0152],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for perky.\n",
      "perplexed is at index 33708\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0425,  0.3463,  0.2576,  ...,  0.0192,  0.0707, -0.1297],\n",
      "         [-0.1786,  0.2013,  0.4345,  ...,  0.3394, -0.5501,  0.1632],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for perplexed.\n",
      "perplexing is at index 33708\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0425,  0.3463,  0.2576,  ...,  0.0192,  0.0707, -0.1297],\n",
      "         [ 0.1383,  0.3796,  0.1368,  ...,  0.2405, -0.3453,  0.0233],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for perplexing.\n",
      "persistent is at index 13109\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3025,  0.1117,  0.0071,  ...,  0.3057,  0.1852,  0.1672],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for persistent.\n",
      "personable is at index 621\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.5727,  0.2071,  0.3882,  ..., -0.0153, -0.6675, -0.4123],\n",
      "         [ 0.4713, -0.1066,  0.1604,  ...,  0.0613,  0.0895,  0.2098],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for personable.\n",
      "perturbed is at index 32819\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1987,  0.1919,  0.0736,  ..., -0.0891,  0.2874, -0.2714],\n",
      "         [ 0.2648,  0.0989,  0.1503,  ..., -0.5718,  0.3409, -0.3254],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for perturbed.\n",
      "perverse is at index 41271\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0663,  0.1310,  0.0419,  ...,  0.5536,  0.4086,  0.2189],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for perverse.\n",
      "pesky is at index 38432\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.4850,  0.0847, -0.2719,  ...,  0.1228,  0.3691,  0.0223],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for pesky.\n",
      "pessimism is at index 36494\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0399,  0.5018,  0.1132,  ..., -0.0644,  0.4791,  0.2749],\n",
      "         [ 0.2579,  0.0328,  0.2941,  ...,  0.1624,  0.2084,  0.5531],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for pessimism.\n",
      "pessimistic is at index 32415\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0740,  0.6500,  0.4088,  ...,  0.2927,  0.4878,  0.0864],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for pessimistic.\n",
      "pestered is at index 19024\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1821, -0.2540,  0.1676,  ..., -0.4983, -0.6086, -0.0023],\n",
      "         [ 0.1771,  0.1589,  0.0945,  ...,  0.1806, -0.3288,  0.3249],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for pestered.\n",
      "petitioning is at index 5265\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0406, -0.7881,  0.4556,  ..., -0.1420, -0.3531,  0.0044],\n",
      "         [ 0.1383,  0.3796,  0.1368,  ...,  0.2405, -0.3453,  0.0233],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for petitioning.\n",
      "petrified is at index 4716\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2627,  0.1699,  0.3237,  ..., -0.3476,  0.1522,  0.2090],\n",
      "         [ 0.1563,  0.4880, -0.0480,  ...,  0.4489, -0.3660, -0.2693],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for petrified.\n",
      "petty is at index 25070\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0398,  0.1820, -0.2506,  ..., -0.2642, -0.1212, -0.1157],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for petty.\n",
      "petulant is at index 4716\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-2.6275e-01,  1.6989e-01,  3.2369e-01,  ..., -3.4759e-01,\n",
      "           1.5218e-01,  2.0903e-01],\n",
      "         [ 9.5318e-02, -1.0351e-01,  6.0368e-01,  ...,  5.0878e-01,\n",
      "          -1.9864e-01, -5.9272e-02],\n",
      "         [-1.7943e-03, -7.2241e-01,  3.6607e-01,  ..., -1.9104e-01,\n",
      "           2.0683e-01, -5.7756e-02],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for petulant.\n",
      "picked is at index 2738\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0798,  0.3022,  0.3132,  ...,  0.1281, -0.5319,  0.1197],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for picked.\n",
      "piercing is at index 38105\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1495,  0.2981,  0.2593,  ...,  0.2277,  0.2269,  0.6725],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for piercing.\n",
      "pinched is at index 7756\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1998,  0.3272,  0.2463,  ...,  0.0350, -0.5091, -0.0968],\n",
      "         [-0.4913,  0.3303,  0.0863,  ..., -0.1675, -0.1343, -0.2704],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for pinched.\n",
      "pious is at index 44843\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1060,  0.3699,  0.2736,  ...,  0.6529,  0.1449, -0.6792],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for pious.\n",
      "piqued is at index 181\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2570,  0.1398,  0.2694,  ...,  0.0402, -0.2035,  0.0750],\n",
      "         [ 0.0195,  0.3226,  0.1574,  ...,  0.4919, -0.0452, -0.1824],\n",
      "         [-0.0763,  0.0823,  0.3715,  ...,  0.3918, -0.5245,  0.1909],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for piqued.\n",
      "pissed is at index 34449\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1932, -0.1629, -0.0264,  ..., -0.4366,  0.3495, -0.6300],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for pissed.\n",
      "pitiable is at index 8516\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [ 8.8662e-02, -5.2524e-04,  2.6245e-01,  ..., -5.2287e-01,\n",
      "           1.4841e-01,  4.7804e-01],\n",
      "         [ 8.3654e-02,  6.2700e-01,  2.2834e-01,  ..., -2.6818e-01,\n",
      "          -9.1640e-02,  9.5489e-02],\n",
      "         [ 1.9912e-01, -1.5637e-01, -7.9924e-02,  ...,  3.5773e-01,\n",
      "          -8.6763e-02,  2.1586e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for pitiable.\n",
      "pitiful is at index 8516\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0887, -0.0005,  0.2625,  ..., -0.5229,  0.1484,  0.4780],\n",
      "         [ 0.2073,  0.3928, -0.2104,  ..., -0.0912, -0.3504, -0.2985],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for pitiful.\n",
      "pity is at index 31373\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0962, -0.0649, -0.0558,  ...,  0.4779,  0.4534, -0.0204],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for pity.\n",
      "pitying is at index 31373\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0962, -0.0649, -0.0558,  ...,  0.4779,  0.4534, -0.0204],\n",
      "         [ 0.1383,  0.3796,  0.1368,  ...,  0.2405, -0.3453,  0.0233],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for pitying.\n",
      "placated is at index 15155\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0628, -0.3835,  0.0313,  ..., -0.2321, -0.1964,  0.3982],\n",
      "         [-0.0291,  1.0262,  0.5924,  ..., -0.1654,  0.0214,  0.4920],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for placated.\n",
      "placation is at index 15155\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0628, -0.3835,  0.0313,  ..., -0.2321, -0.1964,  0.3982],\n",
      "         [ 0.1896,  0.6529,  0.2115,  ...,  0.5904, -0.0469,  0.0362],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for placation.\n",
      "placid is at index 15155\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0628, -0.3835,  0.0313,  ..., -0.2321, -0.1964,  0.3982],\n",
      "         [ 0.1995,  0.1890,  0.1638,  ..., -0.3835, -0.2360,  0.6759],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for placid.\n",
      "plain is at index 10798\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1093, -0.3029, -0.0881,  ...,  0.3626, -0.9090, -0.2694],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for plain.\n",
      "plaintive is at index 46560\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1093,  0.0765,  0.0514,  ...,  0.0475, -0.0857,  0.2323],\n",
      "         [ 0.1941,  0.3173,  0.1725,  ...,  0.0227, -0.1611,  0.4399],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for plaintive.\n",
      "planning is at index 1884\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1706, -0.5678,  0.1726,  ...,  0.2863, -0.5050,  0.2520],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for planning.\n",
      "playful is at index 23317\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2404,  0.1040, -0.1265,  ...,  0.6750, -0.0407,  0.6019],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for playful.\n",
      "playfully is at index 310\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1778, -0.0023, -0.2750,  ...,  0.3871,  0.0021,  0.2167],\n",
      "         [-0.0888,  0.0999, -0.3792,  ...,  0.0177, -0.7239,  0.2116],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for playfully.\n",
      "pleading is at index 17532\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1208, -0.3402, -0.1766,  ...,  0.0011, -0.1470,  0.2993],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for pleading.\n",
      "pleasant is at index 16219\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0850,  0.4392,  0.4057,  ...,  0.5014, -0.4548, -0.4866],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for pleasant.\n",
      "pleased is at index 4343\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0773,  0.1326,  0.4202,  ...,  0.2062,  0.1183, -0.2738],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for pleased.\n",
      "pleasing is at index 25234\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0666,  0.0019,  0.2985,  ...,  0.4395, -0.1331,  0.0074],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for pleasing.\n",
      "pleasurable is at index 19518\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2814, -0.0964,  0.0451,  ...,  0.6343, -0.1361,  0.6877],\n",
      "         [-0.3943,  0.5272, -0.1196,  ..., -0.5518,  0.1920,  0.2120],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for pleasurable.\n",
      "pleasure is at index 10483\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1739, -0.0145,  0.2638,  ...,  0.0772, -0.1477, -0.4076],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for pleasure.\n",
      "pleasured is at index 19518\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2814, -0.0964,  0.0451,  ...,  0.6343, -0.1361,  0.6877],\n",
      "         [-0.2489, -0.3336,  0.2829,  ..., -0.4678, -0.1050, -0.1354],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for pleasured.\n",
      "pliant is at index 2968\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1461, -0.0244,  0.3992,  ..., -0.0937, -0.4945,  0.2382],\n",
      "         [-0.2093,  0.1216, -0.6925,  ..., -0.4027, -0.2113,  0.1260],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for pliant.\n",
      "plotting is at index 22849\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0163,  0.0555, -0.2700,  ..., -0.1134, -0.1899,  0.1216],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for plotting.\n",
      "poignant is at index 27274\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0713,  0.6484,  0.0222,  ...,  0.0201, -0.0587,  0.1685],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for poignant.\n",
      "pointed is at index 3273\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.7387, -0.1520,  0.3728,  ..., -0.0156,  0.0710, -0.0132],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for pointed.\n",
      "poised is at index 10137\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3782,  0.0560,  0.4162,  ..., -0.0284,  0.1511,  0.0581],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for poised.\n",
      "polite is at index 24908\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1235, -0.4075,  0.1364,  ...,  0.4767, -0.7592,  0.2908],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for polite.\n",
      "pompous is at index 34415\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3679,  0.3383,  0.6937,  ...,  0.4583, -0.4387, -0.1119],\n",
      "         [-0.0881, -0.2759,  0.1838,  ...,  0.2681, -0.4104, -0.2701],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for pompous.\n",
      "ponder is at index 31930\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3473,  0.0077,  0.2696,  ...,  0.0912,  0.1703, -0.0025],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for ponder.\n",
      "pondering is at index 13362\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0408,  0.0303,  0.6109,  ..., -0.5252, -0.1875,  0.4570],\n",
      "         [ 0.2306,  0.3185, -0.0189,  ...,  0.4856, -0.2807,  0.3472],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for pondering.\n",
      "pooping is at index 4202\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.4916, -0.2333,  0.4427,  ..., -0.4300,  0.4679, -0.2469],\n",
      "         [ 0.0782,  0.5663, -0.2880,  ..., -0.2828,  0.0338,  0.8884],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for pooping.\n",
      "pop is at index 3495\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1345,  0.4621,  0.2745,  ..., -0.1791, -0.1080, -0.3332],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for pop.\n",
      "posing is at index 12681\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2446,  0.1587, -0.3162,  ..., -0.1165,  0.0601,  0.4120],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for posing.\n",
      "positive is at index 1313\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0198,  0.2813,  0.4607,  ...,  0.5881, -0.1318, -0.0318],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for positive.\n",
      "positivity is at index 8593\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1258,  0.1780,  0.0912,  ...,  0.2480,  0.0986, -0.1607],\n",
      "         [ 0.0201,  0.6576, -0.0730,  ..., -0.0902, -0.2008, -0.3850],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for positivity.\n",
      "possibly is at index 3544\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1853, -0.4193, -0.2784,  ..., -0.0340, -0.2436,  0.3715],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for possibly.\n",
      "pout is at index 181\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2570,  0.1398,  0.2694,  ...,  0.0402, -0.2035,  0.0750],\n",
      "         [-0.1461, -0.3635, -0.1439,  ..., -0.4073, -0.6605,  0.3229],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for pout.\n",
      "pouting is at index 181\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2570,  0.1398,  0.2694,  ...,  0.0402, -0.2035,  0.0750],\n",
      "         [-0.0669,  0.6967, -0.2571,  ..., -0.3600, -0.4037,  0.2111],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for pouting.\n",
      "pouty is at index 181\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-2.5701e-01,  1.3981e-01,  2.6938e-01,  ...,  4.0193e-02,\n",
      "          -2.0354e-01,  7.4979e-02],\n",
      "         [-1.4614e-01, -3.6347e-01, -1.4388e-01,  ..., -4.0734e-01,\n",
      "          -6.6047e-01,  3.2287e-01],\n",
      "         [ 2.3049e-01, -2.8769e-01, -8.6994e-03,  ...,  1.2940e-03,\n",
      "          -4.4119e-01, -2.6326e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for pouty.\n",
      "powerful is at index 2247\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0024,  0.5520,  0.1956,  ..., -0.2652,  0.0720,  0.2386],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for powerful.\n",
      "powerless is at index 33128\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2429,  0.0860,  0.5669,  ..., -0.0420,  0.2441, -0.0720],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for powerless.\n",
      "pranking is at index 3349\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0953,  0.0361,  0.3726,  ...,  0.2389, -0.1440,  0.1083],\n",
      "         [ 0.0718,  0.9980, -0.2397,  ..., -0.0344, -0.4233,  0.1427],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for pranking.\n",
      "precarious is at index 27180\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0374,  0.0552,  0.2966,  ...,  0.0114,  0.4919,  0.0725],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for precarious.\n",
      "predatory is at index 29216\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2231,  0.1691,  0.0756,  ..., -0.2897,  0.0599,  0.2996],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for predatory.\n",
      "prejudiced is at index 34286\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.4536,  0.1977,  0.1368,  ...,  0.4983,  0.2184, -0.1589],\n",
      "         [-0.4012,  0.2121,  0.3380,  ..., -0.3584, -0.2318, -0.3762],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for prejudiced.\n",
      "preoccupied is at index 1198\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.4655,  0.0748, -0.2461,  ..., -0.3032, -0.0295, -0.0673],\n",
      "         [ 0.0717, -0.0815,  0.4079,  ..., -0.6051, -0.3301,  0.0482],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for preoccupied.\n",
      "prepared is at index 2460\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1370, -0.4896,  0.4233,  ..., -0.0710, -0.3668,  0.2560],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for prepared.\n",
      "preparing is at index 4568\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1298, -0.6015, -0.2541,  ..., -0.1701, -0.1777,  0.1893],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for preparing.\n",
      "pretending is at index 23748\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0126, -0.2598, -0.1352,  ..., -0.3416, -0.2721, -0.3138],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for pretending.\n",
      "pretentious is at index 11857\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1099, -0.4070,  0.3423,  ..., -0.0270, -0.2533, -0.1756],\n",
      "         [ 0.4252, -0.0196,  0.3629,  ...,  0.3727, -0.1321, -0.4687],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for pretentious.\n",
      "prideful is at index 7040\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1805, -0.0898,  0.0690,  ..., -0.1505, -0.1582, -0.3372],\n",
      "         [ 0.3025,  0.1036, -0.3624,  ...,  0.1536, -0.4041, -0.2558],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for prideful.\n",
      "priggish is at index 3349\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0953,  0.0361,  0.3726,  ...,  0.2389, -0.1440,  0.1083],\n",
      "         [ 0.3130,  0.2380,  0.0689,  ..., -0.2621, -0.4456,  0.3621],\n",
      "         [ 0.5003, -0.4079,  0.1863,  ..., -0.0380, -0.1729,  0.0309],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for priggish.\n",
      "primed is at index 32575\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1332, -0.4923,  0.0527,  ..., -0.1171,  0.0918, -0.4808],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for primed.\n",
      "private is at index 940\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1703,  0.3336, -0.1237,  ..., -0.5472, -0.2356, -0.1487],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for private.\n",
      "processing is at index 5774\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2812,  0.1474,  0.0914,  ..., -0.0591, -0.2504, -0.0078],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for processing.\n",
      "propositioning is at index 16104\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1283,  0.2904, -0.1255,  ..., -0.0545, -0.1246, -0.0217],\n",
      "         [ 0.1383,  0.3796,  0.1368,  ...,  0.2405, -0.3453,  0.0233],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for propositioning.\n",
      "proud is at index 2602\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0390,  0.1300, -0.0946,  ...,  0.1406, -0.3181, -0.0455],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for proud.\n",
      "provocative is at index 21051\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0994, -0.0163, -0.4207,  ...,  0.0357, -0.2084,  0.2219],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for provocative.\n",
      "provoke is at index 28184\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0261, -0.2567, -0.1815,  ...,  0.0267, -0.1826,  0.2297],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for provoke.\n",
      "provoked is at index 24972\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3607, -0.2611,  0.1359,  ..., -0.0075, -0.0734, -0.0635],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for provoked.\n",
      "provoking is at index 35359\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0871, -0.0496,  0.0831,  ..., -0.1108, -0.0741, -0.0654],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for provoking.\n",
      "prying is at index 181\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2570,  0.1398,  0.2694,  ...,  0.0402, -0.2035,  0.0750],\n",
      "         [ 0.0910,  1.1427, -0.1892,  ...,  0.5133, -0.3214,  0.1389],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for prying.\n",
      "psycho is at index 37338\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0573,  0.5718, -0.6150,  ...,  0.3686, -0.0271, -0.3534],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for psycho.\n",
      "psychotic is at index 41559\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0191,  0.2994,  0.1158,  ..., -0.1083,  0.6249, -0.2402],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for psychotic.\n",
      "puckish is at index 9258\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0194, -0.0211,  0.3903,  ...,  0.0269, -0.2830, -0.4571],\n",
      "         [ 0.4075, -0.2999,  0.2436,  ..., -0.0861, -0.1961,  0.0055],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for puckish.\n",
      "puerile is at index 181\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2570,  0.1398,  0.2694,  ...,  0.0402, -0.2035,  0.0750],\n",
      "         [ 0.2291,  0.1644, -0.0780,  ..., -0.3076, -0.1971, -0.0889],\n",
      "         [-0.2522, -0.4216, -0.3758,  ...,  0.0951,  0.3981,  0.4806],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for puerile.\n",
      "pugnacious is at index 181\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2570,  0.1398,  0.2694,  ...,  0.0402, -0.2035,  0.0750],\n",
      "         [ 0.0813,  0.6133,  0.5764,  ...,  0.1144,  0.3350,  0.4604],\n",
      "         [ 0.5336, -0.4755, -0.0800,  ...,  0.2191, -0.3124,  0.4769],\n",
      "         [ 0.1308, -0.1687, -0.4330,  ..., -0.1207, -0.2399, -0.2944],\n",
      "         [ 0.2760, -0.1979, -0.1075,  ...,  0.4037,  0.0583,  0.1964]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for pugnacious.\n",
      "punished is at index 14459\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1809, -0.4826,  0.0010,  ..., -0.0055, -0.5115,  0.2530],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for punished.\n",
      "punishing is at index 23477\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0905, -0.2474, -0.6569,  ...,  0.2938,  0.0265,  0.3089],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for punishing.\n",
      "punitive is at index 21987\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2209,  0.3529,  0.1432,  ...,  0.0651,  0.0858, -0.1050],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for punitive.\n",
      "punk is at index 19742\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1861, -0.5861, -0.3568,  ..., -0.1003,  0.0778, -0.2112],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for punk.\n",
      "puppyish is at index 20830\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1129, -0.4294, -0.0119,  ...,  0.0488,  0.1348,  0.2991],\n",
      "         [ 0.4075, -0.2999,  0.2436,  ..., -0.0861, -0.1961,  0.0055],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for puppyish.\n",
      "purposeful is at index 3508\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0780,  0.4449,  0.0201,  ..., -0.1504,  0.4074,  0.2058],\n",
      "         [ 0.3025,  0.1036, -0.3624,  ...,  0.1536, -0.4041, -0.2558],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for purposeful.\n",
      "pursed is at index 26934\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3879,  0.0569, -0.2507,  ..., -0.1263, -0.4852,  0.0262],\n",
      "         [-0.1786,  0.2013,  0.4345,  ...,  0.3394, -0.5501,  0.1632],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for pursed.\n",
      "put is at index 342\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1877, -0.1565,  0.4461,  ...,  0.1751, -0.3517, -0.0612],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for put.\n",
      "putting is at index 2057\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1277, -0.1481,  0.5007,  ...,  0.1483, -0.0902, -0.0011],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for putting.\n",
      "puzzled is at index 36742\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.4314,  0.3744,  0.1350,  ...,  0.2902, -0.1330, -0.2705],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for puzzled.\n",
      "puzzlement is at index 47037\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0292,  0.5542, -0.3393,  ...,  0.3746,  0.2023,  0.2971],\n",
      "         [-0.1817, -0.3683, -0.1828,  ...,  0.0339, -0.2513, -0.2172],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for puzzlement.\n",
      "qualms is at index 22043\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.4692,  0.3071,  0.2939,  ..., -0.3485, -0.0082,  0.4407],\n",
      "         [-0.5215,  0.5087,  0.2743,  ..., -0.0483,  0.0665, -0.1918],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for qualms.\n",
      "quarrelsome is at index 39486\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.5427,  0.2800,  0.2298,  ..., -0.0094, -0.0579,  0.0084],\n",
      "         [ 0.0364,  0.3358, -0.3846,  ...,  0.0812, -0.5889,  0.3547],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for quarrelsome.\n",
      "queasy is at index 1192\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3623, -0.5666,  0.7005,  ..., -0.0413, -0.0721, -0.0912],\n",
      "         [-0.2004,  0.1112, -0.0569,  ..., -0.5244, -0.6209, -0.6331],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for queasy.\n",
      "quenched is at index 2677\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-1.8768e-02, -1.3685e-01,  6.1861e-01,  ...,  1.6516e-01,\n",
      "          -5.2478e-02,  3.9589e-01],\n",
      "         [ 2.4538e-01,  4.4398e-02,  6.2909e-01,  ...,  1.3726e-01,\n",
      "          -5.0517e-01,  6.8084e-01],\n",
      "         [-3.9790e-01,  2.2115e-01,  2.8493e-02,  ..., -1.1910e-01,\n",
      "          -1.1143e-01, -2.4574e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for quenched.\n",
      "questionable is at index 12474\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2045,  0.1646,  0.2934,  ...,  0.3494, -0.1527,  0.0947],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for questionable.\n",
      "questioning is at index 8026\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1950,  0.2487,  0.1885,  ...,  0.3367,  0.1235,  0.0030],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for questioning.\n",
      "questioningly is at index 864\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.5275,  0.3069,  0.0191,  ...,  0.1291, -0.6273,  0.0124],\n",
      "         [ 0.0652,  0.2826, -0.2308,  ..., -0.0222, -0.1180,  0.3459],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for questioningly.\n",
      "quiet is at index 5128\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1881, -0.0972,  0.0531,  ..., -0.0023, -0.7728, -0.4038],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for quiet.\n",
      "quietness is at index 5128\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1881, -0.0972,  0.0531,  ..., -0.0023, -0.7728, -0.4038],\n",
      "         [-0.1231,  0.1777,  0.1255,  ..., -0.4542,  0.0778,  0.0067],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for quietness.\n",
      "quilt is at index 2677\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0188, -0.1369,  0.6186,  ...,  0.1652, -0.0525,  0.3959],\n",
      "         [-0.0781,  0.0959,  0.4249,  ...,  0.1356,  0.6255,  0.0032],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for quilt.\n",
      "quirky is at index 22364\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1134,  0.2826,  0.0593,  ...,  0.2718, -0.0078,  0.2475],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for quirky.\n",
      "quizzical is at index 29316\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0937,  0.1085, -0.3426,  ..., -0.2639, -0.2695,  0.3072],\n",
      "         [-0.3909,  0.5831,  0.0951,  ...,  0.2938,  0.2165, -0.0992],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for quizzical.\n",
      "rabid is at index 39660\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1412,  0.0497,  0.0796,  ...,  0.5240, -0.2573,  0.2441],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for rabid.\n",
      "racked is at index 20208\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0284, -0.2503, -0.0121,  ..., -0.1656, -0.1105, -0.0655],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for racked.\n",
      "radiant is at index 35787\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.4203,  0.1878,  0.3552,  ..., -0.0157, -0.0947,  0.1095],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for radiant.\n",
      "rage is at index 14706\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.4526, -0.4775, -0.2335,  ..., -0.1893, -0.1607, -0.0323],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for rage.\n",
      "raged is at index 31927\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0083,  0.5052, -0.3959,  ..., -0.0979, -0.2224,  0.1357],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for raged.\n",
      "ragged is at index 910\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1453, -0.1640,  0.1882,  ...,  0.0429, -0.1351,  0.0048],\n",
      "         [-0.0268,  0.2300, -0.0475,  ..., -0.2656, -0.1335, -0.2889],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for ragged.\n",
      "raging is at index 23333\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0251,  0.1136, -0.1850,  ..., -0.1615,  0.3313,  0.1576],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for raging.\n",
      "rancorous is at index 21560\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3620,  0.3762, -0.0323,  ..., -0.4140,  0.2440, -0.5821],\n",
      "         [ 0.1864,  0.2010, -0.5071,  ...,  0.2052, -0.1649,  0.2339],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for rancorous.\n",
      "randy is at index 910\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1453, -0.1640,  0.1882,  ...,  0.0429, -0.1351,  0.0048],\n",
      "         [-0.1330,  0.7225, -0.0665,  ...,  0.0050, -0.1650,  0.1351],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for randy.\n",
      "rapt is at index 34524\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0447, -0.8175,  0.1678,  ...,  0.1897, -0.2092, -0.1177],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for rapt.\n",
      "rattled is at index 21602\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0859,  0.5703,  0.2422,  ..., -0.5453,  0.3085, -0.1310],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for rattled.\n",
      "raving is at index 910\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1453, -0.1640,  0.1882,  ...,  0.0429, -0.1351,  0.0048],\n",
      "         [-0.0084,  0.1433,  0.3402,  ..., -0.6901,  0.0637, -0.2222],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for raving.\n",
      "reactive is at index 34729\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0319,  0.2969, -0.2332,  ...,  0.0695,  0.2227,  0.3178],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for reactive.\n",
      "ready is at index 1227\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2168, -0.4580, -0.0067,  ...,  0.1716, -0.2113, -0.1494],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for ready.\n",
      "realization is at index 24179\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0376, -0.0149,  0.1942,  ...,  0.1906,  0.5761, -0.1074],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for realization.\n",
      "reassured is at index 29336\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.4443,  0.0235,  0.4306,  ..., -0.4871, -0.0958, -0.0474],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for reassured.\n",
      "rebellious is at index 38017\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0236, -0.0406, -0.2894,  ...,  0.1264,  0.3686, -0.0815],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for rebellious.\n",
      "rebuke is at index 28155\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0238,  0.1685, -0.3271,  ..., -0.0242,  0.1681, -0.0446],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for rebuke.\n",
      "recalling is at index 20239\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0188,  0.1121, -0.0505,  ..., -0.1552,  0.0546,  0.0481],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for recalling.\n",
      "receptive is at index 33052\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0145,  0.1117,  0.0355,  ..., -0.0434, -0.2885,  0.2494],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for receptive.\n",
      "reckless is at index 13508\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2107, -0.1262,  0.0594,  ..., -0.1831, -0.0935, -0.0109],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for reckless.\n",
      "recoil is at index 44983\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2506,  0.2630, -0.1956,  ...,  0.2057, -0.0612,  0.0794],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for recoil.\n",
      "recoiling is at index 3872\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [ 1.2781e-01,  2.0098e-01, -4.6625e-02,  ...,  5.2780e-02,\n",
      "          -5.5178e-01, -4.9124e-01],\n",
      "         [ 6.8538e-01, -1.3212e-01,  1.9097e-01,  ..., -9.0910e-02,\n",
      "          -4.9989e-01, -2.1041e-01],\n",
      "         [ 7.2811e-01,  5.5505e-01, -8.0771e-02,  ..., -1.1237e-01,\n",
      "           1.8862e-01,  1.0138e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for recoiling.\n",
      "reflecting is at index 10811\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1978, -0.3409,  0.1436,  ...,  0.3840,  0.3413,  0.0978],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for reflecting.\n",
      "reflection is at index 12456\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1052, -0.2440,  0.0601,  ...,  0.3485,  0.1652,  0.2748],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for reflection.\n",
      "reflective is at index 22213\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1336, -0.2193,  0.1460,  ...,  0.5375,  0.0199,  0.1170],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for reflective.\n",
      "refulgent is at index 769\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1251, -0.1411,  0.1826,  ..., -0.0451, -0.3038, -0.2100],\n",
      "         [ 0.3025,  0.1036, -0.3624,  ...,  0.1536, -0.4041, -0.2558],\n",
      "         [ 0.1103,  0.0510, -0.4474,  ...,  0.2590,  0.0274,  0.6382],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for refulgent.\n",
      "refusing is at index 10520\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0227, -0.4318,  0.1757,  ...,  0.1558, -0.3250,  0.1641],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for refusing.\n",
      "regret is at index 9917\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.4204, -0.5607,  0.0984,  ..., -0.1304,  0.1406,  0.0297],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for regret.\n",
      "regretful is at index 9917\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.4204, -0.5607,  0.0984,  ..., -0.1304,  0.1406,  0.0297],\n",
      "         [ 0.3025,  0.1036, -0.3624,  ...,  0.1536, -0.4041, -0.2558],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for regretful.\n",
      "rejected is at index 3946\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0738,  0.0887,  0.0977,  ...,  0.5138, -0.0217,  0.2294],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for rejected.\n",
      "rejecting is at index 19695\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0260,  0.1007,  0.0341,  ...,  0.4726,  0.2308,  0.2425],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for rejecting.\n",
      "rejection is at index 16117\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3167,  0.0708, -0.1240,  ...,  0.3562,  0.2461,  0.3890],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for rejection.\n",
      "rejoicing is at index 24586\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1106, -0.1128, -0.0317,  ..., -0.0726,  0.0623,  0.2863],\n",
      "         [-0.0917,  0.5099,  0.1647,  ..., -0.2511,  0.3584,  0.0785],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for rejoicing.\n",
      "relaxation is at index 26545\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0750,  0.2345,  0.0687,  ...,  0.4213,  0.0768,  0.3810],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for relaxation.\n",
      "relaxed is at index 11956\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3180,  0.0078,  0.6777,  ...,  0.2446, -0.0649,  0.5741],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for relaxed.\n",
      "relentless is at index 16476\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2469, -0.1451, -0.3112,  ...,  0.3675,  0.1076,  0.2667],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for relentless.\n",
      "relief is at index 3500\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0525,  0.1596,  0.7148,  ...,  0.3555, -0.2549, -0.4802],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for relief.\n",
      "relieved is at index 15126\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0595,  0.1513,  0.5464,  ...,  0.1147, -0.3682, -0.2653],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for relieved.\n",
      "relived is at index 6258\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.5351,  0.2287,  0.1090,  ..., -0.1475,  0.4334,  0.1862],\n",
      "         [ 0.4794,  0.7077, -0.0094,  ..., -0.0380, -0.2651,  0.1629],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for relived.\n",
      "reluctant is at index 11923\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.4243, -0.0616,  0.1552,  ..., -0.2759, -0.0633,  0.0629],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for reluctant.\n",
      "reluctantly is at index 33146\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2013, -0.0700, -0.1091,  ...,  0.1033, -0.5565,  0.1420],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for reluctantly.\n",
      "remorse is at index 23312\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2940, -0.3056,  0.1216,  ..., -0.3116,  0.3656, -0.3658],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for remorse.\n",
      "remorseful is at index 23312\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2940, -0.3056,  0.1216,  ..., -0.3116,  0.3656, -0.3658],\n",
      "         [ 0.3025,  0.1036, -0.3624,  ...,  0.1536, -0.4041, -0.2558],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for remorseful.\n",
      "repelled is at index 25633\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3352,  0.0020, -0.1393,  ...,  0.3068,  0.3705,  0.4958],\n",
      "         [ 0.0799,  0.2606,  0.1885,  ..., -0.0373, -0.6506, -0.0965],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for repelled.\n",
      "repressed is at index 2851\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0769,  0.3353, -0.3578,  ...,  0.0853, -0.4305,  0.3688],\n",
      "         [ 0.2372, -0.0581,  0.0219,  ..., -0.6627, -0.0584,  0.0307],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for repressed.\n",
      "reproach is at index 2851\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0769,  0.3353, -0.3578,  ...,  0.0853, -0.4305,  0.3688],\n",
      "         [ 0.2030,  0.1383,  0.6013,  ..., -0.4930, -0.2280,  0.0478],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for reproach.\n",
      "reproachful is at index 2851\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0769,  0.3353, -0.3578,  ...,  0.0853, -0.4305,  0.3688],\n",
      "         [ 0.2030,  0.1383,  0.6013,  ..., -0.4930, -0.2280,  0.0478],\n",
      "         [ 0.3990, -0.0088, -0.4213,  ...,  0.2034, -0.3800, -0.2293],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for reproachful.\n",
      "repugnance is at index 2851\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0769,  0.3353, -0.3578,  ...,  0.0853, -0.4305,  0.3688],\n",
      "         [ 0.0813,  0.6133,  0.5764,  ...,  0.1144,  0.3350,  0.4604],\n",
      "         [ 0.2433, -0.1408, -0.4287,  ...,  0.2752, -0.4965,  0.3485],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for repugnance.\n",
      "repugnant is at index 2851\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0769,  0.3353, -0.3578,  ...,  0.0853, -0.4305,  0.3688],\n",
      "         [ 0.0813,  0.6133,  0.5764,  ...,  0.1144,  0.3350,  0.4604],\n",
      "         [ 0.2612, -0.0145,  0.1272,  ..., -0.0439,  0.2648, -0.1537],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for repugnant.\n",
      "repulsed is at index 2851\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0769,  0.3353, -0.3578,  ...,  0.0853, -0.4305,  0.3688],\n",
      "         [ 0.2779, -0.1580,  0.1383,  ...,  0.2511, -0.1571,  0.3641],\n",
      "         [-0.0763,  0.0823,  0.3715,  ...,  0.3918, -0.5245,  0.1909],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for repulsed.\n",
      "repulsion is at index 2851\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0769,  0.3353, -0.3578,  ...,  0.0853, -0.4305,  0.3688],\n",
      "         [ 0.1144,  1.0338,  0.5006,  ..., -0.0168, -0.2424,  0.2642],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for repulsion.\n",
      "resent is at index 31379\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0811,  0.0628,  0.0587,  ..., -0.1712, -0.0457,  0.0204],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for resent.\n",
      "resentful is at index 31379\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0811,  0.0628,  0.0587,  ..., -0.1712, -0.0457,  0.0204],\n",
      "         [ 0.3025,  0.1036, -0.3624,  ...,  0.1536, -0.4041, -0.2558],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for resentful.\n",
      "resenting is at index 31379\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0811,  0.0628,  0.0587,  ..., -0.1712, -0.0457,  0.0204],\n",
      "         [ 0.1383,  0.3796,  0.1368,  ...,  0.2405, -0.3453,  0.0233],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for resenting.\n",
      "resentment is at index 27111\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0306, -0.0140,  0.4012,  ..., -0.1122,  0.4991, -0.0960],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for resentment.\n",
      "reserved is at index 1875\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0874, -0.5322, -0.3001,  ..., -0.2677, -0.4226, -0.2839],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for reserved.\n",
      "resignation is at index 6985\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0624, -0.2041,  0.1157,  ..., -0.2906,  0.2933,  0.4721],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for resignation.\n",
      "resigned is at index 6490\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.4271, -0.1078,  0.4496,  ..., -0.2945, -0.0105,  0.6815],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for resigned.\n",
      "resilience is at index 13790\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0143,  0.4615,  0.1618,  ...,  0.0128,  0.6742,  0.1812],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for resilience.\n",
      "resistance is at index 5910\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3559,  0.2430,  0.2885,  ...,  0.1904,  0.3370,  0.3006],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for resistance.\n",
      "resistant is at index 19152\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1489,  0.2182,  0.1718,  ..., -0.0180,  0.1376,  0.3008],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for resistant.\n",
      "resistent is at index 11942\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2459, -0.3754,  0.1381,  ...,  0.0155,  0.1128,  0.4163],\n",
      "         [ 0.0903, -0.2613,  0.2799,  ...,  0.0009,  0.2593,  0.6205],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for resistent.\n",
      "resisting is at index 18907\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3740, -0.4675,  0.4142,  ...,  0.2050,  0.0851,  0.1756],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for resisting.\n",
      "resolute is at index 5032\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1675,  0.3592, -0.2357,  ...,  0.0481,  0.0156,  0.0276],\n",
      "         [ 0.2352,  0.9327, -0.0351,  ..., -0.1014, -0.0459,  0.5469],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for resolute.\n",
      "resolved is at index 8179\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2289,  0.0964,  0.0989,  ...,  0.0498,  0.0992,  0.2228],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for resolved.\n",
      "responsive is at index 20666\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2689,  0.0617, -0.2873,  ..., -0.0853, -0.3499,  0.5404],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for responsive.\n",
      "restful is at index 1079\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2473, -0.2521,  0.4122,  ...,  0.1479, -0.3978,  0.7482],\n",
      "         [ 0.3025,  0.1036, -0.3624,  ...,  0.1536, -0.4041, -0.2558],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for restful.\n",
      "resting is at index 18403\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3258,  0.0952,  0.0958,  ...,  0.3269, -0.3807,  0.4553],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for resting.\n",
      "restless is at index 36844\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0018, -0.3236,  0.1498,  ..., -0.2132,  0.2927,  0.3154],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for restless.\n",
      "restlessness is at index 1079\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2473, -0.2521,  0.4122,  ...,  0.1479, -0.3978,  0.7482],\n",
      "         [ 0.3333, -0.1008,  0.0248,  ...,  0.1785,  0.3837,  0.1668],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for restlessness.\n",
      "restrained is at index 25063\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.4413, -0.0315,  0.1037,  ...,  0.4608, -0.0329,  0.1772],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for restrained.\n",
      "restraint is at index 20219\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3798, -0.3550, -0.1293,  ...,  0.2040,  0.4509, -0.1622],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for restraint.\n",
      "retaliating is at index 18570\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0394, -0.3930, -0.4679,  ..., -0.1145,  0.2167,  0.1793],\n",
      "         [ 0.1687,  0.8291,  0.4266,  ..., -0.1742,  0.2603,  0.0939],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for retaliating.\n",
      "retaliatory is at index 18570\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0394, -0.3930, -0.4679,  ..., -0.1145,  0.2167,  0.1793],\n",
      "         [-0.2759, -0.2099, -0.0074,  ...,  0.0886, -0.0460,  0.0378],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for retaliatory.\n",
      "rethinking is at index 769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1251, -0.1411,  0.1826,  ..., -0.0451, -0.3038, -0.2100],\n",
      "         [ 0.0985,  0.4854, -0.0301,  ...,  0.0557,  0.4381,  0.1635],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for rethinking.\n",
      "reticence is at index 5494\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1021,  0.0987, -0.1158,  ...,  0.1691, -0.1172, -0.0691],\n",
      "         [ 0.1879,  0.4749,  0.1584,  ...,  0.0505, -0.1448,  0.0398],\n",
      "         [ 0.0933,  0.1282, -0.0739,  ...,  0.0117,  0.1063,  0.2404],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for reticence.\n",
      "reticent is at index 5494\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1021,  0.0987, -0.1158,  ...,  0.1691, -0.1172, -0.0691],\n",
      "         [-0.1825,  0.6600, -0.3045,  ..., -0.6183,  0.0878,  0.1133],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for reticent.\n",
      "revengeful is at index 13543\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3849, -0.3017, -0.3430,  ..., -0.4655,  0.2403, -0.1642],\n",
      "         [ 0.3025,  0.1036, -0.3624,  ...,  0.1536, -0.4041, -0.2558],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for revengeful.\n",
      "reverent is at index 26911\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [ 1.6724e-01,  4.0951e-02,  6.3386e-02,  ..., -1.4282e-01,\n",
      "          -2.8703e-01,  4.9597e-01],\n",
      "         [ 1.1946e-04,  1.8297e-01,  2.4901e-01,  ..., -1.0183e-01,\n",
      "          -7.6961e-01, -4.4653e-02],\n",
      "         [ 1.9912e-01, -1.5637e-01, -7.9924e-02,  ...,  3.5773e-01,\n",
      "          -8.6763e-02,  2.1586e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for reverent.\n",
      "revolted is at index 34633\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2044,  0.1707, -0.3057,  ..., -0.3636, -0.1284, -0.3973],\n",
      "         [-0.1084,  0.3250,  0.1687,  ...,  0.3673, -0.7062, -0.1580],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for revolted.\n",
      "revulsion is at index 6910\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1410,  0.5029, -0.2385,  ...,  0.5680, -0.5024, -0.0715],\n",
      "         [ 0.1144,  1.0338,  0.5006,  ..., -0.0168, -0.2424,  0.2642],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for revulsion.\n",
      "righteous is at index 37909\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3037,  0.2030,  0.0728,  ..., -0.0607, -0.2423, -0.1560],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for righteous.\n",
      "rigid is at index 24577\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1158, -0.0755, -0.0463,  ...,  0.3126, -0.0437,  0.0985],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for rigid.\n",
      "riled is at index 910\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1453, -0.1640,  0.1882,  ...,  0.0429, -0.1351,  0.0048],\n",
      "         [ 0.1684,  0.5575, -0.0496,  ..., -0.5884,  0.0185,  0.0401],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for riled.\n",
      "riotous is at index 13069\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0648, -0.4111, -0.5365,  ..., -0.1197, -0.3357,  0.2505],\n",
      "         [-0.0881, -0.2759,  0.1838,  ...,  0.2681, -0.4104, -0.2701],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for riotous.\n",
      "riveted is at index 32886\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3234,  0.3391,  0.1029,  ..., -0.1079, -0.4093, -0.0686],\n",
      "         [-0.1084,  0.3250,  0.1687,  ...,  0.3673, -0.7062, -0.1580],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for riveted.\n",
      "roar is at index 31733\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.7032,  0.2873,  0.1763,  ..., -0.2244, -0.3640,  0.1402],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for roar.\n",
      "roguish is at index 4533\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [ 1.0335e-02,  3.5905e-01,  4.1115e-01,  ...,  2.4029e-01,\n",
      "          -2.6521e-01,  9.5680e-03],\n",
      "         [ 2.6204e-01, -2.0899e-01, -4.4546e-02,  ..., -2.6594e-01,\n",
      "          -9.4202e-01,  3.8283e-03],\n",
      "         [ 5.0026e-01, -4.0793e-01,  1.8632e-01,  ..., -3.7958e-02,\n",
      "          -1.7293e-01,  3.0884e-02],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for roguish.\n",
      "roiled is at index 4533\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0103,  0.3590,  0.4112,  ...,  0.2403, -0.2652,  0.0096],\n",
      "         [ 0.1684,  0.5575, -0.0496,  ..., -0.5884,  0.0185,  0.0401],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for roiled.\n",
      "rough is at index 6744\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0403,  0.0326,  0.4263,  ...,  0.1300, -0.6410,  0.0583],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for rough.\n",
      "roused is at index 910\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1453, -0.1640,  0.1882,  ...,  0.0429, -0.1351,  0.0048],\n",
      "         [-0.0056,  0.2344, -0.1902,  ..., -0.3245,  0.1663,  0.2745],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for roused.\n",
      "rude is at index 21820\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.4444,  0.3866,  0.0620,  ..., -0.1093, -0.2297, -0.2347],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for rude.\n",
      "rueful is at index 910\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1453, -0.1640,  0.1882,  ...,  0.0429, -0.1351,  0.0048],\n",
      "         [ 0.0728, -0.2239,  0.5071,  ...,  0.0617,  0.1537, -0.4674],\n",
      "         [ 0.3990, -0.0088, -0.4213,  ...,  0.2034, -0.3800, -0.2293],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for rueful.\n",
      "ruffled is at index 910\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-1.4533e-01, -1.6402e-01,  1.8819e-01,  ...,  4.2945e-02,\n",
      "          -1.3511e-01,  4.7836e-03],\n",
      "         [ 3.0661e-01,  6.9952e-01, -4.5631e-02,  ...,  3.7726e-02,\n",
      "          -2.8382e-01,  9.3385e-02],\n",
      "         [ 5.8872e-02, -2.2500e-01,  7.9825e-02,  ..., -1.7086e-01,\n",
      "          -8.7378e-02,  2.7442e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for ruffled.\n",
      "ruminating is at index 11122\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0483, -0.2350,  0.4268,  ..., -0.2475, -0.0754,  0.1727],\n",
      "         [-0.0234,  0.9237, -0.4424,  ..., -0.4303, -0.2436,  0.1260],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for ruminating.\n",
      "rustled is at index 18309\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-7.2753e-02, -1.7096e-01, -5.9957e-02,  ...,  1.0431e-01,\n",
      "           4.4847e-01, -4.7271e-05],\n",
      "         [-4.0240e-02, -1.0977e-01,  1.3987e-01,  ..., -2.2130e-01,\n",
      "          -1.1149e-01,  2.4668e-01],\n",
      "         [ 1.9912e-01, -1.5637e-01, -7.9924e-02,  ...,  3.5773e-01,\n",
      "          -8.6763e-02,  2.1586e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for rustled.\n",
      "ruthless is at index 25597\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0574, -0.0187, -0.0648,  ...,  0.0330, -0.1055,  0.6637],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for ruthless.\n",
      "sad is at index 5074\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2281,  0.3021,  0.4615,  ...,  0.4601, -0.0119,  0.0825],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for sad.\n",
      "sadden is at index 23330\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2242,  0.1252,  0.3332,  ..., -0.0023, -0.2083, -0.1384],\n",
      "         [ 0.2454,  0.0444,  0.6291,  ...,  0.1373, -0.5052,  0.6808],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for sadden.\n",
      "saddened is at index 19934\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1266,  0.3879,  0.0817,  ...,  0.1926,  0.0326,  0.4468],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for saddened.\n",
      "sadistic is at index 5074\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2281,  0.3021,  0.4615,  ...,  0.4601, -0.0119,  0.0825],\n",
      "         [ 0.1147,  0.1744, -0.4991,  ...,  0.4511,  0.0892,  0.2464],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for sadistic.\n",
      "sadness is at index 17437\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2380,  0.6349,  0.5375,  ..., -0.0090,  0.3951,  0.3401],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for sadness.\n",
      "salacious is at index 6641\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2917,  0.1178,  0.0269,  ...,  0.2865, -0.5650, -0.1785],\n",
      "         [ 0.0169, -0.0371, -0.3503,  ..., -0.2053, -0.3313, -0.3332],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for salacious.\n",
      "salivating is at index 6641\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2917,  0.1178,  0.0269,  ...,  0.2865, -0.5650, -0.1785],\n",
      "         [ 0.2041,  0.2774, -0.3190,  ..., -0.0362, -0.4443,  0.2418],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for salivating.\n",
      "sanctimonious is at index 27600\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1689, -0.0973,  0.4013,  ...,  0.2547, -0.2242, -0.3623],\n",
      "         [ 0.3170,  0.1219, -0.2915,  ..., -0.1614, -0.4937,  0.1432],\n",
      "         [ 0.0340,  0.1387,  0.2609,  ...,  0.0206, -0.2610, -0.2692],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for sanctimonious.\n",
      "sane is at index 37091\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3074,  0.2747,  0.2057,  ...,  0.2478, -0.1975, -0.3255],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for sane.\n",
      "sanguine is at index 579\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1403, -0.0299, -0.1708,  ...,  0.2694,  0.1000,  0.1545],\n",
      "         [ 0.1813, -0.1474,  0.2464,  ...,  0.0721, -0.0954,  0.0122],\n",
      "         [ 0.0862,  0.0755,  0.4221,  ...,  0.0103, -0.2485,  0.3881],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for sanguine.\n",
      "sappy is at index 2241\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1097, -0.4587, -0.1689,  ..., -0.0484, -0.0774,  0.0904],\n",
      "         [ 0.3121,  0.3653,  0.1482,  ..., -0.2074, -0.2926,  0.6856],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for sappy.\n",
      "sarcasm is at index 38522\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.5134,  0.0095, -0.2283,  ..., -0.0124, -0.1529,  0.0043],\n",
      "         [-0.1604, -0.0084,  0.3909,  ..., -0.4423,  0.4670, -0.1188],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for sarcasm.\n",
      "sarcastic is at index 39580\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1092,  0.1534,  0.1906,  ...,  0.5339,  0.1119, -0.3415],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for sarcastic.\n",
      "sardonic is at index 579\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1403, -0.0299, -0.1708,  ...,  0.2694,  0.1000,  0.1545],\n",
      "         [ 0.0911,  0.1187, -0.2797,  ..., -0.1094,  0.1585,  0.4836],\n",
      "         [ 0.1555,  0.5492,  0.4023,  ..., -0.0421,  0.2466,  0.1442],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for sardonic.\n",
      "sassy is at index 579\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1403, -0.0299, -0.1708,  ...,  0.2694,  0.1000,  0.1545],\n",
      "         [ 0.0988,  0.6830,  0.1002,  ..., -0.2113, -0.1409,  0.4410],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for sassy.\n",
      "sated is at index 579\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1403, -0.0299, -0.1708,  ...,  0.2694,  0.1000,  0.1545],\n",
      "         [-0.0291,  1.0262,  0.5924,  ..., -0.1654,  0.0214,  0.4920],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for sated.\n",
      "satiated is at index 4005\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0114, -0.0611,  0.2199,  ...,  0.4982, -0.9805, -0.3139],\n",
      "         [-0.0259,  0.4460,  0.2169,  ...,  0.0611, -0.0919,  0.5177],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for satiated.\n",
      "satirical is at index 33937\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2360,  0.1328, -0.2384,  ..., -0.0678, -0.1982,  0.1215],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for satirical.\n",
      "satisfaction is at index 11658\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0293, -0.1946,  0.2445,  ...,  0.0492,  0.0382, -0.1755],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for satisfaction.\n",
      "satisfied is at index 10028\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2607, -0.2738,  0.3902,  ...,  0.0005,  0.0221, -0.2524],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for satisfied.\n",
      "satisfy is at index 15332\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3070, -0.1743, -0.1804,  ..., -0.2097,  0.1843, -0.2566],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for satisfy.\n",
      "saturnine is at index 4005\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-1.1390e-02, -6.1098e-02,  2.1989e-01,  ...,  4.9823e-01,\n",
      "          -9.8053e-01, -3.1390e-01],\n",
      "         [ 4.5892e-01,  2.9596e-01,  2.8653e-01,  ...,  1.2926e-01,\n",
      "          -2.8153e-01, -6.0750e-02],\n",
      "         [ 8.6211e-02,  7.5479e-02,  4.2213e-01,  ...,  1.0289e-02,\n",
      "          -2.4846e-01,  3.8815e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for saturnine.\n",
      "saucy is at index 2241\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [ 1.0970e-01, -4.5871e-01, -1.6890e-01,  ..., -4.8431e-02,\n",
      "          -7.7406e-02,  9.0382e-02],\n",
      "         [ 3.2370e-01, -2.1708e-02,  2.3280e-01,  ..., -4.6612e-01,\n",
      "          -4.4607e-01,  8.4645e-02],\n",
      "         [ 3.4666e-01,  7.3579e-01,  2.1605e-01,  ..., -1.0289e-02,\n",
      "          -6.2435e-01,  4.2349e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for saucy.\n",
      "savage is at index 32264\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3040,  0.3252, -0.2031,  ..., -0.0474,  0.2087,  0.0745],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for savage.\n",
      "scandalized is at index 4220\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0508, -0.3771, -0.2061,  ..., -0.2241, -0.1194,  0.0010],\n",
      "         [-0.0545,  0.4248,  0.1878,  ...,  0.0940, -0.2454,  0.3326],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for scandalized.\n",
      "scare is at index 13207\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1462,  0.3480,  0.0973,  ..., -0.1408, -0.1899,  0.3129],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for scare.\n",
      "scared is at index 8265\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1925,  0.1387,  0.4925,  ..., -0.4250, -0.1783, -0.2454],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for scared.\n",
      "scary is at index 10222\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0354,  0.5157,  0.3407,  ..., -0.1894, -0.4363, -0.1423],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for scary.\n",
      "scattered is at index 12827\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1190,  0.1354, -0.2959,  ..., -0.0967, -0.1278,  0.0961],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for scattered.\n",
      "schadenfreude is at index 8447\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-5.1811e-01, -6.5696e-02,  1.9528e-01,  ...,  4.6349e-04,\n",
      "          -1.1613e-01,  2.5263e-02],\n",
      "         [ 1.2340e-03,  2.1374e-01,  2.8942e-01,  ..., -5.2066e-01,\n",
      "          -1.9314e-01, -1.6943e-01],\n",
      "         [ 3.7936e-01, -2.4989e-01, -4.2581e-01,  ..., -6.7693e-01,\n",
      "           2.1439e-01, -8.1422e-02],\n",
      "         [-1.3948e-01,  5.1012e-01, -9.2145e-02,  ..., -3.9908e-02,\n",
      "          -2.1270e-01, -3.9114e-02],\n",
      "         [ 2.7604e-01, -1.9787e-01, -1.0754e-01,  ...,  4.0371e-01,\n",
      "           5.8283e-02,  1.9644e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for schadenfreude.\n",
      "scheming is at index 30315\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1324,  0.0799, -0.3180,  ..., -0.4649,  0.1119,  0.1107],\n",
      "         [-0.2600,  0.5932, -0.2369,  ..., -0.0972, -0.4669, -0.1684],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for scheming.\n",
      "scoffer is at index 34564\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0408, -0.0530,  0.2208,  ...,  0.5449, -0.0454, -0.2802],\n",
      "         [ 0.4303,  0.2150, -0.2271,  ..., -0.0656, -0.3551,  0.0153],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for scoffer.\n",
      "scoffing is at index 34564\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0408, -0.0530,  0.2208,  ...,  0.5449, -0.0454, -0.2802],\n",
      "         [ 0.1383,  0.3796,  0.1368,  ...,  0.2405, -0.3453,  0.0233],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for scoffing.\n",
      "scorn is at index 38430\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [ 2.2801e-01, -1.5888e-01,  1.4280e-04,  ...,  2.9145e-01,\n",
      "           1.2041e-01,  1.4556e-01],\n",
      "         [ 9.2431e-02, -2.9484e-02, -1.2872e-02,  ...,  3.0573e-01,\n",
      "          -1.1492e-01,  1.8911e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for scorn.\n",
      "scorned is at index 2850\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.7612,  0.1447, -0.2248,  ...,  0.3136, -0.3179, -0.0599],\n",
      "         [-0.2680,  0.0038, -0.1627,  ...,  0.0702, -0.4637, -0.1172],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for scorned.\n",
      "scornful is at index 38430\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [ 2.2801e-01, -1.5888e-01,  1.4280e-04,  ...,  2.9145e-01,\n",
      "           1.2041e-01,  1.4556e-01],\n",
      "         [ 3.0251e-01,  1.0359e-01, -3.6240e-01,  ...,  1.5361e-01,\n",
      "          -4.0406e-01, -2.5580e-01],\n",
      "         [ 1.9912e-01, -1.5637e-01, -7.9924e-02,  ...,  3.5773e-01,\n",
      "          -8.6763e-02,  2.1586e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for scornful.\n",
      "scowl is at index 2850\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.7612,  0.1447, -0.2248,  ...,  0.3136, -0.3179, -0.0599],\n",
      "         [ 0.0109,  0.0860,  0.4155,  ..., -0.0355, -0.4575,  0.0642],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for scowl.\n",
      "scowling is at index 2850\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-7.6122e-01,  1.4467e-01, -2.2479e-01,  ...,  3.1364e-01,\n",
      "          -3.1794e-01, -5.9893e-02],\n",
      "         [ 2.5563e-01,  1.2622e-01,  5.2012e-01,  ...,  1.2770e-01,\n",
      "          -6.3483e-02,  1.0476e-01],\n",
      "         [ 4.9880e-02, -2.1098e-01,  3.4535e-01,  ..., -2.7677e-01,\n",
      "          -1.0062e-01,  3.0451e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for scowling.\n",
      "scream is at index 22093\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0328, -0.0270,  0.2416,  ...,  0.1315, -0.4539,  0.1555],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for scream.\n",
      "screaming is at index 11347\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3295, -0.4053, -0.0946,  ...,  0.0333, -0.2053,  0.1520],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for screaming.\n",
      "scrutinizing is at index 18470\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0621, -0.1922, -0.2255,  ...,  0.4373, -0.4342,  0.4257],\n",
      "         [-0.0178,  0.5333,  0.0785,  ..., -0.2432, -0.0303,  0.2913],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for scrutinizing.\n",
      "sealed is at index 10497\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1277, -0.2156, -0.1287,  ..., -0.1518,  0.0765, -0.5167],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for sealed.\n",
      "searching is at index 6062\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1562, -0.4888, -0.0869,  ...,  0.0682, -0.3397,  0.3173],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for searching.\n",
      "secretive is at index 27174\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0197,  0.0516, -0.6041,  ..., -0.0896,  0.0786,  0.3152],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for secretive.\n",
      "secretively is at index 3556\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1399,  0.2869, -0.5072,  ..., -0.2869, -0.0891, -0.4975],\n",
      "         [ 0.2512,  0.2734, -0.0256,  ...,  0.0393, -0.2657,  0.5681],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for secretively.\n",
      "secure is at index 2823\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0439, -0.1263,  0.3278,  ..., -0.2811, -0.1804,  0.0547],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for secure.\n",
      "sedate is at index 10195\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0537,  0.0518, -0.3108,  ...,  0.1080,  0.1934, -0.0099],\n",
      "         [-0.3462,  0.2802, -0.0972,  ...,  0.2098, -0.1504,  0.2755],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for sedate.\n",
      "seduction is at index 10195\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0537,  0.0518, -0.3108,  ...,  0.1080,  0.1934, -0.0099],\n",
      "         [ 0.0839,  0.3713, -0.8967,  ..., -0.2177,  0.0681, -0.1792],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for seduction.\n",
      "seductive is at index 10195\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0537,  0.0518, -0.3108,  ...,  0.1080,  0.1934, -0.0099],\n",
      "         [ 0.1956,  1.1851, -0.5950,  ..., -0.0265,  0.0229,  0.3400],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for seductive.\n",
      "seething is at index 842\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1717, -0.3277,  0.2666,  ..., -0.0664, -0.2551, -0.1933],\n",
      "         [ 0.2150, -0.0975,  0.2144,  ..., -0.5394, -0.4805,  0.0656],\n",
      "         [ 0.2157, -0.1995,  0.2899,  ..., -0.2893, -0.3630, -0.0463],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for seething.\n",
      "self is at index 1403\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0978, -0.3543,  0.4850,  ...,  0.0534, -0.0124, -0.3000],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for self.\n",
      "sensual is at index 18105\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2592,  0.0638,  0.6648,  ...,  0.1637, -0.0736,  0.1971],\n",
      "         [ 0.3085, -0.2544,  0.3521,  ...,  0.0270, -0.0454,  0.0202],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for sensual.\n",
      "sentimental is at index 32693\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2361,  0.4391,  0.2905,  ...,  0.1527,  0.4251, -0.3022],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for sentimental.\n",
      "serene is at index 842\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1717, -0.3277,  0.2666,  ..., -0.0664, -0.2551, -0.1933],\n",
      "         [ 0.0646,  0.3740,  0.4937,  ...,  0.0976, -0.3743,  0.5973],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for serene.\n",
      "serious is at index 1473\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3161,  0.3804,  0.1421,  ...,  0.2574, -0.0860,  0.1283],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for serious.\n",
      "seriousness is at index 24146\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3159,  0.2725,  0.1860,  ..., -0.0486,  0.1413,  0.1281],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for seriousness.\n",
      "servile is at index 18527\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0709, -0.5155,  0.0447,  ...,  0.1354, -0.4577, -0.4189],\n",
      "         [-0.3470, -0.3129, -0.3190,  ...,  0.0467,  0.3759,  0.4561],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for servile.\n",
      "set is at index 278\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3380, -0.2120,  0.2659,  ..., -0.0869, -0.1655, -0.5669],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for set.\n",
      "severe is at index 3814\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3732,  0.3760, -0.2295,  ...,  0.3188,  0.0546,  0.3280],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for severe.\n",
      "shabby is at index 1481\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.6479, -0.5010,  0.1013,  ..., -0.0209, -0.0260, -0.3201],\n",
      "         [ 0.2213,  1.1635,  0.5288,  ...,  0.3689, -0.9955,  0.2050],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for shabby.\n",
      "shady is at index 31665\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1568,  0.2195,  0.4133,  ...,  0.0297, -0.0406, -0.3178],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for shady.\n",
      "shaken is at index 17548\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0665,  0.1269,  0.1243,  ..., -0.0575,  0.3365,  0.2295],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for shaken.\n",
      "shaky is at index 22032\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0138,  0.2207,  0.3234,  ..., -0.3445,  0.2356, -0.1108],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for shaky.\n",
      "shame is at index 9208\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0058, -0.4668,  0.2747,  ..., -0.4623,  0.0990,  0.1607],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for shame.\n",
      "shamed is at index 1481\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.6479, -0.5010,  0.1013,  ..., -0.0209, -0.0260, -0.3201],\n",
      "         [ 0.0505,  0.0059,  0.1942,  ..., -0.4513, -0.3499,  0.0357],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for shamed.\n",
      "shamefaced is at index 9208\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0058, -0.4668,  0.2747,  ..., -0.4623,  0.0990,  0.1607],\n",
      "         [-0.0952,  0.0830, -0.2540,  ..., -0.5868, -0.1641, -0.4385],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for shamefaced.\n",
      "shameful is at index 26722\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2749, -0.2655, -0.4362,  ...,  0.2464,  0.0881, -0.1016],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for shameful.\n",
      "shameless is at index 36778\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.4129, -0.5664, -0.1153,  ..., -0.3202, -0.1405,  0.2428],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for shameless.\n",
      "sharp is at index 4406\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1609,  0.0623, -0.2888,  ...,  0.3321, -0.1815,  0.4989],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for sharp.\n",
      "sheepish is at index 14336\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.6222, -0.3506,  0.2166,  ..., -0.6096, -0.0940, -0.1632],\n",
      "         [ 0.4075, -0.2999,  0.2436,  ..., -0.0861, -0.1961,  0.0055],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for sheepish.\n",
      "sheepishness is at index 14336\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.6222, -0.3506,  0.2166,  ..., -0.6096, -0.0940, -0.1632],\n",
      "         [ 0.4075, -0.2999,  0.2436,  ..., -0.0861, -0.1961,  0.0055],\n",
      "         [-0.0261,  0.0648,  0.0660,  ..., -0.4037,  0.1015,  0.0331],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for sheepishness.\n",
      "shelled is at index 79\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0189, -0.0913, -0.0187,  ...,  0.4871, -0.2676,  0.3376],\n",
      "         [ 0.0799,  0.2606,  0.1885,  ..., -0.0373, -0.6506, -0.0965],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for shelled.\n",
      "shifty is at index 37503\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1153, -0.4884,  0.0773,  ..., -0.1680,  0.0061,  0.0477],\n",
      "         [ 0.0507,  0.2282, -0.2432,  ..., -0.2395,  0.0726, -0.2768],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for shifty.\n",
      "shock is at index 4817\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2567,  0.4126,  0.2451,  ...,  0.1759,  0.2220,  0.0670],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for shock.\n",
      "shocked is at index 6649\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3091,  0.1893,  0.0437,  ...,  0.0736, -0.1138,  0.1143],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for shocked.\n",
      "shocking is at index 8777\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0965,  0.1095, -0.4453,  ..., -0.0764,  0.0739,  0.1407],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for shocking.\n",
      "shockingly is at index 36804\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0948,  0.0887,  0.0006,  ..., -0.0886, -0.2349,  0.2361],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for shockingly.\n",
      "shook is at index 14774\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0072,  0.5043,  0.0389,  ..., -0.5936,  0.3930,  0.0882],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for shook.\n",
      "shout is at index 18066\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3185, -0.3575, -0.0088,  ..., -0.0789, -0.2590,  0.1145],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for shout.\n",
      "shouting is at index 14487\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1946, -0.4336, -0.2280,  ...,  0.0305, -0.2955, -0.1149],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for shouting.\n",
      "shrewd is at index 36943\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1827,  0.1088,  0.0305,  ..., -0.1196,  0.2197,  0.1597],\n",
      "         [-0.0445, -0.0307, -0.1699,  ...,  0.1606, -0.2926,  0.5322],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for shrewd.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shy is at index 9152\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1080, -0.1002,  0.2818,  ..., -0.3200, -0.4521, -0.3531],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for shy.\n",
      "shyness is at index 9152\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1080, -0.1002,  0.2818,  ..., -0.3200, -0.4521, -0.3531],\n",
      "         [-0.1231,  0.1777,  0.1255,  ..., -0.4542,  0.0778,  0.0067],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for shyness.\n",
      "sick is at index 4736\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0654, -0.2518,  0.3409,  ...,  0.3972,  0.0084, -0.0017],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for sick.\n",
      "sicken is at index 579\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1403, -0.0299, -0.1708,  ...,  0.2694,  0.1000,  0.1545],\n",
      "         [-0.2021,  0.6901,  0.0512,  ..., -0.3576,  0.1223,  0.0196],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for sicken.\n",
      "sickened is at index 4736\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0654, -0.2518,  0.3409,  ...,  0.3972,  0.0084, -0.0017],\n",
      "         [-0.0674, -0.2683,  0.6696,  ..., -0.0751, -0.2735,  0.6508],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for sickened.\n",
      "sigh is at index 27305\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.4437,  0.3506,  0.3394,  ..., -0.0868,  0.1119, -0.2296],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for sigh.\n",
      "silenced is at index 30125\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0788, -0.1509, -0.2163,  ..., -0.0711, -0.5240, -0.4001],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for silenced.\n",
      "silent is at index 8454\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0294, -0.2902, -0.3473,  ...,  0.0329, -0.6146, -0.2966],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for silent.\n",
      "silliness is at index 38052\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0812,  0.1273, -0.0055,  ...,  0.1593, -0.2673,  0.2152],\n",
      "         [-0.2111,  0.2981, -0.1767,  ..., -0.0285,  0.2131, -0.4322],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for silliness.\n",
      "silly is at index 15470\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3543, -0.2857,  0.2049,  ...,  0.1684,  0.2211,  0.1457],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for silly.\n",
      "simmering is at index 25726\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.4908, -0.8721, -0.1752,  ...,  0.0318,  0.0606,  0.3073],\n",
      "         [ 0.1383,  0.3796,  0.1368,  ...,  0.2405, -0.3453,  0.0233],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for simmering.\n",
      "simper is at index 16207\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0383,  0.1408, -0.4337,  ...,  0.2250, -0.1693, -0.0878],\n",
      "         [-0.2683,  0.2955, -0.0755,  ..., -0.4540,  0.0991,  0.2756],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for simper.\n",
      "simpering is at index 16207\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0383,  0.1408, -0.4337,  ...,  0.2250, -0.1693, -0.0878],\n",
      "         [ 0.1057,  1.0936, -0.1933,  ..., -0.2768,  0.5266,  0.2954],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for simpering.\n",
      "simple is at index 2007\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1471,  0.2619, -0.1612,  ..., -0.0261, -0.3663, -0.2952],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for simple.\n",
      "simplicity is at index 25342\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2614, -0.1798,  0.0479,  ..., -0.0303,  0.1292, -0.1203],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for simplicity.\n",
      "sincere is at index 19255\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1726,  0.2488,  0.1450,  ..., -0.1382, -0.0681,  0.2839],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for sincere.\n",
      "sinful is at index 44364\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0054, -0.1045, -0.2241,  ..., -0.0538,  0.0463, -0.3694],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for sinful.\n",
      "singing is at index 6970\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0927, -0.1371,  0.2003,  ...,  0.2653, -0.0552, -0.0144],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for singing.\n",
      "sinister is at index 27570\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0459,  0.5580,  0.1942,  ...,  0.4213, -0.1408,  0.2164],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for sinister.\n",
      "sinisterly is at index 27570\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0459,  0.5580,  0.1942,  ...,  0.4213, -0.1408,  0.2164],\n",
      "         [ 0.3543,  0.3169,  0.0401,  ..., -0.1069, -0.5598,  0.1301],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for sinisterly.\n",
      "sizing is at index 39328\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3689, -0.3880,  0.0910,  ..., -0.0342, -0.3742,  0.3149],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for sizing.\n",
      "skeptic is at index 42386\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1521,  0.5422,  0.1185,  ...,  0.2816,  0.2107, -0.0807],\n",
      "         [ 0.1879,  0.4749,  0.1584,  ...,  0.0505, -0.1448,  0.0398],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for skeptic.\n",
      "skeptical is at index 14992\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.5740,  0.0894,  0.3426,  ...,  0.5651,  0.0411, -0.1765],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for skeptical.\n",
      "skeptically is at index 42386\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1521,  0.5422,  0.1185,  ...,  0.2816,  0.2107, -0.0807],\n",
      "         [-0.3732,  0.5844, -0.4075,  ..., -0.0642, -0.0196,  0.1810],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for skeptically.\n",
      "skepticism is at index 22222\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.4170,  0.1554,  0.3051,  ...,  0.5228,  0.1908, -0.2173],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for skepticism.\n",
      "sketchy is at index 15923\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0958, -0.4119,  0.4623,  ...,  0.4676, -0.7003,  0.0993],\n",
      "         [ 0.1311, -0.1715,  0.0534,  ..., -0.0509, -0.4687, -0.2923],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for sketchy.\n",
      "skittish is at index 2972\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-2.9452e-01, -1.2585e-02,  3.1367e-01,  ...,  1.3045e-01,\n",
      "           5.2817e-01,  5.3372e-01],\n",
      "         [ 7.9732e-02,  4.4871e-01,  4.0982e-01,  ...,  5.3150e-01,\n",
      "          -1.4552e-01,  7.9736e-01],\n",
      "         [ 5.0026e-01, -4.0793e-01,  1.8632e-01,  ..., -3.7958e-02,\n",
      "          -1.7293e-01,  3.0884e-02],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for skittish.\n",
      "slack is at index 25163\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2066, -0.7933,  0.0809,  ..., -0.0124, -0.1868, -0.1062],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for slack.\n",
      "sleazy is at index 18388\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0988, -0.4720, -0.4509,  ...,  0.6255,  0.1135,  0.8064],\n",
      "         [ 0.1288,  0.1876, -0.0079,  ..., -1.0380,  0.1692, -0.0582],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for sleazy.\n",
      "sleepy is at index 33782\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0918,  0.1096,  0.5244,  ...,  0.1674,  0.0617, -0.0871],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for sleepy.\n",
      "slick is at index 19038\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3143,  0.1217,  0.3377,  ..., -0.2715, -0.6562,  0.1001],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for slick.\n",
      "slothful is at index 3369\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [ 5.8034e-02, -7.4202e-01, -1.6305e-01,  ...,  5.4639e-01,\n",
      "           2.6537e-01,  5.8417e-01],\n",
      "         [-2.4698e-01,  3.5691e-01,  9.6421e-01,  ..., -3.9785e-01,\n",
      "           5.1217e-01,  2.5003e-01],\n",
      "         [ 3.9899e-01, -8.8491e-03, -4.2134e-01,  ...,  2.0336e-01,\n",
      "          -3.8005e-01, -2.2930e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for slothful.\n",
      "slow is at index 2635\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0059, -0.1717,  0.5567,  ..., -0.0861, -0.3072, -0.2334],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for slow.\n",
      "sluggish is at index 16642\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0355, -0.3837,  0.3272,  ...,  0.0703,  0.1328,  0.2715],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for sluggish.\n",
      "sly is at index 40568\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.8252, -0.0081,  0.0925,  ..., -0.2446, -0.1144,  0.3330],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for sly.\n",
      "smarmy is at index 5278\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0316, -0.0729,  0.2630,  ...,  0.5293, -0.2762, -0.2531],\n",
      "         [ 0.1980,  0.2442, -0.0498,  ..., -0.1750,  0.3427,  0.1249],\n",
      "         [ 0.2305, -0.2877, -0.0087,  ...,  0.0013, -0.4412, -0.2633],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for smarmy.\n",
      "smart is at index 2793\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1418, -0.1773,  0.0706,  ...,  0.2418, -0.4055,  0.3197],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for smart.\n",
      "smashed is at index 13263\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1226, -0.5711,  0.4174,  ...,  0.5394,  0.0893,  0.1624],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for smashed.\n",
      "smile is at index 6675\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2033,  0.1228,  0.6097,  ..., -0.2414, -0.1697,  0.2334],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for smile.\n",
      "smiley is at index 6675\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2033,  0.1228,  0.6097,  ..., -0.2414, -0.1697,  0.2334],\n",
      "         [ 0.1311, -0.1715,  0.0534,  ..., -0.0509, -0.4687, -0.2923],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for smiley.\n",
      "smiling is at index 12382\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1045, -0.2821,  0.2680,  ...,  0.1015, -0.2199,  0.3131],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for smiling.\n",
      "smirk is at index 5278\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0316, -0.0729,  0.2630,  ...,  0.5293, -0.2762, -0.2531],\n",
      "         [-0.2011,  0.6517,  0.2879,  ..., -0.0091, -0.1610,  0.3116],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for smirk.\n",
      "smirking is at index 44414\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1212, -0.0021,  0.1723,  ..., -0.1818, -0.0057,  0.0902],\n",
      "         [-0.1251,  0.2403, -0.0132,  ..., -0.0973, -0.1114,  0.0891],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for smirking.\n",
      "smoldering is at index 5278\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0316, -0.0729,  0.2630,  ...,  0.5293, -0.2762, -0.2531],\n",
      "         [-0.2326, -0.5020,  0.2245,  ..., -0.1175,  0.1106,  0.2398],\n",
      "         [ 0.3281,  0.2076, -0.0778,  ...,  0.5370, -0.2579,  0.3748],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for smoldering.\n",
      "smooching is at index 5278\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0316, -0.0729,  0.2630,  ...,  0.5293, -0.2762, -0.2531],\n",
      "         [ 0.3367, -0.2569, -0.0737,  ..., -0.1229, -0.2377, -0.3663],\n",
      "         [-0.3909,  0.3142,  0.2973,  ..., -0.1891, -0.2294,  0.0541],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for smooching.\n",
      "smooth is at index 6921\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2758,  0.4399,  0.4420,  ..., -0.1216, -0.5335, -0.2755],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for smooth.\n",
      "smug is at index 41283\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.4601, -0.0779,  0.6663,  ...,  0.3089, -0.3070, -0.4099],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for smug.\n",
      "smugness is at index 41283\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.4601, -0.0779,  0.6663,  ...,  0.3089, -0.3070, -0.4099],\n",
      "         [-0.1231,  0.1777,  0.1255,  ..., -0.4542,  0.0778,  0.0067],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for smugness.\n",
      "snake is at index 16173\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2562, -0.1704,  0.5799,  ..., -0.4670,  0.1123,  0.2035],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for snake.\n",
      "snappy is at index 4543\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0327, -0.1610,  0.0178,  ...,  0.6230,  0.1605,  0.4008],\n",
      "         [-0.3440,  1.1024, -0.0559,  ..., -0.0201, -0.2555,  0.1588],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for snappy.\n",
      "snarky is at index 4543\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0327, -0.1610,  0.0178,  ...,  0.6230,  0.1605,  0.4008],\n",
      "         [-0.3827,  0.1467, -0.0543,  ...,  0.0113,  0.0348, -0.1577],\n",
      "         [ 0.2305, -0.2877, -0.0087,  ...,  0.0013, -0.4412, -0.2633],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for snarky.\n",
      "snarl is at index 4543\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0327, -0.1610,  0.0178,  ...,  0.6230,  0.1605,  0.4008],\n",
      "         [ 0.1298,  0.6738, -0.1278,  ..., -0.7942, -0.1010,  0.2759],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for snarl.\n",
      "snarled is at index 4543\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0327, -0.1610,  0.0178,  ...,  0.6230,  0.1605,  0.4008],\n",
      "         [ 0.4713,  0.2423, -0.0089,  ..., -0.3798, -0.1164, -0.0228],\n",
      "         [ 0.0589, -0.2250,  0.0798,  ..., -0.1709, -0.0874,  0.2744],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for snarled.\n",
      "snarling is at index 4543\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0327, -0.1610,  0.0178,  ...,  0.6230,  0.1605,  0.4008],\n",
      "         [ 0.0862,  1.0575,  0.0320,  ..., -0.8085, -0.2813,  0.2919],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for snarling.\n",
      "snarly is at index 4543\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0327, -0.1610,  0.0178,  ...,  0.6230,  0.1605,  0.4008],\n",
      "         [ 0.4713,  0.2423, -0.0089,  ..., -0.3798, -0.1164, -0.0228],\n",
      "         [ 0.4529,  0.1975, -0.0221,  ..., -0.0542, -0.5319,  0.1568],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for snarly.\n",
      "sneaky is at index 39399\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2273,  0.1855, -0.2520,  ..., -0.1597, -0.0621,  0.1004],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for sneaky.\n",
      "sneer is at index 18013\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0319,  0.1860, -0.2241,  ..., -0.1197,  0.1901,  0.3335],\n",
      "         [ 0.4303,  0.2150, -0.2271,  ..., -0.0656, -0.3551,  0.0153],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for sneer.\n",
      "sneering is at index 18013\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0319,  0.1860, -0.2241,  ..., -0.1197,  0.1901,  0.3335],\n",
      "         [ 0.2306,  0.3185, -0.0189,  ...,  0.4856, -0.2807,  0.3472],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for sneering.\n",
      "sneeze is at index 18013\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0319,  0.1860, -0.2241,  ..., -0.1197,  0.1901,  0.3335],\n",
      "         [ 0.4767, -0.5947, -0.5114,  ...,  0.4044, -0.5822,  0.5323],\n",
      "         [-0.2646, -0.0450, -0.1470,  ...,  0.0345, -0.4068,  0.5536],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for sneeze.\n",
      "sneezing is at index 18013\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0319,  0.1860, -0.2241,  ..., -0.1197,  0.1901,  0.3335],\n",
      "         [ 0.1048, -0.2597,  0.0712,  ..., -0.4094, -0.4191,  0.4157],\n",
      "         [ 0.2407,  0.2558,  0.0720,  ...,  0.2923, -0.3174,  0.0513],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for sneezing.\n",
      "snicker is at index 4543\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0327, -0.1610,  0.0178,  ...,  0.6230,  0.1605,  0.4008],\n",
      "         [ 0.0523,  1.0145, -0.3308,  ..., -0.1365, -0.1815,  0.1478],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for snicker.\n",
      "snickering is at index 4543\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0327, -0.1610,  0.0178,  ...,  0.6230,  0.1605,  0.4008],\n",
      "         [-0.1118,  0.3405,  0.3984,  ...,  0.4437,  0.4347, -0.0613],\n",
      "         [ 0.3281,  0.2076, -0.0778,  ...,  0.5370, -0.2579,  0.3748],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for snickering.\n",
      "snide is at index 4543\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0327, -0.1610,  0.0178,  ...,  0.6230,  0.1605,  0.4008],\n",
      "         [-0.2467,  0.6990,  0.0891,  ..., -0.3310, -0.2731,  0.3602],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for snide.\n",
      "sniggering is at index 4543\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0327, -0.1610,  0.0178,  ...,  0.6230,  0.1605,  0.4008],\n",
      "         [-0.0359,  0.5697,  0.3337,  ...,  0.1328, -0.4229, -0.0525],\n",
      "         [ 0.2407,  0.2558,  0.0720,  ...,  0.2923, -0.3174,  0.0513],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for sniggering.\n",
      "sniveling is at index 4543\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0327, -0.1610,  0.0178,  ...,  0.6230,  0.1605,  0.4008],\n",
      "         [ 0.1941,  0.3173,  0.1725,  ...,  0.0227, -0.1611,  0.4399],\n",
      "         [ 0.0499, -0.2110,  0.3453,  ..., -0.2768, -0.1006,  0.3045],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for sniveling.\n",
      "snobbish is at index 4543\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0327, -0.1610,  0.0178,  ...,  0.6230,  0.1605,  0.4008],\n",
      "         [ 0.0491,  0.6298,  0.2645,  ..., -0.6429, -0.1772, -0.1363],\n",
      "         [ 0.5003, -0.4079,  0.1863,  ..., -0.0380, -0.1729,  0.0309],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for snobbish.\n",
      "snobby is at index 4543\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0327, -0.1610,  0.0178,  ...,  0.6230,  0.1605,  0.4008],\n",
      "         [-0.0466,  1.2386,  0.4485,  ..., -0.5134, -0.6910, -0.0222],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for snobby.\n",
      "snooty is at index 4543\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0327, -0.1610,  0.0178,  ...,  0.6230,  0.1605,  0.4008],\n",
      "         [ 0.0126, -0.1083,  0.1583,  ...,  0.1710, -0.5671, -0.2024],\n",
      "         [ 0.2305, -0.2877, -0.0087,  ...,  0.0013, -0.4412, -0.2633],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for snooty.\n",
      "snotty is at index 579\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1403, -0.0299, -0.1708,  ...,  0.2694,  0.1000,  0.1545],\n",
      "         [ 0.1642,  0.2773, -0.0681,  ...,  0.0319, -0.1030,  0.2105],\n",
      "         [ 0.1435,  0.1202, -0.2999,  ..., -0.1916,  0.0954, -0.2514],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for snotty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sociable is at index 17380\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2142,  0.2030,  0.4645,  ...,  0.1478, -0.2616,  0.5376],\n",
      "         [ 0.0837,  0.6270,  0.2283,  ..., -0.2682, -0.0916,  0.0955],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for sociable.\n",
      "soft is at index 3793\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0522,  0.1268, -0.2963,  ..., -0.1973, -0.6074, -0.0395],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for soft.\n",
      "solemn is at index 29807\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1821,  0.2523, -0.0580,  ...,  0.5267, -0.2220, -0.2160],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for solemn.\n",
      "solicitous is at index 22706\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2367, -0.2091,  0.0680,  ..., -0.1562, -0.0017,  0.2919],\n",
      "         [-0.0881, -0.2759,  0.1838,  ...,  0.2681, -0.4104, -0.2701],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for solicitous.\n",
      "solitary is at index 24429\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2708, -0.3677, -0.0519,  ...,  0.4347, -0.4319,  0.1889],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for solitary.\n",
      "solitude is at index 41813\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.4983, -0.2243,  0.4117,  ...,  0.0726, -0.1014, -0.0421],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for solitude.\n",
      "somber is at index 16487\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0188,  0.1406,  0.5051,  ...,  0.2531,  0.2207,  0.1546],\n",
      "         [ 0.1820, -0.3009,  0.5443,  ...,  0.3820, -0.1316,  0.3402],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for somber.\n",
      "somberly is at index 16487\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0188,  0.1406,  0.5051,  ...,  0.2531,  0.2207,  0.1546],\n",
      "         [ 0.1820, -0.3009,  0.5443,  ...,  0.3820, -0.1316,  0.3402],\n",
      "         [ 0.4529,  0.1975, -0.0221,  ..., -0.0542, -0.5319,  0.1568],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for somberly.\n",
      "somnolent is at index 16487\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0188,  0.1406,  0.5051,  ...,  0.2531,  0.2207,  0.1546],\n",
      "         [ 0.4332, -0.3587, -0.0185,  ...,  0.1673, -0.3373,  0.4497],\n",
      "         [ 0.2884, -0.0695, -0.0613,  ...,  0.1887, -0.2483, -0.0174],\n",
      "         [ 0.2123, -0.4018,  0.1873,  ...,  0.0916,  0.3550,  0.6567],\n",
      "         [ 0.2760, -0.1979, -0.1075,  ...,  0.4037,  0.0583,  0.1964]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for somnolent.\n",
      "soothed is at index 98\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [ 2.4741e-01, -7.8896e-02,  7.5146e-02,  ...,  2.2224e-01,\n",
      "           1.1514e-01,  5.3040e-04],\n",
      "         [ 1.0451e-01, -7.5795e-02,  2.8391e-01,  ..., -4.3262e-01,\n",
      "          -7.8964e-01,  2.0736e-01],\n",
      "         [-5.5869e-02, -3.2498e-01, -7.6261e-02,  ..., -2.2209e-01,\n",
      "           9.0629e-02,  8.5119e-02],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for soothed.\n",
      "sore is at index 12867\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0878, -0.4244,  0.4102,  ..., -0.2730, -0.1167, -0.2277],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for sore.\n",
      "sorrow is at index 26130\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3974,  0.2230,  0.2250,  ..., -0.1150,  0.4120,  0.1004],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for sorrow.\n",
      "sorrowful is at index 26130\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3974,  0.2230,  0.2250,  ..., -0.1150,  0.4120,  0.1004],\n",
      "         [ 0.3025,  0.1036, -0.3624,  ...,  0.1536, -0.4041, -0.2558],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for sorrowful.\n",
      "sorry is at index 6661\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0208, -0.7676,  0.3415,  ..., -0.1034, -0.0712, -0.1374],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for sorry.\n",
      "sour is at index 16933\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0680,  0.1485,  0.4290,  ..., -0.1026,  0.4814, -0.6054],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for sour.\n",
      "spaced is at index 42926\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0824,  0.2772, -0.0254,  ...,  0.1975, -0.5780, -0.4793],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for spaced.\n",
      "spacing is at index 39152\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0487,  0.1278,  0.3142,  ..., -0.3404, -0.3282, -0.3008],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for spacing.\n",
      "spastic is at index 2292\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0793,  0.4347, -0.2167,  ..., -0.1523,  0.1032,  0.0388],\n",
      "         [-0.2239,  0.4999, -0.0082,  ..., -0.3061, -0.1794,  0.1437],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for spastic.\n",
      "speaking is at index 2686\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.4031, -0.4923, -0.4573,  ..., -0.0653,  0.0373, -0.3472],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for speaking.\n",
      "specious is at index 12002\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1305, -0.2028, -0.3019,  ...,  0.2671, -0.0228, -0.4143],\n",
      "         [-0.0583,  0.2461,  0.3175,  ..., -0.0270, -0.2839, -0.2945],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for specious.\n",
      "speculative is at index 21779\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0300,  0.0649, -0.3406,  ..., -0.0992, -0.3137, -0.2807],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for speculative.\n",
      "speechless is at index 1901\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2927, -0.0896, -0.0357,  ..., -0.2544, -0.3337, -0.0640],\n",
      "         [-0.0646, -0.7736,  0.2078,  ...,  0.1990, -0.4643, -0.1719],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for speechless.\n",
      "spent is at index 1240\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0889,  0.0617,  0.6332,  ..., -0.0974, -0.1925,  0.4312],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for spent.\n",
      "spirited is at index 27206\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0898,  0.2670,  0.0370,  ...,  0.4810,  0.2900,  0.2793],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for spirited.\n",
      "spiritless is at index 4780\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2473,  0.5150,  0.6135,  ...,  0.2254,  0.1232,  0.4373],\n",
      "         [-0.0646, -0.7736,  0.2078,  ...,  0.1990, -0.4643, -0.1719],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for spiritless.\n",
      "spite is at index 14117\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0561, -0.1987,  0.2489,  ...,  0.1351,  0.1520, -0.3594],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for spite.\n",
      "spiteful is at index 14117\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0561, -0.1987,  0.2489,  ...,  0.1351,  0.1520, -0.3594],\n",
      "         [ 0.3025,  0.1036, -0.3624,  ...,  0.1536, -0.4041, -0.2558],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for spiteful.\n",
      "spoiled is at index 29136\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0811, -0.1455,  0.1841,  ...,  0.2983,  0.5913, -0.9408],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for spoiled.\n",
      "spooked is at index 2292\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0793,  0.4347, -0.2167,  ..., -0.1523,  0.1032,  0.0388],\n",
      "         [-0.2212,  1.0464, -0.0466,  ..., -0.3264, -0.0076, -0.0131],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for spooked.\n",
      "squeamish is at index 33380\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1562,  0.6410,  0.2634,  ..., -0.1563, -0.2762, -0.0831],\n",
      "         [ 0.0517,  0.1733, -0.0684,  ..., -0.5554,  0.2448,  0.0999],\n",
      "         [ 0.5003, -0.4079,  0.1863,  ..., -0.0380, -0.1729,  0.0309],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for squeamish.\n",
      "staggered is at index 37646\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3972, -0.3511,  0.0956,  ..., -0.3247,  0.2520, -0.0985],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for staggered.\n",
      "stalker is at index 1690\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1214, -0.1286,  0.2419,  ...,  0.1982, -0.0803,  0.1829],\n",
      "         [ 0.6521, -0.1446, -0.4178,  ..., -0.2447,  0.1930,  0.0792],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for stalker.\n",
      "stare is at index 27655\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3850, -0.2754,  0.0439,  ..., -0.0608, -0.4915,  0.4717],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for stare.\n",
      "staring is at index 19311\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0172, -0.7033, -0.1207,  ...,  0.2531, -0.4245,  0.2946],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for staring.\n",
      "starstruck is at index 999\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2306, -0.2148, -0.0333,  ..., -0.1988, -0.2865,  0.1753],\n",
      "         [ 0.1982, -0.3151, -0.2151,  ..., -0.3520, -0.0846,  0.2366],\n",
      "         [ 0.4102,  0.0215,  0.2072,  ..., -0.0231,  0.1642,  0.5378],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for starstruck.\n",
      "started is at index 554\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1937,  0.0893,  0.3343,  ...,  0.4702, -0.3879,  0.1339],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for started.\n",
      "startled is at index 37747\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.4903, -0.0627,  0.0426,  ...,  0.2112,  0.0819,  0.2182],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for startled.\n",
      "stately is at index 194\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.5008,  0.2712, -0.1364,  ..., -0.1282, -0.1404,  0.3474],\n",
      "         [ 0.3543,  0.3169,  0.0401,  ..., -0.1069, -0.5598,  0.1301],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for stately.\n",
      "steadfast is at index 25781\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1999, -0.1145, -0.0157,  ..., -0.0754, -0.1174,  0.2407],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for steadfast.\n",
      "steady is at index 5204\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0720,  0.2893,  0.4482,  ...,  0.0024, -0.2173, -0.3692],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for steady.\n",
      "stealthy is at index 27026\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2910, -0.3803, -0.0843,  ..., -0.0783,  0.2105,  0.5912],\n",
      "         [ 0.1311, -0.1715,  0.0534,  ..., -0.0509, -0.4687, -0.2923],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for stealthy.\n",
      "steamed is at index 11235\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3817, -0.2330, -0.0268,  ..., -0.0495,  0.0977, -0.1783],\n",
      "         [ 0.0505,  0.0059,  0.1942,  ..., -0.4513, -0.3499,  0.0357],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for steamed.\n",
      "steaming is at index 11235\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3817, -0.2330, -0.0268,  ..., -0.0495,  0.0977, -0.1783],\n",
      "         [-0.0629,  0.0570,  0.2557,  ..., -0.3957, -0.1494, -0.4727],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for steaming.\n",
      "steeling is at index 3689\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0162, -0.2875,  0.3015,  ..., -0.3333,  0.4345,  0.4353],\n",
      "         [ 0.1383,  0.3796,  0.1368,  ...,  0.2405, -0.3453,  0.0233],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for steeling.\n",
      "steely is at index 1690\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1214, -0.1286,  0.2419,  ...,  0.1982, -0.0803,  0.1829],\n",
      "         [-0.0492,  0.1045, -0.2870,  ...,  0.0336, -0.6255,  0.5435],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for steely.\n",
      "stern is at index 23427\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1607,  0.4281,  0.0203,  ...,  0.3554,  0.2427,  0.4661],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for stern.\n",
      "stiff is at index 13116\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2394, -0.4173, -0.0166,  ..., -0.1180, -0.1975,  0.3245],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for stiff.\n",
      "stifled is at index 1690\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1214, -0.1286,  0.2419,  ...,  0.1982, -0.0803,  0.1829],\n",
      "         [ 0.0846,  0.1682, -0.5485,  ..., -0.5752,  0.0548, -0.1380],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for stifled.\n",
      "stifling is at index 1690\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1214, -0.1286,  0.2419,  ...,  0.1982, -0.0803,  0.1829],\n",
      "         [ 0.3438,  0.3516, -0.5040,  ..., -0.0504,  0.1618,  0.1370],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for stifling.\n",
      "still is at index 202\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3169, -0.4360,  0.1398,  ...,  0.2117, -0.6058, -0.0722],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for still.\n",
      "stillness is at index 202\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3169, -0.4360,  0.1398,  ...,  0.2117, -0.6058, -0.0722],\n",
      "         [-0.1231,  0.1777,  0.1255,  ..., -0.4542,  0.0778,  0.0067],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for stillness.\n",
      "stimulated is at index 42040\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0330,  0.1296,  0.5728,  ...,  0.5523, -0.1397, -0.1021],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for stimulated.\n",
      "stinky is at index 1690\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1214, -0.1286,  0.2419,  ...,  0.1982, -0.0803,  0.1829],\n",
      "         [ 0.0105,  0.7070,  0.1164,  ..., -0.0494, -0.0588,  0.1010],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for stinky.\n",
      "stirred is at index 26158\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3084, -0.3091,  0.0216,  ...,  0.2732,  0.1731, -0.0927],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for stirred.\n",
      "stoic is at index 20572\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1721,  0.4093,  0.4579,  ...,  0.1233,  0.0465,  0.3349],\n",
      "         [ 0.1879,  0.4749,  0.1584,  ...,  0.0505, -0.1448,  0.0398],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for stoic.\n",
      "stoical is at index 20572\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1721,  0.4093,  0.4579,  ...,  0.1233,  0.0465,  0.3349],\n",
      "         [-0.3909,  0.5831,  0.0951,  ...,  0.2938,  0.2165, -0.0992],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for stoical.\n",
      "stolid is at index 1690\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1214, -0.1286,  0.2419,  ...,  0.1982, -0.0803,  0.1829],\n",
      "         [ 0.0168,  0.0994, -0.1124,  ..., -0.3459,  0.1990,  0.5751],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for stolid.\n",
      "stoned is at index 1690\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1214, -0.1286,  0.2419,  ...,  0.1982, -0.0803,  0.1829],\n",
      "         [-0.1904,  0.0874,  0.1170,  ...,  0.1680, -0.1987,  0.3426],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for stoned.\n",
      "storming is at index 2130\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1959,  0.0576,  0.3705,  ..., -0.4138,  0.1826,  0.2789],\n",
      "         [ 0.1383,  0.3796,  0.1368,  ...,  0.2405, -0.3453,  0.0233],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for storming.\n",
      "stormy is at index 2130\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1959,  0.0576,  0.3705,  ..., -0.4138,  0.1826,  0.2789],\n",
      "         [ 0.1311, -0.1715,  0.0534,  ..., -0.0509, -0.4687, -0.2923],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for stormy.\n",
      "stout is at index 34636\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0466, -0.1469,  0.3227,  ...,  0.2584, -0.0045,  0.2503],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for stout.\n",
      "straight is at index 1359\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1589, -0.1743,  0.0200,  ...,  0.0158, -0.5480, -0.1428],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for straight.\n",
      "strained is at index 15718\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1872, -0.0113, -0.1739,  ...,  0.0260,  0.2594,  0.2980],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for strained.\n",
      "strange is at index 7782\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1390, -0.0274,  0.0975,  ...,  0.4471,  0.0278, -0.3111],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for strange.\n",
      "stressed is at index 5882\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0244,  0.5377,  0.4775,  ...,  0.0599,  0.3283, -0.0328],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for stressed.\n",
      "stricken is at index 35876\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0794, -0.1999, -0.0851,  ..., -0.0567, -0.2277,  0.2463],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for stricken.\n",
      "strict is at index 8414\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2736,  0.1041, -0.3152,  ...,  0.4487, -0.3180,  0.1145],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for strict.\n",
      "strong is at index 670\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0463,  0.1893,  0.0739,  ..., -0.0645,  0.0102,  0.3184],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for strong.\n",
      "struck is at index 2322\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0692,  0.0114,  0.4108,  ...,  0.3046,  0.2320,  0.0965],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for struck.\n",
      "stubborn is at index 20476\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1824, -0.0102,  0.0748,  ...,  0.3057,  0.3643,  0.1193],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for stubborn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stubbornness is at index 20476\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1824, -0.0102,  0.0748,  ...,  0.3057,  0.3643,  0.1193],\n",
      "         [-0.1231,  0.1777,  0.1255,  ..., -0.4542,  0.0778,  0.0067],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for stubbornness.\n",
      "studious is at index 15863\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0683, -0.1275, -0.0512,  ..., -0.1057, -0.1784,  0.3042],\n",
      "         [-0.0583,  0.2461,  0.3175,  ..., -0.0270, -0.2839, -0.2945],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for studious.\n",
      "studying is at index 7739\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1123, -0.3492, -0.1095,  ...,  0.3137, -0.3877,  0.3123],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for studying.\n",
      "stumped is at index 1690\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1214, -0.1286,  0.2419,  ...,  0.1982, -0.0803,  0.1829],\n",
      "         [-0.2722,  0.2395,  0.0265,  ..., -0.2879,  0.1759, -0.2444],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for stumped.\n",
      "stung is at index 1690\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1214, -0.1286,  0.2419,  ...,  0.1982, -0.0803,  0.1829],\n",
      "         [-0.5001,  0.5596,  0.6303,  ...,  0.1200,  0.0894, -0.3461],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for stung.\n",
      "stunned is at index 12144\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1633, -0.0857, -0.0121,  ...,  0.2545,  0.0156,  0.3163],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for stunned.\n",
      "stupefaction is at index 1690\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1214, -0.1286,  0.2419,  ...,  0.1982, -0.0803,  0.1829],\n",
      "         [-0.0503,  0.8481,  0.3377,  ..., -0.2432, -0.3805,  0.2403],\n",
      "         [ 0.0906,  0.0777,  0.0721,  ...,  0.1381,  0.1165,  0.4367],\n",
      "         [ 0.4938,  0.0574, -0.4404,  ..., -0.6649,  0.2984, -0.0836],\n",
      "         [ 0.2760, -0.1979, -0.1075,  ...,  0.4037,  0.0583,  0.1964]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for stupefaction.\n",
      "stupefied is at index 1690\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1214, -0.1286,  0.2419,  ...,  0.1982, -0.0803,  0.1829],\n",
      "         [-0.0503,  0.8481,  0.3377,  ..., -0.2432, -0.3805,  0.2403],\n",
      "         [ 0.0906,  0.0777,  0.0721,  ...,  0.1381,  0.1165,  0.4367],\n",
      "         [-0.5373,  0.4813,  0.1041,  ...,  0.2873, -0.2383,  0.0922],\n",
      "         [ 0.2760, -0.1979, -0.1075,  ...,  0.4037,  0.0583,  0.1964]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for stupefied.\n",
      "stupefy is at index 1690\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-1.2137e-01, -1.2859e-01,  2.4191e-01,  ...,  1.9825e-01,\n",
      "          -8.0278e-02,  1.8286e-01],\n",
      "         [-5.0304e-02,  8.4812e-01,  3.3767e-01,  ..., -2.4324e-01,\n",
      "          -3.8045e-01,  2.4032e-01],\n",
      "         [ 5.3508e-01,  4.3269e-01, -1.4597e-01,  ..., -4.6304e-01,\n",
      "          -5.8895e-01,  8.6398e-02],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for stupefy.\n",
      "stupid is at index 12103\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1619, -0.5263, -0.1841,  ...,  0.0801,  0.0189, -0.3165],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for stupid.\n",
      "stuporous is at index 1690\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1214, -0.1286,  0.2419,  ...,  0.1982, -0.0803,  0.1829],\n",
      "         [-0.1094,  0.0960, -0.2253,  ..., -0.3735, -0.5131,  0.2688],\n",
      "         [ 0.2756,  0.0953, -0.5605,  ...,  0.2509, -0.1422,  0.2575],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for stuporous.\n",
      "suave is at index 2628\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1205,  0.2472,  0.4376,  ..., -0.2408,  0.0673, -0.2775],\n",
      "         [ 0.0645, -0.0396,  0.3732,  ..., -0.5471, -0.1754,  0.0523],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for suave.\n",
      "subdued is at index 20247\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0560, -0.1966, -0.0086,  ...,  0.2822, -0.0271,  0.3142],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for subdued.\n",
      "sublime is at index 32477\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1307,  0.4189,  0.3278,  ...,  0.0305,  0.0599,  0.2291],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for sublime.\n",
      "submissive is at index 2849\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0744,  0.1648,  0.4325,  ..., -0.3278, -0.2440,  0.1509],\n",
      "         [-0.4151,  0.2510, -0.5984,  ...,  0.0240, -0.2289,  0.2637],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for submissive.\n",
      "suffering is at index 3606\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2462,  0.2723,  0.4325,  ...,  0.0606,  0.1270,  0.0106],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for suffering.\n",
      "suggestive is at index 38907\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0364, -0.2405, -0.3026,  ...,  0.5416, -0.1759,  0.2484],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for suggestive.\n",
      "sulking is at index 26648\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2282,  0.1181,  0.1533,  ..., -0.2789, -0.1349, -0.0264],\n",
      "         [-0.1251,  0.2403, -0.0132,  ..., -0.0973, -0.1114,  0.0891],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for sulking.\n",
      "sulky is at index 26648\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2282,  0.1181,  0.1533,  ..., -0.2789, -0.1349, -0.0264],\n",
      "         [-0.4044,  0.8069, -0.0090,  ..., -0.1264, -0.3957, -0.0152],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for sulky.\n",
      "sullen is at index 2628\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-1.2050e-01,  2.4718e-01,  4.3762e-01,  ..., -2.4081e-01,\n",
      "           6.7327e-02, -2.7748e-01],\n",
      "         [ 2.9783e-01, -3.9918e-01,  4.1641e-01,  ...,  1.1059e-01,\n",
      "          -2.8383e-01,  1.2317e-01],\n",
      "         [ 3.4456e-01, -7.0675e-02,  5.6877e-01,  ...,  1.8837e-01,\n",
      "          -4.8098e-01,  7.0811e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for sullen.\n",
      "sullenness is at index 2628\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1205,  0.2472,  0.4376,  ..., -0.2408,  0.0673, -0.2775],\n",
      "         [ 0.2978, -0.3992,  0.4164,  ...,  0.1106, -0.2838,  0.1232],\n",
      "         [ 0.3446, -0.0707,  0.5688,  ...,  0.1884, -0.4810,  0.7081],\n",
      "         [ 0.0038,  0.0321,  0.0331,  ..., -0.3626,  0.1786,  0.0489],\n",
      "         [ 0.2760, -0.1979, -0.1075,  ...,  0.4037,  0.0583,  0.1964]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for sullenness.\n",
      "sunny is at index 5419\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2604,  0.2252,  0.5106,  ...,  0.2613, -0.1871, -0.2793],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for sunny.\n",
      "superior is at index 10295\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2635,  0.3189, -0.1407,  ..., -0.1820, -0.0447,  0.2090],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for superior.\n",
      "superiority is at index 32951\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1731,  0.3115,  0.2169,  ...,  0.0438,  0.5226,  0.0161],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for superiority.\n",
      "suppressed is at index 31683\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.4311, -0.3265, -0.1177,  ..., -0.0568,  0.2747, -0.3471],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for suppressed.\n",
      "suppressing is at index 38919\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0590, -0.3388,  0.2052,  ..., -0.0790,  0.2025, -0.3873],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for suppressing.\n",
      "suppression is at index 25276\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1093, -0.1990,  0.0125,  ...,  0.0643,  0.1433,  0.0293],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for suppression.\n",
      "sure is at index 686\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0168,  0.0358,  0.5216,  ..., -0.2988,  0.1565,  0.5154],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for sure.\n",
      "surly is at index 8113\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2614,  0.0365,  0.5994,  ..., -0.0622,  0.0807, -0.0998],\n",
      "         [ 0.3543,  0.3169,  0.0401,  ..., -0.1069, -0.5598,  0.1301],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for surly.\n",
      "surprise is at index 2755\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.4839, -0.4080,  0.0485,  ..., -0.2440,  0.3914, -0.2901],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for surprise.\n",
      "surprised is at index 3911\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.4820,  0.0507,  0.3885,  ...,  0.0872, -0.0220, -0.1688],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for surprised.\n",
      "surprising is at index 6167\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.5291,  0.0238, -0.0377,  ...,  0.4244, -0.0487,  0.0397],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for surprising.\n",
      "surprisingly is at index 10262\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3937, -0.0632,  0.0096,  ..., -0.0149, -0.0878,  0.3322],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for surprisingly.\n",
      "surreptitious is at index 8113\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2614,  0.0365,  0.5994,  ..., -0.0622,  0.0807, -0.0998],\n",
      "         [-0.2533, -0.1367, -0.1395,  ...,  0.4556,  0.2148,  0.0992],\n",
      "         [ 0.1843, -0.0356, -0.1994,  ..., -0.6613, -0.3206,  0.3108],\n",
      "         [ 0.1529,  0.4618,  0.1414,  ..., -0.0759,  0.2715, -0.1925],\n",
      "         [ 0.2760, -0.1979, -0.1075,  ...,  0.4037,  0.0583,  0.1964]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for surreptitious.\n",
      "suspect is at index 1985\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1357, -0.6065, -0.5474,  ..., -0.0093, -0.5764,  0.4874],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for suspect.\n",
      "suspecting is at index 1985\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1357, -0.6065, -0.5474,  ..., -0.0093, -0.5764,  0.4874],\n",
      "         [ 0.1383,  0.3796,  0.1368,  ...,  0.2405, -0.3453,  0.0233],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for suspecting.\n",
      "suspense is at index 31803\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1557,  0.0819,  0.0574,  ..., -0.3343,  0.1576,  0.0115],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for suspense.\n",
      "suspicion is at index 8551\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0199,  0.1445,  0.2176,  ...,  0.0545, -0.2212,  0.1103],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for suspicion.\n",
      "suspicious is at index 7775\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2751,  0.1705, -0.0136,  ..., -0.0063, -0.3317, -0.2747],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for suspicious.\n",
      "suspiciously is at index 7775\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2751,  0.1705, -0.0136,  ..., -0.0063, -0.3317, -0.2747],\n",
      "         [ 0.3543,  0.3169,  0.0401,  ..., -0.1069, -0.5598,  0.1301],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for suspiciously.\n",
      "suspiciousness is at index 7775\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2751,  0.1705, -0.0136,  ..., -0.0063, -0.3317, -0.2747],\n",
      "         [-0.1231,  0.1777,  0.1255,  ..., -0.4542,  0.0778,  0.0067],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for suspiciousness.\n",
      "swaggering is at index 3514\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3015, -0.0434,  0.1706,  ...,  0.2469, -0.0784,  0.4065],\n",
      "         [ 0.0352,  0.2911,  0.1550,  ..., -0.5539, -0.2777,  0.0963],\n",
      "         [ 0.2407,  0.2558,  0.0720,  ...,  0.2923, -0.3174,  0.0513],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for swaggering.\n",
      "swearing is at index 21854\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0169,  0.2177,  0.0982,  ...,  0.1189, -0.0927,  0.1416],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for swearing.\n",
      "sympathetic is at index 22869\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0866,  0.2686,  0.1313,  ...,  0.0615,  0.1220,  0.3177],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for sympathetic.\n",
      "sympathizing is at index 19023\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2402,  0.0714, -0.0738,  ..., -0.2677, -0.3243,  0.0041],\n",
      "         [-0.0178,  0.5333,  0.0785,  ..., -0.2432, -0.0303,  0.2913],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for sympathizing.\n",
      "sympathy is at index 16554\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0443,  0.1823,  0.0466,  ..., -0.0600,  0.0323,  0.3292],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for sympathy.\n",
      "taciturn is at index 36502\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1386, -0.2547, -0.2064,  ..., -0.0270, -0.2116,  0.2103],\n",
      "         [ 0.4589,  0.2960,  0.2865,  ...,  0.1293, -0.2815, -0.0607],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for taciturn.\n",
      "talkative is at index 1067\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0416, -0.5037, -0.1827,  ...,  0.0132, -0.1320,  0.2189],\n",
      "         [ 0.0452,  0.3078, -0.1904,  ..., -0.2063,  0.4188,  0.0517],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for talkative.\n",
      "talking is at index 1686\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3287, -0.3521, -0.0579,  ..., -0.5095, -0.2084,  0.0136],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for talking.\n",
      "tantalized is at index 33496\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2181, -0.4134, -0.2551,  ..., -0.1087, -0.0942,  0.2621],\n",
      "         [-0.0545,  0.4248,  0.1878,  ...,  0.0940, -0.2454,  0.3326],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for tantalized.\n",
      "tart is at index 27468\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2595,  0.0024, -0.2772,  ...,  0.3299,  0.1210, -0.2455],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for tart.\n",
      "tasteful is at index 24867\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0754, -0.0044,  0.2340,  ...,  0.0395, -0.0580,  0.2197],\n",
      "         [ 0.2202,  0.4626,  0.0943,  ...,  0.4154, -0.6916,  0.0966],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for tasteful.\n",
      "tattling is at index 45951\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1307, -0.4779, -0.0958,  ..., -0.2305, -0.4689, -0.3995],\n",
      "         [-0.0505, -0.0944,  0.4063,  ..., -0.3282, -0.1252,  0.2769],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for tattling.\n",
      "taunt is at index 44048\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0246, -0.4752, -0.3290,  ...,  0.0474, -0.1349,  0.3106],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for taunt.\n",
      "taunting is at index 326\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1827, -0.3751,  0.2733,  ...,  0.2242, -0.1294,  0.2861],\n",
      "         [-0.1436,  1.0278, -0.0541,  ..., -0.4806,  0.1120,  0.2544],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for taunting.\n",
      "taut is at index 326\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1827, -0.3751,  0.2733,  ...,  0.2242, -0.1294,  0.2861],\n",
      "         [-0.4878,  0.0897,  0.2676,  ..., -0.5656, -0.5949,  0.5129],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for taut.\n",
      "tearful is at index 7366\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0559,  0.1172, -0.2460,  ...,  0.6178, -0.2320, -0.1867],\n",
      "         [ 0.3025,  0.1036, -0.3624,  ...,  0.1536, -0.4041, -0.2558],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for tearful.\n",
      "teary is at index 7366\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0559,  0.1172, -0.2460,  ...,  0.6178, -0.2320, -0.1867],\n",
      "         [ 0.1311, -0.1715,  0.0534,  ..., -0.0509, -0.4687, -0.2923],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for teary.\n",
      "tease is at index 29993\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1570,  0.0797, -0.6852,  ...,  0.0877,  0.2292, -0.0297],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for tease.\n",
      "teasing is at index 29752\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0024, -0.0570, -0.3135,  ..., -0.2445,  0.1536,  0.2497],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for teasing.\n",
      "tempered is at index 31380\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3376,  0.0010, -0.0527,  ...,  0.3802,  0.4700, -0.2546],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for tempered.\n",
      "tempest is at index 32196\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0186,  0.2307,  0.1333,  ...,  0.1427,  0.0078, -0.0584],\n",
      "         [-0.0121, -0.0101,  0.1906,  ..., -0.3980, -0.3205,  0.6850],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for tempest.\n",
      "tempestuous is at index 32196\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [ 1.8566e-02,  2.3068e-01,  1.3330e-01,  ...,  1.4268e-01,\n",
      "           7.8455e-03, -5.8386e-02],\n",
      "         [-1.2120e-02, -1.0135e-02,  1.9057e-01,  ..., -3.9804e-01,\n",
      "          -3.2055e-01,  6.8503e-01],\n",
      "         [ 2.2174e-01, -1.3881e-01,  2.1061e-01,  ..., -3.0596e-02,\n",
      "          -3.6831e-01, -2.8217e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for tempestuous.\n",
      "tempted is at index 23448\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0554, -0.0454,  0.2400,  ..., -0.0675,  0.0880,  0.3040],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for tempted.\n",
      "tenacious is at index 2724\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0029, -0.2614,  0.3818,  ...,  0.0579, -0.0501,  0.4223],\n",
      "         [ 0.0169, -0.0371, -0.3503,  ..., -0.2053, -0.3313, -0.3332],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for tenacious.\n",
      "tender is at index 8780\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2429, -0.3348, -0.1159,  ...,  0.1982, -0.0523,  0.6386],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for tender.\n",
      "tenderness is at index 8780\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2429, -0.3348, -0.1159,  ...,  0.1982, -0.0523,  0.6386],\n",
      "         [-0.1231,  0.1777,  0.1255,  ..., -0.4542,  0.0778,  0.0067],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for tenderness.\n",
      "tense is at index 13554\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0533, -0.1610,  0.6334,  ...,  0.0617,  0.0585,  0.1642],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for tense.\n",
      "tensed is at index 7281\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0557, -0.3520,  0.1893,  ...,  0.3200, -0.3657,  0.7008],\n",
      "         [-0.1786,  0.2013,  0.4345,  ...,  0.3394, -0.5501,  0.1632],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for tensed.\n",
      "tension is at index 8556\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2246,  0.5224,  0.4948,  ..., -0.4835,  0.2546,  0.0283],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for tension.\n",
      "tentative is at index 22948\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.5315, -0.0407, -0.1239,  ..., -0.2619, -0.1430,  0.2840],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for tentative.\n",
      "terrified is at index 19419\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1890,  0.0240,  0.2972,  ..., -0.2018, -0.0948, -0.1731],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for terrified.\n",
      "terror is at index 5231\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.4008, -0.0308, -0.2811,  ..., -0.3662,  0.1118,  0.1899],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for terror.\n",
      "terrorized is at index 5231\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.4008, -0.0308, -0.2811,  ..., -0.3662,  0.1118,  0.1899],\n",
      "         [-0.0545,  0.4248,  0.1878,  ...,  0.0940, -0.2454,  0.3326],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for terrorized.\n",
      "terrorizing is at index 5231\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.4008, -0.0308, -0.2811,  ..., -0.3662,  0.1118,  0.1899],\n",
      "         [-0.0178,  0.5333,  0.0785,  ..., -0.2432, -0.0303,  0.2913],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for terrorizing.\n",
      "terse is at index 8470\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1505,  0.4212,  0.0270,  ...,  0.3675, -0.2686,  0.1399],\n",
      "         [-0.5479,  0.0030, -0.1065,  ..., -0.1790,  0.0684,  0.1185],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for terse.\n",
      "testy is at index 1296\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0639, -0.0372,  0.3328,  ...,  0.4603, -0.6231, -0.0889],\n",
      "         [ 0.1311, -0.1715,  0.0534,  ..., -0.0509, -0.4687, -0.2923],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for testy.\n",
      "tetchy is at index 326\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1827, -0.3751,  0.2733,  ...,  0.2242, -0.1294,  0.2861],\n",
      "         [-0.1597,  0.1657, -0.0491,  ..., -0.3737, -0.0428,  0.0071],\n",
      "         [ 0.2305, -0.2877, -0.0087,  ...,  0.0013, -0.4412, -0.2633],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for tetchy.\n",
      "thankful is at index 12025\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2711, -0.4330,  0.3507,  ...,  0.0402,  0.0801, -0.1522],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for thankful.\n",
      "thinking is at index 2053\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0486, -0.1643,  0.2086,  ...,  0.0839,  0.3127,  0.1829],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for thinking.\n",
      "thought is at index 802\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0905,  0.1245,  0.2401,  ...,  0.2374, -0.2808,  0.1397],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for thought.\n",
      "thoughtful is at index 16801\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0531, -0.3180,  0.0866,  ...,  0.3075,  0.1448,  0.2800],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for thoughtful.\n",
      "thoughtfulness is at index 802\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0905,  0.1245,  0.2401,  ...,  0.2374, -0.2808,  0.1397],\n",
      "         [-0.2371,  0.1973, -0.2739,  ...,  0.0637,  0.1708,  0.2685],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for thoughtfulness.\n",
      "threat is at index 1856\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0569,  0.4058, -0.3138,  ...,  0.2029, -0.1946,  0.4743],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for threat.\n",
      "threatened is at index 3711\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1927, -0.1025, -0.0621,  ..., -0.1311,  0.0453, -0.2993],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for threatened.\n",
      "threatening is at index 5608\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3845,  0.1932,  0.0796,  ..., -0.0329, -0.2244,  0.0606],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for threatening.\n",
      "thrilled is at index 8689\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0084,  0.3395,  0.2240,  ...,  0.1949,  0.2096, -0.1672],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for thrilled.\n",
      "thrown is at index 5629\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0709, -0.6065,  0.1260,  ...,  0.2818,  0.3300,  0.0904],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for thrown.\n",
      "thunderstruck is at index 4775\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1409, -0.1897, -0.2165,  ..., -0.3336,  0.4537, -0.0936],\n",
      "         [ 0.1982, -0.3151, -0.2151,  ..., -0.3520, -0.0846,  0.2366],\n",
      "         [ 0.4102,  0.0215,  0.2072,  ..., -0.0231,  0.1642,  0.5378],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for thunderstruck.\n",
      "thwarted is at index 28299\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0339, -0.5015,  0.2192,  ...,  0.0657,  0.4091,  0.1139],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for thwarted.\n",
      "ticked is at index 10457\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1524, -0.0194,  0.1634,  ..., -0.2252, -0.0192, -0.0336],\n",
      "         [-0.1786,  0.2013,  0.4345,  ...,  0.3394, -0.5501,  0.1632],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for ticked.\n",
      "tickled is at index 10457\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1524, -0.0194,  0.1634,  ..., -0.2252, -0.0192, -0.0336],\n",
      "         [-0.0402, -0.1098,  0.1399,  ..., -0.2213, -0.1115,  0.2467],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for tickled.\n",
      "tied is at index 3016\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1719, -0.4230,  0.1365,  ..., -0.1460, -0.4735, -0.1178],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for tied.\n",
      "tiered is at index 3318\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1641,  0.0133,  0.2750,  ..., -0.3887, -0.0712,  0.3142],\n",
      "         [ 0.3309,  0.2068, -0.1227,  ...,  0.1026, -0.0409,  0.0010],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for tiered.\n",
      "tight is at index 3229\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0365, -0.2262, -0.1618,  ..., -0.2810, -0.1891, -0.0598],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for tight.\n",
      "tightlipped is at index 3229\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0365, -0.2262, -0.1618,  ..., -0.2810, -0.1891, -0.0598],\n",
      "         [ 0.1232,  0.0721,  0.0478,  ...,  0.2697, -0.1203,  0.1628],\n",
      "         [ 0.2058,  0.5957,  0.1355,  ...,  0.0273, -0.1491,  0.0398],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for tightlipped.\n",
      "timid is at index 39649\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0462, -0.0367,  0.2320,  ..., -0.0594, -0.1243,  0.3234],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for timid.\n",
      "timidly is at index 39649\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0462, -0.0367,  0.2320,  ..., -0.0594, -0.1243,  0.3234],\n",
      "         [ 0.3543,  0.3169,  0.0401,  ..., -0.1069, -0.5598,  0.1301],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for timidly.\n",
      "timidness is at index 39649\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0462, -0.0367,  0.2320,  ..., -0.0594, -0.1243,  0.3234],\n",
      "         [-0.1231,  0.1777,  0.1255,  ..., -0.4542,  0.0778,  0.0067],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for timidness.\n",
      "tired is at index 7428\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0954, -0.3160,  0.5811,  ...,  0.3161,  0.0394,  0.1738],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for tired.\n",
      "tiredly is at index 7428\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0954, -0.3160,  0.5811,  ...,  0.3161,  0.0394,  0.1738],\n",
      "         [ 0.3543,  0.3169,  0.0401,  ..., -0.1069, -0.5598,  0.1301],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for tiredly.\n",
      "tiredness is at index 7428\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0954, -0.3160,  0.5811,  ...,  0.3161,  0.0394,  0.1738],\n",
      "         [-0.1231,  0.1777,  0.1255,  ..., -0.4542,  0.0778,  0.0067],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for tiredness.\n",
      "titillated is at index 13515\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-1.6118e-01,  7.0943e-02, -1.1938e-01,  ...,  1.1974e-01,\n",
      "           2.0992e-01,  4.8746e-02],\n",
      "         [ 6.6730e-01,  5.3889e-01,  4.0654e-01,  ...,  1.7306e-01,\n",
      "          -4.4610e-01, -2.7243e-01],\n",
      "         [ 7.0715e-02,  9.0628e-01,  5.2908e-01,  ..., -1.1324e-01,\n",
      "           4.5858e-02,  5.1753e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for titillated.\n",
      "tolerant is at index 32836\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0233, -0.3751,  0.3422,  ...,  0.2803, -0.3864,  0.1871],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for tolerant.\n",
      "tongue is at index 15686\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3757, -0.7124,  0.5041,  ..., -0.2505,  0.1547, -0.5112],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for tongue.\n",
      "tormented is at index 16535\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0150, -0.0796,  0.1004,  ...,  0.0609,  0.6692, -0.3928],\n",
      "         [-0.3516,  0.6415, -0.3666,  ...,  0.2161, -0.2011,  0.3667],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for tormented.\n",
      "touched is at index 6699\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0758,  0.5101,  0.4851,  ..., -0.0022, -0.1686, -0.3330],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for touched.\n",
      "tough is at index 1828\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0511, -0.0766,  0.1921,  ...,  0.5930, -0.2631,  0.1551],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for tough.\n",
      "toying is at index 7\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0609, -0.0148,  0.2529,  ...,  0.1063, -0.3661,  0.2041],\n",
      "         [-0.1450,  0.6074, -0.1164,  ..., -0.2051, -0.0454,  0.4222],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for toying.\n",
      "tragic is at index 8805\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3249,  0.4677, -0.1773,  ..., -0.0331,  0.1221,  0.1150],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for tragic.\n",
      "tragical is at index 2664\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1417,  0.3510,  0.4179,  ...,  0.0237, -0.2656, -0.0339],\n",
      "         [ 0.3773,  0.3764,  0.6317,  ..., -0.2165,  0.2533,  0.1200],\n",
      "         [-0.2949,  0.4707,  0.0365,  ...,  0.3417,  0.2391, -0.0731],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for tragical.\n",
      "tranquil is at index 33535\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2319, -0.0073, -0.0889,  ..., -0.1894,  0.1141,  0.2171],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for tranquil.\n",
      "tranquility is at index 36474\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1701,  0.3653,  0.0852,  ..., -0.1997, -0.0814, -0.0045],\n",
      "         [-0.0935,  0.1815, -0.1183,  ...,  0.2855,  0.1111, -0.1170],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for tranquility.\n",
      "transfixed is at index 30387\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0107,  0.3284, -0.0735,  ..., -0.0865, -0.2676,  0.0706],\n",
      "         [-0.0393,  1.2448,  0.1758,  ...,  0.1215, -0.3328, -0.0133],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for transfixed.\n",
      "traumatized is at index 25178\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.4426, -0.1084, -0.2234,  ..., -0.1216,  0.2618, -0.0052],\n",
      "         [-0.0545,  0.4248,  0.1878,  ...,  0.0940, -0.2454,  0.3326],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for traumatized.\n",
      "trembling is at index 44912\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1619,  0.0763, -0.0608,  ..., -0.2581,  0.0394,  0.4148],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for trembling.\n",
      "trepid is at index 6110\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2420, -0.4866,  0.3374,  ...,  0.2067,  0.3039,  0.3004],\n",
      "         [ 0.0599,  0.1816, -0.1090,  ...,  0.0073, -0.2533,  0.3635],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for trepid.\n",
      "trepidation is at index 6110\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2420, -0.4866,  0.3374,  ...,  0.2067,  0.3039,  0.3004],\n",
      "         [-0.0947,  0.1127,  0.1079,  ...,  0.0166, -0.3818,  0.0607],\n",
      "         [ 0.2244,  0.2537, -0.0322,  ...,  0.5135, -0.1114,  0.0242],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for trepidation.\n",
      "trickster is at index 7610\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0434, -0.0069, -0.4202,  ...,  0.2689, -0.2372, -0.1050],\n",
      "         [ 0.3110,  0.0227, -0.1571,  ..., -0.5314,  0.2444,  0.4598],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for trickster.\n",
      "tricky is at index 12792\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1010,  0.2697, -0.0945,  ...,  0.0369,  0.1537,  0.0229],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for tricky.\n",
      "triumphant is at index 32025\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2465, -0.1259, -0.0285,  ...,  0.4349, -0.1013,  0.1669],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for triumphant.\n",
      "troubled is at index 9895\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3273,  0.5862,  0.1347,  ..., -0.0889,  0.2429,  0.3133],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for troubled.\n",
      "troublesome is at index 34056\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2381,  0.3384,  0.2362,  ..., -0.0108, -0.1755,  0.1693],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for troublesome.\n",
      "troubling is at index 15554\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0931,  0.3175,  0.2278,  ...,  0.1020, -0.1016,  0.3614],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for troubling.\n",
      "trusting is at index 28969\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1382, -0.3358,  0.2937,  ..., -0.3547, -0.1693, -0.1292],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for trusting.\n",
      "trustworthy is at index 32101\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2263,  0.1498,  0.1598,  ...,  0.1198, -0.4777,  0.3055],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for trustworthy.\n",
      "tumultuous is at index 23787\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1663,  0.3109, -0.3033,  ..., -0.0463,  0.4203,  0.1419],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for tumultuous.\n",
      "turbulent is at index 23415\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1139,  0.4274, -0.1028,  ..., -0.1477,  0.4684,  0.1247],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for turbulent.\n",
      "twinkly is at index 11901\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [ 5.8656e-02, -3.2102e-01,  1.6706e-02,  ...,  3.4328e-01,\n",
      "           1.5636e-01, -1.7486e-01],\n",
      "         [ 1.2415e-01,  4.1029e-02,  2.1294e-01,  ..., -3.8131e-01,\n",
      "           1.7595e-01,  7.3921e-01],\n",
      "         [ 4.5286e-01,  1.9752e-01, -2.2084e-02,  ..., -5.4241e-02,\n",
      "          -5.3192e-01,  1.5678e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for twinkly.\n",
      "umbrage is at index 7252\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-5.4918e-02, -4.0500e-01,  1.8883e-01,  ...,  2.2048e-01,\n",
      "           3.4424e-01, -3.4041e-01],\n",
      "         [ 4.7558e-01,  1.0609e-01,  1.8696e-01,  ..., -4.0943e-01,\n",
      "          -2.0581e-01,  8.3390e-01],\n",
      "         [-1.4012e-01, -3.3306e-01,  9.8940e-02,  ..., -4.7451e-03,\n",
      "           3.1741e-01,  2.2223e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for umbrage.\n",
      "umbrageous is at index 7252\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0549, -0.4050,  0.1888,  ...,  0.2205,  0.3442, -0.3404],\n",
      "         [ 0.4756,  0.1061,  0.1870,  ..., -0.4094, -0.2058,  0.8339],\n",
      "         [-0.1401, -0.3331,  0.0989,  ..., -0.0047,  0.3174,  0.2222],\n",
      "         [ 0.0350, -0.4172,  0.0931,  ...,  0.3579, -0.3119, -0.2287],\n",
      "         [ 0.2760, -0.1979, -0.1075,  ...,  0.4037,  0.0583,  0.1964]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for umbrageous.\n",
      "unaffected is at index 32512\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1222,  0.3531,  0.3679,  ..., -0.0377,  0.4397,  0.0860],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for unaffected.\n",
      "unagitated is at index 542\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1661, -0.4835,  0.2549,  ..., -0.1693, -0.2685, -0.4708],\n",
      "         [ 0.3773,  0.3764,  0.6317,  ..., -0.2165,  0.2533,  0.1200],\n",
      "         [ 0.1956,  0.1353,  0.1495,  ...,  0.0962,  0.3019,  0.3594],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for unagitated.\n",
      "unamused is at index 542\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1661, -0.4835,  0.2549,  ..., -0.1693, -0.2685, -0.4708],\n",
      "         [ 0.0517,  0.1733, -0.0684,  ..., -0.5554,  0.2448,  0.0999],\n",
      "         [ 0.1234,  0.5817, -0.1878,  ..., -0.6112, -0.1588,  0.1293],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for unamused.\n",
      "unappreciative is at index 542\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1661, -0.4835,  0.2549,  ..., -0.1693, -0.2685, -0.4708],\n",
      "         [ 0.0545,  0.4054,  0.2023,  ..., -0.1209, -0.0834,  0.3863],\n",
      "         [ 0.4692, -0.0139,  0.5674,  ..., -0.2530,  0.2501,  0.1665],\n",
      "         [ 0.1694,  0.1624, -0.2812,  ..., -0.1136,  0.5157,  0.0927],\n",
      "         [ 0.2760, -0.1979, -0.1075,  ...,  0.4037,  0.0583,  0.1964]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for unappreciative.\n",
      "unapproachable is at index 542\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-1.6610e-01, -4.8348e-01,  2.5491e-01,  ..., -1.6931e-01,\n",
      "          -2.6851e-01, -4.7084e-01],\n",
      "         [ 3.1020e-01,  7.9693e-01, -5.4903e-01,  ..., -2.4704e-01,\n",
      "          -4.2359e-01,  2.0880e-01],\n",
      "         [ 2.4364e-01, -2.0376e-01, -3.8105e-01,  ..., -4.8618e-01,\n",
      "          -2.4357e-01, -1.8687e-02],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for unapproachable.\n",
      "unassertive is at index 542\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1661, -0.4835,  0.2549,  ..., -0.1693, -0.2685, -0.4708],\n",
      "         [-0.0614,  0.0572, -0.0523,  ..., -0.2685, -0.0829,  0.4021],\n",
      "         [ 0.2886,  0.2062,  0.1140,  ...,  0.0716, -0.1374,  0.4649],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for unassertive.\n",
      "unassuming is at index 542\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1661, -0.4835,  0.2549,  ..., -0.1693, -0.2685, -0.4708],\n",
      "         [-0.0264,  0.3326, -0.1166,  ..., -0.5716, -0.2448, -0.1213],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for unassuming.\n",
      "unaware is at index 14021\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3859, -0.2838, -0.2429,  ..., -0.4377, -0.1139, -0.1129],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for unaware.\n",
      "unbelief is at index 46646\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1627, -0.3408,  0.8139,  ..., -0.0592, -0.1696, -0.1214],\n",
      "         [ 0.3453,  0.5795,  0.0110,  ..., -0.1703, -0.2048,  0.4024],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for unbelief.\n",
      "unbelievable is at index 14011\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2376,  0.1560, -0.0360,  ..., -0.1251,  0.2751, -0.2898],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for unbelievable.\n",
      "unbelieving is at index 46646\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1627, -0.3408,  0.8139,  ..., -0.0592, -0.1696, -0.1214],\n",
      "         [-0.0295,  0.6889, -0.3564,  ...,  0.1062,  0.4223,  0.0153],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for unbelieving.\n",
      "unbothered is at index 542\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1661, -0.4835,  0.2549,  ..., -0.1693, -0.2685, -0.4708],\n",
      "         [-0.2795,  0.4968,  0.2214,  ..., -0.3465, -0.4149,  0.1677],\n",
      "         [ 0.1838,  0.2294,  0.0608,  ..., -0.0798,  0.0483,  0.0545],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for unbothered.\n",
      "uncaring is at index 16511\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1733,  0.1319, -0.0700,  ...,  0.3934, -0.2144, -0.4708],\n",
      "         [ 0.0506,  0.6732,  0.2138,  ..., -0.2322, -0.1516,  0.6982],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for uncaring.\n",
      "uncertain is at index 9684\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1760, -0.0796,  0.1108,  ..., -0.2867,  0.4567,  0.1213],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for uncertain.\n",
      "uncertainly is at index 9684\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1760, -0.0796,  0.1108,  ..., -0.2867,  0.4567,  0.1213],\n",
      "         [ 0.3543,  0.3169,  0.0401,  ..., -0.1069, -0.5598,  0.1301],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for uncertainly.\n",
      "uncertainty is at index 4983\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1008,  0.2882, -0.0565,  ..., -0.3287,  0.6329, -0.0299],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for uncertainty.\n",
      "uncivil is at index 16511\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1733,  0.1319, -0.0700,  ...,  0.3934, -0.2144, -0.4708],\n",
      "         [ 0.5098,  0.2765, -0.2544,  ...,  0.2680, -0.7187, -0.0605],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for uncivil.\n",
      "uncomfortable is at index 9800\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1706, -0.0854,  0.6335,  ..., -0.1254,  0.0163,  0.1257],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for uncomfortable.\n",
      "uncommitted is at index 32275\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0799,  0.0989,  0.2953,  ..., -0.4707, -0.0406, -0.0807],\n",
      "         [-0.1277,  0.6704, -0.5112,  ..., -0.5152, -0.5937,  0.1553],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for uncommitted.\n",
      "uncommunicative is at index 32275\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0799,  0.0989,  0.2953,  ..., -0.4707, -0.0406, -0.0807],\n",
      "         [ 0.3477,  0.1842,  0.2989,  ...,  0.3948, -0.3983,  0.2540],\n",
      "         [ 0.0345,  0.5213, -0.6232,  ..., -0.2026, -0.1930,  0.3608],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for uncommunicative.\n",
      "uncomprehending is at index 32275\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0799,  0.0989,  0.2953,  ..., -0.4707, -0.0406, -0.0807],\n",
      "         [-0.4173, -0.0806, -0.0098,  ..., -0.3255,  0.1112,  0.2496],\n",
      "         [ 0.3490, -0.4902,  0.7105,  ..., -0.3705, -0.3716,  0.4770],\n",
      "         [ 0.2728,  0.2208,  0.0364,  ...,  0.3389, -0.2359,  0.0680],\n",
      "         [ 0.2760, -0.1979, -0.1075,  ...,  0.4037,  0.0583,  0.1964]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for uncomprehending.\n",
      "uncompromising is at index 32213\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0333,  0.1868, -0.1377,  ..., -0.0547, -0.1481,  0.1881],\n",
      "         [ 0.1062,  0.2360, -0.1622,  ..., -0.1491,  0.3053,  0.5317],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for uncompromising.\n",
      "unconcerned is at index 28198\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1875,  0.0104,  0.3959,  ..., -0.2699,  0.0414, -0.1186],\n",
      "         [-0.4486,  1.2923, -0.1588,  ..., -0.5504, -0.2444,  0.4774],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for unconcerned.\n",
      "unconfident is at index 542\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-1.6610e-01, -4.8348e-01,  2.5491e-01,  ..., -1.6931e-01,\n",
      "          -2.6851e-01, -4.7084e-01],\n",
      "         [-1.4694e-01,  4.1407e-01,  3.1714e-03,  ..., -3.1612e-01,\n",
      "          -2.8326e-02, -3.1264e-01],\n",
      "         [-1.0276e-01,  7.2009e-01,  5.6509e-02,  ..., -5.0153e-01,\n",
      "          -1.4850e-01,  1.1767e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for unconfident.\n",
      "unconvinced is at index 28198\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-1.8750e-01,  1.0400e-02,  3.9589e-01,  ..., -2.6994e-01,\n",
      "           4.1423e-02, -1.1862e-01],\n",
      "         [-3.3434e-01,  1.0221e-02,  5.4096e-01,  ..., -5.7763e-02,\n",
      "          -3.3520e-01,  4.7136e-02],\n",
      "         [-1.7364e-01,  5.1629e-01, -8.1892e-02,  ..., -1.7145e-01,\n",
      "          -7.2258e-01,  2.6829e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for unconvinced.\n",
      "uncooperative is at index 542\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-1.6610e-01, -4.8348e-01,  2.5491e-01,  ..., -1.6931e-01,\n",
      "          -2.6851e-01, -4.7084e-01],\n",
      "         [ 1.3533e-01,  9.5683e-01,  3.0804e-01,  ..., -4.0682e-01,\n",
      "          -3.3250e-01, -4.1808e-02],\n",
      "         [-2.1771e-01, -2.5043e-01, -5.1795e-01,  ...,  5.0492e-02,\n",
      "          -1.2113e-01,  2.4460e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for uncooperative.\n",
      "uncurious is at index 16511\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1733,  0.1319, -0.0700,  ...,  0.3934, -0.2144, -0.4708],\n",
      "         [ 0.0674,  0.2586, -0.0345,  ...,  0.1410,  0.0100,  0.0963],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for uncurious.\n",
      "undecided is at index 28598\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1521,  0.2244,  0.4207,  ...,  0.0173, -0.2672, -0.2125],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for undecided.\n",
      "underhanded is at index 223\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0987, -0.1298,  0.1097,  ...,  0.0971, -0.2871,  0.2193],\n",
      "         [-0.3785, -0.1858, -0.0753,  ..., -0.1790, -0.1432,  0.2136],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for underhanded.\n",
      "understanding is at index 2969\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0776, -0.0174,  0.1078,  ...,  0.1748,  0.3758,  0.1908],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for understanding.\n",
      "undesirable is at index 39028\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0970,  0.2883,  0.1075,  ..., -0.0684,  0.1561,  0.2548],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for undesirable.\n",
      "unease is at index 12515\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3465, -0.4222, -0.3762,  ...,  0.0482, -0.0468,  0.3025],\n",
      "         [-0.1660,  0.0600,  0.3686,  ..., -0.7509,  0.1465, -0.1595],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for unease.\n",
      "uneasily is at index 12515\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-3.4648e-01, -4.2220e-01, -3.7621e-01,  ...,  4.8218e-02,\n",
      "          -4.6753e-02,  3.0252e-01],\n",
      "         [-1.6851e-01,  6.4825e-02,  1.1156e-02,  ..., -5.3431e-01,\n",
      "          -2.7914e-01, -1.2566e-01],\n",
      "         [ 3.8036e-02,  2.8584e-01, -4.6204e-01,  ..., -6.6164e-02,\n",
      "          -7.6790e-01, -5.0455e-02],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for uneasily.\n",
      "uneasiness is at index 12515\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3465, -0.4222, -0.3762,  ...,  0.0482, -0.0468,  0.3025],\n",
      "         [-0.1685,  0.0648,  0.0112,  ..., -0.5343, -0.2791, -0.1257],\n",
      "         [-0.1155,  0.1870, -0.2350,  ...,  0.0207,  0.2364, -0.4059],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for uneasiness.\n",
      "uneasy is at index 29569\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3531,  0.2074,  0.1819,  ..., -0.3694, -0.0362,  0.1052],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for uneasy.\n",
      "unemotional is at index 542\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-1.6610e-01, -4.8348e-01,  2.5491e-01,  ..., -1.6931e-01,\n",
      "          -2.6851e-01, -4.7084e-01],\n",
      "         [ 6.1949e-01, -2.3978e-01,  1.0783e-01,  ...,  1.9645e-02,\n",
      "           1.6094e-01,  8.1056e-01],\n",
      "         [ 1.9154e-01,  7.6296e-01, -3.8440e-02,  ..., -3.7544e-01,\n",
      "           2.5704e-02,  3.0676e-02],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for unemotional.\n",
      "unenthusiastic is at index 542\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1661, -0.4835,  0.2549,  ..., -0.1693, -0.2685, -0.4708],\n",
      "         [ 0.0903, -0.2613,  0.2799,  ...,  0.0009,  0.2593,  0.6205],\n",
      "         ...,\n",
      "         [ 0.8461, -0.1502, -0.0947,  ..., -0.1917, -0.1337,  0.3315],\n",
      "         [-0.0695,  0.3583, -0.0867,  ..., -0.2211, -0.0361,  0.1512],\n",
      "         [ 0.2451, -0.1658, -0.0346,  ...,  0.3914,  0.1459,  0.1849]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for unenthusiastic.\n",
      "unexcited is at index 39432\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-1.8515e-02,  3.0806e-01,  2.8911e-01,  ..., -1.3964e-01,\n",
      "           3.6044e-02,  3.2512e-01],\n",
      "         [ 2.5519e-01,  3.7928e-01, -1.6959e-01,  ...,  6.7259e-02,\n",
      "          -1.1665e-01,  2.4678e-01],\n",
      "         [ 5.0011e-01,  7.6923e-01,  4.9628e-02,  ...,  1.1828e-02,\n",
      "           2.1502e-01,  1.0322e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for unexcited.\n",
      "unexpected is at index 7152\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.5095,  0.3318, -0.2159,  ...,  0.0299,  0.3020, -0.2645],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for unexpected.\n",
      "unfamiliar is at index 21942\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0162, -0.3690,  0.0349,  ..., -0.0953, -0.1094, -0.3316],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for unfamiliar.\n",
      "unfathomable is at index 9515\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2549, -0.1388,  0.0018,  ..., -0.1009,  0.0103, -0.1620],\n",
      "         [ 0.5618, -0.1703,  0.1973,  ..., -0.3991, -0.1988, -0.3837],\n",
      "         [ 0.5674, -0.2207,  0.0994,  ...,  0.1118,  0.1132,  0.2356],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for unfathomable.\n",
      "unfazed is at index 9515\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2549, -0.1388,  0.0018,  ..., -0.1009,  0.0103, -0.1620],\n",
      "         [ 0.0665,  0.0330,  0.4868,  ..., -0.1887,  0.0429,  0.3282],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for unfazed.\n",
      "unfeeling is at index 9515\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2549, -0.1388,  0.0018,  ..., -0.1009,  0.0103, -0.1620],\n",
      "         [ 0.4767, -0.5947, -0.5114,  ...,  0.4044, -0.5822,  0.5323],\n",
      "         [ 0.2474, -0.0826,  0.3113,  ..., -0.2265, -0.0207,  0.5334],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for unfeeling.\n",
      "unfocused is at index 47306\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1280,  0.0979, -0.3946,  ..., -0.0588, -0.1096,  0.1909],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for unfocused.\n",
      "unforeseen is at index 33257\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0361,  0.1648, -0.3938,  ..., -0.3059,  0.4801,  0.1328],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for unforeseen.\n",
      "unforgiving is at index 34262\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3905, -0.6429, -0.0376,  ..., -0.0376,  0.1044,  0.2361],\n",
      "         [ 0.0584, -0.3741,  0.0604,  ..., -0.2394,  0.3973,  0.1999],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for unforgiving.\n",
      "unforthcoming is at index 9515\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [ 2.5489e-01, -1.3878e-01,  1.8453e-03,  ..., -1.0086e-01,\n",
      "           1.0337e-02, -1.6204e-01],\n",
      "         [ 1.3947e-01,  1.6598e-01,  1.0218e+00,  ...,  7.9640e-02,\n",
      "          -1.0785e-01,  5.1058e-02],\n",
      "         [-2.3749e-01, -2.3347e-01, -2.2283e-01,  ..., -7.1225e-01,\n",
      "          -1.2384e-01,  1.4281e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for unforthcoming.\n",
      "unfortunate is at index 9327\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0886, -0.0015,  0.1518,  ...,  0.1952,  0.0205,  0.0200],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for unfortunate.\n",
      "unfriendly is at index 9515\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2549, -0.1388,  0.0018,  ..., -0.1009,  0.0103, -0.1620],\n",
      "         [ 0.2633, -0.2029, -0.2948,  ..., -0.2098, -0.2125,  0.1161],\n",
      "         [ 0.4529,  0.1975, -0.0221,  ..., -0.0542, -0.5319,  0.1568],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for unfriendly.\n",
      "unhappy is at index 13865\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1247,  0.5134,  0.5861,  ..., -0.0829,  0.1090,  0.2167],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for unhappy.\n",
      "unhinged is at index 542\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1661, -0.4835,  0.2549,  ..., -0.1693, -0.2685, -0.4708],\n",
      "         [ 0.1277, -0.0968,  0.3449,  ..., -0.3357, -0.3856, -0.0705],\n",
      "         [-0.0763,  0.0823,  0.3715,  ...,  0.3918, -0.5245,  0.1909],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for unhinged.\n",
      "unimpressed is at index 542\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1661, -0.4835,  0.2549,  ..., -0.1693, -0.2685, -0.4708],\n",
      "         [-0.1572,  0.4870, -0.0817,  ...,  0.3071,  0.3932, -0.0341],\n",
      "         [ 0.3300, -0.1649, -0.0340,  ..., -0.6173, -0.0359,  0.0560],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for unimpressed.\n",
      "uninformed is at index 21969\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0411,  0.1438,  0.3850,  ..., -0.3763,  0.2363, -0.2091],\n",
      "         [-0.3035,  0.3253, -0.1228,  ..., -0.7519, -0.6674, -0.1319],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for uninformed.\n",
      "uninspired is at index 542\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1661, -0.4835,  0.2549,  ..., -0.1693, -0.2685, -0.4708],\n",
      "         [ 0.1084,  0.3618, -0.4488,  ...,  0.2134,  0.0217,  0.0995],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for uninspired.\n",
      "uninterested is at index 542\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1661, -0.4835,  0.2549,  ..., -0.1693, -0.2685, -0.4708],\n",
      "         [ 0.1845,  0.6920, -0.1450,  ..., -0.8040, -0.1258,  0.3181],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for uninterested.\n",
      "uninvolved is at index 542\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1661, -0.4835,  0.2549,  ..., -0.1693, -0.2685, -0.4708],\n",
      "         [-0.1884,  0.1631, -0.3985,  ..., -0.5762, -0.0196, -0.0841],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for uninvolved.\n",
      "unique is at index 2216\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0554,  0.4157, -0.1286,  ...,  0.3744,  0.2871, -0.0984],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for unique.\n",
      "unlikeable is at index 7328\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1774, -0.5866,  0.1738,  ...,  0.1408,  0.2838,  0.4185],\n",
      "         [ 0.4713, -0.1066,  0.1604,  ...,  0.0613,  0.0895,  0.2098],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for unlikeable.\n",
      "unmoved is at index 30780\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1009,  0.0969,  0.2000,  ...,  0.0416,  0.1759, -0.3739],\n",
      "         [-0.4362,  0.9195,  0.1323,  ..., -0.1092,  0.0458,  0.6165],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for unmoved.\n",
      "unnerved is at index 31550\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1910,  0.0654,  0.3988,  ...,  0.0302,  0.3826,  0.2930],\n",
      "         [-0.4216,  0.7628,  0.6954,  ..., -0.0713,  0.0912, -0.0121],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for unnerved.\n",
      "unpleasant is at index 26262\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0267,  0.2289,  0.3971,  ...,  0.1789, -0.1520, -0.3138],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for unpleasant.\n",
      "unprepared is at index 35578\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0502, -0.4136, -0.0746,  ..., -0.3031, -0.0674, -0.3527],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for unprepared.\n",
      "unquiet is at index 542\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1661, -0.4835,  0.2549,  ..., -0.1693, -0.2685, -0.4708],\n",
      "         [ 0.0660,  0.0401,  0.0242,  ..., -0.3747, -0.2477,  0.1395],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for unquiet.\n",
      "unreactive is at index 21153\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.5085, -0.2122,  0.1974,  ..., -0.0678, -0.0720, -0.1380],\n",
      "         [-0.1872,  0.1475,  0.0291,  ..., -0.3139,  0.0372,  0.2490],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for unreactive.\n",
      "unresolved is at index 29909\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0848, -0.0677, -0.7524,  ..., -0.1063,  0.0085, -0.0308],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for unresolved.\n",
      "unrestrained is at index 12254\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0530,  0.0242,  0.0700,  ..., -0.0532, -0.1582,  0.2176],\n",
      "         [ 0.1231,  0.3949, -0.0139,  ...,  0.2165, -0.4112,  0.4657],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for unrestrained.\n",
      "unruffled is at index 542\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1661, -0.4835,  0.2549,  ..., -0.1693, -0.2685, -0.4708],\n",
      "         [-0.0543, -0.0223,  0.2946,  ...,  0.2564,  0.0295,  0.1321],\n",
      "         [ 0.0589, -0.2250,  0.0798,  ..., -0.1709, -0.0874,  0.2744],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for unruffled.\n",
      "unsatisfied is at index 36010\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0071, -0.3687,  0.0805,  ..., -0.1259, -0.0731, -0.3026],\n",
      "         [-0.6580,  0.6204,  0.1935,  ...,  0.1951, -0.3345,  0.0507],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for unsatisfied.\n",
      "unsettled is at index 30933\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2774,  0.3890,  0.1081,  ..., -0.3651,  0.3794,  0.3054],\n",
      "         [-0.0402, -0.1098,  0.1399,  ..., -0.2213, -0.1115,  0.2467],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for unsettled.\n",
      "unsociable is at index 9977\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0919, -0.1988, -0.0764,  ...,  0.2507, -0.3077,  0.0631],\n",
      "         [ 0.4790,  0.0343, -0.1077,  ..., -0.5338,  0.4010,  0.3966],\n",
      "         [ 0.5674, -0.2207,  0.0994,  ...,  0.1118,  0.1132,  0.2356],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for unsociable.\n",
      "unspeaking is at index 542\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1661, -0.4835,  0.2549,  ..., -0.1693, -0.2685, -0.4708],\n",
      "         [-0.3411, -0.4986, -0.4475,  ..., -0.4399, -0.4055, -0.4739],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for unspeaking.\n",
      "unspoken is at index 542\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1661, -0.4835,  0.2549,  ..., -0.1693, -0.2685, -0.4708],\n",
      "         [-0.5485,  0.1086, -0.3569,  ..., -0.5408, -0.0394, -0.3170],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for unspoken.\n",
      "unstrung is at index 542\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1661, -0.4835,  0.2549,  ..., -0.1693, -0.2685, -0.4708],\n",
      "         [ 0.0232,  0.0113, -0.4245,  ..., -0.2486,  0.2409,  0.4824],\n",
      "         [-0.4069,  0.4513,  0.5727,  ...,  0.1675,  0.1120, -0.3204],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for unstrung.\n",
      "unsuccessful is at index 15943\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0596, -0.3790, -0.2994,  ...,  0.0197, -0.2320,  0.4045],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for unsuccessful.\n",
      "unsure is at index 17118\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0058,  0.1423,  0.3924,  ..., -0.5100,  0.0387, -0.0273],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for unsure.\n",
      "unsurprised is at index 36637\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0896, -0.3698,  0.0844,  ..., -0.0990, -0.0442,  0.0983],\n",
      "         [ 0.3830,  0.0858,  0.0192,  ...,  0.3836, -0.1857,  0.0512],\n",
      "         [ 0.0551, -0.1164,  0.0087,  ..., -0.4503, -0.2866,  0.5446],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for unsurprised.\n",
      "unsuspecting is at index 32276\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0960,  0.0852,  0.0472,  ..., -0.2547,  0.2304,  0.2517],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for unsuspecting.\n",
      "unswayed is at index 9977\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0919, -0.1988, -0.0764,  ...,  0.2507, -0.3077,  0.0631],\n",
      "         [-0.1561,  0.4994,  0.4555,  ..., -0.4668, -0.4897, -0.0169],\n",
      "         [-0.0763,  0.0823,  0.3715,  ...,  0.3918, -0.5245,  0.1909],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for unswayed.\n",
      "unsympathetic is at index 542\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1661, -0.4835,  0.2549,  ..., -0.1693, -0.2685, -0.4708],\n",
      "         [ 0.2127,  0.3758,  0.1184,  ..., -0.4298, -0.0941, -0.0520],\n",
      "         [-0.0311,  0.4091,  0.0083,  ...,  0.0514, -0.2704, -0.2298],\n",
      "         [ 0.2086,  0.3092,  0.4063,  ..., -0.2828,  0.5744,  0.5166],\n",
      "         [ 0.2760, -0.1979, -0.1075,  ...,  0.4037,  0.0583,  0.1964]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for unsympathetic.\n",
      "untouched is at index 29929\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0912, -0.2461,  0.0940,  ...,  0.1669, -0.0176,  0.1004],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for untouched.\n",
      "untroubled is at index 7587\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0612, -0.0488, -0.1252,  ..., -0.0715,  0.2503, -0.3029],\n",
      "         [-0.0681,  0.0991,  0.2899,  ..., -0.3853, -0.3815,  0.1001],\n",
      "         [-0.3390,  0.1419, -0.2939,  ..., -0.0752, -0.0495,  0.1118],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for untroubled.\n",
      "untrusting is at index 7587\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0612, -0.0488, -0.1252,  ..., -0.0715,  0.2503, -0.3029],\n",
      "         [ 0.0468, -0.4333, -0.1019,  ..., -0.3731,  0.0349,  0.1065],\n",
      "         [ 0.2407,  0.2558,  0.0720,  ...,  0.2923, -0.3174,  0.0513],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for untrusting.\n",
      "unwanted is at index 15067\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3345, -0.4626, -0.1460,  ..., -0.0709,  0.5448,  0.4576],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for unwanted.\n",
      "unwavering is at index 10963\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1280, -0.2360,  0.2625,  ...,  0.4977,  0.1545,  0.3394],\n",
      "         [-0.2387,  0.3866, -0.1421,  ..., -0.3486, -0.0310,  0.2108],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for unwavering.\n",
      "unwelcoming is at index 10963\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [ 1.2804e-01, -2.3604e-01,  2.6251e-01,  ...,  4.9767e-01,\n",
      "           1.5450e-01,  3.3937e-01],\n",
      "         [ 6.4273e-01, -3.2281e-01,  6.9389e-01,  ...,  6.6426e-02,\n",
      "          -2.6424e-01,  2.0779e-01],\n",
      "         [-2.3749e-01, -2.3347e-01, -2.2283e-01,  ..., -7.1225e-01,\n",
      "          -1.2384e-01,  1.4281e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for unwelcoming.\n",
      "unwell is at index 542\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1661, -0.4835,  0.2549,  ..., -0.1693, -0.2685, -0.4708],\n",
      "         [ 0.1593, -0.0350,  0.2522,  ..., -0.1278, -0.0823,  0.2390],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for unwell.\n",
      "unwilling is at index 20656\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0152, -0.5582,  0.4938,  ..., -0.2835,  0.0652,  0.0671],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for unwilling.\n",
      "unyielding is at index 542\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1661, -0.4835,  0.2549,  ..., -0.1693, -0.2685, -0.4708],\n",
      "         [ 0.1311, -0.1715,  0.0534,  ..., -0.0509, -0.4687, -0.2923],\n",
      "         [ 0.2883,  0.3924, -0.3804,  ..., -0.4945,  0.3080, -0.0477],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for unyielding.\n",
      "up is at index 62\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1017,  0.0091,  0.0610,  ..., -0.0568, -0.6239,  0.1089],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for up.\n",
      "upbeat is at index 14899\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0301,  0.8282, -0.0985,  ..., -0.0327,  0.1571,  0.2146],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for upbeat.\n",
      "uplifting is at index 17627\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3381,  0.1007,  0.4108,  ...,  0.0313,  0.1630, -0.0833],\n",
      "         [ 0.1003,  0.7553, -0.1580,  ...,  0.0804,  0.5529,  0.4891],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for uplifting.\n",
      "uppity is at index 1717\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0727,  0.0644,  0.3074,  ...,  0.1203,  0.1099,  0.0646],\n",
      "         [ 0.0869,  0.2135,  0.3538,  ..., -0.5718, -0.4344,  0.4724],\n",
      "         [ 0.2334,  0.3192,  0.2969,  ..., -0.5207, -0.0139, -0.2105],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for uppity.\n",
      "upset is at index 4904\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1904,  0.4793,  0.3417,  ..., -0.6677,  0.1466, -0.1010],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for upset.\n",
      "uptight is at index 18256\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1227, -0.1255,  0.2056,  ..., -0.0380,  0.1005, -0.4176],\n",
      "         [-0.3401,  0.0603,  0.0688,  ..., -0.4690,  0.4747,  0.2104],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for uptight.\n",
      "useless is at index 23584\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1613, -0.1600, -0.0050,  ...,  0.2127,  0.1040,  0.1981],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for useless.\n",
      "vacant is at index 11042\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2942, -0.0366,  0.4535,  ..., -0.5787, -0.2468, -0.0237],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for vacant.\n",
      "vacuous is at index 18721\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3921, -0.4201,  0.2384,  ..., -0.1625,  0.1742,  0.1120],\n",
      "         [ 0.1306, -0.0317,  0.2685,  ..., -0.0785, -0.3928, -0.3087],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for vacuous.\n",
      "vanquished is at index 44400\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0101, -0.4978,  0.0312,  ..., -0.0358,  0.1507,  0.0507],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for vanquished.\n",
      "vehement is at index 45373\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0398,  0.1575,  0.2106,  ..., -0.0250, -0.1837,  0.2654],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for vehement.\n",
      "vengeful is at index 748\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-4.8911e-02, -4.8734e-02,  7.3876e-01,  ...,  1.3276e-01,\n",
      "          -3.8818e-01,  4.3566e-01],\n",
      "         [ 8.0643e-03, -2.0430e-01, -2.4867e-02,  ..., -2.7163e-01,\n",
      "          -2.3330e-01,  1.8056e-01],\n",
      "         [ 3.9899e-01, -8.8491e-03, -4.2134e-01,  ...,  2.0336e-01,\n",
      "          -3.8005e-01, -2.2930e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for vengeful.\n",
      "venomous is at index 32051\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1325,  0.1236,  0.4903,  ...,  0.1154,  0.4317,  0.1296],\n",
      "         [-0.0881, -0.2759,  0.1838,  ...,  0.2681, -0.4104, -0.2701],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for venomous.\n",
      "vex is at index 37894\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1952,  0.2712,  0.4364,  ...,  0.3311, -0.0856,  0.2631],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for vex.\n",
      "vexation is at index 37894\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1952,  0.2712,  0.4364,  ...,  0.3311, -0.0856,  0.2631],\n",
      "         [ 0.1896,  0.6529,  0.2115,  ...,  0.5904, -0.0469,  0.0362],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for vexation.\n",
      "vexed is at index 37894\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1952,  0.2712,  0.4364,  ...,  0.3311, -0.0856,  0.2631],\n",
      "         [-0.1786,  0.2013,  0.4345,  ...,  0.3394, -0.5501,  0.1632],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for vexed.\n",
      "vicious is at index 16339\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2917,  0.5700, -0.0838,  ..., -0.0020, -0.1390,  0.3906],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for vicious.\n",
      "victorious is at index 22518\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0755, -0.5815,  0.3429,  ...,  0.0563,  0.0648,  0.1860],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for victorious.\n",
      "vigilant is at index 17258\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2403, -0.1699,  0.1110,  ..., -0.0956, -0.2690,  0.1613],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for vigilant.\n",
      "vile is at index 32359\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2722, -0.1281, -0.3669,  ..., -0.0240, -0.1593, -0.1013],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for vile.\n",
      "villainous is at index 17031\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0635,  0.0949,  0.1833,  ...,  0.1549,  0.3963, -0.1950],\n",
      "         [-0.0881, -0.2759,  0.1838,  ...,  0.2681, -0.4104, -0.2701],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for villainous.\n",
      "vindictive is at index 21339\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0867, -0.7167,  0.2456,  ...,  0.4168, -0.0458, -0.3853],\n",
      "         [ 0.4133,  1.2211, -0.6790,  ..., -0.1850, -0.0198, -0.1203],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for vindictive.\n",
      "violence is at index 1476\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1559,  0.1591, -0.2528,  ...,  0.0741,  0.2354,  0.5758],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for violence.\n",
      "violent is at index 4153\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1138,  0.2743, -0.1206,  ...,  0.0306,  0.1200,  0.3447],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for violent.\n",
      "viperous is at index 748\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-4.8911e-02, -4.8734e-02,  7.3876e-01,  ...,  1.3276e-01,\n",
      "          -3.8818e-01,  4.3566e-01],\n",
      "         [-7.4414e-03,  6.1003e-01, -3.9842e-01,  ..., -3.3423e-03,\n",
      "          -6.2020e-03,  9.4470e-02],\n",
      "         [ 6.2312e-03, -3.8450e-01,  1.2523e-01,  ...,  3.1559e-01,\n",
      "          -3.8559e-01, -2.4341e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for viperous.\n",
      "vituperative is at index 14306\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-3.3223e-01,  5.8642e-01,  3.6723e-01,  ...,  3.7350e-01,\n",
      "          -1.6591e-01,  2.2201e-01],\n",
      "         [ 2.0499e-01,  7.5825e-01,  2.1704e-01,  ..., -2.0195e-01,\n",
      "           6.2347e-02,  4.3359e-02],\n",
      "         [ 1.4141e-01,  1.9555e-01, -2.4921e-01,  ..., -1.5649e-01,\n",
      "           4.4205e-01,  7.7889e-02],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for vituperative.\n",
      "vocal is at index 7578\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0128, -0.0876, -0.1188,  ...,  0.1163, -0.6378, -0.0863],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for vocal.\n",
      "vocalized is at index 7578\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0128, -0.0876, -0.1188,  ...,  0.1163, -0.6378, -0.0863],\n",
      "         [-0.0545,  0.4248,  0.1878,  ...,  0.0940, -0.2454,  0.3326],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for vocalized.\n",
      "vulgar is at index 28792\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1819, -0.2340, -0.0643,  ..., -0.0796, -0.4123,  0.1952],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for vulgar.\n",
      "vulnerability is at index 15661\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1788,  0.3985,  0.0935,  ..., -0.1990,  0.7026,  0.3967],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for vulnerability.\n",
      "vulnerable is at index 4478\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.4025, -0.1061,  0.3300,  ..., -0.3837,  0.0048,  0.0816],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for vulnerable.\n",
      "wacky is at index 885\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1498, -0.3193,  0.3917,  ...,  0.2504,  0.1554,  0.1085],\n",
      "         [ 0.1303,  1.0380,  0.2439,  ..., -0.0031, -0.1617,  0.2978],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for wacky.\n",
      "waiting is at index 2445\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3025, -0.8051, -0.1348,  ..., -0.1457, -0.2316, -0.3400],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for waiting.\n",
      "wanted is at index 770\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0117,  0.2109,  0.1054,  ..., -0.1457, -0.3669,  0.2368],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for wanted.\n",
      "wanting is at index 6923\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1480, -0.3305,  0.0034,  ..., -0.0010,  0.4254, -0.0953],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for wanting.\n",
      "wanton is at index 236\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2720, -0.0885,  0.0661,  ...,  0.2133, -0.0264,  0.0577],\n",
      "         [ 0.1831, -0.0266,  0.3688,  ..., -0.0765, -0.2517,  0.2195],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for wanton.\n",
      "wariness is at index 997\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0230,  0.2180,  0.2015,  ...,  0.3297,  0.2287, -0.0933],\n",
      "         [-0.2111,  0.2981, -0.1767,  ..., -0.0285,  0.2131, -0.4322],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for wariness.\n",
      "warm is at index 3279\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.5955, -0.2253,  0.3070,  ...,  0.1277, -0.1686, -0.1782],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for warm.\n",
      "wary is at index 13441\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.4362, -0.1033, -0.0351,  ...,  0.0161,  0.0722,  0.4759],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for wary.\n",
      "wasted is at index 14260\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2265,  0.0286,  0.6049,  ..., -0.1236,  0.4671,  0.1176],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for wasted.\n",
      "watch is at index 1183\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.4470, -0.5454,  0.3008,  ..., -0.0015, -0.2191,  0.5908],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for watch.\n",
      "watchful is at index 1183\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.4470, -0.5454,  0.3008,  ..., -0.0015, -0.2191,  0.5908],\n",
      "         [ 0.3025,  0.1036, -0.3624,  ...,  0.1536, -0.4041, -0.2558],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for watchful.\n",
      "watching is at index 2494\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1519, -0.6280,  0.3511,  ..., -0.1770, -0.0948,  0.0210],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for watching.\n",
      "wavering is at index 13332\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0741, -0.2426, -0.0482,  ...,  0.0275,  0.3951, -0.1361],\n",
      "         [ 0.2024, -0.0917, -0.4739,  ...,  0.2724, -0.4808,  0.2246],\n",
      "         [ 0.2407,  0.2558,  0.0720,  ...,  0.2923, -0.3174,  0.0513],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for wavering.\n",
      "weariness is at index 3568\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3260, -0.3737,  0.2810,  ...,  0.4531, -0.0309,  0.4062],\n",
      "         [-0.2111,  0.2981, -0.1767,  ..., -0.0285,  0.2131, -0.4322],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for weariness.\n",
      "weary is at index 31554\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0462, -0.1809,  0.3783,  ...,  0.0799, -0.0919,  0.4735],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for weary.\n",
      "weeping is at index 39423\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2944,  0.1337,  0.1687,  ...,  0.0151, -0.1082,  0.2848],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for weeping.\n",
      "weird is at index 7735\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1058, -0.1886,  0.2265,  ...,  0.4997, -0.0995, -0.4793],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for weird.\n",
      "welcome is at index 2814\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.5124, -0.0456,  0.1496,  ...,  0.3237,  0.1384,  0.3693],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for welcome.\n",
      "welcoming is at index 10423\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.2813, -0.2016,  0.3592,  ...,  0.5784, -0.3867,  0.1948],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for welcoming.\n",
      "whatever is at index 3046\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1830, -0.3804,  0.1450,  ...,  0.0324,  0.1702, -0.3061],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for whatever.\n",
      "whimpering is at index 31754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1258,  0.3327,  0.0427,  ...,  0.2645,  0.1700,  0.0413],\n",
      "         [ 0.1057,  1.0936, -0.1933,  ..., -0.2768,  0.5266,  0.2954],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for whimpering.\n",
      "whimsical is at index 29363\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3293, -0.0334,  0.1540,  ...,  0.2871,  0.3565,  0.2077],\n",
      "         [-0.3909,  0.5831,  0.0951,  ...,  0.2938,  0.2165, -0.0992],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for whimsical.\n",
      "whisper is at index 37539\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1171,  0.0063, -0.3555,  ..., -0.0726, -0.4253, -0.2073],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for whisper.\n",
      "whistle is at index 16867\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.5274,  0.3000,  0.1390,  ...,  0.0750, -0.3716, -0.4332],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for whistle.\n",
      "white is at index 1104\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2777, -0.1375,  0.1550,  ..., -0.2162, -0.0940, -0.1277],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for white.\n",
      "wicked is at index 28418\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0580,  0.1594,  0.1361,  ..., -0.0321, -0.0660, -0.2859],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for wicked.\n",
      "wild is at index 3418\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0732, -0.2203,  0.6778,  ..., -0.0652, -0.0959,  0.0274],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for wild.\n",
      "willful is at index 40960\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0750,  0.1242, -0.0468,  ...,  0.1406, -0.2117,  0.2382],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for willful.\n",
      "willing is at index 2882\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1417, -0.5932,  0.7024,  ..., -0.0965, -0.0599, -0.0350],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for willing.\n",
      "wily is at index 885\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1498, -0.3193,  0.3917,  ...,  0.2504,  0.1554,  0.1085],\n",
      "         [-0.0544,  0.3943, -0.4063,  ..., -0.1141, -0.7923, -0.0758],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for wily.\n",
      "wink is at index 39422\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0996, -0.5155,  0.4903,  ..., -0.2788,  0.1874, -0.1461],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for wink.\n",
      "wired is at index 26977\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0330,  0.3642,  0.3592,  ..., -0.0712, -0.5927, -0.2716],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for wired.\n",
      "wishful is at index 2813\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.6518,  0.1750,  0.0550,  ..., -0.0286, -0.0801, -0.0361],\n",
      "         [ 0.3025,  0.1036, -0.3624,  ...,  0.1536, -0.4041, -0.2558],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for wishful.\n",
      "wistful is at index 885\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1498, -0.3193,  0.3917,  ...,  0.2504,  0.1554,  0.1085],\n",
      "         [ 0.3308,  0.0126,  0.1269,  ..., -0.2180, -0.0485,  0.1916],\n",
      "         [ 0.3990, -0.0088, -0.4213,  ...,  0.2034, -0.3800, -0.2293],\n",
      "         [ 0.2327, -0.1938, -0.1176,  ...,  0.4068, -0.0007,  0.2337]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for wistful.\n",
      "wistfully is at index 885\n",
      "tensor([[[ 1.7678e-01, -2.3006e-02, -1.1993e-02,  ..., -1.1778e-01,\n",
      "           8.3837e-02,  2.0007e-02],\n",
      "         [-1.4980e-01, -3.1932e-01,  3.9171e-01,  ...,  2.5044e-01,\n",
      "           1.5541e-01,  1.0846e-01],\n",
      "         [ 3.3077e-01,  1.2588e-02,  1.2688e-01,  ..., -2.1800e-01,\n",
      "          -4.8507e-02,  1.9158e-01],\n",
      "         [ 7.4055e-03, -1.2305e-02, -4.3681e-01,  ...,  6.7143e-02,\n",
      "          -6.9791e-01,  2.3705e-01],\n",
      "         [ 2.3272e-01, -1.9380e-01, -1.1761e-01,  ...,  4.0675e-01,\n",
      "          -6.5191e-04,  2.3365e-01]]], grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for wistfully.\n",
      "withdraw is at index 8202\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.4123,  0.2240, -0.2231,  ..., -0.4390, -0.0469,  0.4179],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for withdraw.\n",
      "withdrawn is at index 13375\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2453,  0.1646, -0.1547,  ..., -0.3482, -0.2450,  0.3165],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for withdrawn.\n",
      "withheld is at index 22292\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0947,  0.4892, -0.2293,  ..., -0.1027, -0.0028, -0.2164],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for withheld.\n",
      "withholding is at index 25661\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0418,  0.3166, -0.2410,  ..., -0.0941,  0.4392,  0.0129],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for withholding.\n",
      "woe is at index 885\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1498, -0.3193,  0.3917,  ...,  0.2504,  0.1554,  0.1085],\n",
      "         [-0.0826,  0.6470, -0.2173,  ...,  0.0708, -0.1170,  0.1990],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for woe.\n",
      "woeful is at index 19958\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0896,  0.0843, -0.0534,  ...,  0.1428,  0.0885, -0.0970],\n",
      "         [ 0.2202,  0.4626,  0.0943,  ...,  0.4154, -0.6916,  0.0966],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for woeful.\n",
      "wonder is at index 5170\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.4381,  0.2013, -0.1795,  ..., -0.2243,  0.5522,  0.1018],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for wonder.\n",
      "wondering is at index 8020\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3546,  0.2580,  0.2513,  ..., -0.5273,  0.5015,  0.1603],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for wondering.\n",
      "wonderment is at index 5170\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.4381,  0.2013, -0.1795,  ..., -0.2243,  0.5522,  0.1018],\n",
      "         [ 0.0237,  0.5318, -0.0470,  ...,  0.1930,  0.0311,  0.5084],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for wonderment.\n",
      "wooly is at index 24815\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0183, -0.6401,  0.6444,  ...,  0.0390,  0.0839,  0.0061],\n",
      "         [ 0.3543,  0.3169,  0.0401,  ..., -0.1069, -0.5598,  0.1301],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for wooly.\n",
      "woozy is at index 24815\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.0183, -0.6401,  0.6444,  ...,  0.0390,  0.0839,  0.0061],\n",
      "         [-0.0577,  0.5858,  0.1074,  ..., -0.6844, -0.2767,  0.0738],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for woozy.\n",
      "worn is at index 10610\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3275, -0.3587,  0.3084,  ...,  0.4183, -0.4072,  0.2044],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for worn.\n",
      "worried is at index 3915\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1862,  0.7427,  0.4507,  ..., -0.2967,  0.4135,  0.2045],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for worried.\n",
      "worrisome is at index 29611\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0277,  0.5795,  0.3569,  ...,  0.0560, -0.0236,  0.3137],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for worrisome.\n",
      "worry is at index 4022\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1849,  0.5930,  0.1059,  ..., -0.3955,  0.7587,  0.2667],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for worry.\n",
      "worrying is at index 12648\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.3416,  0.4615,  0.4430,  ..., -0.0454,  0.4999,  0.2744],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for worrying.\n",
      "worryingly is at index 4022\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1849,  0.5930,  0.1059,  ..., -0.3955,  0.7587,  0.2667],\n",
      "         [ 0.0652,  0.2826, -0.2308,  ..., -0.0222, -0.1180,  0.3459],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for worryingly.\n",
      "wounded is at index 5424\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1830, -0.4731,  0.1854,  ...,  0.1822,  0.0651,  0.1816],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for wounded.\n",
      "wow is at index 26388\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.3508,  0.1197,  0.3562,  ...,  0.1150,  0.1497, -0.0210],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for wow.\n",
      "wrathful is at index 30220\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.4807, -0.1598,  0.0379,  ...,  0.0206,  0.4687, -0.1680],\n",
      "         [ 0.3025,  0.1036, -0.3624,  ...,  0.1536, -0.4041, -0.2558],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for wrathful.\n",
      "wrathfully is at index 30220\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.4807, -0.1598,  0.0379,  ...,  0.0206,  0.4687, -0.1680],\n",
      "         [-0.0888,  0.0999, -0.3792,  ...,  0.0177, -0.7239,  0.2116],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for wrathfully.\n",
      "wrecked is at index 30090\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1961,  0.1931,  0.2085,  ...,  0.2727, -0.1159, -0.1608],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for wrecked.\n",
      "wretched is at index 42824\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0876,  0.0728, -0.0089,  ...,  0.5445,  0.2370,  0.1607],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for wretched.\n",
      "wronged is at index 1593\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0088,  0.1192,  0.6745,  ..., -0.0280, -0.8351, -0.4304],\n",
      "         [-0.1786,  0.2013,  0.4345,  ...,  0.3394, -0.5501,  0.1632],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for wronged.\n",
      "wroth is at index 885\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1498, -0.3193,  0.3917,  ...,  0.2504,  0.1554,  0.1085],\n",
      "         [-0.2921,  0.6359,  0.6772,  ..., -0.0031,  0.1589, -0.1770],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for wroth.\n",
      "wry is at index 885\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1498, -0.3193,  0.3917,  ...,  0.2504,  0.1554,  0.1085],\n",
      "         [ 0.0867,  0.5194, -0.3409,  ...,  0.1609, -0.2120,  0.2307],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for wry.\n",
      "yawn is at index 39654\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1875, -0.1659,  0.3566,  ..., -0.0612, -0.1569, -0.0129],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for yawn.\n",
      "yawning is at index 39654\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.1875, -0.1659,  0.3566,  ..., -0.0612, -0.1569, -0.0129],\n",
      "         [ 0.1383,  0.3796,  0.1368,  ...,  0.2405, -0.3453,  0.0233],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for yawning.\n",
      "yearning is at index 76\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1796,  0.0896,  0.6561,  ...,  0.0997,  0.0453,  0.3094],\n",
      "         [-0.0301,  0.3702,  0.4610,  ...,  0.0439, -0.6158,  0.1083],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for yearning.\n",
      "yell is at index 28930\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [ 0.2284, -0.0863, -0.1560,  ...,  0.1206, -0.5679, -0.0648],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for yell.\n",
      "yelling is at index 16600\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1623, -0.2233, -0.0949,  ...,  0.0303, -0.2075, -0.0209],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for yelling.\n",
      "yielding is at index 25438\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1024,  0.1127,  0.3431,  ..., -0.0433,  0.2399,  0.2357],\n",
      "         [ 0.0924, -0.0295, -0.0129,  ...,  0.3057, -0.1149,  0.1891]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for yielding.\n",
      "yuck is at index 1423\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.0191,  0.1959,  0.1938,  ...,  0.2823, -0.1360,  0.0202],\n",
      "         [-0.0278,  0.6460,  0.1070,  ..., -0.2030,  0.1815,  0.1723],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for yuck.\n",
      "zany is at index 992\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1765,  0.0908,  0.4811,  ...,  0.3580,  0.2773,  0.2025],\n",
      "         [ 0.1710,  0.2459,  0.5517,  ...,  0.2732, -0.5558,  0.1083],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for zany.\n",
      "zealous is at index 992\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1765,  0.0908,  0.4811,  ...,  0.3580,  0.2773,  0.2025],\n",
      "         [-0.1063,  0.4852,  0.1138,  ...,  0.1395, -0.1453, -0.0922],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for zealous.\n",
      "zen is at index 992\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1765,  0.0908,  0.4811,  ...,  0.3580,  0.2773,  0.2025],\n",
      "         [ 0.2454,  0.0444,  0.6291,  ...,  0.1373, -0.5052,  0.6808],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for zen.\n",
      "zoned is at index 992\n",
      "tensor([[[ 0.1768, -0.0230, -0.0120,  ..., -0.1178,  0.0838,  0.0200],\n",
      "         [-0.1765,  0.0908,  0.4811,  ...,  0.3580,  0.2773,  0.2025],\n",
      "         [-0.1904,  0.0874,  0.1170,  ...,  0.1680, -0.1987,  0.3426],\n",
      "         [ 0.1991, -0.1564, -0.0799,  ...,  0.3577, -0.0868,  0.2159]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "Saved the embedding for zoned.\n"
     ]
    }
   ],
   "source": [
    "################################################\n",
    "# This cell will write out output embeddings   #\n",
    "# for all the words in my vocabulary, using    #\n",
    "# RoBERTa fine-tuned on wiki-103 training text.#\n",
    "################################################\n",
    "\n",
    "# THESE EMBEDDINGS GIVE A SCORE OF 1.0 FOR ALL WORD PAIRS ON THE\n",
    "# SYNONYMY SCORING TASK: DO NOT USE!!!\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = RobertaTokenizer.from_pretrained('./output_wiki-103/')\n",
    "\n",
    "model = RobertaForMaskedLM.from_pretrained('./output_wiki-103/', config=config)\n",
    "\n",
    "config = RobertaConfig.from_pretrained('./output_wiki-103/')\n",
    "config.output_hidden_states = True\n",
    "embeddings_file = '/home/jupyter/Notebooks/crystal/NLP/nlp_testing/embeddings_context_vocab/roberta_output_wiki-103.txt'\n",
    "for v in vocab:\n",
    "    v_tensor = torch.tensor([tokenizer.encode(v)])\n",
    "    # Print the index of the test word.\n",
    "    print(f'{v} is at index {v_tensor[0][1].item()}')\n",
    "    v_embed = model.roberta.embeddings(v_tensor)\n",
    "#     print(v_embed)\n",
    "    try:\n",
    "        with open(embeddings_file, 'a') as f:\n",
    "            f.write(v)\n",
    "            for value in v_embed[0][0]:\n",
    "                f.write(' ' + str(value.item()))\n",
    "            f.write('\\n')\n",
    "        print(f'Saved the embedding for {v}.')\n",
    "    except:\n",
    "        print('Oh no! Unable to write to the embeddings file.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vocab' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-f3527136452e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0membeddings_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/home/jupyter/Notebooks/crystal/NLP/nlp_testing/embeddings_context_vocab/roberta_output-word_wiki-103.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mv_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# Print the index of the test word.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vocab' is not defined"
     ]
    }
   ],
   "source": [
    "################################################\n",
    "# This cell will write out output embeddings   #\n",
    "# at the word level for all the words in my    #\n",
    "# vocabulary, using RoBERTa fine-tuned on      #\n",
    "# wiki-103 training text.                      #\n",
    "################################################\n",
    "\n",
    "# THESE EMBEDDINGS GIVE A SCORE OF 1.0 FOR ALL WORD PAIRS ON THE\n",
    "# SYNONYMY SCORING TASK: DO NOT USE!!!\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = RobertaTokenizer.from_pretrained('./output_wiki-103/')\n",
    "\n",
    "model = RobertaForMaskedLM.from_pretrained('./output_wiki-103/', config=config)\n",
    "\n",
    "config = RobertaConfig.from_pretrained('./output_wiki-103/')\n",
    "config.output_hidden_states = True\n",
    "embeddings_file = '/home/jupyter/Notebooks/crystal/NLP/nlp_testing/embeddings_context_vocab/roberta_output-word_wiki-103.txt'\n",
    "for v in vocab:\n",
    "    v_tensor = torch.tensor([tokenizer.encode(v)])\n",
    "    # Print the index of the test word.\n",
    "    print(f'{v} is at index {v_tensor[0][1].item()}')\n",
    "    v_embed = model.roberta.embeddings.word_embeddings(v_tensor)\n",
    "#     print(v_embed)\n",
    "    try:\n",
    "        with open(embeddings_file, 'a') as f:\n",
    "            f.write(v)\n",
    "            for value in v_embed[0][0]:\n",
    "                f.write(' ' + str(value.item()))\n",
    "            f.write('\\n')\n",
    "        print(f'Saved the embedding for {v}.')\n",
    "    except:\n",
    "        print('Oh no! Unable to write to the embeddings file.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aback is at index 36347\n",
      "Saved the embedding for aback.\n",
      "abashed is at index 4091\n",
      "Saved the embedding for abashed.\n",
      "abhor is at index 35350\n",
      "Saved the embedding for abhor.\n",
      "abhorred is at index 35350\n",
      "Saved the embedding for abhorred.\n",
      "abhorrence is at index 35350\n",
      "Saved the embedding for abhorrence.\n",
      "abhorrent is at index 35350\n",
      "Saved the embedding for abhorrent.\n",
      "abominable is at index 4091\n",
      "Saved the embedding for abominable.\n",
      "abound is at index 32937\n",
      "Saved the embedding for abound.\n",
      "absent is at index 11640\n",
      "Saved the embedding for absent.\n",
      "absorbed is at index 22416\n",
      "Saved the embedding for absorbed.\n",
      "acceptance is at index 10502\n",
      "Saved the embedding for acceptance.\n",
      "accepted is at index 3903\n",
      "Saved the embedding for accepted.\n",
      "accepting is at index 8394\n",
      "Saved the embedding for accepting.\n",
      "accommodating is at index 33681\n",
      "Saved the embedding for accommodating.\n",
      "accomplished is at index 9370\n",
      "Saved the embedding for accomplished.\n",
      "accordant is at index 10170\n",
      "Saved the embedding for accordant.\n",
      "accursed is at index 7678\n",
      "Saved the embedding for accursed.\n",
      "accusatory is at index 23123\n",
      "Saved the embedding for accusatory.\n",
      "accused is at index 1238\n",
      "Saved the embedding for accused.\n",
      "accusing is at index 8601\n",
      "Saved the embedding for accusing.\n",
      "acerbic is at index 4285\n",
      "Saved the embedding for acerbic.\n",
      "acidic is at index 41314\n",
      "Saved the embedding for acidic.\n",
      "active is at index 2171\n",
      "Saved the embedding for active.\n",
      "acute is at index 13827\n",
      "Saved the embedding for acute.\n",
      "adamant is at index 22668\n",
      "Saved the embedding for adamant.\n",
      "addled is at index 1606\n",
      "Saved the embedding for addled.\n",
      "admiration is at index 24287\n",
      "Saved the embedding for admiration.\n",
      "admit is at index 8109\n",
      "Saved the embedding for admit.\n",
      "adoration is at index 2329\n",
      "Saved the embedding for adoration.\n",
      "adoring is at index 2329\n",
      "Saved the embedding for adoring.\n",
      "adrift is at index 2329\n",
      "Saved the embedding for adrift.\n",
      "adversarial is at index 37930\n",
      "Saved the embedding for adversarial.\n",
      "affability is at index 11129\n",
      "Saved the embedding for affability.\n",
      "affected is at index 2132\n",
      "Saved the embedding for affected.\n",
      "affectionate is at index 15955\n",
      "Saved the embedding for affectionate.\n",
      "afflicted is at index 39234\n",
      "Saved the embedding for afflicted.\n",
      "affronted is at index 11129\n",
      "Saved the embedding for affronted.\n",
      "aflutter is at index 10\n",
      "Saved the embedding for aflutter.\n",
      "afraid is at index 6023\n",
      "Saved the embedding for afraid.\n",
      "agape is at index 5951\n",
      "Saved the embedding for agape.\n",
      "aggravated is at index 10040\n",
      "Saved the embedding for aggravated.\n",
      "aggravation is at index 29223\n",
      "Saved the embedding for aggravation.\n",
      "aggression is at index 14227\n",
      "Saved the embedding for aggression.\n",
      "aggressive is at index 4353\n",
      "Saved the embedding for aggressive.\n",
      "aggrieve is at index 28940\n",
      "Saved the embedding for aggrieve.\n",
      "aggrieved is at index 28940\n",
      "Saved the embedding for aggrieved.\n",
      "aghast is at index 10\n",
      "Saved the embedding for aghast.\n",
      "agitated is at index 33426\n",
      "Saved the embedding for agitated.\n",
      "agog is at index 5951\n",
      "Saved the embedding for agog.\n",
      "agonized is at index 27497\n",
      "Saved the embedding for agonized.\n",
      "agreeable is at index 43359\n",
      "Saved the embedding for agreeable.\n",
      "agressive is at index 5951\n",
      "Saved the embedding for agressive.\n",
      "airhead is at index 935\n",
      "Saved the embedding for airhead.\n",
      "alarm is at index 8054\n",
      "Saved the embedding for alarm.\n",
      "alarmed is at index 23438\n",
      "Saved the embedding for alarmed.\n",
      "alarming is at index 16156\n",
      "Saved the embedding for alarming.\n",
      "alert is at index 5439\n",
      "Saved the embedding for alert.\n",
      "alerted is at index 14588\n",
      "Saved the embedding for alerted.\n",
      "alienated is at index 36462\n",
      "Saved the embedding for alienated.\n",
      "allergic is at index 28349\n",
      "Saved the embedding for allergic.\n",
      "alleviated is at index 32216\n",
      "Saved the embedding for alleviated.\n",
      "alluring is at index 70\n",
      "Saved the embedding for alluring.\n",
      "aloof is at index 1076\n",
      "Saved the embedding for aloof.\n",
      "amatory is at index 524\n",
      "Saved the embedding for amatory.\n",
      "amazed is at index 22431\n",
      "Saved the embedding for amazed.\n",
      "amazement is at index 42402\n",
      "Saved the embedding for amazement.\n",
      "amazing is at index 2770\n",
      "Saved the embedding for amazing.\n",
      "ambition is at index 12831\n",
      "Saved the embedding for ambition.\n",
      "ambitious is at index 8263\n",
      "Saved the embedding for ambitious.\n",
      "ambivalence is at index 13569\n",
      "Saved the embedding for ambivalence.\n",
      "ambivalent is at index 13569\n",
      "Saved the embedding for ambivalent.\n",
      "amenable is at index 524\n",
      "Saved the embedding for amenable.\n",
      "amiable is at index 524\n",
      "Saved the embedding for amiable.\n",
      "amicable is at index 524\n",
      "Saved the embedding for amicable.\n",
      "amused is at index 36530\n",
      "Saved the embedding for amused.\n",
      "amusement is at index 28445\n",
      "Saved the embedding for amusement.\n",
      "analytical is at index 23554\n",
      "Saved the embedding for analytical.\n",
      "analyzing is at index 18999\n",
      "Saved the embedding for analyzing.\n",
      "anger is at index 6378\n",
      "Saved the embedding for anger.\n",
      "angered is at index 20166\n",
      "Saved the embedding for angered.\n",
      "angrily is at index 30302\n",
      "Saved the embedding for angrily.\n",
      "angry is at index 5800\n",
      "Saved the embedding for angry.\n",
      "angst is at index 33010\n",
      "Saved the embedding for angst.\n",
      "anguish is at index 32446\n",
      "Saved the embedding for anguish.\n",
      "anguished is at index 5667\n",
      "Saved the embedding for anguished.\n",
      "animated is at index 12847\n",
      "Saved the embedding for animated.\n",
      "animosity is at index 34351\n",
      "Saved the embedding for animosity.\n",
      "annoyance is at index 39341\n",
      "Saved the embedding for annoyance.\n",
      "annoyed is at index 26678\n",
      "Saved the embedding for annoyed.\n",
      "annoying is at index 19887\n",
      "Saved the embedding for annoying.\n",
      "antagonistic is at index 32726\n",
      "Saved the embedding for antagonistic.\n",
      "antagonized is at index 32726\n",
      "Saved the embedding for antagonized.\n",
      "anticipated is at index 5291\n",
      "Saved the embedding for anticipated.\n",
      "anticipating is at index 22535\n",
      "Saved the embedding for anticipating.\n",
      "anticipation is at index 14714\n",
      "Saved the embedding for anticipation.\n",
      "anticipative is at index 21428\n",
      "Saved the embedding for anticipative.\n",
      "anticipatory is at index 21428\n",
      "Saved the embedding for anticipatory.\n",
      "antipathy is at index 37554\n",
      "Saved the embedding for antipathy.\n",
      "antsy is at index 32855\n",
      "Saved the embedding for antsy.\n",
      "anxiety is at index 6882\n",
      "Saved the embedding for anxiety.\n",
      "anxious is at index 13473\n",
      "Saved the embedding for anxious.\n",
      "anxiously is at index 27442\n",
      "Saved the embedding for anxiously.\n",
      "apathetic is at index 6256\n",
      "Saved the embedding for apathetic.\n",
      "apathy is at index 6256\n",
      "Saved the embedding for apathy.\n",
      "apologetic is at index 23842\n",
      "Saved the embedding for apologetic.\n",
      "appalled is at index 31514\n",
      "Saved the embedding for appalled.\n",
      "appallingly is at index 1553\n",
      "Saved the embedding for appallingly.\n",
      "appeased is at index 44151\n",
      "Saved the embedding for appeased.\n",
      "appeasing is at index 44151\n",
      "Saved the embedding for appeasing.\n",
      "appreciative is at index 14137\n",
      "Saved the embedding for appreciative.\n",
      "apprehension is at index 34640\n",
      "Saved the embedding for apprehension.\n",
      "apprehensive is at index 33655\n",
      "Saved the embedding for apprehensive.\n",
      "approve is at index 7244\n",
      "Saved the embedding for approve.\n",
      "approved is at index 2033\n",
      "Saved the embedding for approved.\n",
      "approving is at index 20499\n",
      "Saved the embedding for approving.\n",
      "argue is at index 5848\n",
      "Saved the embedding for argue.\n",
      "argumentative is at index 4795\n",
      "Saved the embedding for argumentative.\n",
      "aroused is at index 42941\n",
      "Saved the embedding for aroused.\n",
      "arrogance is at index 32818\n",
      "Saved the embedding for arrogance.\n",
      "arrogant is at index 30967\n",
      "Saved the embedding for arrogant.\n",
      "arrogantly is at index 46553\n",
      "Saved the embedding for arrogantly.\n",
      "artificial is at index 7350\n",
      "Saved the embedding for artificial.\n",
      "ashamed is at index 20085\n",
      "Saved the embedding for ashamed.\n",
      "aspiring is at index 18885\n",
      "Saved the embedding for aspiring.\n",
      "assertive is at index 18088\n",
      "Saved the embedding for assertive.\n",
      "assertively is at index 18088\n",
      "Saved the embedding for assertively.\n",
      "assessing is at index 16629\n",
      "Saved the embedding for assessing.\n",
      "assured is at index 7189\n",
      "Saved the embedding for assured.\n",
      "astonished is at index 40788\n",
      "Saved the embedding for astonished.\n",
      "astonishment is at index 44434\n",
      "Saved the embedding for astonishment.\n",
      "astounded is at index 12976\n",
      "Saved the embedding for astounded.\n",
      "attempting is at index 6475\n",
      "Saved the embedding for attempting.\n",
      "attentive is at index 36670\n",
      "Saved the embedding for attentive.\n",
      "attentiveness is at index 39879\n",
      "Saved the embedding for attentiveness.\n",
      "attracted is at index 7671\n",
      "Saved the embedding for attracted.\n",
      "avenging is at index 38796\n",
      "Saved the embedding for avenging.\n",
      "averse is at index 10\n",
      "Saved the embedding for averse.\n",
      "aversion is at index 33814\n",
      "Saved the embedding for aversion.\n",
      "aversive is at index 10\n",
      "Saved the embedding for aversive.\n",
      "avid is at index 20137\n",
      "Saved the embedding for avid.\n",
      "avoiding is at index 11473\n",
      "Saved the embedding for avoiding.\n",
      "awaiting is at index 10254\n",
      "Saved the embedding for awaiting.\n",
      "awakened is at index 40593\n",
      "Saved the embedding for awakened.\n",
      "aware is at index 2542\n",
      "Saved the embedding for aware.\n",
      "awareness is at index 4199\n",
      "Saved the embedding for awareness.\n",
      "awe is at index 21531\n",
      "Saved the embedding for awe.\n",
      "awed is at index 19267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for awed.\n",
      "awestruck is at index 19267\n",
      "Saved the embedding for awestruck.\n",
      "awful is at index 11522\n",
      "Saved the embedding for awful.\n",
      "awkward is at index 11789\n",
      "Saved the embedding for awkward.\n",
      "awkwardness is at index 11789\n",
      "Saved the embedding for awkwardness.\n",
      "axed is at index 18884\n",
      "Saved the embedding for axed.\n",
      "backhanded is at index 124\n",
      "Saved the embedding for backhanded.\n",
      "badly is at index 7340\n",
      "Saved the embedding for badly.\n",
      "baffle is at index 33139\n",
      "Saved the embedding for baffle.\n",
      "baffled is at index 33396\n",
      "Saved the embedding for baffled.\n",
      "baffling is at index 33139\n",
      "Saved the embedding for baffling.\n",
      "baked is at index 17241\n",
      "Saved the embedding for baked.\n",
      "banal is at index 2020\n",
      "Saved the embedding for banal.\n",
      "barking is at index 35828\n",
      "Saved the embedding for barking.\n",
      "bashful is at index 12882\n",
      "Saved the embedding for bashful.\n",
      "beaming is at index 28\n",
      "Saved the embedding for beaming.\n",
      "bearish is at index 4649\n",
      "Saved the embedding for bearish.\n",
      "beat is at index 1451\n",
      "Saved the embedding for beat.\n",
      "beaten is at index 6432\n",
      "Saved the embedding for beaten.\n",
      "bedeviled is at index 3267\n",
      "Saved the embedding for bedeviled.\n",
      "befuddled is at index 28\n",
      "Saved the embedding for befuddled.\n",
      "begging is at index 22901\n",
      "Saved the embedding for begging.\n",
      "begrudge is at index 28\n",
      "Saved the embedding for begrudge.\n",
      "begrudging is at index 28\n",
      "Saved the embedding for begrudging.\n",
      "begrudgingly is at index 28\n",
      "Saved the embedding for begrudgingly.\n",
      "beguiled is at index 21422\n",
      "Saved the embedding for beguiled.\n",
      "belated is at index 12138\n",
      "Saved the embedding for belated.\n",
      "belittling is at index 12138\n",
      "Saved the embedding for belittling.\n",
      "belligerence is at index 35756\n",
      "Saved the embedding for belligerence.\n",
      "belligerent is at index 35756\n",
      "Saved the embedding for belligerent.\n",
      "belonging is at index 11441\n",
      "Saved the embedding for belonging.\n",
      "bemused is at index 28\n",
      "Saved the embedding for bemused.\n",
      "bemusement is at index 28\n",
      "Saved the embedding for bemusement.\n",
      "benevolence is at index 42364\n",
      "Saved the embedding for benevolence.\n",
      "benevolent is at index 43186\n",
      "Saved the embedding for benevolent.\n",
      "benumbed is at index 21576\n",
      "Saved the embedding for benumbed.\n",
      "berate is at index 14719\n",
      "Saved the embedding for berate.\n",
      "berating is at index 14719\n",
      "Saved the embedding for berating.\n",
      "bereaved is at index 17738\n",
      "Saved the embedding for bereaved.\n",
      "bereft is at index 17738\n",
      "Saved the embedding for bereft.\n",
      "beseeching is at index 9988\n",
      "Saved the embedding for beseeching.\n",
      "bested is at index 275\n",
      "Saved the embedding for bested.\n",
      "betrayal is at index 26760\n",
      "Saved the embedding for betrayal.\n",
      "betrayed is at index 26913\n",
      "Saved the embedding for betrayed.\n",
      "bewildered is at index 33304\n",
      "Saved the embedding for bewildered.\n",
      "bewilderment is at index 33304\n",
      "Saved the embedding for bewilderment.\n",
      "bi is at index 4003\n",
      "Saved the embedding for bi.\n",
      "bilious is at index 31617\n",
      "Saved the embedding for bilious.\n",
      "bit is at index 828\n",
      "Saved the embedding for bit.\n",
      "biting is at index 25609\n",
      "Saved the embedding for biting.\n",
      "bitter is at index 10513\n",
      "Saved the embedding for bitter.\n",
      "bittersweet is at index 28609\n",
      "Saved the embedding for bittersweet.\n",
      "blaming is at index 15249\n",
      "Saved the embedding for blaming.\n",
      "bland is at index 35063\n",
      "Saved the embedding for bland.\n",
      "blank is at index 15818\n",
      "Saved the embedding for blank.\n",
      "blase is at index 3089\n",
      "Saved the embedding for blase.\n",
      "blazed is at index 3089\n",
      "Saved the embedding for blazed.\n",
      "bleak is at index 23530\n",
      "Saved the embedding for bleak.\n",
      "bleary is at index 13819\n",
      "Saved the embedding for bleary.\n",
      "blessed is at index 12230\n",
      "Saved the embedding for blessed.\n",
      "blew is at index 10879\n",
      "Saved the embedding for blew.\n",
      "blinded is at index 40094\n",
      "Saved the embedding for blinded.\n",
      "blindsided is at index 7709\n",
      "Saved the embedding for blindsided.\n",
      "bliss is at index 30299\n",
      "Saved the embedding for bliss.\n",
      "blissful is at index 30299\n",
      "Saved the embedding for blissful.\n",
      "blissfully is at index 30299\n",
      "Saved the embedding for blissfully.\n",
      "blithe is at index 3089\n",
      "Saved the embedding for blithe.\n",
      "blown is at index 12315\n",
      "Saved the embedding for blown.\n",
      "blue is at index 2440\n",
      "Saved the embedding for blue.\n",
      "blues is at index 15629\n",
      "Saved the embedding for blues.\n",
      "bluffing is at index 37372\n",
      "Saved the embedding for bluffing.\n",
      "blunt is at index 18720\n",
      "Saved the embedding for blunt.\n",
      "blushing is at index 3089\n",
      "Saved the embedding for blushing.\n",
      "blustering is at index 3089\n",
      "Saved the embedding for blustering.\n",
      "boastful is at index 18639\n",
      "Saved the embedding for boastful.\n",
      "boggled is at index 741\n",
      "Saved the embedding for boggled.\n",
      "boiling is at index 27513\n",
      "Saved the embedding for boiling.\n",
      "boisterous is at index 5276\n",
      "Saved the embedding for boisterous.\n",
      "bold is at index 7457\n",
      "Saved the embedding for bold.\n",
      "bored is at index 23809\n",
      "Saved the embedding for bored.\n",
      "boredom is at index 40326\n",
      "Saved the embedding for boredom.\n",
      "boring is at index 15305\n",
      "Saved the embedding for boring.\n",
      "bothered is at index 18523\n",
      "Saved the embedding for bothered.\n",
      "bounder is at index 8191\n",
      "Saved the embedding for bounder.\n",
      "brashness is at index 5378\n",
      "Saved the embedding for brashness.\n",
      "bratty is at index 5378\n",
      "Saved the embedding for bratty.\n",
      "brave is at index 10025\n",
      "Saved the embedding for brave.\n",
      "bright is at index 4520\n",
      "Saved the embedding for bright.\n",
      "bristling is at index 37135\n",
      "Saved the embedding for bristling.\n",
      "broken is at index 3187\n",
      "Saved the embedding for broken.\n",
      "brokenhearted is at index 3187\n",
      "Saved the embedding for brokenhearted.\n",
      "brokenheartedly is at index 3187\n",
      "Saved the embedding for brokenheartedly.\n",
      "brooding is at index 11051\n",
      "Saved the embedding for brooding.\n",
      "broody is at index 11051\n",
      "Saved the embedding for broody.\n",
      "bruised is at index 26360\n",
      "Saved the embedding for bruised.\n",
      "brusque is at index 5378\n",
      "Saved the embedding for brusque.\n",
      "bug is at index 13673\n",
      "Saved the embedding for bug.\n",
      "bulging is at index 22382\n",
      "Saved the embedding for bulging.\n",
      "bully is at index 23934\n",
      "Saved the embedding for bully.\n",
      "bullying is at index 11902\n",
      "Saved the embedding for bullying.\n",
      "bummed is at index 29673\n",
      "Saved the embedding for bummed.\n",
      "buoyant is at index 15980\n",
      "Saved the embedding for buoyant.\n",
      "burdened is at index 32875\n",
      "Saved the embedding for burdened.\n",
      "burn is at index 7403\n",
      "Saved the embedding for burn.\n",
      "bursting is at index 28548\n",
      "Saved the embedding for bursting.\n",
      "bushed is at index 2353\n",
      "Saved the embedding for bushed.\n",
      "cagey is at index 16051\n",
      "Saved the embedding for cagey.\n",
      "cagy is at index 740\n",
      "Saved the embedding for cagy.\n",
      "calculating is at index 29770\n",
      "Saved the embedding for calculating.\n",
      "callous is at index 486\n",
      "Saved the embedding for callous.\n",
      "callused is at index 486\n",
      "Saved the embedding for callused.\n",
      "calm is at index 6327\n",
      "Saved the embedding for calm.\n",
      "calming is at index 31220\n",
      "Saved the embedding for calming.\n",
      "calmness is at index 6327\n",
      "Saved the embedding for calmness.\n",
      "canny is at index 64\n",
      "Saved the embedding for canny.\n",
      "cantankerous is at index 17672\n",
      "Saved the embedding for cantankerous.\n",
      "capable is at index 4453\n",
      "Saved the embedding for capable.\n",
      "capricious is at index 2927\n",
      "Saved the embedding for capricious.\n",
      "captivated is at index 13363\n",
      "Saved the embedding for captivated.\n",
      "captive is at index 24145\n",
      "Saved the embedding for captive.\n",
      "carefree is at index 575\n",
      "Saved the embedding for carefree.\n",
      "careful is at index 7316\n",
      "Saved the embedding for careful.\n",
      "careless is at index 29399\n",
      "Saved the embedding for careless.\n",
      "caring is at index 10837\n",
      "Saved the embedding for caring.\n",
      "catty is at index 4758\n",
      "Saved the embedding for catty.\n",
      "caustic is at index 6056\n",
      "Saved the embedding for caustic.\n",
      "cautionary is at index 8038\n",
      "Saved the embedding for cautionary.\n",
      "cautious is at index 9420\n",
      "Saved the embedding for cautious.\n",
      "cavalier is at index 41869\n",
      "Saved the embedding for cavalier.\n",
      "celebrating is at index 6146\n",
      "Saved the embedding for celebrating.\n",
      "celebration is at index 4821\n",
      "Saved the embedding for celebration.\n",
      "censure is at index 26489\n",
      "Saved the embedding for censure.\n",
      "centered is at index 14889\n",
      "Saved the embedding for centered.\n",
      "certain is at index 1402\n",
      "Saved the embedding for certain.\n",
      "chafed is at index 1855\n",
      "Saved the embedding for chafed.\n",
      "chagrin is at index 1855\n",
      "Saved the embedding for chagrin.\n",
      "chagrined is at index 1855\n",
      "Saved the embedding for chagrined.\n",
      "chagrinned is at index 1855\n",
      "Saved the embedding for chagrinned.\n",
      "challenge is at index 1539\n",
      "Saved the embedding for challenge.\n",
      "challenged is at index 6835\n",
      "Saved the embedding for challenged.\n",
      "challenging is at index 4087\n",
      "Saved the embedding for challenging.\n",
      "chaotic is at index 16529\n",
      "Saved the embedding for chaotic.\n",
      "charged is at index 1340\n",
      "Saved the embedding for charged.\n",
      "charmed is at index 16224\n",
      "Saved the embedding for charmed.\n",
      "charming is at index 18452\n",
      "Saved the embedding for charming.\n",
      "chary is at index 1855\n",
      "Saved the embedding for chary.\n",
      "cheated is at index 25177\n",
      "Saved the embedding for cheated.\n",
      "cheeky is at index 15401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for cheeky.\n",
      "cheered is at index 18643\n",
      "Saved the embedding for cheered.\n",
      "cheerful is at index 33928\n",
      "Saved the embedding for cheerful.\n",
      "cheering is at index 16765\n",
      "Saved the embedding for cheering.\n",
      "cheerless is at index 9450\n",
      "Saved the embedding for cheerless.\n",
      "cheery is at index 5851\n",
      "Saved the embedding for cheery.\n",
      "cheesy is at index 36331\n",
      "Saved the embedding for cheesy.\n",
      "chesty is at index 7050\n",
      "Saved the embedding for chesty.\n",
      "chide is at index 1855\n",
      "Saved the embedding for chide.\n",
      "chiding is at index 1855\n",
      "Saved the embedding for chiding.\n",
      "childish is at index 40531\n",
      "Saved the embedding for childish.\n",
      "childishly is at index 920\n",
      "Saved the embedding for childishly.\n",
      "childlike is at index 920\n",
      "Saved the embedding for childlike.\n",
      "chill is at index 13146\n",
      "Saved the embedding for chill.\n",
      "chilled is at index 32338\n",
      "Saved the embedding for chilled.\n",
      "chilling is at index 22577\n",
      "Saved the embedding for chilling.\n",
      "chipper is at index 1855\n",
      "Saved the embedding for chipper.\n",
      "chirpy is at index 1855\n",
      "Saved the embedding for chirpy.\n",
      "choleric is at index 1855\n",
      "Saved the embedding for choleric.\n",
      "chortling is at index 1855\n",
      "Saved the embedding for chortling.\n",
      "chuckle is at index 37496\n",
      "Saved the embedding for chuckle.\n",
      "chuckling is at index 34600\n",
      "Saved the embedding for chuckling.\n",
      "churlish is at index 1855\n",
      "Saved the embedding for churlish.\n",
      "circumspect is at index 38529\n",
      "Saved the embedding for circumspect.\n",
      "clamorous is at index 24045\n",
      "Saved the embedding for clamorous.\n",
      "clash is at index 6064\n",
      "Saved the embedding for clash.\n",
      "clear is at index 699\n",
      "Saved the embedding for clear.\n",
      "clenched is at index 44646\n",
      "Saved the embedding for clenched.\n",
      "clever is at index 13074\n",
      "Saved the embedding for clever.\n",
      "close is at index 593\n",
      "Saved the embedding for close.\n",
      "closed is at index 1367\n",
      "Saved the embedding for closed.\n",
      "closemouthed is at index 593\n",
      "Saved the embedding for closemouthed.\n",
      "cloy is at index 3741\n",
      "Saved the embedding for cloy.\n",
      "clueless is at index 36776\n",
      "Saved the embedding for clueless.\n",
      "clutched is at index 29409\n",
      "Saved the embedding for clutched.\n",
      "cluttered is at index 29409\n",
      "Saved the embedding for cluttered.\n",
      "cockeyed is at index 740\n",
      "Saved the embedding for cockeyed.\n",
      "cockiness is at index 24231\n",
      "Saved the embedding for cockiness.\n",
      "cocksure is at index 740\n",
      "Saved the embedding for cocksure.\n",
      "cocky is at index 24231\n",
      "Saved the embedding for cocky.\n",
      "cognizant is at index 28105\n",
      "Saved the embedding for cognizant.\n",
      "cold is at index 2569\n",
      "Saved the embedding for cold.\n",
      "collected is at index 4786\n",
      "Saved the embedding for collected.\n",
      "collusive is at index 9843\n",
      "Saved the embedding for collusive.\n",
      "colonized is at index 17735\n",
      "Saved the embedding for colonized.\n",
      "combative is at index 14960\n",
      "Saved the embedding for combative.\n",
      "comedic is at index 29045\n",
      "Saved the embedding for comedic.\n",
      "comfort is at index 5863\n",
      "Saved the embedding for comfort.\n",
      "comfortable is at index 3473\n",
      "Saved the embedding for comfortable.\n",
      "comforted is at index 5863\n",
      "Saved the embedding for comforted.\n",
      "comical is at index 3137\n",
      "Saved the embedding for comical.\n",
      "commanding is at index 20510\n",
      "Saved the embedding for commanding.\n",
      "commiserating is at index 7034\n",
      "Saved the embedding for commiserating.\n",
      "commiserative is at index 7034\n",
      "Saved the embedding for commiserative.\n",
      "communicative is at index 16759\n",
      "Saved the embedding for communicative.\n",
      "compassion is at index 14736\n",
      "Saved the embedding for compassion.\n",
      "compassionate is at index 23303\n",
      "Saved the embedding for compassionate.\n",
      "competent is at index 17451\n",
      "Saved the embedding for competent.\n",
      "competitive is at index 2695\n",
      "Saved the embedding for competitive.\n",
      "complacence is at index 13000\n",
      "Saved the embedding for complacence.\n",
      "complacency is at index 13000\n",
      "Saved the embedding for complacency.\n",
      "complacent is at index 13000\n",
      "Saved the embedding for complacent.\n",
      "complacently is at index 13000\n",
      "Saved the embedding for complacently.\n",
      "complain is at index 11316\n",
      "Saved the embedding for complain.\n",
      "complaining is at index 13689\n",
      "Saved the embedding for complaining.\n",
      "composed is at index 14092\n",
      "Saved the embedding for composed.\n",
      "comprehending is at index 30030\n",
      "Saved the embedding for comprehending.\n",
      "compulsive is at index 7753\n",
      "Saved the embedding for compulsive.\n",
      "concealed is at index 17180\n",
      "Saved the embedding for concealed.\n",
      "conceding is at index 24647\n",
      "Saved the embedding for conceding.\n",
      "conceited is at index 21177\n",
      "Saved the embedding for conceited.\n",
      "concentrated is at index 15450\n",
      "Saved the embedding for concentrated.\n",
      "concentrating is at index 28619\n",
      "Saved the embedding for concentrating.\n",
      "concentration is at index 11772\n",
      "Saved the embedding for concentration.\n",
      "concern is at index 2212\n",
      "Saved the embedding for concern.\n",
      "concerned is at index 2273\n",
      "Saved the embedding for concerned.\n",
      "conciliatory is at index 10146\n",
      "Saved the embedding for conciliatory.\n",
      "conclusive is at index 37847\n",
      "Saved the embedding for conclusive.\n",
      "condemning is at index 21856\n",
      "Saved the embedding for condemning.\n",
      "condescending is at index 40742\n",
      "Saved the embedding for condescending.\n",
      "condoling is at index 35279\n",
      "Saved the embedding for condoling.\n",
      "confidence is at index 2123\n",
      "Saved the embedding for confidence.\n",
      "confident is at index 3230\n",
      "Saved the embedding for confident.\n",
      "confidently is at index 27447\n",
      "Saved the embedding for confidently.\n",
      "conflicted is at index 34428\n",
      "Saved the embedding for conflicted.\n",
      "confound is at index 7856\n",
      "Saved the embedding for confound.\n",
      "confounded is at index 7856\n",
      "Saved the embedding for confounded.\n",
      "confrontational is at index 10749\n",
      "Saved the embedding for confrontational.\n",
      "confused is at index 10985\n",
      "Saved the embedding for confused.\n",
      "confusion is at index 9655\n",
      "Saved the embedding for confusion.\n",
      "congenial is at index 36764\n",
      "Saved the embedding for congenial.\n",
      "congratulatory is at index 26303\n",
      "Saved the embedding for congratulatory.\n",
      "conniving is at index 39277\n",
      "Saved the embedding for conniving.\n",
      "conscious is at index 13316\n",
      "Saved the embedding for conscious.\n",
      "conservative is at index 3354\n",
      "Saved the embedding for conservative.\n",
      "considerate is at index 1701\n",
      "Saved the embedding for considerate.\n",
      "considering is at index 2811\n",
      "Saved the embedding for considering.\n",
      "consoling is at index 7407\n",
      "Saved the embedding for consoling.\n",
      "conspiratorial is at index 31150\n",
      "Saved the embedding for conspiratorial.\n",
      "conspiring is at index 27230\n",
      "Saved the embedding for conspiring.\n",
      "consternation is at index 10759\n",
      "Saved the embedding for consternation.\n",
      "constipated is at index 10759\n",
      "Saved the embedding for constipated.\n",
      "constrained is at index 26525\n",
      "Saved the embedding for constrained.\n",
      "consumed is at index 13056\n",
      "Saved the embedding for consumed.\n",
      "consuming is at index 16997\n",
      "Saved the embedding for consuming.\n",
      "contained is at index 5558\n",
      "Saved the embedding for contained.\n",
      "contemplate is at index 32848\n",
      "Saved the embedding for contemplate.\n",
      "contemplating is at index 27744\n",
      "Saved the embedding for contemplating.\n",
      "contemplation is at index 44072\n",
      "Saved the embedding for contemplation.\n",
      "contemplative is at index 43580\n",
      "Saved the embedding for contemplative.\n",
      "contempt is at index 16176\n",
      "Saved the embedding for contempt.\n",
      "contemptuous is at index 16176\n",
      "Saved the embedding for contemptuous.\n",
      "content is at index 1383\n",
      "Saved the embedding for content.\n",
      "contented is at index 1383\n",
      "Saved the embedding for contented.\n",
      "contentious is at index 14883\n",
      "Saved the embedding for contentious.\n",
      "contently is at index 8541\n",
      "Saved the embedding for contently.\n",
      "contentment is at index 1383\n",
      "Saved the embedding for contentment.\n",
      "contradictory is at index 31515\n",
      "Saved the embedding for contradictory.\n",
      "contrary is at index 11159\n",
      "Saved the embedding for contrary.\n",
      "contrite is at index 17035\n",
      "Saved the embedding for contrite.\n",
      "controlled is at index 4875\n",
      "Saved the embedding for controlled.\n",
      "controlling is at index 10568\n",
      "Saved the embedding for controlling.\n",
      "controversial is at index 4456\n",
      "Saved the embedding for controversial.\n",
      "contumacious is at index 8541\n",
      "Saved the embedding for contumacious.\n",
      "convinced is at index 7013\n",
      "Saved the embedding for convinced.\n",
      "cool is at index 3035\n",
      "Saved the embedding for cool.\n",
      "cooperative is at index 18777\n",
      "Saved the embedding for cooperative.\n",
      "cordial is at index 13051\n",
      "Saved the embedding for cordial.\n",
      "courageous is at index 24219\n",
      "Saved the embedding for courageous.\n",
      "covert is at index 25523\n",
      "Saved the embedding for covert.\n",
      "cowardly is at index 36881\n",
      "Saved the embedding for cowardly.\n",
      "coy is at index 20176\n",
      "Saved the embedding for coy.\n",
      "crabby is at index 23320\n",
      "Saved the embedding for crabby.\n",
      "crafty is at index 6306\n",
      "Saved the embedding for crafty.\n",
      "cranky is at index 30952\n",
      "Saved the embedding for cranky.\n",
      "crazed is at index 26002\n",
      "Saved the embedding for crazed.\n",
      "crazy is at index 5373\n",
      "Saved the embedding for crazy.\n",
      "credulous is at index 18994\n",
      "Saved the embedding for credulous.\n",
      "creepy is at index 23814\n",
      "Saved the embedding for creepy.\n",
      "crestfallen is at index 32220\n",
      "Saved the embedding for crestfallen.\n",
      "cringing is at index 3977\n",
      "Saved the embedding for cringing.\n",
      "critical is at index 2008\n",
      "Saved the embedding for critical.\n",
      "cross is at index 2116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for cross.\n",
      "crotchety is at index 11398\n",
      "Saved the embedding for crotchety.\n",
      "crude is at index 2976\n",
      "Saved the embedding for crude.\n",
      "cruel is at index 15939\n",
      "Saved the embedding for cruel.\n",
      "crushed is at index 14045\n",
      "Saved the embedding for crushed.\n",
      "cry is at index 8930\n",
      "Saved the embedding for cry.\n",
      "crying is at index 9701\n",
      "Saved the embedding for crying.\n",
      "cryptic is at index 35916\n",
      "Saved the embedding for cryptic.\n",
      "culpable is at index 29410\n",
      "Saved the embedding for culpable.\n",
      "cunning is at index 41526\n",
      "Saved the embedding for cunning.\n",
      "curios is at index 5350\n",
      "Saved the embedding for curios.\n",
      "curiosity is at index 20610\n",
      "Saved the embedding for curiosity.\n",
      "curious is at index 10691\n",
      "Saved the embedding for curious.\n",
      "cutting is at index 3931\n",
      "Saved the embedding for cutting.\n",
      "cynic is at index 40240\n",
      "Saved the embedding for cynic.\n",
      "cynical is at index 27566\n",
      "Saved the embedding for cynical.\n",
      "cynicism is at index 39245\n",
      "Saved the embedding for cynicism.\n",
      "dalliance is at index 385\n",
      "Saved the embedding for dalliance.\n",
      "dandy is at index 385\n",
      "Saved the embedding for dandy.\n",
      "dangerous is at index 2702\n",
      "Saved the embedding for dangerous.\n",
      "darkly is at index 2933\n",
      "Saved the embedding for darkly.\n",
      "daunted is at index 385\n",
      "Saved the embedding for daunted.\n",
      "daydream is at index 183\n",
      "Saved the embedding for daydream.\n",
      "daydreaming is at index 183\n",
      "Saved the embedding for daydreaming.\n",
      "dazed is at index 385\n",
      "Saved the embedding for dazed.\n",
      "dazzled is at index 32614\n",
      "Saved the embedding for dazzled.\n",
      "deadly is at index 4847\n",
      "Saved the embedding for deadly.\n",
      "deadpan is at index 1462\n",
      "Saved the embedding for deadpan.\n",
      "debate is at index 2625\n",
      "Saved the embedding for debate.\n",
      "debating is at index 24996\n",
      "Saved the embedding for debating.\n",
      "debauched is at index 10189\n",
      "Saved the embedding for debauched.\n",
      "deceitful is at index 35049\n",
      "Saved the embedding for deceitful.\n",
      "deceived is at index 38079\n",
      "Saved the embedding for deceived.\n",
      "deceiving is at index 34575\n",
      "Saved the embedding for deceiving.\n",
      "deceivingly is at index 34575\n",
      "Saved the embedding for deceivingly.\n",
      "deception is at index 29244\n",
      "Saved the embedding for deception.\n",
      "deceptive is at index 31405\n",
      "Saved the embedding for deceptive.\n",
      "deciding is at index 8997\n",
      "Saved the embedding for deciding.\n",
      "decisive is at index 12703\n",
      "Saved the embedding for decisive.\n",
      "dedicated is at index 3688\n",
      "Saved the embedding for dedicated.\n",
      "defeat is at index 3002\n",
      "Saved the embedding for defeat.\n",
      "defeated is at index 5125\n",
      "Saved the embedding for defeated.\n",
      "defenseless is at index 3816\n",
      "Saved the embedding for defenseless.\n",
      "defensive is at index 2465\n",
      "Saved the embedding for defensive.\n",
      "defiance is at index 25442\n",
      "Saved the embedding for defiance.\n",
      "defiant is at index 23802\n",
      "Saved the embedding for defiant.\n",
      "deflated is at index 3816\n",
      "Saved the embedding for deflated.\n",
      "degage is at index 31295\n",
      "Saved the embedding for degage.\n",
      "degrading is at index 36892\n",
      "Saved the embedding for degrading.\n",
      "dejected is at index 263\n",
      "Saved the embedding for dejected.\n",
      "dejection is at index 263\n",
      "Saved the embedding for dejection.\n",
      "deliberate is at index 14775\n",
      "Saved the embedding for deliberate.\n",
      "deliberating is at index 21614\n",
      "Saved the embedding for deliberating.\n",
      "delight is at index 13213\n",
      "Saved the embedding for delight.\n",
      "delighted is at index 7808\n",
      "Saved the embedding for delighted.\n",
      "delightful is at index 24897\n",
      "Saved the embedding for delightful.\n",
      "delirious is at index 2424\n",
      "Saved the embedding for delirious.\n",
      "delirium is at index 2424\n",
      "Saved the embedding for delirium.\n",
      "delude is at index 2424\n",
      "Saved the embedding for delude.\n",
      "delusional is at index 40160\n",
      "Saved the embedding for delusional.\n",
      "demanding is at index 5783\n",
      "Saved the embedding for demanding.\n",
      "demeaning is at index 4410\n",
      "Saved the embedding for demeaning.\n",
      "demented is at index 44202\n",
      "Saved the embedding for demented.\n",
      "demised is at index 4410\n",
      "Saved the embedding for demised.\n",
      "demoralized is at index 36810\n",
      "Saved the embedding for demoralized.\n",
      "demure is at index 4410\n",
      "Saved the embedding for demure.\n",
      "denied is at index 2296\n",
      "Saved the embedding for denied.\n",
      "denouncing is at index 32439\n",
      "Saved the embedding for denouncing.\n",
      "depleted is at index 26391\n",
      "Saved the embedding for depleted.\n",
      "deplorable is at index 28156\n",
      "Saved the embedding for deplorable.\n",
      "deprecating is at index 8273\n",
      "Saved the embedding for deprecating.\n",
      "depressed is at index 16658\n",
      "Saved the embedding for depressed.\n",
      "depression is at index 6943\n",
      "Saved the embedding for depression.\n",
      "deprived is at index 22632\n",
      "Saved the embedding for deprived.\n",
      "deranged is at index 1935\n",
      "Saved the embedding for deranged.\n",
      "derision is at index 1935\n",
      "Saved the embedding for derision.\n",
      "derisive is at index 1935\n",
      "Saved the embedding for derisive.\n",
      "derogatory is at index 30971\n",
      "Saved the embedding for derogatory.\n",
      "desire is at index 4724\n",
      "Saved the embedding for desire.\n",
      "desiring is at index 2694\n",
      "Saved the embedding for desiring.\n",
      "desirous is at index 2694\n",
      "Saved the embedding for desirous.\n",
      "desolate is at index 43177\n",
      "Saved the embedding for desolate.\n",
      "despair is at index 21508\n",
      "Saved the embedding for despair.\n",
      "despaired is at index 2694\n",
      "Saved the embedding for despaired.\n",
      "despairing is at index 21508\n",
      "Saved the embedding for despairing.\n",
      "desperate is at index 7764\n",
      "Saved the embedding for desperate.\n",
      "desperation is at index 24278\n",
      "Saved the embedding for desperation.\n",
      "despise is at index 43255\n",
      "Saved the embedding for despise.\n",
      "despondent is at index 18690\n",
      "Saved the embedding for despondent.\n",
      "destitute is at index 15357\n",
      "Saved the embedding for destitute.\n",
      "destroyed is at index 4957\n",
      "Saved the embedding for destroyed.\n",
      "detached is at index 27687\n",
      "Saved the embedding for detached.\n",
      "determination is at index 8964\n",
      "Saved the embedding for determination.\n",
      "determined is at index 3030\n",
      "Saved the embedding for determined.\n",
      "determining is at index 13684\n",
      "Saved the embedding for determining.\n",
      "deterred is at index 10922\n",
      "Saved the embedding for deterred.\n",
      "detest is at index 6769\n",
      "Saved the embedding for detest.\n",
      "detestable is at index 6769\n",
      "Saved the embedding for detestable.\n",
      "detesting is at index 6769\n",
      "Saved the embedding for detesting.\n",
      "detriment is at index 31969\n",
      "Saved the embedding for detriment.\n",
      "devastated is at index 11521\n",
      "Saved the embedding for devastated.\n",
      "deviant is at index 8709\n",
      "Saved the embedding for deviant.\n",
      "devilish is at index 22406\n",
      "Saved the embedding for devilish.\n",
      "devious is at index 263\n",
      "Saved the embedding for devious.\n",
      "devising is at index 8709\n",
      "Saved the embedding for devising.\n",
      "diffident is at index 25871\n",
      "Saved the embedding for diffident.\n",
      "dilatory is at index 14632\n",
      "Saved the embedding for dilatory.\n",
      "diligent is at index 33721\n",
      "Saved the embedding for diligent.\n",
      "dimwitted is at index 14548\n",
      "Saved the embedding for dimwitted.\n",
      "dire is at index 10697\n",
      "Saved the embedding for dire.\n",
      "disagree is at index 11967\n",
      "Saved the embedding for disagree.\n",
      "disagreeable is at index 11967\n",
      "Saved the embedding for disagreeable.\n",
      "disagreement is at index 20628\n",
      "Saved the embedding for disagreement.\n",
      "disappointed is at index 5779\n",
      "Saved the embedding for disappointed.\n",
      "disappointing is at index 6770\n",
      "Saved the embedding for disappointing.\n",
      "disappointment is at index 10208\n",
      "Saved the embedding for disappointment.\n",
      "disapproval is at index 32129\n",
      "Saved the embedding for disapproval.\n",
      "disapproving is at index 36631\n",
      "Saved the embedding for disapproving.\n",
      "disbelief is at index 26440\n",
      "Saved the embedding for disbelief.\n",
      "disbelieve is at index 45668\n",
      "Saved the embedding for disbelieve.\n",
      "disbelieving is at index 45668\n",
      "Saved the embedding for disbelieving.\n",
      "discerning is at index 9553\n",
      "Saved the embedding for discerning.\n",
      "discombobulated is at index 2982\n",
      "Saved the embedding for discombobulated.\n",
      "discomfited is at index 2982\n",
      "Saved the embedding for discomfited.\n",
      "discomfort is at index 19535\n",
      "Saved the embedding for discomfort.\n",
      "discomforted is at index 19535\n",
      "Saved the embedding for discomforted.\n",
      "disconcerted is at index 2982\n",
      "Saved the embedding for disconcerted.\n",
      "disconnected is at index 30005\n",
      "Saved the embedding for disconnected.\n",
      "disconsolate is at index 9553\n",
      "Saved the embedding for disconsolate.\n",
      "discontent is at index 27478\n",
      "Saved the embedding for discontent.\n",
      "discontented is at index 47772\n",
      "Saved the embedding for discontented.\n",
      "discounted is at index 17533\n",
      "Saved the embedding for discounted.\n",
      "discouraged is at index 25788\n",
      "Saved the embedding for discouraged.\n",
      "discovery is at index 6953\n",
      "Saved the embedding for discovery.\n",
      "discriminating is at index 38303\n",
      "Saved the embedding for discriminating.\n",
      "discussed is at index 3373\n",
      "Saved the embedding for discussed.\n",
      "disdain is at index 29512\n",
      "Saved the embedding for disdain.\n",
      "disdained is at index 2982\n",
      "Saved the embedding for disdained.\n",
      "disdainful is at index 29512\n",
      "Saved the embedding for disdainful.\n",
      "disdainfully is at index 29512\n",
      "Saved the embedding for disdainfully.\n",
      "disenchanted is at index 2982\n",
      "Saved the embedding for disenchanted.\n",
      "disengaged is at index 35170\n",
      "Saved the embedding for disengaged.\n",
      "disgraced is at index 25425\n",
      "Saved the embedding for disgraced.\n",
      "disgruntled is at index 29412\n",
      "Saved the embedding for disgruntled.\n",
      "disgruntlement is at index 25425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for disgruntlement.\n",
      "disgust is at index 30883\n",
      "Saved the embedding for disgust.\n",
      "disgusted is at index 32759\n",
      "Saved the embedding for disgusted.\n",
      "disgustedly is at index 32759\n",
      "Saved the embedding for disgustedly.\n",
      "disgusting is at index 21096\n",
      "Saved the embedding for disgusting.\n",
      "disheartened is at index 2982\n",
      "Saved the embedding for disheartened.\n",
      "dishonest is at index 27820\n",
      "Saved the embedding for dishonest.\n",
      "disillusioned is at index 33447\n",
      "Saved the embedding for disillusioned.\n",
      "disinclined is at index 2982\n",
      "Saved the embedding for disinclined.\n",
      "disingenuous is at index 39622\n",
      "Saved the embedding for disingenuous.\n",
      "disinterest is at index 2982\n",
      "Saved the embedding for disinterest.\n",
      "disinterested is at index 2982\n",
      "Saved the embedding for disinterested.\n",
      "disjointed is at index 2982\n",
      "Saved the embedding for disjointed.\n",
      "dislike is at index 28101\n",
      "Saved the embedding for dislike.\n",
      "disliked is at index 40891\n",
      "Saved the embedding for disliked.\n",
      "disliking is at index 19131\n",
      "Saved the embedding for disliking.\n",
      "dismal is at index 23446\n",
      "Saved the embedding for dismal.\n",
      "disman is at index 2982\n",
      "Saved the embedding for disman.\n",
      "dismay is at index 22135\n",
      "Saved the embedding for dismay.\n",
      "dismayed is at index 22135\n",
      "Saved the embedding for dismayed.\n",
      "dismissive is at index 37890\n",
      "Saved the embedding for dismissive.\n",
      "disobedient is at index 43738\n",
      "Saved the embedding for disobedient.\n",
      "disorderly is at index 23547\n",
      "Saved the embedding for disorderly.\n",
      "disoriented is at index 2982\n",
      "Saved the embedding for disoriented.\n",
      "dispair is at index 11734\n",
      "Saved the embedding for dispair.\n",
      "disparaging is at index 24331\n",
      "Saved the embedding for disparaging.\n",
      "dispassionate is at index 11734\n",
      "Saved the embedding for dispassionate.\n",
      "dispirited is at index 2982\n",
      "Saved the embedding for dispirited.\n",
      "dispiritedness is at index 2982\n",
      "Saved the embedding for dispiritedness.\n",
      "displeased is at index 43709\n",
      "Saved the embedding for displeased.\n",
      "displeasure is at index 30201\n",
      "Saved the embedding for displeasure.\n",
      "disquiet is at index 2982\n",
      "Saved the embedding for disquiet.\n",
      "disquieted is at index 2982\n",
      "Saved the embedding for disquieted.\n",
      "disregard is at index 21034\n",
      "Saved the embedding for disregard.\n",
      "disrespectful is at index 26401\n",
      "Saved the embedding for disrespectful.\n",
      "disrupted is at index 15902\n",
      "Saved the embedding for disrupted.\n",
      "disruptive is at index 17561\n",
      "Saved the embedding for disruptive.\n",
      "dissatisfaction is at index 31776\n",
      "Saved the embedding for dissatisfaction.\n",
      "dissatisfied is at index 37278\n",
      "Saved the embedding for dissatisfied.\n",
      "dissatisfy is at index 48830\n",
      "Saved the embedding for dissatisfy.\n",
      "dissecting is at index 33562\n",
      "Saved the embedding for dissecting.\n",
      "dissociated is at index 14863\n",
      "Saved the embedding for dissociated.\n",
      "dissonant is at index 43162\n",
      "Saved the embedding for dissonant.\n",
      "distain is at index 7018\n",
      "Saved the embedding for distain.\n",
      "distant is at index 13258\n",
      "Saved the embedding for distant.\n",
      "distaste is at index 7018\n",
      "Saved the embedding for distaste.\n",
      "distasteful is at index 7018\n",
      "Saved the embedding for distasteful.\n",
      "distracted is at index 16573\n",
      "Saved the embedding for distracted.\n",
      "distraught is at index 30719\n",
      "Saved the embedding for distraught.\n",
      "distress is at index 13250\n",
      "Saved the embedding for distress.\n",
      "distressed is at index 21460\n",
      "Saved the embedding for distressed.\n",
      "distressing is at index 7018\n",
      "Saved the embedding for distressing.\n",
      "distrust is at index 27948\n",
      "Saved the embedding for distrust.\n",
      "distrustful is at index 27948\n",
      "Saved the embedding for distrustful.\n",
      "distrusting is at index 27948\n",
      "Saved the embedding for distrusting.\n",
      "disturbed is at index 22938\n",
      "Saved the embedding for disturbed.\n",
      "diverted is at index 19070\n",
      "Saved the embedding for diverted.\n",
      "dodgy is at index 25744\n",
      "Saved the embedding for dodgy.\n",
      "doleful is at index 109\n",
      "Saved the embedding for doleful.\n",
      "doltish is at index 385\n",
      "Saved the embedding for doltish.\n",
      "dominant is at index 7353\n",
      "Saved the embedding for dominant.\n",
      "dominating is at index 17349\n",
      "Saved the embedding for dominating.\n",
      "domineering is at index 13567\n",
      "Saved the embedding for domineering.\n",
      "done is at index 626\n",
      "Saved the embedding for done.\n",
      "doomed is at index 23326\n",
      "Saved the embedding for doomed.\n",
      "dopey is at index 32331\n",
      "Saved the embedding for dopey.\n",
      "doting is at index 385\n",
      "Saved the embedding for doting.\n",
      "doubt is at index 2980\n",
      "Saved the embedding for doubt.\n",
      "doubter is at index 26463\n",
      "Saved the embedding for doubter.\n",
      "doubtful is at index 26645\n",
      "Saved the embedding for doubtful.\n",
      "doubtfully is at index 2980\n",
      "Saved the embedding for doubtfully.\n",
      "doubtfulness is at index 2980\n",
      "Saved the embedding for doubtfulness.\n",
      "doubting is at index 26463\n",
      "Saved the embedding for doubting.\n",
      "dour is at index 385\n",
      "Saved the embedding for dour.\n",
      "down is at index 159\n",
      "Saved the embedding for down.\n",
      "downcast is at index 159\n",
      "Saved the embedding for downcast.\n",
      "downhearted is at index 159\n",
      "Saved the embedding for downhearted.\n",
      "downheartedness is at index 159\n",
      "Saved the embedding for downheartedness.\n",
      "downtrodden is at index 29407\n",
      "Saved the embedding for downtrodden.\n",
      "dozing is at index 109\n",
      "Saved the embedding for dozing.\n",
      "drained is at index 23544\n",
      "Saved the embedding for drained.\n",
      "dramatic is at index 5386\n",
      "Saved the embedding for dramatic.\n",
      "drawn is at index 4777\n",
      "Saved the embedding for drawn.\n",
      "dread is at index 24506\n",
      "Saved the embedding for dread.\n",
      "dreadful is at index 31715\n",
      "Saved the embedding for dreadful.\n",
      "dreading is at index 24506\n",
      "Saved the embedding for dreading.\n",
      "dreaming is at index 26240\n",
      "Saved the embedding for dreaming.\n",
      "dreamy is at index 3366\n",
      "Saved the embedding for dreamy.\n",
      "dreary is at index 385\n",
      "Saved the embedding for dreary.\n",
      "driven is at index 3185\n",
      "Saved the embedding for driven.\n",
      "drowsy is at index 385\n",
      "Saved the embedding for drowsy.\n",
      "drugged is at index 385\n",
      "Saved the embedding for drugged.\n",
      "drunk is at index 10789\n",
      "Saved the embedding for drunk.\n",
      "drunkenness is at index 19835\n",
      "Saved the embedding for drunkenness.\n",
      "dubiety is at index 30180\n",
      "Saved the embedding for dubiety.\n",
      "dubious is at index 24381\n",
      "Saved the embedding for dubious.\n",
      "dubiously is at index 30180\n",
      "Saved the embedding for dubiously.\n",
      "dull is at index 22018\n",
      "Saved the embedding for dull.\n",
      "dumb is at index 16881\n",
      "Saved the embedding for dumb.\n",
      "dumbfound is at index 16881\n",
      "Saved the embedding for dumbfound.\n",
      "dumbfounded is at index 16881\n",
      "Saved the embedding for dumbfounded.\n",
      "dumbstruck is at index 16881\n",
      "Saved the embedding for dumbstruck.\n",
      "dumfounded is at index 385\n",
      "Saved the embedding for dumfounded.\n",
      "dupe is at index 4279\n",
      "Saved the embedding for dupe.\n",
      "duplicitous is at index 30501\n",
      "Saved the embedding for duplicitous.\n",
      "dysphoric is at index 44153\n",
      "Saved the embedding for dysphoric.\n",
      "eager is at index 7921\n",
      "Saved the embedding for eager.\n",
      "eagerness is at index 7921\n",
      "Saved the embedding for eagerness.\n",
      "earnest is at index 22623\n",
      "Saved the embedding for earnest.\n",
      "easy is at index 1365\n",
      "Saved the embedding for easy.\n",
      "ebullient is at index 364\n",
      "Saved the embedding for ebullient.\n",
      "ecstasy is at index 37695\n",
      "Saved the embedding for ecstasy.\n",
      "ecstatic is at index 30754\n",
      "Saved the embedding for ecstatic.\n",
      "ecstatically is at index 20508\n",
      "Saved the embedding for ecstatically.\n",
      "edgy is at index 4803\n",
      "Saved the embedding for edgy.\n",
      "eerie is at index 33960\n",
      "Saved the embedding for eerie.\n",
      "effulgent is at index 22089\n",
      "Saved the embedding for effulgent.\n",
      "egoistic is at index 21450\n",
      "Saved the embedding for egoistic.\n",
      "egotistical is at index 364\n",
      "Saved the embedding for egotistical.\n",
      "egregious is at index 28971\n",
      "Saved the embedding for egregious.\n",
      "elated is at index 1615\n",
      "Saved the embedding for elated.\n",
      "elation is at index 1615\n",
      "Saved the embedding for elation.\n",
      "electrified is at index 17995\n",
      "Saved the embedding for electrified.\n",
      "elusive is at index 21483\n",
      "Saved the embedding for elusive.\n",
      "embarrassed is at index 17319\n",
      "Saved the embedding for embarrassed.\n",
      "embarrassment is at index 19124\n",
      "Saved the embedding for embarrassment.\n",
      "embittered is at index 2841\n",
      "Saved the embedding for embittered.\n",
      "embody is at index 33865\n",
      "Saved the embedding for embody.\n",
      "emotional is at index 3722\n",
      "Saved the embedding for emotional.\n",
      "emotionless is at index 11926\n",
      "Saved the embedding for emotionless.\n",
      "empathetic is at index 2841\n",
      "Saved the embedding for empathetic.\n",
      "empathic is at index 2841\n",
      "Saved the embedding for empathic.\n",
      "empathy is at index 17805\n",
      "Saved the embedding for empathy.\n",
      "emptiness is at index 44480\n",
      "Saved the embedding for emptiness.\n",
      "empty is at index 5802\n",
      "Saved the embedding for empty.\n",
      "enamored is at index 1177\n",
      "Saved the embedding for enamored.\n",
      "enchanted is at index 44141\n",
      "Saved the embedding for enchanted.\n",
      "encouraged is at index 4446\n",
      "Saved the embedding for encouraged.\n",
      "encouragement is at index 18197\n",
      "Saved the embedding for encouragement.\n",
      "encouraging is at index 5513\n",
      "Saved the embedding for encouraging.\n",
      "endeared is at index 253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for endeared.\n",
      "endearing is at index 253\n",
      "Saved the embedding for endearing.\n",
      "enduring is at index 16480\n",
      "Saved the embedding for enduring.\n",
      "energetic is at index 20425\n",
      "Saved the embedding for energetic.\n",
      "energized is at index 15957\n",
      "Saved the embedding for energized.\n",
      "engaged is at index 4009\n",
      "Saved the embedding for engaged.\n",
      "engrossed is at index 20407\n",
      "Saved the embedding for engrossed.\n",
      "engrossment is at index 20407\n",
      "Saved the embedding for engrossment.\n",
      "enigmatic is at index 38910\n",
      "Saved the embedding for enigmatic.\n",
      "enjoy is at index 2254\n",
      "Saved the embedding for enjoy.\n",
      "enjoying is at index 6218\n",
      "Saved the embedding for enjoying.\n",
      "enjoyment is at index 26611\n",
      "Saved the embedding for enjoyment.\n",
      "enlightened is at index 38853\n",
      "Saved the embedding for enlightened.\n",
      "enmity is at index 1177\n",
      "Saved the embedding for enmity.\n",
      "ennui is at index 1177\n",
      "Saved the embedding for ennui.\n",
      "enraged is at index 33415\n",
      "Saved the embedding for enraged.\n",
      "enraging is at index 1177\n",
      "Saved the embedding for enraging.\n",
      "enraptured is at index 1177\n",
      "Saved the embedding for enraptured.\n",
      "entertained is at index 23979\n",
      "Saved the embedding for entertained.\n",
      "enthralled is at index 3838\n",
      "Saved the embedding for enthralled.\n",
      "enthused is at index 3838\n",
      "Saved the embedding for enthused.\n",
      "enthusiasm is at index 11240\n",
      "Saved the embedding for enthusiasm.\n",
      "enthusiastic is at index 15947\n",
      "Saved the embedding for enthusiastic.\n",
      "enticed is at index 3838\n",
      "Saved the embedding for enticed.\n",
      "entranced is at index 3838\n",
      "Saved the embedding for entranced.\n",
      "envious is at index 1177\n",
      "Saved the embedding for envious.\n",
      "envy is at index 29778\n",
      "Saved the embedding for envy.\n",
      "erotically is at index 3335\n",
      "Saved the embedding for erotically.\n",
      "estranged is at index 20599\n",
      "Saved the embedding for estranged.\n",
      "etched is at index 35542\n",
      "Saved the embedding for etched.\n",
      "euphoric is at index 30882\n",
      "Saved the embedding for euphoric.\n",
      "evaluating is at index 15190\n",
      "Saved the embedding for evaluating.\n",
      "evasive is at index 7630\n",
      "Saved the embedding for evasive.\n",
      "evil is at index 9247\n",
      "Saved the embedding for evil.\n",
      "evoke is at index 35334\n",
      "Saved the embedding for evoke.\n",
      "exacerbated is at index 24961\n",
      "Saved the embedding for exacerbated.\n",
      "exalted is at index 45514\n",
      "Saved the embedding for exalted.\n",
      "examining is at index 14951\n",
      "Saved the embedding for examining.\n",
      "exasperate is at index 1931\n",
      "Saved the embedding for exasperate.\n",
      "exasperated is at index 34698\n",
      "Saved the embedding for exasperated.\n",
      "exasperation is at index 34698\n",
      "Saved the embedding for exasperation.\n",
      "excited is at index 2283\n",
      "Saved the embedding for excited.\n",
      "excitedly is at index 2283\n",
      "Saved the embedding for excitedly.\n",
      "excitement is at index 8354\n",
      "Saved the embedding for excitement.\n",
      "exclamation is at index 1931\n",
      "Saved the embedding for exclamation.\n",
      "exclamatory is at index 1931\n",
      "Saved the embedding for exclamatory.\n",
      "exhausted is at index 17067\n",
      "Saved the embedding for exhausted.\n",
      "exhaustion is at index 30567\n",
      "Saved the embedding for exhaustion.\n",
      "exhaustive is at index 29180\n",
      "Saved the embedding for exhaustive.\n",
      "exhilarated is at index 32749\n",
      "Saved the embedding for exhilarated.\n",
      "exhilaration is at index 32749\n",
      "Saved the embedding for exhilaration.\n",
      "exited is at index 17469\n",
      "Saved the embedding for exited.\n",
      "expectant is at index 1057\n",
      "Saved the embedding for expectant.\n",
      "expectation is at index 9250\n",
      "Saved the embedding for expectation.\n",
      "expecting is at index 4804\n",
      "Saved the embedding for expecting.\n",
      "explain is at index 3922\n",
      "Saved the embedding for explain.\n",
      "explaining is at index 8926\n",
      "Saved the embedding for explaining.\n",
      "exploitive is at index 38984\n",
      "Saved the embedding for exploitive.\n",
      "explosive is at index 8560\n",
      "Saved the embedding for explosive.\n",
      "exposure is at index 4895\n",
      "Saved the embedding for exposure.\n",
      "expressive is at index 36340\n",
      "Saved the embedding for expressive.\n",
      "exuberant is at index 1931\n",
      "Saved the embedding for exuberant.\n",
      "exultant is at index 1931\n",
      "Saved the embedding for exultant.\n",
      "exulted is at index 1931\n",
      "Saved the embedding for exulted.\n",
      "eye is at index 2295\n",
      "Saved the embedding for eye.\n",
      "eyed is at index 36235\n",
      "Saved the embedding for eyed.\n",
      "faced is at index 2713\n",
      "Saved the embedding for faced.\n",
      "facetious is at index 34407\n",
      "Saved the embedding for facetious.\n",
      "failure is at index 2988\n",
      "Saved the embedding for failure.\n",
      "faint is at index 27922\n",
      "Saved the embedding for faint.\n",
      "fair is at index 2105\n",
      "Saved the embedding for fair.\n",
      "fake is at index 4486\n",
      "Saved the embedding for fake.\n",
      "faking is at index 856\n",
      "Saved the embedding for faking.\n",
      "falter is at index 14848\n",
      "Saved the embedding for falter.\n",
      "famished is at index 13403\n",
      "Saved the embedding for famished.\n",
      "fanatic is at index 38604\n",
      "Saved the embedding for fanatic.\n",
      "fanciful is at index 33639\n",
      "Saved the embedding for fanciful.\n",
      "fart is at index 36762\n",
      "Saved the embedding for fart.\n",
      "fascinated is at index 27025\n",
      "Saved the embedding for fascinated.\n",
      "fastidious is at index 1769\n",
      "Saved the embedding for fastidious.\n",
      "fatigue is at index 16069\n",
      "Saved the embedding for fatigue.\n",
      "fatigued is at index 36239\n",
      "Saved the embedding for fatigued.\n",
      "faultfinding is at index 7684\n",
      "Saved the embedding for faultfinding.\n",
      "favorable is at index 9879\n",
      "Saved the embedding for favorable.\n",
      "fawning is at index 856\n",
      "Saved the embedding for fawning.\n",
      "fazed is at index 856\n",
      "Saved the embedding for fazed.\n",
      "fear is at index 2490\n",
      "Saved the embedding for fear.\n",
      "feared is at index 9741\n",
      "Saved the embedding for feared.\n",
      "fearful is at index 23526\n",
      "Saved the embedding for fearful.\n",
      "fearing is at index 21510\n",
      "Saved the embedding for fearing.\n",
      "fearless is at index 29107\n",
      "Saved the embedding for fearless.\n",
      "fearsome is at index 39185\n",
      "Saved the embedding for fearsome.\n",
      "feckless is at index 10668\n",
      "Saved the embedding for feckless.\n",
      "fed is at index 9789\n",
      "Saved the embedding for fed.\n",
      "feeble is at index 42217\n",
      "Saved the embedding for feeble.\n",
      "feign is at index 10668\n",
      "Saved the embedding for feign.\n",
      "felicitous is at index 14383\n",
      "Saved the embedding for felicitous.\n",
      "ferocious is at index 31429\n",
      "Saved the embedding for ferocious.\n",
      "ferocity is at index 16022\n",
      "Saved the embedding for ferocity.\n",
      "festive is at index 12298\n",
      "Saved the embedding for festive.\n",
      "fidgety is at index 856\n",
      "Saved the embedding for fidgety.\n",
      "fiendish is at index 13383\n",
      "Saved the embedding for fiendish.\n",
      "fierce is at index 11039\n",
      "Saved the embedding for fierce.\n",
      "fiery is at index 19068\n",
      "Saved the embedding for fiery.\n",
      "fighting is at index 2190\n",
      "Saved the embedding for fighting.\n",
      "fine is at index 2051\n",
      "Saved the embedding for fine.\n",
      "finished is at index 1550\n",
      "Saved the embedding for finished.\n",
      "firm is at index 933\n",
      "Saved the embedding for firm.\n",
      "fishy is at index 3539\n",
      "Saved the embedding for fishy.\n",
      "fixated is at index 4190\n",
      "Saved the embedding for fixated.\n",
      "fixed is at index 4460\n",
      "Saved the embedding for fixed.\n",
      "flabbergasted is at index 2342\n",
      "Saved the embedding for flabbergasted.\n",
      "flaming is at index 37222\n",
      "Saved the embedding for flaming.\n",
      "flat is at index 3269\n",
      "Saved the embedding for flat.\n",
      "flaunting is at index 2342\n",
      "Saved the embedding for flaunting.\n",
      "flighty is at index 2524\n",
      "Saved the embedding for flighty.\n",
      "flippant is at index 2342\n",
      "Saved the embedding for flippant.\n",
      "flipped is at index 18626\n",
      "Saved the embedding for flipped.\n",
      "flirtation is at index 33743\n",
      "Saved the embedding for flirtation.\n",
      "flirtatious is at index 33743\n",
      "Saved the embedding for flirtatious.\n",
      "flirty is at index 2342\n",
      "Saved the embedding for flirty.\n",
      "floored is at index 27325\n",
      "Saved the embedding for floored.\n",
      "flummoxed is at index 2342\n",
      "Saved the embedding for flummoxed.\n",
      "flustered is at index 2342\n",
      "Saved the embedding for flustered.\n",
      "focus is at index 1056\n",
      "Saved the embedding for focus.\n",
      "focused is at index 2061\n",
      "Saved the embedding for focused.\n",
      "focusing is at index 5650\n",
      "Saved the embedding for focusing.\n",
      "foiled is at index 9565\n",
      "Saved the embedding for foiled.\n",
      "foolish is at index 22789\n",
      "Saved the embedding for foolish.\n",
      "forbearing is at index 34550\n",
      "Saved the embedding for forbearing.\n",
      "forbidding is at index 34550\n",
      "Saved the embedding for forbidding.\n",
      "forced is at index 1654\n",
      "Saved the embedding for forced.\n",
      "forceful is at index 32165\n",
      "Saved the embedding for forceful.\n",
      "forfeited is at index 31844\n",
      "Saved the embedding for forfeited.\n",
      "forlorn is at index 13\n",
      "Saved the embedding for forlorn.\n",
      "fortunate is at index 10583\n",
      "Saved the embedding for fortunate.\n",
      "forward is at index 556\n",
      "Saved the embedding for forward.\n",
      "foul is at index 6962\n",
      "Saved the embedding for foul.\n",
      "fractious is at index 38251\n",
      "Saved the embedding for fractious.\n",
      "fragile is at index 14283\n",
      "Saved the embedding for fragile.\n",
      "frantic is at index 27396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for frantic.\n",
      "fraudulent is at index 15381\n",
      "Saved the embedding for fraudulent.\n",
      "fraught is at index 25481\n",
      "Saved the embedding for fraught.\n",
      "frazzled is at index 26830\n",
      "Saved the embedding for frazzled.\n",
      "freaked is at index 7619\n",
      "Saved the embedding for freaked.\n",
      "frenzied is at index 26908\n",
      "Saved the embedding for frenzied.\n",
      "fretful is at index 31391\n",
      "Saved the embedding for fretful.\n",
      "friendliness is at index 1441\n",
      "Saved the embedding for friendliness.\n",
      "friendly is at index 5192\n",
      "Saved the embedding for friendly.\n",
      "fright is at index 32580\n",
      "Saved the embedding for fright.\n",
      "frightened is at index 26851\n",
      "Saved the embedding for frightened.\n",
      "frightening is at index 21111\n",
      "Saved the embedding for frightening.\n",
      "frigid is at index 25805\n",
      "Saved the embedding for frigid.\n",
      "frisky is at index 6664\n",
      "Saved the embedding for frisky.\n",
      "frolicker is at index 856\n",
      "Saved the embedding for frolicker.\n",
      "frown is at index 41588\n",
      "Saved the embedding for frown.\n",
      "frowning is at index 41588\n",
      "Saved the embedding for frowning.\n",
      "frozen is at index 9214\n",
      "Saved the embedding for frozen.\n",
      "frumpy is at index 6664\n",
      "Saved the embedding for frumpy.\n",
      "frustrated is at index 8164\n",
      "Saved the embedding for frustrated.\n",
      "frustration is at index 8413\n",
      "Saved the embedding for frustration.\n",
      "fulfilled is at index 20218\n",
      "Saved the embedding for fulfilled.\n",
      "fumed is at index 856\n",
      "Saved the embedding for fumed.\n",
      "fuming is at index 856\n",
      "Saved the embedding for fuming.\n",
      "fun is at index 1531\n",
      "Saved the embedding for fun.\n",
      "funny is at index 6269\n",
      "Saved the embedding for funny.\n",
      "furious is at index 15940\n",
      "Saved the embedding for furious.\n",
      "furiously is at index 39202\n",
      "Saved the embedding for furiously.\n",
      "furiousness is at index 15940\n",
      "Saved the embedding for furiousness.\n",
      "furrowed is at index 15503\n",
      "Saved the embedding for furrowed.\n",
      "furtive is at index 856\n",
      "Saved the embedding for furtive.\n",
      "fury is at index 22228\n",
      "Saved the embedding for fury.\n",
      "fussy is at index 856\n",
      "Saved the embedding for fussy.\n",
      "galled is at index 821\n",
      "Saved the embedding for galled.\n",
      "galling is at index 19869\n",
      "Saved the embedding for galling.\n",
      "gasp is at index 41681\n",
      "Saved the embedding for gasp.\n",
      "gasped is at index 44918\n",
      "Saved the embedding for gasped.\n",
      "gasping is at index 1123\n",
      "Saved the embedding for gasping.\n",
      "gay is at index 5100\n",
      "Saved the embedding for gay.\n",
      "gazing is at index 40804\n",
      "Saved the embedding for gazing.\n",
      "genial is at index 12358\n",
      "Saved the embedding for genial.\n",
      "gentle is at index 16634\n",
      "Saved the embedding for gentle.\n",
      "genuine is at index 8916\n",
      "Saved the embedding for genuine.\n",
      "ghastly is at index 34648\n",
      "Saved the embedding for ghastly.\n",
      "giddy is at index 821\n",
      "Saved the embedding for giddy.\n",
      "giggle is at index 821\n",
      "Saved the embedding for giggle.\n",
      "giggling is at index 33786\n",
      "Saved the embedding for giggling.\n",
      "glad is at index 7785\n",
      "Saved the embedding for glad.\n",
      "gladdened is at index 5921\n",
      "Saved the embedding for gladdened.\n",
      "gladiola is at index 7785\n",
      "Saved the embedding for gladiola.\n",
      "gladness is at index 7785\n",
      "Saved the embedding for gladness.\n",
      "gladsome is at index 5921\n",
      "Saved the embedding for gladsome.\n",
      "glare is at index 37355\n",
      "Saved the embedding for glare.\n",
      "glaring is at index 26077\n",
      "Saved the embedding for glaring.\n",
      "glazed is at index 5921\n",
      "Saved the embedding for glazed.\n",
      "glee is at index 821\n",
      "Saved the embedding for glee.\n",
      "gleeful is at index 22460\n",
      "Saved the embedding for gleeful.\n",
      "gleefully is at index 22460\n",
      "Saved the embedding for gleefully.\n",
      "glib is at index 5921\n",
      "Saved the embedding for glib.\n",
      "gloating is at index 5921\n",
      "Saved the embedding for gloating.\n",
      "gloom is at index 31752\n",
      "Saved the embedding for gloom.\n",
      "gloomy is at index 32627\n",
      "Saved the embedding for gloomy.\n",
      "glowering is at index 5921\n",
      "Saved the embedding for glowering.\n",
      "glowing is at index 22285\n",
      "Saved the embedding for glowing.\n",
      "glum is at index 5921\n",
      "Saved the embedding for glum.\n",
      "gnarl is at index 31021\n",
      "Saved the embedding for gnarl.\n",
      "gobsmacked is at index 213\n",
      "Saved the embedding for gobsmacked.\n",
      "good is at index 205\n",
      "Saved the embedding for good.\n",
      "goofy is at index 36302\n",
      "Saved the embedding for goofy.\n",
      "gossipy is at index 20445\n",
      "Saved the embedding for gossipy.\n",
      "grandiose is at index 2821\n",
      "Saved the embedding for grandiose.\n",
      "grateful is at index 6161\n",
      "Saved the embedding for grateful.\n",
      "gratified is at index 20153\n",
      "Saved the embedding for gratified.\n",
      "grave is at index 9753\n",
      "Saved the embedding for grave.\n",
      "great is at index 372\n",
      "Saved the embedding for great.\n",
      "greedy is at index 34405\n",
      "Saved the embedding for greedy.\n",
      "greeting is at index 25801\n",
      "Saved the embedding for greeting.\n",
      "grief is at index 12903\n",
      "Saved the embedding for grief.\n",
      "grieved is at index 821\n",
      "Saved the embedding for grieved.\n",
      "grieving is at index 22567\n",
      "Saved the embedding for grieving.\n",
      "grim is at index 17081\n",
      "Saved the embedding for grim.\n",
      "grimace is at index 17081\n",
      "Saved the embedding for grimace.\n",
      "grimacing is at index 17081\n",
      "Saved the embedding for grimacing.\n",
      "grin is at index 30986\n",
      "Saved the embedding for grin.\n",
      "grinning is at index 39662\n",
      "Saved the embedding for grinning.\n",
      "griping is at index 11155\n",
      "Saved the embedding for griping.\n",
      "gross is at index 4200\n",
      "Saved the embedding for gross.\n",
      "grossed is at index 4200\n",
      "Saved the embedding for grossed.\n",
      "grouchy is at index 22970\n",
      "Saved the embedding for grouchy.\n",
      "growl is at index 1733\n",
      "Saved the embedding for growl.\n",
      "growling is at index 1733\n",
      "Saved the embedding for growling.\n",
      "grudge is at index 4435\n",
      "Saved the embedding for grudge.\n",
      "grudging is at index 4435\n",
      "Saved the embedding for grudging.\n",
      "gruff is at index 15551\n",
      "Saved the embedding for gruff.\n",
      "grumbling is at index 4435\n",
      "Saved the embedding for grumbling.\n",
      "grumpy is at index 4435\n",
      "Saved the embedding for grumpy.\n",
      "grunt is at index 44376\n",
      "Saved the embedding for grunt.\n",
      "grunting is at index 39204\n",
      "Saved the embedding for grunting.\n",
      "guarded is at index 25853\n",
      "Saved the embedding for guarded.\n",
      "guilty is at index 2181\n",
      "Saved the embedding for guilty.\n",
      "gulp is at index 821\n",
      "Saved the embedding for gulp.\n",
      "haggard is at index 1368\n",
      "Saved the embedding for haggard.\n",
      "halfhearted is at index 457\n",
      "Saved the embedding for halfhearted.\n",
      "halted is at index 12856\n",
      "Saved the embedding for halted.\n",
      "hapless is at index 2489\n",
      "Saved the embedding for hapless.\n",
      "happiness is at index 11098\n",
      "Saved the embedding for happiness.\n",
      "happy is at index 1372\n",
      "Saved the embedding for happy.\n",
      "harassed is at index 16835\n",
      "Saved the embedding for harassed.\n",
      "hard is at index 543\n",
      "Saved the embedding for hard.\n",
      "hardened is at index 33631\n",
      "Saved the embedding for hardened.\n",
      "harmful is at index 11190\n",
      "Saved the embedding for harmful.\n",
      "harried is at index 12280\n",
      "Saved the embedding for harried.\n",
      "harsh is at index 9776\n",
      "Saved the embedding for harsh.\n",
      "hate is at index 4157\n",
      "Saved the embedding for hate.\n",
      "hateful is at index 26393\n",
      "Saved the embedding for hateful.\n",
      "hating is at index 40873\n",
      "Saved the embedding for hating.\n",
      "hatred is at index 13453\n",
      "Saved the embedding for hatred.\n",
      "haughty is at index 2489\n",
      "Saved the embedding for haughty.\n",
      "haunted is at index 22717\n",
      "Saved the embedding for haunted.\n",
      "hazy is at index 2489\n",
      "Saved the embedding for hazy.\n",
      "headshake is at index 471\n",
      "Saved the embedding for headshake.\n",
      "heartache is at index 1144\n",
      "Saved the embedding for heartache.\n",
      "heartbroken is at index 1144\n",
      "Saved the embedding for heartbroken.\n",
      "hearted is at index 1144\n",
      "Saved the embedding for hearted.\n",
      "heartsick is at index 7754\n",
      "Saved the embedding for heartsick.\n",
      "heated is at index 10819\n",
      "Saved the embedding for heated.\n",
      "heavyhearted is at index 2016\n",
      "Saved the embedding for heavyhearted.\n",
      "heckle is at index 17835\n",
      "Saved the embedding for heckle.\n",
      "heedful is at index 25432\n",
      "Saved the embedding for heedful.\n",
      "heinous is at index 30091\n",
      "Saved the embedding for heinous.\n",
      "helpful is at index 7163\n",
      "Saved the embedding for helpful.\n",
      "helpless is at index 22445\n",
      "Saved the embedding for helpless.\n",
      "hesitant is at index 24668\n",
      "Saved the embedding for hesitant.\n",
      "hesitantly is at index 36279\n",
      "Saved the embedding for hesitantly.\n",
      "hesitating is at index 36279\n",
      "Saved the embedding for hesitating.\n",
      "hesitation is at index 28946\n",
      "Saved the embedding for hesitation.\n",
      "high is at index 239\n",
      "Saved the embedding for high.\n",
      "hollering is at index 1368\n",
      "Saved the embedding for hollering.\n",
      "homicidal is at index 9486\n",
      "Saved the embedding for homicidal.\n",
      "honest is at index 5322\n",
      "Saved the embedding for honest.\n",
      "honorable is at index 28537\n",
      "Saved the embedding for honorable.\n",
      "hope is at index 1034\n",
      "Saved the embedding for hope.\n",
      "hopeful is at index 7917\n",
      "Saved the embedding for hopeful.\n",
      "hopefulness is at index 7917\n",
      "Saved the embedding for hopefulness.\n",
      "hopeless is at index 24418\n",
      "Saved the embedding for hopeless.\n",
      "hoping is at index 2818\n",
      "Saved the embedding for hoping.\n",
      "horny is at index 46216\n",
      "Saved the embedding for horny.\n",
      "horrible is at index 11385\n",
      "Saved the embedding for horrible.\n",
      "horrified is at index 27807\n",
      "Saved the embedding for horrified.\n",
      "horrify is at index 48067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for horrify.\n",
      "horrifying is at index 28242\n",
      "Saved the embedding for horrifying.\n",
      "horror is at index 8444\n",
      "Saved the embedding for horror.\n",
      "hostile is at index 11928\n",
      "Saved the embedding for hostile.\n",
      "hostility is at index 22069\n",
      "Saved the embedding for hostility.\n",
      "hot is at index 2131\n",
      "Saved the embedding for hot.\n",
      "hotshot is at index 2131\n",
      "Saved the embedding for hotshot.\n",
      "huffiness is at index 1368\n",
      "Saved the embedding for huffiness.\n",
      "huffy is at index 1368\n",
      "Saved the embedding for huffy.\n",
      "humble is at index 14083\n",
      "Saved the embedding for humble.\n",
      "humbled is at index 10080\n",
      "Saved the embedding for humbled.\n",
      "humdrum is at index 10080\n",
      "Saved the embedding for humdrum.\n",
      "humiliated is at index 32386\n",
      "Saved the embedding for humiliated.\n",
      "humility is at index 27352\n",
      "Saved the embedding for humility.\n",
      "humming is at index 35774\n",
      "Saved the embedding for humming.\n",
      "humor is at index 12073\n",
      "Saved the embedding for humor.\n",
      "humored is at index 10080\n",
      "Saved the embedding for humored.\n",
      "humorous is at index 31214\n",
      "Saved the embedding for humorous.\n",
      "hunger is at index 12226\n",
      "Saved the embedding for hunger.\n",
      "hungry is at index 11130\n",
      "Saved the embedding for hungry.\n",
      "hunted is at index 32602\n",
      "Saved the embedding for hunted.\n",
      "hurt is at index 2581\n",
      "Saved the embedding for hurt.\n",
      "hurtful is at index 2581\n",
      "Saved the embedding for hurtful.\n",
      "hurting is at index 12780\n",
      "Saved the embedding for hurting.\n",
      "hush is at index 1368\n",
      "Saved the embedding for hush.\n",
      "hushed is at index 33476\n",
      "Saved the embedding for hushed.\n",
      "hyper is at index 8944\n",
      "Saved the embedding for hyper.\n",
      "hyperactive is at index 8944\n",
      "Saved the embedding for hyperactive.\n",
      "hypnotized is at index 39040\n",
      "Saved the embedding for hypnotized.\n",
      "hypocritical is at index 37769\n",
      "Saved the embedding for hypocritical.\n",
      "hysteria is at index 35099\n",
      "Saved the embedding for hysteria.\n",
      "hysterical is at index 38561\n",
      "Saved the embedding for hysterical.\n",
      "idiotic is at index 13561\n",
      "Saved the embedding for idiotic.\n",
      "ignorant is at index 27726\n",
      "Saved the embedding for ignorant.\n",
      "ignoring is at index 15515\n",
      "Saved the embedding for ignoring.\n",
      "ill is at index 4812\n",
      "Saved the embedding for ill.\n",
      "imaginative is at index 35026\n",
      "Saved the embedding for imaginative.\n",
      "immature is at index 39001\n",
      "Saved the embedding for immature.\n",
      "immersed is at index 31971\n",
      "Saved the embedding for immersed.\n",
      "impacted is at index 7284\n",
      "Saved the embedding for impacted.\n",
      "impartial is at index 24283\n",
      "Saved the embedding for impartial.\n",
      "impassioned is at index 4023\n",
      "Saved the embedding for impassioned.\n",
      "impassive is at index 4023\n",
      "Saved the embedding for impassive.\n",
      "impatience is at index 43635\n",
      "Saved the embedding for impatience.\n",
      "impatient is at index 32601\n",
      "Saved the embedding for impatient.\n",
      "imperious is at index 21245\n",
      "Saved the embedding for imperious.\n",
      "impersonal is at index 23153\n",
      "Saved the embedding for impersonal.\n",
      "impertinent is at index 21245\n",
      "Saved the embedding for impertinent.\n",
      "impish is at index 4023\n",
      "Saved the embedding for impish.\n",
      "implicated is at index 23316\n",
      "Saved the embedding for implicated.\n",
      "imploring is at index 12956\n",
      "Saved the embedding for imploring.\n",
      "important is at index 505\n",
      "Saved the embedding for important.\n",
      "impressed is at index 6889\n",
      "Saved the embedding for impressed.\n",
      "impulsive is at index 4023\n",
      "Saved the embedding for impulsive.\n",
      "inactive is at index 25986\n",
      "Saved the embedding for inactive.\n",
      "inadequate is at index 15650\n",
      "Saved the embedding for inadequate.\n",
      "inarticulate is at index 11\n",
      "Saved the embedding for inarticulate.\n",
      "inattentive is at index 11\n",
      "Saved the embedding for inattentive.\n",
      "inaudible is at index 11\n",
      "Saved the embedding for inaudible.\n",
      "inauthentic is at index 11\n",
      "Saved the embedding for inauthentic.\n",
      "incapable is at index 30256\n",
      "Saved the embedding for incapable.\n",
      "incensed is at index 5853\n",
      "Saved the embedding for incensed.\n",
      "incertain is at index 5853\n",
      "Saved the embedding for incertain.\n",
      "incertitude is at index 5853\n",
      "Saved the embedding for incertitude.\n",
      "incited is at index 5853\n",
      "Saved the embedding for incited.\n",
      "incomprehensible is at index 42494\n",
      "Saved the embedding for incomprehensible.\n",
      "inconspicuous is at index 40817\n",
      "Saved the embedding for inconspicuous.\n",
      "incredulity is at index 38366\n",
      "Saved the embedding for incredulity.\n",
      "incredulous is at index 38366\n",
      "Saved the embedding for incredulous.\n",
      "incredulously is at index 38366\n",
      "Saved the embedding for incredulously.\n",
      "inculpate is at index 5853\n",
      "Saved the embedding for inculpate.\n",
      "incurious is at index 5853\n",
      "Saved the embedding for incurious.\n",
      "indecipherable is at index 32227\n",
      "Saved the embedding for indecipherable.\n",
      "indecision is at index 32227\n",
      "Saved the embedding for indecision.\n",
      "indecisive is at index 32227\n",
      "Saved the embedding for indecisive.\n",
      "indifferent is at index 34657\n",
      "Saved the embedding for indifferent.\n",
      "indifferently is at index 34657\n",
      "Saved the embedding for indifferently.\n",
      "indignant is at index 9473\n",
      "Saved the embedding for indignant.\n",
      "indolent is at index 9473\n",
      "Saved the embedding for indolent.\n",
      "inebriated is at index 11\n",
      "Saved the embedding for inebriated.\n",
      "inert is at index 43783\n",
      "Saved the embedding for inert.\n",
      "infatuating is at index 4047\n",
      "Saved the embedding for infatuating.\n",
      "inferior is at index 28510\n",
      "Saved the embedding for inferior.\n",
      "inferiority is at index 28510\n",
      "Saved the embedding for inferiority.\n",
      "inflamed is at index 11411\n",
      "Saved the embedding for inflamed.\n",
      "informal is at index 14110\n",
      "Saved the embedding for informal.\n",
      "informing is at index 21835\n",
      "Saved the embedding for informing.\n",
      "infuriated is at index 26974\n",
      "Saved the embedding for infuriated.\n",
      "inhibited is at index 45427\n",
      "Saved the embedding for inhibited.\n",
      "inhibiting is at index 38512\n",
      "Saved the embedding for inhibiting.\n",
      "inimical is at index 11\n",
      "Saved the embedding for inimical.\n",
      "injured is at index 1710\n",
      "Saved the embedding for injured.\n",
      "innocent is at index 7850\n",
      "Saved the embedding for innocent.\n",
      "inpatient is at index 11\n",
      "Saved the embedding for inpatient.\n",
      "inquiring is at index 27874\n",
      "Saved the embedding for inquiring.\n",
      "inquisitive is at index 27874\n",
      "Saved the embedding for inquisitive.\n",
      "insane is at index 18544\n",
      "Saved the embedding for insane.\n",
      "inscrutable is at index 7540\n",
      "Saved the embedding for inscrutable.\n",
      "insecure is at index 27810\n",
      "Saved the embedding for insecure.\n",
      "insecurity is at index 19401\n",
      "Saved the embedding for insecurity.\n",
      "insensitive is at index 29401\n",
      "Saved the embedding for insensitive.\n",
      "insidious is at index 40012\n",
      "Saved the embedding for insidious.\n",
      "insinuating is at index 32016\n",
      "Saved the embedding for insinuating.\n",
      "insistence is at index 24974\n",
      "Saved the embedding for insistence.\n",
      "insistent is at index 7540\n",
      "Saved the embedding for insistent.\n",
      "insisting is at index 13875\n",
      "Saved the embedding for insisting.\n",
      "insolent is at index 23799\n",
      "Saved the embedding for insolent.\n",
      "insouciance is at index 7540\n",
      "Saved the embedding for insouciance.\n",
      "insouciant is at index 7540\n",
      "Saved the embedding for insouciant.\n",
      "inspired is at index 4083\n",
      "Saved the embedding for inspired.\n",
      "inspiring is at index 11653\n",
      "Saved the embedding for inspiring.\n",
      "instigating is at index 9084\n",
      "Saved the embedding for instigating.\n",
      "instructing is at index 20587\n",
      "Saved the embedding for instructing.\n",
      "insubordinate is at index 7540\n",
      "Saved the embedding for insubordinate.\n",
      "insular is at index 7540\n",
      "Saved the embedding for insular.\n",
      "insulted is at index 32149\n",
      "Saved the embedding for insulted.\n",
      "insulting is at index 22602\n",
      "Saved the embedding for insulting.\n",
      "intelligence is at index 2316\n",
      "Saved the embedding for intelligence.\n",
      "intense is at index 5676\n",
      "Saved the embedding for intense.\n",
      "intensely is at index 29727\n",
      "Saved the embedding for intensely.\n",
      "intensity is at index 10603\n",
      "Saved the embedding for intensity.\n",
      "intensive is at index 12296\n",
      "Saved the embedding for intensive.\n",
      "intent is at index 5927\n",
      "Saved the embedding for intent.\n",
      "intentional is at index 18797\n",
      "Saved the embedding for intentional.\n",
      "interacting is at index 23140\n",
      "Saved the embedding for interacting.\n",
      "interest is at index 773\n",
      "Saved the embedding for interest.\n",
      "interested is at index 2509\n",
      "Saved the embedding for interested.\n",
      "interjecting is at index 3222\n",
      "Saved the embedding for interjecting.\n",
      "internalizing is at index 3425\n",
      "Saved the embedding for internalizing.\n",
      "interrogating is at index 28592\n",
      "Saved the embedding for interrogating.\n",
      "interrupting is at index 22749\n",
      "Saved the embedding for interrupting.\n",
      "intimidated is at index 25443\n",
      "Saved the embedding for intimidated.\n",
      "intimidating is at index 23292\n",
      "Saved the embedding for intimidating.\n",
      "intolerant is at index 39348\n",
      "Saved the embedding for intolerant.\n",
      "intoxicated is at index 20600\n",
      "Saved the embedding for intoxicated.\n",
      "intrigue is at index 30368\n",
      "Saved the embedding for intrigue.\n",
      "intrigued is at index 28622\n",
      "Saved the embedding for intrigued.\n",
      "intriguing is at index 14816\n",
      "Saved the embedding for intriguing.\n",
      "introspective is at index 22845\n",
      "Saved the embedding for introspective.\n",
      "invested is at index 5221\n",
      "Saved the embedding for invested.\n",
      "investigate is at index 4830\n",
      "Saved the embedding for investigate.\n",
      "investigative is at index 13222\n",
      "Saved the embedding for investigative.\n",
      "investigatory is at index 25463\n",
      "Saved the embedding for investigatory.\n",
      "invigorated is at index 12259\n",
      "Saved the embedding for invigorated.\n",
      "involved is at index 963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for involved.\n",
      "irascible is at index 10209\n",
      "Saved the embedding for irascible.\n",
      "irate is at index 10209\n",
      "Saved the embedding for irate.\n",
      "ire is at index 25509\n",
      "Saved the embedding for ire.\n",
      "ireful is at index 25509\n",
      "Saved the embedding for ireful.\n",
      "irked is at index 10209\n",
      "Saved the embedding for irked.\n",
      "ironic is at index 25553\n",
      "Saved the embedding for ironic.\n",
      "irony is at index 21490\n",
      "Saved the embedding for irony.\n",
      "irresolute is at index 10209\n",
      "Saved the embedding for irresolute.\n",
      "irritable is at index 26570\n",
      "Saved the embedding for irritable.\n",
      "irritably is at index 26570\n",
      "Saved the embedding for irritably.\n",
      "irritated is at index 35270\n",
      "Saved the embedding for irritated.\n",
      "irritation is at index 32776\n",
      "Saved the embedding for irritation.\n",
      "isolated is at index 8067\n",
      "Saved the embedding for isolated.\n",
      "jabbed is at index 27916\n",
      "Saved the embedding for jabbed.\n",
      "jaded is at index 1236\n",
      "Saved the embedding for jaded.\n",
      "jarred is at index 25413\n",
      "Saved the embedding for jarred.\n",
      "jarring is at index 35659\n",
      "Saved the embedding for jarring.\n",
      "jaunty is at index 1236\n",
      "Saved the embedding for jaunty.\n",
      "jawed is at index 15345\n",
      "Saved the embedding for jawed.\n",
      "jealous is at index 27064\n",
      "Saved the embedding for jealous.\n",
      "jeering is at index 4112\n",
      "Saved the embedding for jeering.\n",
      "jesting is at index 1236\n",
      "Saved the embedding for jesting.\n",
      "jilted is at index 1236\n",
      "Saved the embedding for jilted.\n",
      "jittery is at index 1236\n",
      "Saved the embedding for jittery.\n",
      "jocular is at index 1236\n",
      "Saved the embedding for jocular.\n",
      "joking is at index 22024\n",
      "Saved the embedding for joking.\n",
      "jolly is at index 1236\n",
      "Saved the embedding for jolly.\n",
      "jolted is at index 1236\n",
      "Saved the embedding for jolted.\n",
      "jovial is at index 1236\n",
      "Saved the embedding for jovial.\n",
      "joy is at index 5823\n",
      "Saved the embedding for joy.\n",
      "joyful is at index 32076\n",
      "Saved the embedding for joyful.\n",
      "joyfulness is at index 5823\n",
      "Saved the embedding for joyfulness.\n",
      "joyless is at index 5823\n",
      "Saved the embedding for joyless.\n",
      "joyous is at index 5823\n",
      "Saved the embedding for joyous.\n",
      "jubilant is at index 1236\n",
      "Saved the embedding for jubilant.\n",
      "jubilation is at index 1236\n",
      "Saved the embedding for jubilation.\n",
      "judgemental is at index 17219\n",
      "Saved the embedding for judgemental.\n",
      "judging is at index 17298\n",
      "Saved the embedding for judging.\n",
      "judgmental is at index 7579\n",
      "Saved the embedding for judgmental.\n",
      "judicious is at index 21392\n",
      "Saved the embedding for judicious.\n",
      "jumpy is at index 3704\n",
      "Saved the embedding for jumpy.\n",
      "justified is at index 14267\n",
      "Saved the embedding for justified.\n",
      "keen is at index 5609\n",
      "Saved the embedding for keen.\n",
      "kind is at index 761\n",
      "Saved the embedding for kind.\n",
      "kindhearted is at index 761\n",
      "Saved the embedding for kindhearted.\n",
      "kiss is at index 13301\n",
      "Saved the embedding for kiss.\n",
      "knowing is at index 4730\n",
      "Saved the embedding for knowing.\n",
      "knowledgable is at index 216\n",
      "Saved the embedding for knowledgable.\n",
      "knowledgeable is at index 26782\n",
      "Saved the embedding for knowledgeable.\n",
      "kosher is at index 36930\n",
      "Saved the embedding for kosher.\n",
      "lackadaisical is at index 1762\n",
      "Saved the embedding for lackadaisical.\n",
      "lackluster is at index 28369\n",
      "Saved the embedding for lackluster.\n",
      "laconic is at index 784\n",
      "Saved the embedding for laconic.\n",
      "lambaste is at index 17988\n",
      "Saved the embedding for lambaste.\n",
      "lamentable is at index 25532\n",
      "Saved the embedding for lamentable.\n",
      "lamenting is at index 25532\n",
      "Saved the embedding for lamenting.\n",
      "lascivious is at index 784\n",
      "Saved the embedding for lascivious.\n",
      "laugh is at index 7923\n",
      "Saved the embedding for laugh.\n",
      "laughing is at index 11339\n",
      "Saved the embedding for laughing.\n",
      "laughter is at index 16805\n",
      "Saved the embedding for laughter.\n",
      "lazy is at index 22414\n",
      "Saved the embedding for lazy.\n",
      "leaving is at index 1618\n",
      "Saved the embedding for leaving.\n",
      "lecherous is at index 2084\n",
      "Saved the embedding for lecherous.\n",
      "lecturing is at index 25673\n",
      "Saved the embedding for lecturing.\n",
      "leering is at index 2084\n",
      "Saved the embedding for leering.\n",
      "leery is at index 2084\n",
      "Saved the embedding for leery.\n",
      "letdown is at index 905\n",
      "Saved the embedding for letdown.\n",
      "lethargic is at index 35370\n",
      "Saved the embedding for lethargic.\n",
      "levelheaded is at index 672\n",
      "Saved the embedding for levelheaded.\n",
      "lewd is at index 31942\n",
      "Saved the embedding for lewd.\n",
      "libidinous is at index 21748\n",
      "Saved the embedding for libidinous.\n",
      "lifeless is at index 37019\n",
      "Saved the embedding for lifeless.\n",
      "lighthearted is at index 1109\n",
      "Saved the embedding for lighthearted.\n",
      "lipped is at index 784\n",
      "Saved the embedding for lipped.\n",
      "listening is at index 6288\n",
      "Saved the embedding for listening.\n",
      "listless is at index 889\n",
      "Saved the embedding for listless.\n",
      "lively is at index 20902\n",
      "Saved the embedding for lively.\n",
      "livid is at index 784\n",
      "Saved the embedding for livid.\n",
      "loaded is at index 7973\n",
      "Saved the embedding for loaded.\n",
      "loath is at index 4600\n",
      "Saved the embedding for loath.\n",
      "loathe is at index 4600\n",
      "Saved the embedding for loathe.\n",
      "loathing is at index 4600\n",
      "Saved the embedding for loathing.\n",
      "loathsome is at index 4600\n",
      "Saved the embedding for loathsome.\n",
      "locked is at index 5930\n",
      "Saved the embedding for locked.\n",
      "loneliness is at index 27942\n",
      "Saved the embedding for loneliness.\n",
      "lonely is at index 20100\n",
      "Saved the embedding for lonely.\n",
      "longing is at index 36171\n",
      "Saved the embedding for longing.\n",
      "looking is at index 546\n",
      "Saved the embedding for looking.\n",
      "loony is at index 4600\n",
      "Saved the embedding for loony.\n",
      "loss is at index 872\n",
      "Saved the embedding for loss.\n",
      "lost is at index 685\n",
      "Saved the embedding for lost.\n",
      "loud is at index 7337\n",
      "Saved the embedding for loud.\n",
      "lousy is at index 38909\n",
      "Saved the embedding for lousy.\n",
      "love is at index 657\n",
      "Saved the embedding for love.\n",
      "loving is at index 8520\n",
      "Saved the embedding for loving.\n",
      "lowliness is at index 614\n",
      "Saved the embedding for lowliness.\n",
      "lurid is at index 30461\n",
      "Saved the embedding for lurid.\n",
      "lustful is at index 30864\n",
      "Saved the embedding for lustful.\n",
      "lusting is at index 30864\n",
      "Saved the embedding for lusting.\n",
      "lusty is at index 30864\n",
      "Saved the embedding for lusty.\n",
      "lying is at index 6480\n",
      "Saved the embedding for lying.\n",
      "mad is at index 7758\n",
      "Saved the embedding for mad.\n",
      "maddened is at index 475\n",
      "Saved the embedding for maddened.\n",
      "madness is at index 24714\n",
      "Saved the embedding for madness.\n",
      "malcontent is at index 8196\n",
      "Saved the embedding for malcontent.\n",
      "maleficent is at index 8196\n",
      "Saved the embedding for maleficent.\n",
      "malevolent is at index 2943\n",
      "Saved the embedding for malevolent.\n",
      "malice is at index 39625\n",
      "Saved the embedding for malice.\n",
      "malicious is at index 15237\n",
      "Saved the embedding for malicious.\n",
      "malignant is at index 8196\n",
      "Saved the embedding for malignant.\n",
      "maniacal is at index 41288\n",
      "Saved the embedding for maniacal.\n",
      "manipulative is at index 39802\n",
      "Saved the embedding for manipulative.\n",
      "marveled is at index 25591\n",
      "Saved the embedding for marveled.\n",
      "master is at index 4710\n",
      "Saved the embedding for master.\n",
      "mean is at index 1266\n",
      "Saved the embedding for mean.\n",
      "meaningful is at index 6667\n",
      "Saved the embedding for meaningful.\n",
      "meditative is at index 5679\n",
      "Saved the embedding for meditative.\n",
      "meek is at index 162\n",
      "Saved the embedding for meek.\n",
      "melancholic is at index 45565\n",
      "Saved the embedding for melancholic.\n",
      "melancholy is at index 40602\n",
      "Saved the embedding for melancholy.\n",
      "mellow is at index 34384\n",
      "Saved the embedding for mellow.\n",
      "menace is at index 24213\n",
      "Saved the embedding for menace.\n",
      "menacing is at index 32002\n",
      "Saved the embedding for menacing.\n",
      "mental is at index 2536\n",
      "Saved the embedding for mental.\n",
      "merrily is at index 9374\n",
      "Saved the embedding for merrily.\n",
      "merry is at index 35814\n",
      "Saved the embedding for merry.\n",
      "mesmerized is at index 31294\n",
      "Saved the embedding for mesmerized.\n",
      "miffed is at index 475\n",
      "Saved the embedding for miffed.\n",
      "mild is at index 10439\n",
      "Saved the embedding for mild.\n",
      "mincing is at index 5251\n",
      "Saved the embedding for mincing.\n",
      "mindful is at index 20807\n",
      "Saved the embedding for mindful.\n",
      "mindless is at index 41406\n",
      "Saved the embedding for mindless.\n",
      "mirrored is at index 31349\n",
      "Saved the embedding for mirrored.\n",
      "mirth is at index 475\n",
      "Saved the embedding for mirth.\n",
      "mirthful is at index 475\n",
      "Saved the embedding for mirthful.\n",
      "misanthropic is at index 3834\n",
      "Saved the embedding for misanthropic.\n",
      "mischief is at index 26245\n",
      "Saved the embedding for mischief.\n",
      "mischievous is at index 3834\n",
      "Saved the embedding for mischievous.\n",
      "mischievousness is at index 3834\n",
      "Saved the embedding for mischievousness.\n",
      "miserable is at index 20161\n",
      "Saved the embedding for miserable.\n",
      "misery is at index 23110\n",
      "Saved the embedding for misery.\n",
      "misgiving is at index 3834\n",
      "Saved the embedding for misgiving.\n",
      "mislead is at index 34747\n",
      "Saved the embedding for mislead.\n",
      "mistrust is at index 34873\n",
      "Saved the embedding for mistrust.\n",
      "mistrustful is at index 34873\n",
      "Saved the embedding for mistrustful.\n",
      "mistrusting is at index 34873\n",
      "Saved the embedding for mistrusting.\n",
      "misunderstood is at index 32085\n",
      "Saved the embedding for misunderstood.\n",
      "mockery is at index 34641\n",
      "Saved the embedding for mockery.\n",
      "mocking is at index 27813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for mocking.\n",
      "mockingly is at index 16177\n",
      "Saved the embedding for mockingly.\n",
      "modest is at index 6473\n",
      "Saved the embedding for modest.\n",
      "monotone is at index 6154\n",
      "Saved the embedding for monotone.\n",
      "monster is at index 13317\n",
      "Saved the embedding for monster.\n",
      "moody is at index 6711\n",
      "Saved the embedding for moody.\n",
      "mopey is at index 475\n",
      "Saved the embedding for mopey.\n",
      "morose is at index 14628\n",
      "Saved the embedding for morose.\n",
      "mortified is at index 18631\n",
      "Saved the embedding for mortified.\n",
      "motivated is at index 7958\n",
      "Saved the embedding for motivated.\n",
      "mournful is at index 15213\n",
      "Saved the embedding for mournful.\n",
      "mournfulness is at index 15213\n",
      "Saved the embedding for mournfulness.\n",
      "mourning is at index 19293\n",
      "Saved the embedding for mourning.\n",
      "mouthed is at index 475\n",
      "Saved the embedding for mouthed.\n",
      "moved is at index 1410\n",
      "Saved the embedding for moved.\n",
      "muddled is at index 475\n",
      "Saved the embedding for muddled.\n",
      "mum is at index 8562\n",
      "Saved the embedding for mum.\n",
      "murderous is at index 32883\n",
      "Saved the embedding for murderous.\n",
      "musical is at index 4388\n",
      "Saved the embedding for musical.\n",
      "musing is at index 11721\n",
      "Saved the embedding for musing.\n",
      "muster is at index 27665\n",
      "Saved the embedding for muster.\n",
      "mute is at index 33758\n",
      "Saved the embedding for mute.\n",
      "muted is at index 21677\n",
      "Saved the embedding for muted.\n",
      "muttering is at index 16119\n",
      "Saved the embedding for muttering.\n",
      "mysterious is at index 12754\n",
      "Saved the embedding for mysterious.\n",
      "mystical is at index 39795\n",
      "Saved the embedding for mystical.\n",
      "mystified is at index 37763\n",
      "Saved the embedding for mystified.\n",
      "naive is at index 25672\n",
      "Saved the embedding for naive.\n",
      "napping is at index 295\n",
      "Saved the embedding for napping.\n",
      "narrow is at index 6787\n",
      "Saved the embedding for narrow.\n",
      "nasty is at index 15455\n",
      "Saved the embedding for nasty.\n",
      "natural is at index 1632\n",
      "Saved the embedding for natural.\n",
      "natured is at index 23577\n",
      "Saved the embedding for natured.\n",
      "naughty is at index 38384\n",
      "Saved the embedding for naughty.\n",
      "nausea is at index 27214\n",
      "Saved the embedding for nausea.\n",
      "nauseated is at index 39117\n",
      "Saved the embedding for nauseated.\n",
      "nauseous is at index 39117\n",
      "Saved the embedding for nauseous.\n",
      "needy is at index 28166\n",
      "Saved the embedding for needy.\n",
      "nefarious is at index 33952\n",
      "Saved the embedding for nefarious.\n",
      "negating is at index 15183\n",
      "Saved the embedding for negating.\n",
      "negative is at index 2430\n",
      "Saved the embedding for negative.\n",
      "negativity is at index 30269\n",
      "Saved the embedding for negativity.\n",
      "neglected is at index 20428\n",
      "Saved the embedding for neglected.\n",
      "nerdy is at index 38286\n",
      "Saved the embedding for nerdy.\n",
      "nerved is at index 295\n",
      "Saved the embedding for nerved.\n",
      "nerves is at index 17358\n",
      "Saved the embedding for nerves.\n",
      "nervous is at index 7464\n",
      "Saved the embedding for nervous.\n",
      "nervously is at index 40968\n",
      "Saved the embedding for nervously.\n",
      "nervousness is at index 7464\n",
      "Saved the embedding for nervousness.\n",
      "nescient is at index 295\n",
      "Saved the embedding for nescient.\n",
      "nettled is at index 1161\n",
      "Saved the embedding for nettled.\n",
      "neutral is at index 7974\n",
      "Saved the embedding for neutral.\n",
      "neutrality is at index 18755\n",
      "Saved the embedding for neutrality.\n",
      "nice is at index 2579\n",
      "Saved the embedding for nice.\n",
      "noisy is at index 28269\n",
      "Saved the embedding for noisy.\n",
      "nonbelief is at index 786\n",
      "Saved the embedding for nonbelief.\n",
      "nonchalance is at index 786\n",
      "Saved the embedding for nonchalance.\n",
      "nonchalant is at index 786\n",
      "Saved the embedding for nonchalant.\n",
      "noncommittal is at index 786\n",
      "Saved the embedding for noncommittal.\n",
      "noncompliant is at index 786\n",
      "Saved the embedding for noncompliant.\n",
      "nonplussed is at index 786\n",
      "Saved the embedding for nonplussed.\n",
      "nonsensical is at index 42475\n",
      "Saved the embedding for nonsensical.\n",
      "normal is at index 2340\n",
      "Saved the embedding for normal.\n",
      "nosey is at index 8658\n",
      "Saved the embedding for nosey.\n",
      "nostalgic is at index 28055\n",
      "Saved the embedding for nostalgic.\n",
      "nosy is at index 13736\n",
      "Saved the embedding for nosy.\n",
      "numb is at index 31086\n",
      "Saved the embedding for numb.\n",
      "obedient is at index 44729\n",
      "Saved the embedding for obedient.\n",
      "objecting is at index 7626\n",
      "Saved the embedding for objecting.\n",
      "objection is at index 24763\n",
      "Saved the embedding for objection.\n",
      "objective is at index 4554\n",
      "Saved the embedding for objective.\n",
      "obliged is at index 23964\n",
      "Saved the embedding for obliged.\n",
      "obliging is at index 23762\n",
      "Saved the embedding for obliging.\n",
      "oblivious is at index 35606\n",
      "Saved the embedding for oblivious.\n",
      "observant is at index 20717\n",
      "Saved the embedding for observant.\n",
      "observing is at index 21981\n",
      "Saved the embedding for observing.\n",
      "obsessed is at index 17593\n",
      "Saved the embedding for obsessed.\n",
      "obstinate is at index 30896\n",
      "Saved the embedding for obstinate.\n",
      "occupied is at index 9533\n",
      "Saved the embedding for occupied.\n",
      "odd is at index 8372\n",
      "Saved the embedding for odd.\n",
      "odious is at index 7452\n",
      "Saved the embedding for odious.\n",
      "off is at index 160\n",
      "Saved the embedding for off.\n",
      "offended is at index 22169\n",
      "Saved the embedding for offended.\n",
      "offensive is at index 2555\n",
      "Saved the embedding for offensive.\n",
      "ogling is at index 1021\n",
      "Saved the embedding for ogling.\n",
      "okay is at index 8578\n",
      "Saved the embedding for okay.\n",
      "on is at index 15\n",
      "Saved the embedding for on.\n",
      "open is at index 490\n",
      "Saved the embedding for open.\n",
      "openness is at index 23163\n",
      "Saved the embedding for openness.\n",
      "opposed is at index 4340\n",
      "Saved the embedding for opposed.\n",
      "oppositional is at index 39734\n",
      "Saved the embedding for oppositional.\n",
      "oppressed is at index 32881\n",
      "Saved the embedding for oppressed.\n",
      "optimism is at index 9743\n",
      "Saved the embedding for optimism.\n",
      "optimistic is at index 7168\n",
      "Saved the embedding for optimistic.\n",
      "ordering is at index 12926\n",
      "Saved the embedding for ordering.\n",
      "orgasmic is at index 39396\n",
      "Saved the embedding for orgasmic.\n",
      "ornery is at index 50\n",
      "Saved the embedding for ornery.\n",
      "ouch is at index 1021\n",
      "Saved the embedding for ouch.\n",
      "out is at index 66\n",
      "Saved the embedding for out.\n",
      "outburst is at index 28999\n",
      "Saved the embedding for outburst.\n",
      "outcry is at index 19900\n",
      "Saved the embedding for outcry.\n",
      "outed is at index 66\n",
      "Saved the embedding for outed.\n",
      "outlandish is at index 35785\n",
      "Saved the embedding for outlandish.\n",
      "outrage is at index 10618\n",
      "Saved the embedding for outrage.\n",
      "outraged is at index 22339\n",
      "Saved the embedding for outraged.\n",
      "outspoken is at index 16120\n",
      "Saved the embedding for outspoken.\n",
      "overbearing is at index 81\n",
      "Saved the embedding for overbearing.\n",
      "overexcited is at index 39919\n",
      "Saved the embedding for overexcited.\n",
      "overjoyed is at index 81\n",
      "Saved the embedding for overjoyed.\n",
      "overshadowed is at index 22140\n",
      "Saved the embedding for overshadowed.\n",
      "overstrung is at index 81\n",
      "Saved the embedding for overstrung.\n",
      "overwhelmed is at index 13203\n",
      "Saved the embedding for overwhelmed.\n",
      "overworked is at index 81\n",
      "Saved the embedding for overworked.\n",
      "overwrought is at index 42674\n",
      "Saved the embedding for overwrought.\n",
      "pain is at index 2400\n",
      "Saved the embedding for pain.\n",
      "pained is at index 181\n",
      "Saved the embedding for pained.\n",
      "painful is at index 8661\n",
      "Saved the embedding for painful.\n",
      "painfully is at index 32020\n",
      "Saved the embedding for painfully.\n",
      "panic is at index 9810\n",
      "Saved the embedding for panic.\n",
      "panicked is at index 28604\n",
      "Saved the embedding for panicked.\n",
      "panicky is at index 5730\n",
      "Saved the embedding for panicky.\n",
      "paralyzed is at index 28582\n",
      "Saved the embedding for paralyzed.\n",
      "paranoid is at index 33554\n",
      "Saved the embedding for paranoid.\n",
      "passionate is at index 8840\n",
      "Saved the embedding for passionate.\n",
      "passive is at index 18718\n",
      "Saved the embedding for passive.\n",
      "patience is at index 11383\n",
      "Saved the embedding for patience.\n",
      "patient is at index 3186\n",
      "Saved the embedding for patient.\n",
      "patronizing is at index 18528\n",
      "Saved the embedding for patronizing.\n",
      "pause is at index 13787\n",
      "Saved the embedding for pause.\n",
      "pausing is at index 6044\n",
      "Saved the embedding for pausing.\n",
      "peaceful is at index 7053\n",
      "Saved the embedding for peaceful.\n",
      "peculiar is at index 28178\n",
      "Saved the embedding for peculiar.\n",
      "peering is at index 3723\n",
      "Saved the embedding for peering.\n",
      "peeved is at index 32734\n",
      "Saved the embedding for peeved.\n",
      "peevish is at index 3723\n",
      "Saved the embedding for peevish.\n",
      "pensive is at index 181\n",
      "Saved the embedding for pensive.\n",
      "peppy is at index 3723\n",
      "Saved the embedding for peppy.\n",
      "perceptive is at index 228\n",
      "Saved the embedding for perceptive.\n",
      "perfidious is at index 32168\n",
      "Saved the embedding for perfidious.\n",
      "perky is at index 228\n",
      "Saved the embedding for perky.\n",
      "perplexed is at index 33708\n",
      "Saved the embedding for perplexed.\n",
      "perplexing is at index 33708\n",
      "Saved the embedding for perplexing.\n",
      "persistent is at index 13109\n",
      "Saved the embedding for persistent.\n",
      "personable is at index 621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for personable.\n",
      "perturbed is at index 32819\n",
      "Saved the embedding for perturbed.\n",
      "perverse is at index 41271\n",
      "Saved the embedding for perverse.\n",
      "pesky is at index 38432\n",
      "Saved the embedding for pesky.\n",
      "pessimism is at index 36494\n",
      "Saved the embedding for pessimism.\n",
      "pessimistic is at index 32415\n",
      "Saved the embedding for pessimistic.\n",
      "pestered is at index 19024\n",
      "Saved the embedding for pestered.\n",
      "petitioning is at index 5265\n",
      "Saved the embedding for petitioning.\n",
      "petrified is at index 4716\n",
      "Saved the embedding for petrified.\n",
      "petty is at index 25070\n",
      "Saved the embedding for petty.\n",
      "petulant is at index 4716\n",
      "Saved the embedding for petulant.\n",
      "picked is at index 2738\n",
      "Saved the embedding for picked.\n",
      "piercing is at index 38105\n",
      "Saved the embedding for piercing.\n",
      "pinched is at index 7756\n",
      "Saved the embedding for pinched.\n",
      "pious is at index 44843\n",
      "Saved the embedding for pious.\n",
      "piqued is at index 181\n",
      "Saved the embedding for piqued.\n",
      "pissed is at index 34449\n",
      "Saved the embedding for pissed.\n",
      "pitiable is at index 8516\n",
      "Saved the embedding for pitiable.\n",
      "pitiful is at index 8516\n",
      "Saved the embedding for pitiful.\n",
      "pity is at index 31373\n",
      "Saved the embedding for pity.\n",
      "pitying is at index 31373\n",
      "Saved the embedding for pitying.\n",
      "placated is at index 15155\n",
      "Saved the embedding for placated.\n",
      "placation is at index 15155\n",
      "Saved the embedding for placation.\n",
      "placid is at index 15155\n",
      "Saved the embedding for placid.\n",
      "plain is at index 10798\n",
      "Saved the embedding for plain.\n",
      "plaintive is at index 46560\n",
      "Saved the embedding for plaintive.\n",
      "planning is at index 1884\n",
      "Saved the embedding for planning.\n",
      "playful is at index 23317\n",
      "Saved the embedding for playful.\n",
      "playfully is at index 310\n",
      "Saved the embedding for playfully.\n",
      "pleading is at index 17532\n",
      "Saved the embedding for pleading.\n",
      "pleasant is at index 16219\n",
      "Saved the embedding for pleasant.\n",
      "pleased is at index 4343\n",
      "Saved the embedding for pleased.\n",
      "pleasing is at index 25234\n",
      "Saved the embedding for pleasing.\n",
      "pleasurable is at index 19518\n",
      "Saved the embedding for pleasurable.\n",
      "pleasure is at index 10483\n",
      "Saved the embedding for pleasure.\n",
      "pleasured is at index 19518\n",
      "Saved the embedding for pleasured.\n",
      "pliant is at index 2968\n",
      "Saved the embedding for pliant.\n",
      "plotting is at index 22849\n",
      "Saved the embedding for plotting.\n",
      "poignant is at index 27274\n",
      "Saved the embedding for poignant.\n",
      "pointed is at index 3273\n",
      "Saved the embedding for pointed.\n",
      "poised is at index 10137\n",
      "Saved the embedding for poised.\n",
      "polite is at index 24908\n",
      "Saved the embedding for polite.\n",
      "pompous is at index 34415\n",
      "Saved the embedding for pompous.\n",
      "ponder is at index 31930\n",
      "Saved the embedding for ponder.\n",
      "pondering is at index 13362\n",
      "Saved the embedding for pondering.\n",
      "pooping is at index 4202\n",
      "Saved the embedding for pooping.\n",
      "pop is at index 3495\n",
      "Saved the embedding for pop.\n",
      "posing is at index 12681\n",
      "Saved the embedding for posing.\n",
      "positive is at index 1313\n",
      "Saved the embedding for positive.\n",
      "positivity is at index 8593\n",
      "Saved the embedding for positivity.\n",
      "possibly is at index 3544\n",
      "Saved the embedding for possibly.\n",
      "pout is at index 181\n",
      "Saved the embedding for pout.\n",
      "pouting is at index 181\n",
      "Saved the embedding for pouting.\n",
      "pouty is at index 181\n",
      "Saved the embedding for pouty.\n",
      "powerful is at index 2247\n",
      "Saved the embedding for powerful.\n",
      "powerless is at index 33128\n",
      "Saved the embedding for powerless.\n",
      "pranking is at index 3349\n",
      "Saved the embedding for pranking.\n",
      "precarious is at index 27180\n",
      "Saved the embedding for precarious.\n",
      "predatory is at index 29216\n",
      "Saved the embedding for predatory.\n",
      "prejudiced is at index 34286\n",
      "Saved the embedding for prejudiced.\n",
      "preoccupied is at index 1198\n",
      "Saved the embedding for preoccupied.\n",
      "prepared is at index 2460\n",
      "Saved the embedding for prepared.\n",
      "preparing is at index 4568\n",
      "Saved the embedding for preparing.\n",
      "pretending is at index 23748\n",
      "Saved the embedding for pretending.\n",
      "pretentious is at index 11857\n",
      "Saved the embedding for pretentious.\n",
      "prideful is at index 7040\n",
      "Saved the embedding for prideful.\n",
      "priggish is at index 3349\n",
      "Saved the embedding for priggish.\n",
      "primed is at index 32575\n",
      "Saved the embedding for primed.\n",
      "private is at index 940\n",
      "Saved the embedding for private.\n",
      "processing is at index 5774\n",
      "Saved the embedding for processing.\n",
      "propositioning is at index 16104\n",
      "Saved the embedding for propositioning.\n",
      "proud is at index 2602\n",
      "Saved the embedding for proud.\n",
      "provocative is at index 21051\n",
      "Saved the embedding for provocative.\n",
      "provoke is at index 28184\n",
      "Saved the embedding for provoke.\n",
      "provoked is at index 24972\n",
      "Saved the embedding for provoked.\n",
      "provoking is at index 35359\n",
      "Saved the embedding for provoking.\n",
      "prying is at index 181\n",
      "Saved the embedding for prying.\n",
      "psycho is at index 37338\n",
      "Saved the embedding for psycho.\n",
      "psychotic is at index 41559\n",
      "Saved the embedding for psychotic.\n",
      "puckish is at index 9258\n",
      "Saved the embedding for puckish.\n",
      "puerile is at index 181\n",
      "Saved the embedding for puerile.\n",
      "pugnacious is at index 181\n",
      "Saved the embedding for pugnacious.\n",
      "punished is at index 14459\n",
      "Saved the embedding for punished.\n",
      "punishing is at index 23477\n",
      "Saved the embedding for punishing.\n",
      "punitive is at index 21987\n",
      "Saved the embedding for punitive.\n",
      "punk is at index 19742\n",
      "Saved the embedding for punk.\n",
      "puppyish is at index 20830\n",
      "Saved the embedding for puppyish.\n",
      "purposeful is at index 3508\n",
      "Saved the embedding for purposeful.\n",
      "pursed is at index 26934\n",
      "Saved the embedding for pursed.\n",
      "put is at index 342\n",
      "Saved the embedding for put.\n",
      "putting is at index 2057\n",
      "Saved the embedding for putting.\n",
      "puzzled is at index 36742\n",
      "Saved the embedding for puzzled.\n",
      "puzzlement is at index 47037\n",
      "Saved the embedding for puzzlement.\n",
      "qualms is at index 22043\n",
      "Saved the embedding for qualms.\n",
      "quarrelsome is at index 39486\n",
      "Saved the embedding for quarrelsome.\n",
      "queasy is at index 1192\n",
      "Saved the embedding for queasy.\n",
      "quenched is at index 2677\n",
      "Saved the embedding for quenched.\n",
      "questionable is at index 12474\n",
      "Saved the embedding for questionable.\n",
      "questioning is at index 8026\n",
      "Saved the embedding for questioning.\n",
      "questioningly is at index 864\n",
      "Saved the embedding for questioningly.\n",
      "quiet is at index 5128\n",
      "Saved the embedding for quiet.\n",
      "quietness is at index 5128\n",
      "Saved the embedding for quietness.\n",
      "quilt is at index 2677\n",
      "Saved the embedding for quilt.\n",
      "quirky is at index 22364\n",
      "Saved the embedding for quirky.\n",
      "quizzical is at index 29316\n",
      "Saved the embedding for quizzical.\n",
      "rabid is at index 39660\n",
      "Saved the embedding for rabid.\n",
      "racked is at index 20208\n",
      "Saved the embedding for racked.\n",
      "radiant is at index 35787\n",
      "Saved the embedding for radiant.\n",
      "rage is at index 14706\n",
      "Saved the embedding for rage.\n",
      "raged is at index 31927\n",
      "Saved the embedding for raged.\n",
      "ragged is at index 910\n",
      "Saved the embedding for ragged.\n",
      "raging is at index 23333\n",
      "Saved the embedding for raging.\n",
      "rancorous is at index 21560\n",
      "Saved the embedding for rancorous.\n",
      "randy is at index 910\n",
      "Saved the embedding for randy.\n",
      "rapt is at index 34524\n",
      "Saved the embedding for rapt.\n",
      "rattled is at index 21602\n",
      "Saved the embedding for rattled.\n",
      "raving is at index 910\n",
      "Saved the embedding for raving.\n",
      "reactive is at index 34729\n",
      "Saved the embedding for reactive.\n",
      "ready is at index 1227\n",
      "Saved the embedding for ready.\n",
      "realization is at index 24179\n",
      "Saved the embedding for realization.\n",
      "reassured is at index 29336\n",
      "Saved the embedding for reassured.\n",
      "rebellious is at index 38017\n",
      "Saved the embedding for rebellious.\n",
      "rebuke is at index 28155\n",
      "Saved the embedding for rebuke.\n",
      "recalling is at index 20239\n",
      "Saved the embedding for recalling.\n",
      "receptive is at index 33052\n",
      "Saved the embedding for receptive.\n",
      "reckless is at index 13508\n",
      "Saved the embedding for reckless.\n",
      "recoil is at index 44983\n",
      "Saved the embedding for recoil.\n",
      "recoiling is at index 3872\n",
      "Saved the embedding for recoiling.\n",
      "reflecting is at index 10811\n",
      "Saved the embedding for reflecting.\n",
      "reflection is at index 12456\n",
      "Saved the embedding for reflection.\n",
      "reflective is at index 22213\n",
      "Saved the embedding for reflective.\n",
      "refulgent is at index 769\n",
      "Saved the embedding for refulgent.\n",
      "refusing is at index 10520\n",
      "Saved the embedding for refusing.\n",
      "regret is at index 9917\n",
      "Saved the embedding for regret.\n",
      "regretful is at index 9917\n",
      "Saved the embedding for regretful.\n",
      "rejected is at index 3946\n",
      "Saved the embedding for rejected.\n",
      "rejecting is at index 19695\n",
      "Saved the embedding for rejecting.\n",
      "rejection is at index 16117\n",
      "Saved the embedding for rejection.\n",
      "rejoicing is at index 24586\n",
      "Saved the embedding for rejoicing.\n",
      "relaxation is at index 26545\n",
      "Saved the embedding for relaxation.\n",
      "relaxed is at index 11956\n",
      "Saved the embedding for relaxed.\n",
      "relentless is at index 16476\n",
      "Saved the embedding for relentless.\n",
      "relief is at index 3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for relief.\n",
      "relieved is at index 15126\n",
      "Saved the embedding for relieved.\n",
      "relived is at index 6258\n",
      "Saved the embedding for relived.\n",
      "reluctant is at index 11923\n",
      "Saved the embedding for reluctant.\n",
      "reluctantly is at index 33146\n",
      "Saved the embedding for reluctantly.\n",
      "remorse is at index 23312\n",
      "Saved the embedding for remorse.\n",
      "remorseful is at index 23312\n",
      "Saved the embedding for remorseful.\n",
      "repelled is at index 25633\n",
      "Saved the embedding for repelled.\n",
      "repressed is at index 2851\n",
      "Saved the embedding for repressed.\n",
      "reproach is at index 2851\n",
      "Saved the embedding for reproach.\n",
      "reproachful is at index 2851\n",
      "Saved the embedding for reproachful.\n",
      "repugnance is at index 2851\n",
      "Saved the embedding for repugnance.\n",
      "repugnant is at index 2851\n",
      "Saved the embedding for repugnant.\n",
      "repulsed is at index 2851\n",
      "Saved the embedding for repulsed.\n",
      "repulsion is at index 2851\n",
      "Saved the embedding for repulsion.\n",
      "resent is at index 31379\n",
      "Saved the embedding for resent.\n",
      "resentful is at index 31379\n",
      "Saved the embedding for resentful.\n",
      "resenting is at index 31379\n",
      "Saved the embedding for resenting.\n",
      "resentment is at index 27111\n",
      "Saved the embedding for resentment.\n",
      "reserved is at index 1875\n",
      "Saved the embedding for reserved.\n",
      "resignation is at index 6985\n",
      "Saved the embedding for resignation.\n",
      "resigned is at index 6490\n",
      "Saved the embedding for resigned.\n",
      "resilience is at index 13790\n",
      "Saved the embedding for resilience.\n",
      "resistance is at index 5910\n",
      "Saved the embedding for resistance.\n",
      "resistant is at index 19152\n",
      "Saved the embedding for resistant.\n",
      "resistent is at index 11942\n",
      "Saved the embedding for resistent.\n",
      "resisting is at index 18907\n",
      "Saved the embedding for resisting.\n",
      "resolute is at index 5032\n",
      "Saved the embedding for resolute.\n",
      "resolved is at index 8179\n",
      "Saved the embedding for resolved.\n",
      "responsive is at index 20666\n",
      "Saved the embedding for responsive.\n",
      "restful is at index 1079\n",
      "Saved the embedding for restful.\n",
      "resting is at index 18403\n",
      "Saved the embedding for resting.\n",
      "restless is at index 36844\n",
      "Saved the embedding for restless.\n",
      "restlessness is at index 1079\n",
      "Saved the embedding for restlessness.\n",
      "restrained is at index 25063\n",
      "Saved the embedding for restrained.\n",
      "restraint is at index 20219\n",
      "Saved the embedding for restraint.\n",
      "retaliating is at index 18570\n",
      "Saved the embedding for retaliating.\n",
      "retaliatory is at index 18570\n",
      "Saved the embedding for retaliatory.\n",
      "rethinking is at index 769\n",
      "Saved the embedding for rethinking.\n",
      "reticence is at index 5494\n",
      "Saved the embedding for reticence.\n",
      "reticent is at index 5494\n",
      "Saved the embedding for reticent.\n",
      "revengeful is at index 13543\n",
      "Saved the embedding for revengeful.\n",
      "reverent is at index 26911\n",
      "Saved the embedding for reverent.\n",
      "revolted is at index 34633\n",
      "Saved the embedding for revolted.\n",
      "revulsion is at index 6910\n",
      "Saved the embedding for revulsion.\n",
      "righteous is at index 37909\n",
      "Saved the embedding for righteous.\n",
      "rigid is at index 24577\n",
      "Saved the embedding for rigid.\n",
      "riled is at index 910\n",
      "Saved the embedding for riled.\n",
      "riotous is at index 13069\n",
      "Saved the embedding for riotous.\n",
      "riveted is at index 32886\n",
      "Saved the embedding for riveted.\n",
      "roar is at index 31733\n",
      "Saved the embedding for roar.\n",
      "roguish is at index 4533\n",
      "Saved the embedding for roguish.\n",
      "roiled is at index 4533\n",
      "Saved the embedding for roiled.\n",
      "rough is at index 6744\n",
      "Saved the embedding for rough.\n",
      "roused is at index 910\n",
      "Saved the embedding for roused.\n",
      "rude is at index 21820\n",
      "Saved the embedding for rude.\n",
      "rueful is at index 910\n",
      "Saved the embedding for rueful.\n",
      "ruffled is at index 910\n",
      "Saved the embedding for ruffled.\n",
      "ruminating is at index 11122\n",
      "Saved the embedding for ruminating.\n",
      "rustled is at index 18309\n",
      "Saved the embedding for rustled.\n",
      "ruthless is at index 25597\n",
      "Saved the embedding for ruthless.\n",
      "sad is at index 5074\n",
      "Saved the embedding for sad.\n",
      "sadden is at index 23330\n",
      "Saved the embedding for sadden.\n",
      "saddened is at index 19934\n",
      "Saved the embedding for saddened.\n",
      "sadistic is at index 5074\n",
      "Saved the embedding for sadistic.\n",
      "sadness is at index 17437\n",
      "Saved the embedding for sadness.\n",
      "salacious is at index 6641\n",
      "Saved the embedding for salacious.\n",
      "salivating is at index 6641\n",
      "Saved the embedding for salivating.\n",
      "sanctimonious is at index 27600\n",
      "Saved the embedding for sanctimonious.\n",
      "sane is at index 37091\n",
      "Saved the embedding for sane.\n",
      "sanguine is at index 579\n",
      "Saved the embedding for sanguine.\n",
      "sappy is at index 2241\n",
      "Saved the embedding for sappy.\n",
      "sarcasm is at index 38522\n",
      "Saved the embedding for sarcasm.\n",
      "sarcastic is at index 39580\n",
      "Saved the embedding for sarcastic.\n",
      "sardonic is at index 579\n",
      "Saved the embedding for sardonic.\n",
      "sassy is at index 579\n",
      "Saved the embedding for sassy.\n",
      "sated is at index 579\n",
      "Saved the embedding for sated.\n",
      "satiated is at index 4005\n",
      "Saved the embedding for satiated.\n",
      "satirical is at index 33937\n",
      "Saved the embedding for satirical.\n",
      "satisfaction is at index 11658\n",
      "Saved the embedding for satisfaction.\n",
      "satisfied is at index 10028\n",
      "Saved the embedding for satisfied.\n",
      "satisfy is at index 15332\n",
      "Saved the embedding for satisfy.\n",
      "saturnine is at index 4005\n",
      "Saved the embedding for saturnine.\n",
      "saucy is at index 2241\n",
      "Saved the embedding for saucy.\n",
      "savage is at index 32264\n",
      "Saved the embedding for savage.\n",
      "scandalized is at index 4220\n",
      "Saved the embedding for scandalized.\n",
      "scare is at index 13207\n",
      "Saved the embedding for scare.\n",
      "scared is at index 8265\n",
      "Saved the embedding for scared.\n",
      "scary is at index 10222\n",
      "Saved the embedding for scary.\n",
      "scattered is at index 12827\n",
      "Saved the embedding for scattered.\n",
      "schadenfreude is at index 8447\n",
      "Saved the embedding for schadenfreude.\n",
      "scheming is at index 30315\n",
      "Saved the embedding for scheming.\n",
      "scoffer is at index 34564\n",
      "Saved the embedding for scoffer.\n",
      "scoffing is at index 34564\n",
      "Saved the embedding for scoffing.\n",
      "scorn is at index 38430\n",
      "Saved the embedding for scorn.\n",
      "scorned is at index 2850\n",
      "Saved the embedding for scorned.\n",
      "scornful is at index 38430\n",
      "Saved the embedding for scornful.\n",
      "scowl is at index 2850\n",
      "Saved the embedding for scowl.\n",
      "scowling is at index 2850\n",
      "Saved the embedding for scowling.\n",
      "scream is at index 22093\n",
      "Saved the embedding for scream.\n",
      "screaming is at index 11347\n",
      "Saved the embedding for screaming.\n",
      "scrutinizing is at index 18470\n",
      "Saved the embedding for scrutinizing.\n",
      "sealed is at index 10497\n",
      "Saved the embedding for sealed.\n",
      "searching is at index 6062\n",
      "Saved the embedding for searching.\n",
      "secretive is at index 27174\n",
      "Saved the embedding for secretive.\n",
      "secretively is at index 3556\n",
      "Saved the embedding for secretively.\n",
      "secure is at index 2823\n",
      "Saved the embedding for secure.\n",
      "sedate is at index 10195\n",
      "Saved the embedding for sedate.\n",
      "seduction is at index 10195\n",
      "Saved the embedding for seduction.\n",
      "seductive is at index 10195\n",
      "Saved the embedding for seductive.\n",
      "seething is at index 842\n",
      "Saved the embedding for seething.\n",
      "self is at index 1403\n",
      "Saved the embedding for self.\n",
      "sensual is at index 18105\n",
      "Saved the embedding for sensual.\n",
      "sentimental is at index 32693\n",
      "Saved the embedding for sentimental.\n",
      "serene is at index 842\n",
      "Saved the embedding for serene.\n",
      "serious is at index 1473\n",
      "Saved the embedding for serious.\n",
      "seriousness is at index 24146\n",
      "Saved the embedding for seriousness.\n",
      "servile is at index 18527\n",
      "Saved the embedding for servile.\n",
      "set is at index 278\n",
      "Saved the embedding for set.\n",
      "severe is at index 3814\n",
      "Saved the embedding for severe.\n",
      "shabby is at index 1481\n",
      "Saved the embedding for shabby.\n",
      "shady is at index 31665\n",
      "Saved the embedding for shady.\n",
      "shaken is at index 17548\n",
      "Saved the embedding for shaken.\n",
      "shaky is at index 22032\n",
      "Saved the embedding for shaky.\n",
      "shame is at index 9208\n",
      "Saved the embedding for shame.\n",
      "shamed is at index 1481\n",
      "Saved the embedding for shamed.\n",
      "shamefaced is at index 9208\n",
      "Saved the embedding for shamefaced.\n",
      "shameful is at index 26722\n",
      "Saved the embedding for shameful.\n",
      "shameless is at index 36778\n",
      "Saved the embedding for shameless.\n",
      "sharp is at index 4406\n",
      "Saved the embedding for sharp.\n",
      "sheepish is at index 14336\n",
      "Saved the embedding for sheepish.\n",
      "sheepishness is at index 14336\n",
      "Saved the embedding for sheepishness.\n",
      "shelled is at index 79\n",
      "Saved the embedding for shelled.\n",
      "shifty is at index 37503\n",
      "Saved the embedding for shifty.\n",
      "shock is at index 4817\n",
      "Saved the embedding for shock.\n",
      "shocked is at index 6649\n",
      "Saved the embedding for shocked.\n",
      "shocking is at index 8777\n",
      "Saved the embedding for shocking.\n",
      "shockingly is at index 36804\n",
      "Saved the embedding for shockingly.\n",
      "shook is at index 14774\n",
      "Saved the embedding for shook.\n",
      "shout is at index 18066\n",
      "Saved the embedding for shout.\n",
      "shouting is at index 14487\n",
      "Saved the embedding for shouting.\n",
      "shrewd is at index 36943\n",
      "Saved the embedding for shrewd.\n",
      "shy is at index 9152\n",
      "Saved the embedding for shy.\n",
      "shyness is at index 9152\n",
      "Saved the embedding for shyness.\n",
      "sick is at index 4736\n",
      "Saved the embedding for sick.\n",
      "sicken is at index 579\n",
      "Saved the embedding for sicken.\n",
      "sickened is at index 4736\n",
      "Saved the embedding for sickened.\n",
      "sigh is at index 27305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for sigh.\n",
      "silenced is at index 30125\n",
      "Saved the embedding for silenced.\n",
      "silent is at index 8454\n",
      "Saved the embedding for silent.\n",
      "silliness is at index 38052\n",
      "Saved the embedding for silliness.\n",
      "silly is at index 15470\n",
      "Saved the embedding for silly.\n",
      "simmering is at index 25726\n",
      "Saved the embedding for simmering.\n",
      "simper is at index 16207\n",
      "Saved the embedding for simper.\n",
      "simpering is at index 16207\n",
      "Saved the embedding for simpering.\n",
      "simple is at index 2007\n",
      "Saved the embedding for simple.\n",
      "simplicity is at index 25342\n",
      "Saved the embedding for simplicity.\n",
      "sincere is at index 19255\n",
      "Saved the embedding for sincere.\n",
      "sinful is at index 44364\n",
      "Saved the embedding for sinful.\n",
      "singing is at index 6970\n",
      "Saved the embedding for singing.\n",
      "sinister is at index 27570\n",
      "Saved the embedding for sinister.\n",
      "sinisterly is at index 27570\n",
      "Saved the embedding for sinisterly.\n",
      "sizing is at index 39328\n",
      "Saved the embedding for sizing.\n",
      "skeptic is at index 42386\n",
      "Saved the embedding for skeptic.\n",
      "skeptical is at index 14992\n",
      "Saved the embedding for skeptical.\n",
      "skeptically is at index 42386\n",
      "Saved the embedding for skeptically.\n",
      "skepticism is at index 22222\n",
      "Saved the embedding for skepticism.\n",
      "sketchy is at index 15923\n",
      "Saved the embedding for sketchy.\n",
      "skittish is at index 2972\n",
      "Saved the embedding for skittish.\n",
      "slack is at index 25163\n",
      "Saved the embedding for slack.\n",
      "sleazy is at index 18388\n",
      "Saved the embedding for sleazy.\n",
      "sleepy is at index 33782\n",
      "Saved the embedding for sleepy.\n",
      "slick is at index 19038\n",
      "Saved the embedding for slick.\n",
      "slothful is at index 3369\n",
      "Saved the embedding for slothful.\n",
      "slow is at index 2635\n",
      "Saved the embedding for slow.\n",
      "sluggish is at index 16642\n",
      "Saved the embedding for sluggish.\n",
      "sly is at index 40568\n",
      "Saved the embedding for sly.\n",
      "smarmy is at index 5278\n",
      "Saved the embedding for smarmy.\n",
      "smart is at index 2793\n",
      "Saved the embedding for smart.\n",
      "smashed is at index 13263\n",
      "Saved the embedding for smashed.\n",
      "smile is at index 6675\n",
      "Saved the embedding for smile.\n",
      "smiley is at index 6675\n",
      "Saved the embedding for smiley.\n",
      "smiling is at index 12382\n",
      "Saved the embedding for smiling.\n",
      "smirk is at index 5278\n",
      "Saved the embedding for smirk.\n",
      "smirking is at index 44414\n",
      "Saved the embedding for smirking.\n",
      "smoldering is at index 5278\n",
      "Saved the embedding for smoldering.\n",
      "smooching is at index 5278\n",
      "Saved the embedding for smooching.\n",
      "smooth is at index 6921\n",
      "Saved the embedding for smooth.\n",
      "smug is at index 41283\n",
      "Saved the embedding for smug.\n",
      "smugness is at index 41283\n",
      "Saved the embedding for smugness.\n",
      "snake is at index 16173\n",
      "Saved the embedding for snake.\n",
      "snappy is at index 4543\n",
      "Saved the embedding for snappy.\n",
      "snarky is at index 4543\n",
      "Saved the embedding for snarky.\n",
      "snarl is at index 4543\n",
      "Saved the embedding for snarl.\n",
      "snarled is at index 4543\n",
      "Saved the embedding for snarled.\n",
      "snarling is at index 4543\n",
      "Saved the embedding for snarling.\n",
      "snarly is at index 4543\n",
      "Saved the embedding for snarly.\n",
      "sneaky is at index 39399\n",
      "Saved the embedding for sneaky.\n",
      "sneer is at index 18013\n",
      "Saved the embedding for sneer.\n",
      "sneering is at index 18013\n",
      "Saved the embedding for sneering.\n",
      "sneeze is at index 18013\n",
      "Saved the embedding for sneeze.\n",
      "sneezing is at index 18013\n",
      "Saved the embedding for sneezing.\n",
      "snicker is at index 4543\n",
      "Saved the embedding for snicker.\n",
      "snickering is at index 4543\n",
      "Saved the embedding for snickering.\n",
      "snide is at index 4543\n",
      "Saved the embedding for snide.\n",
      "sniggering is at index 4543\n",
      "Saved the embedding for sniggering.\n",
      "sniveling is at index 4543\n",
      "Saved the embedding for sniveling.\n",
      "snobbish is at index 4543\n",
      "Saved the embedding for snobbish.\n",
      "snobby is at index 4543\n",
      "Saved the embedding for snobby.\n",
      "snooty is at index 4543\n",
      "Saved the embedding for snooty.\n",
      "snotty is at index 579\n",
      "Saved the embedding for snotty.\n",
      "sociable is at index 17380\n",
      "Saved the embedding for sociable.\n",
      "soft is at index 3793\n",
      "Saved the embedding for soft.\n",
      "solemn is at index 29807\n",
      "Saved the embedding for solemn.\n",
      "solicitous is at index 22706\n",
      "Saved the embedding for solicitous.\n",
      "solitary is at index 24429\n",
      "Saved the embedding for solitary.\n",
      "solitude is at index 41813\n",
      "Saved the embedding for solitude.\n",
      "somber is at index 16487\n",
      "Saved the embedding for somber.\n",
      "somberly is at index 16487\n",
      "Saved the embedding for somberly.\n",
      "somnolent is at index 16487\n",
      "Saved the embedding for somnolent.\n",
      "soothed is at index 98\n",
      "Saved the embedding for soothed.\n",
      "sore is at index 12867\n",
      "Saved the embedding for sore.\n",
      "sorrow is at index 26130\n",
      "Saved the embedding for sorrow.\n",
      "sorrowful is at index 26130\n",
      "Saved the embedding for sorrowful.\n",
      "sorry is at index 6661\n",
      "Saved the embedding for sorry.\n",
      "sour is at index 16933\n",
      "Saved the embedding for sour.\n",
      "spaced is at index 42926\n",
      "Saved the embedding for spaced.\n",
      "spacing is at index 39152\n",
      "Saved the embedding for spacing.\n",
      "spastic is at index 2292\n",
      "Saved the embedding for spastic.\n",
      "speaking is at index 2686\n",
      "Saved the embedding for speaking.\n",
      "specious is at index 12002\n",
      "Saved the embedding for specious.\n",
      "speculative is at index 21779\n",
      "Saved the embedding for speculative.\n",
      "speechless is at index 1901\n",
      "Saved the embedding for speechless.\n",
      "spent is at index 1240\n",
      "Saved the embedding for spent.\n",
      "spirited is at index 27206\n",
      "Saved the embedding for spirited.\n",
      "spiritless is at index 4780\n",
      "Saved the embedding for spiritless.\n",
      "spite is at index 14117\n",
      "Saved the embedding for spite.\n",
      "spiteful is at index 14117\n",
      "Saved the embedding for spiteful.\n",
      "spoiled is at index 29136\n",
      "Saved the embedding for spoiled.\n",
      "spooked is at index 2292\n",
      "Saved the embedding for spooked.\n",
      "squeamish is at index 33380\n",
      "Saved the embedding for squeamish.\n",
      "staggered is at index 37646\n",
      "Saved the embedding for staggered.\n",
      "stalker is at index 1690\n",
      "Saved the embedding for stalker.\n",
      "stare is at index 27655\n",
      "Saved the embedding for stare.\n",
      "staring is at index 19311\n",
      "Saved the embedding for staring.\n",
      "starstruck is at index 999\n",
      "Saved the embedding for starstruck.\n",
      "started is at index 554\n",
      "Saved the embedding for started.\n",
      "startled is at index 37747\n",
      "Saved the embedding for startled.\n",
      "stately is at index 194\n",
      "Saved the embedding for stately.\n",
      "steadfast is at index 25781\n",
      "Saved the embedding for steadfast.\n",
      "steady is at index 5204\n",
      "Saved the embedding for steady.\n",
      "stealthy is at index 27026\n",
      "Saved the embedding for stealthy.\n",
      "steamed is at index 11235\n",
      "Saved the embedding for steamed.\n",
      "steaming is at index 11235\n",
      "Saved the embedding for steaming.\n",
      "steeling is at index 3689\n",
      "Saved the embedding for steeling.\n",
      "steely is at index 1690\n",
      "Saved the embedding for steely.\n",
      "stern is at index 23427\n",
      "Saved the embedding for stern.\n",
      "stiff is at index 13116\n",
      "Saved the embedding for stiff.\n",
      "stifled is at index 1690\n",
      "Saved the embedding for stifled.\n",
      "stifling is at index 1690\n",
      "Saved the embedding for stifling.\n",
      "still is at index 202\n",
      "Saved the embedding for still.\n",
      "stillness is at index 202\n",
      "Saved the embedding for stillness.\n",
      "stimulated is at index 42040\n",
      "Saved the embedding for stimulated.\n",
      "stinky is at index 1690\n",
      "Saved the embedding for stinky.\n",
      "stirred is at index 26158\n",
      "Saved the embedding for stirred.\n",
      "stoic is at index 20572\n",
      "Saved the embedding for stoic.\n",
      "stoical is at index 20572\n",
      "Saved the embedding for stoical.\n",
      "stolid is at index 1690\n",
      "Saved the embedding for stolid.\n",
      "stoned is at index 1690\n",
      "Saved the embedding for stoned.\n",
      "storming is at index 2130\n",
      "Saved the embedding for storming.\n",
      "stormy is at index 2130\n",
      "Saved the embedding for stormy.\n",
      "stout is at index 34636\n",
      "Saved the embedding for stout.\n",
      "straight is at index 1359\n",
      "Saved the embedding for straight.\n",
      "strained is at index 15718\n",
      "Saved the embedding for strained.\n",
      "strange is at index 7782\n",
      "Saved the embedding for strange.\n",
      "stressed is at index 5882\n",
      "Saved the embedding for stressed.\n",
      "stricken is at index 35876\n",
      "Saved the embedding for stricken.\n",
      "strict is at index 8414\n",
      "Saved the embedding for strict.\n",
      "strong is at index 670\n",
      "Saved the embedding for strong.\n",
      "struck is at index 2322\n",
      "Saved the embedding for struck.\n",
      "stubborn is at index 20476\n",
      "Saved the embedding for stubborn.\n",
      "stubbornness is at index 20476\n",
      "Saved the embedding for stubbornness.\n",
      "studious is at index 15863\n",
      "Saved the embedding for studious.\n",
      "studying is at index 7739\n",
      "Saved the embedding for studying.\n",
      "stumped is at index 1690\n",
      "Saved the embedding for stumped.\n",
      "stung is at index 1690\n",
      "Saved the embedding for stung.\n",
      "stunned is at index 12144\n",
      "Saved the embedding for stunned.\n",
      "stupefaction is at index 1690\n",
      "Saved the embedding for stupefaction.\n",
      "stupefied is at index 1690\n",
      "Saved the embedding for stupefied.\n",
      "stupefy is at index 1690\n",
      "Saved the embedding for stupefy.\n",
      "stupid is at index 12103\n",
      "Saved the embedding for stupid.\n",
      "stuporous is at index 1690\n",
      "Saved the embedding for stuporous.\n",
      "suave is at index 2628\n",
      "Saved the embedding for suave.\n",
      "subdued is at index 20247\n",
      "Saved the embedding for subdued.\n",
      "sublime is at index 32477\n",
      "Saved the embedding for sublime.\n",
      "submissive is at index 2849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for submissive.\n",
      "suffering is at index 3606\n",
      "Saved the embedding for suffering.\n",
      "suggestive is at index 38907\n",
      "Saved the embedding for suggestive.\n",
      "sulking is at index 26648\n",
      "Saved the embedding for sulking.\n",
      "sulky is at index 26648\n",
      "Saved the embedding for sulky.\n",
      "sullen is at index 2628\n",
      "Saved the embedding for sullen.\n",
      "sullenness is at index 2628\n",
      "Saved the embedding for sullenness.\n",
      "sunny is at index 5419\n",
      "Saved the embedding for sunny.\n",
      "superior is at index 10295\n",
      "Saved the embedding for superior.\n",
      "superiority is at index 32951\n",
      "Saved the embedding for superiority.\n",
      "suppressed is at index 31683\n",
      "Saved the embedding for suppressed.\n",
      "suppressing is at index 38919\n",
      "Saved the embedding for suppressing.\n",
      "suppression is at index 25276\n",
      "Saved the embedding for suppression.\n",
      "sure is at index 686\n",
      "Saved the embedding for sure.\n",
      "surly is at index 8113\n",
      "Saved the embedding for surly.\n",
      "surprise is at index 2755\n",
      "Saved the embedding for surprise.\n",
      "surprised is at index 3911\n",
      "Saved the embedding for surprised.\n",
      "surprising is at index 6167\n",
      "Saved the embedding for surprising.\n",
      "surprisingly is at index 10262\n",
      "Saved the embedding for surprisingly.\n",
      "surreptitious is at index 8113\n",
      "Saved the embedding for surreptitious.\n",
      "suspect is at index 1985\n",
      "Saved the embedding for suspect.\n",
      "suspecting is at index 1985\n",
      "Saved the embedding for suspecting.\n",
      "suspense is at index 31803\n",
      "Saved the embedding for suspense.\n",
      "suspicion is at index 8551\n",
      "Saved the embedding for suspicion.\n",
      "suspicious is at index 7775\n",
      "Saved the embedding for suspicious.\n",
      "suspiciously is at index 7775\n",
      "Saved the embedding for suspiciously.\n",
      "suspiciousness is at index 7775\n",
      "Saved the embedding for suspiciousness.\n",
      "swaggering is at index 3514\n",
      "Saved the embedding for swaggering.\n",
      "swearing is at index 21854\n",
      "Saved the embedding for swearing.\n",
      "sympathetic is at index 22869\n",
      "Saved the embedding for sympathetic.\n",
      "sympathizing is at index 19023\n",
      "Saved the embedding for sympathizing.\n",
      "sympathy is at index 16554\n",
      "Saved the embedding for sympathy.\n",
      "taciturn is at index 36502\n",
      "Saved the embedding for taciturn.\n",
      "talkative is at index 1067\n",
      "Saved the embedding for talkative.\n",
      "talking is at index 1686\n",
      "Saved the embedding for talking.\n",
      "tantalized is at index 33496\n",
      "Saved the embedding for tantalized.\n",
      "tart is at index 27468\n",
      "Saved the embedding for tart.\n",
      "tasteful is at index 24867\n",
      "Saved the embedding for tasteful.\n",
      "tattling is at index 45951\n",
      "Saved the embedding for tattling.\n",
      "taunt is at index 44048\n",
      "Saved the embedding for taunt.\n",
      "taunting is at index 326\n",
      "Saved the embedding for taunting.\n",
      "taut is at index 326\n",
      "Saved the embedding for taut.\n",
      "tearful is at index 7366\n",
      "Saved the embedding for tearful.\n",
      "teary is at index 7366\n",
      "Saved the embedding for teary.\n",
      "tease is at index 29993\n",
      "Saved the embedding for tease.\n",
      "teasing is at index 29752\n",
      "Saved the embedding for teasing.\n",
      "tempered is at index 31380\n",
      "Saved the embedding for tempered.\n",
      "tempest is at index 32196\n",
      "Saved the embedding for tempest.\n",
      "tempestuous is at index 32196\n",
      "Saved the embedding for tempestuous.\n",
      "tempted is at index 23448\n",
      "Saved the embedding for tempted.\n",
      "tenacious is at index 2724\n",
      "Saved the embedding for tenacious.\n",
      "tender is at index 8780\n",
      "Saved the embedding for tender.\n",
      "tenderness is at index 8780\n",
      "Saved the embedding for tenderness.\n",
      "tense is at index 13554\n",
      "Saved the embedding for tense.\n",
      "tensed is at index 7281\n",
      "Saved the embedding for tensed.\n",
      "tension is at index 8556\n",
      "Saved the embedding for tension.\n",
      "tentative is at index 22948\n",
      "Saved the embedding for tentative.\n",
      "terrified is at index 19419\n",
      "Saved the embedding for terrified.\n",
      "terror is at index 5231\n",
      "Saved the embedding for terror.\n",
      "terrorized is at index 5231\n",
      "Saved the embedding for terrorized.\n",
      "terrorizing is at index 5231\n",
      "Saved the embedding for terrorizing.\n",
      "terse is at index 8470\n",
      "Saved the embedding for terse.\n",
      "testy is at index 1296\n",
      "Saved the embedding for testy.\n",
      "tetchy is at index 326\n",
      "Saved the embedding for tetchy.\n",
      "thankful is at index 12025\n",
      "Saved the embedding for thankful.\n",
      "thinking is at index 2053\n",
      "Saved the embedding for thinking.\n",
      "thought is at index 802\n",
      "Saved the embedding for thought.\n",
      "thoughtful is at index 16801\n",
      "Saved the embedding for thoughtful.\n",
      "thoughtfulness is at index 802\n",
      "Saved the embedding for thoughtfulness.\n",
      "threat is at index 1856\n",
      "Saved the embedding for threat.\n",
      "threatened is at index 3711\n",
      "Saved the embedding for threatened.\n",
      "threatening is at index 5608\n",
      "Saved the embedding for threatening.\n",
      "thrilled is at index 8689\n",
      "Saved the embedding for thrilled.\n",
      "thrown is at index 5629\n",
      "Saved the embedding for thrown.\n",
      "thunderstruck is at index 4775\n",
      "Saved the embedding for thunderstruck.\n",
      "thwarted is at index 28299\n",
      "Saved the embedding for thwarted.\n",
      "ticked is at index 10457\n",
      "Saved the embedding for ticked.\n",
      "tickled is at index 10457\n",
      "Saved the embedding for tickled.\n",
      "tied is at index 3016\n",
      "Saved the embedding for tied.\n",
      "tiered is at index 3318\n",
      "Saved the embedding for tiered.\n",
      "tight is at index 3229\n",
      "Saved the embedding for tight.\n",
      "tightlipped is at index 3229\n",
      "Saved the embedding for tightlipped.\n",
      "timid is at index 39649\n",
      "Saved the embedding for timid.\n",
      "timidly is at index 39649\n",
      "Saved the embedding for timidly.\n",
      "timidness is at index 39649\n",
      "Saved the embedding for timidness.\n",
      "tired is at index 7428\n",
      "Saved the embedding for tired.\n",
      "tiredly is at index 7428\n",
      "Saved the embedding for tiredly.\n",
      "tiredness is at index 7428\n",
      "Saved the embedding for tiredness.\n",
      "titillated is at index 13515\n",
      "Saved the embedding for titillated.\n",
      "tolerant is at index 32836\n",
      "Saved the embedding for tolerant.\n",
      "tongue is at index 15686\n",
      "Saved the embedding for tongue.\n",
      "tormented is at index 16535\n",
      "Saved the embedding for tormented.\n",
      "touched is at index 6699\n",
      "Saved the embedding for touched.\n",
      "tough is at index 1828\n",
      "Saved the embedding for tough.\n",
      "toying is at index 7\n",
      "Saved the embedding for toying.\n",
      "tragic is at index 8805\n",
      "Saved the embedding for tragic.\n",
      "tragical is at index 2664\n",
      "Saved the embedding for tragical.\n",
      "tranquil is at index 33535\n",
      "Saved the embedding for tranquil.\n",
      "tranquility is at index 36474\n",
      "Saved the embedding for tranquility.\n",
      "transfixed is at index 30387\n",
      "Saved the embedding for transfixed.\n",
      "traumatized is at index 25178\n",
      "Saved the embedding for traumatized.\n",
      "trembling is at index 44912\n",
      "Saved the embedding for trembling.\n",
      "trepid is at index 6110\n",
      "Saved the embedding for trepid.\n",
      "trepidation is at index 6110\n",
      "Saved the embedding for trepidation.\n",
      "trickster is at index 7610\n",
      "Saved the embedding for trickster.\n",
      "tricky is at index 12792\n",
      "Saved the embedding for tricky.\n",
      "triumphant is at index 32025\n",
      "Saved the embedding for triumphant.\n",
      "troubled is at index 9895\n",
      "Saved the embedding for troubled.\n",
      "troublesome is at index 34056\n",
      "Saved the embedding for troublesome.\n",
      "troubling is at index 15554\n",
      "Saved the embedding for troubling.\n",
      "trusting is at index 28969\n",
      "Saved the embedding for trusting.\n",
      "trustworthy is at index 32101\n",
      "Saved the embedding for trustworthy.\n",
      "tumultuous is at index 23787\n",
      "Saved the embedding for tumultuous.\n",
      "turbulent is at index 23415\n",
      "Saved the embedding for turbulent.\n",
      "twinkly is at index 11901\n",
      "Saved the embedding for twinkly.\n",
      "umbrage is at index 7252\n",
      "Saved the embedding for umbrage.\n",
      "umbrageous is at index 7252\n",
      "Saved the embedding for umbrageous.\n",
      "unaffected is at index 32512\n",
      "Saved the embedding for unaffected.\n",
      "unagitated is at index 542\n",
      "Saved the embedding for unagitated.\n",
      "unamused is at index 542\n",
      "Saved the embedding for unamused.\n",
      "unappreciative is at index 542\n",
      "Saved the embedding for unappreciative.\n",
      "unapproachable is at index 542\n",
      "Saved the embedding for unapproachable.\n",
      "unassertive is at index 542\n",
      "Saved the embedding for unassertive.\n",
      "unassuming is at index 542\n",
      "Saved the embedding for unassuming.\n",
      "unaware is at index 14021\n",
      "Saved the embedding for unaware.\n",
      "unbelief is at index 46646\n",
      "Saved the embedding for unbelief.\n",
      "unbelievable is at index 14011\n",
      "Saved the embedding for unbelievable.\n",
      "unbelieving is at index 46646\n",
      "Saved the embedding for unbelieving.\n",
      "unbothered is at index 542\n",
      "Saved the embedding for unbothered.\n",
      "uncaring is at index 16511\n",
      "Saved the embedding for uncaring.\n",
      "uncertain is at index 9684\n",
      "Saved the embedding for uncertain.\n",
      "uncertainly is at index 9684\n",
      "Saved the embedding for uncertainly.\n",
      "uncertainty is at index 4983\n",
      "Saved the embedding for uncertainty.\n",
      "uncivil is at index 16511\n",
      "Saved the embedding for uncivil.\n",
      "uncomfortable is at index 9800\n",
      "Saved the embedding for uncomfortable.\n",
      "uncommitted is at index 32275\n",
      "Saved the embedding for uncommitted.\n",
      "uncommunicative is at index 32275\n",
      "Saved the embedding for uncommunicative.\n",
      "uncomprehending is at index 32275\n",
      "Saved the embedding for uncomprehending.\n",
      "uncompromising is at index 32213\n",
      "Saved the embedding for uncompromising.\n",
      "unconcerned is at index 28198\n",
      "Saved the embedding for unconcerned.\n",
      "unconfident is at index 542\n",
      "Saved the embedding for unconfident.\n",
      "unconvinced is at index 28198\n",
      "Saved the embedding for unconvinced.\n",
      "uncooperative is at index 542\n",
      "Saved the embedding for uncooperative.\n",
      "uncurious is at index 16511\n",
      "Saved the embedding for uncurious.\n",
      "undecided is at index 28598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for undecided.\n",
      "underhanded is at index 223\n",
      "Saved the embedding for underhanded.\n",
      "understanding is at index 2969\n",
      "Saved the embedding for understanding.\n",
      "undesirable is at index 39028\n",
      "Saved the embedding for undesirable.\n",
      "unease is at index 12515\n",
      "Saved the embedding for unease.\n",
      "uneasily is at index 12515\n",
      "Saved the embedding for uneasily.\n",
      "uneasiness is at index 12515\n",
      "Saved the embedding for uneasiness.\n",
      "uneasy is at index 29569\n",
      "Saved the embedding for uneasy.\n",
      "unemotional is at index 542\n",
      "Saved the embedding for unemotional.\n",
      "unenthusiastic is at index 542\n",
      "Saved the embedding for unenthusiastic.\n",
      "unexcited is at index 39432\n",
      "Saved the embedding for unexcited.\n",
      "unexpected is at index 7152\n",
      "Saved the embedding for unexpected.\n",
      "unfamiliar is at index 21942\n",
      "Saved the embedding for unfamiliar.\n",
      "unfathomable is at index 9515\n",
      "Saved the embedding for unfathomable.\n",
      "unfazed is at index 9515\n",
      "Saved the embedding for unfazed.\n",
      "unfeeling is at index 9515\n",
      "Saved the embedding for unfeeling.\n",
      "unfocused is at index 47306\n",
      "Saved the embedding for unfocused.\n",
      "unforeseen is at index 33257\n",
      "Saved the embedding for unforeseen.\n",
      "unforgiving is at index 34262\n",
      "Saved the embedding for unforgiving.\n",
      "unforthcoming is at index 9515\n",
      "Saved the embedding for unforthcoming.\n",
      "unfortunate is at index 9327\n",
      "Saved the embedding for unfortunate.\n",
      "unfriendly is at index 9515\n",
      "Saved the embedding for unfriendly.\n",
      "unhappy is at index 13865\n",
      "Saved the embedding for unhappy.\n",
      "unhinged is at index 542\n",
      "Saved the embedding for unhinged.\n",
      "unimpressed is at index 542\n",
      "Saved the embedding for unimpressed.\n",
      "uninformed is at index 21969\n",
      "Saved the embedding for uninformed.\n",
      "uninspired is at index 542\n",
      "Saved the embedding for uninspired.\n",
      "uninterested is at index 542\n",
      "Saved the embedding for uninterested.\n",
      "uninvolved is at index 542\n",
      "Saved the embedding for uninvolved.\n",
      "unique is at index 2216\n",
      "Saved the embedding for unique.\n",
      "unlikeable is at index 7328\n",
      "Saved the embedding for unlikeable.\n",
      "unmoved is at index 30780\n",
      "Saved the embedding for unmoved.\n",
      "unnerved is at index 31550\n",
      "Saved the embedding for unnerved.\n",
      "unpleasant is at index 26262\n",
      "Saved the embedding for unpleasant.\n",
      "unprepared is at index 35578\n",
      "Saved the embedding for unprepared.\n",
      "unquiet is at index 542\n",
      "Saved the embedding for unquiet.\n",
      "unreactive is at index 21153\n",
      "Saved the embedding for unreactive.\n",
      "unresolved is at index 29909\n",
      "Saved the embedding for unresolved.\n",
      "unrestrained is at index 12254\n",
      "Saved the embedding for unrestrained.\n",
      "unruffled is at index 542\n",
      "Saved the embedding for unruffled.\n",
      "unsatisfied is at index 36010\n",
      "Saved the embedding for unsatisfied.\n",
      "unsettled is at index 30933\n",
      "Saved the embedding for unsettled.\n",
      "unsociable is at index 9977\n",
      "Saved the embedding for unsociable.\n",
      "unspeaking is at index 542\n",
      "Saved the embedding for unspeaking.\n",
      "unspoken is at index 542\n",
      "Saved the embedding for unspoken.\n",
      "unstrung is at index 542\n",
      "Saved the embedding for unstrung.\n",
      "unsuccessful is at index 15943\n",
      "Saved the embedding for unsuccessful.\n",
      "unsure is at index 17118\n",
      "Saved the embedding for unsure.\n",
      "unsurprised is at index 36637\n",
      "Saved the embedding for unsurprised.\n",
      "unsuspecting is at index 32276\n",
      "Saved the embedding for unsuspecting.\n",
      "unswayed is at index 9977\n",
      "Saved the embedding for unswayed.\n",
      "unsympathetic is at index 542\n",
      "Saved the embedding for unsympathetic.\n",
      "untouched is at index 29929\n",
      "Saved the embedding for untouched.\n",
      "untroubled is at index 7587\n",
      "Saved the embedding for untroubled.\n",
      "untrusting is at index 7587\n",
      "Saved the embedding for untrusting.\n",
      "unwanted is at index 15067\n",
      "Saved the embedding for unwanted.\n",
      "unwavering is at index 10963\n",
      "Saved the embedding for unwavering.\n",
      "unwelcoming is at index 10963\n",
      "Saved the embedding for unwelcoming.\n",
      "unwell is at index 542\n",
      "Saved the embedding for unwell.\n",
      "unwilling is at index 20656\n",
      "Saved the embedding for unwilling.\n",
      "unyielding is at index 542\n",
      "Saved the embedding for unyielding.\n",
      "up is at index 62\n",
      "Saved the embedding for up.\n",
      "upbeat is at index 14899\n",
      "Saved the embedding for upbeat.\n",
      "uplifting is at index 17627\n",
      "Saved the embedding for uplifting.\n",
      "uppity is at index 1717\n",
      "Saved the embedding for uppity.\n",
      "upset is at index 4904\n",
      "Saved the embedding for upset.\n",
      "uptight is at index 18256\n",
      "Saved the embedding for uptight.\n",
      "useless is at index 23584\n",
      "Saved the embedding for useless.\n",
      "vacant is at index 11042\n",
      "Saved the embedding for vacant.\n",
      "vacuous is at index 18721\n",
      "Saved the embedding for vacuous.\n",
      "vanquished is at index 44400\n",
      "Saved the embedding for vanquished.\n",
      "vehement is at index 45373\n",
      "Saved the embedding for vehement.\n",
      "vengeful is at index 748\n",
      "Saved the embedding for vengeful.\n",
      "venomous is at index 32051\n",
      "Saved the embedding for venomous.\n",
      "vex is at index 37894\n",
      "Saved the embedding for vex.\n",
      "vexation is at index 37894\n",
      "Saved the embedding for vexation.\n",
      "vexed is at index 37894\n",
      "Saved the embedding for vexed.\n",
      "vicious is at index 16339\n",
      "Saved the embedding for vicious.\n",
      "victorious is at index 22518\n",
      "Saved the embedding for victorious.\n",
      "vigilant is at index 17258\n",
      "Saved the embedding for vigilant.\n",
      "vile is at index 32359\n",
      "Saved the embedding for vile.\n",
      "villainous is at index 17031\n",
      "Saved the embedding for villainous.\n",
      "vindictive is at index 21339\n",
      "Saved the embedding for vindictive.\n",
      "violence is at index 1476\n",
      "Saved the embedding for violence.\n",
      "violent is at index 4153\n",
      "Saved the embedding for violent.\n",
      "viperous is at index 748\n",
      "Saved the embedding for viperous.\n",
      "vituperative is at index 14306\n",
      "Saved the embedding for vituperative.\n",
      "vocal is at index 7578\n",
      "Saved the embedding for vocal.\n",
      "vocalized is at index 7578\n",
      "Saved the embedding for vocalized.\n",
      "vulgar is at index 28792\n",
      "Saved the embedding for vulgar.\n",
      "vulnerability is at index 15661\n",
      "Saved the embedding for vulnerability.\n",
      "vulnerable is at index 4478\n",
      "Saved the embedding for vulnerable.\n",
      "wacky is at index 885\n",
      "Saved the embedding for wacky.\n",
      "waiting is at index 2445\n",
      "Saved the embedding for waiting.\n",
      "wanted is at index 770\n",
      "Saved the embedding for wanted.\n",
      "wanting is at index 6923\n",
      "Saved the embedding for wanting.\n",
      "wanton is at index 236\n",
      "Saved the embedding for wanton.\n",
      "wariness is at index 997\n",
      "Saved the embedding for wariness.\n",
      "warm is at index 3279\n",
      "Saved the embedding for warm.\n",
      "wary is at index 13441\n",
      "Saved the embedding for wary.\n",
      "wasted is at index 14260\n",
      "Saved the embedding for wasted.\n",
      "watch is at index 1183\n",
      "Saved the embedding for watch.\n",
      "watchful is at index 1183\n",
      "Saved the embedding for watchful.\n",
      "watching is at index 2494\n",
      "Saved the embedding for watching.\n",
      "wavering is at index 13332\n",
      "Saved the embedding for wavering.\n",
      "weariness is at index 3568\n",
      "Saved the embedding for weariness.\n",
      "weary is at index 31554\n",
      "Saved the embedding for weary.\n",
      "weeping is at index 39423\n",
      "Saved the embedding for weeping.\n",
      "weird is at index 7735\n",
      "Saved the embedding for weird.\n",
      "welcome is at index 2814\n",
      "Saved the embedding for welcome.\n",
      "welcoming is at index 10423\n",
      "Saved the embedding for welcoming.\n",
      "whatever is at index 3046\n",
      "Saved the embedding for whatever.\n",
      "whimpering is at index 31754\n",
      "Saved the embedding for whimpering.\n",
      "whimsical is at index 29363\n",
      "Saved the embedding for whimsical.\n",
      "whisper is at index 37539\n",
      "Saved the embedding for whisper.\n",
      "whistle is at index 16867\n",
      "Saved the embedding for whistle.\n",
      "white is at index 1104\n",
      "Saved the embedding for white.\n",
      "wicked is at index 28418\n",
      "Saved the embedding for wicked.\n",
      "wild is at index 3418\n",
      "Saved the embedding for wild.\n",
      "willful is at index 40960\n",
      "Saved the embedding for willful.\n",
      "willing is at index 2882\n",
      "Saved the embedding for willing.\n",
      "wily is at index 885\n",
      "Saved the embedding for wily.\n",
      "wink is at index 39422\n",
      "Saved the embedding for wink.\n",
      "wired is at index 26977\n",
      "Saved the embedding for wired.\n",
      "wishful is at index 2813\n",
      "Saved the embedding for wishful.\n",
      "wistful is at index 885\n",
      "Saved the embedding for wistful.\n",
      "wistfully is at index 885\n",
      "Saved the embedding for wistfully.\n",
      "withdraw is at index 8202\n",
      "Saved the embedding for withdraw.\n",
      "withdrawn is at index 13375\n",
      "Saved the embedding for withdrawn.\n",
      "withheld is at index 22292\n",
      "Saved the embedding for withheld.\n",
      "withholding is at index 25661\n",
      "Saved the embedding for withholding.\n",
      "woe is at index 885\n",
      "Saved the embedding for woe.\n",
      "woeful is at index 19958\n",
      "Saved the embedding for woeful.\n",
      "wonder is at index 5170\n",
      "Saved the embedding for wonder.\n",
      "wondering is at index 8020\n",
      "Saved the embedding for wondering.\n",
      "wonderment is at index 5170\n",
      "Saved the embedding for wonderment.\n",
      "wooly is at index 24815\n",
      "Saved the embedding for wooly.\n",
      "woozy is at index 24815\n",
      "Saved the embedding for woozy.\n",
      "worn is at index 10610\n",
      "Saved the embedding for worn.\n",
      "worried is at index 3915\n",
      "Saved the embedding for worried.\n",
      "worrisome is at index 29611\n",
      "Saved the embedding for worrisome.\n",
      "worry is at index 4022\n",
      "Saved the embedding for worry.\n",
      "worrying is at index 12648\n",
      "Saved the embedding for worrying.\n",
      "worryingly is at index 4022\n",
      "Saved the embedding for worryingly.\n",
      "wounded is at index 5424\n",
      "Saved the embedding for wounded.\n",
      "wow is at index 26388\n",
      "Saved the embedding for wow.\n",
      "wrathful is at index 30220\n",
      "Saved the embedding for wrathful.\n",
      "wrathfully is at index 30220\n",
      "Saved the embedding for wrathfully.\n",
      "wrecked is at index 30090\n",
      "Saved the embedding for wrecked.\n",
      "wretched is at index 42824\n",
      "Saved the embedding for wretched.\n",
      "wronged is at index 1593\n",
      "Saved the embedding for wronged.\n",
      "wroth is at index 885\n",
      "Saved the embedding for wroth.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wry is at index 885\n",
      "Saved the embedding for wry.\n",
      "yawn is at index 39654\n",
      "Saved the embedding for yawn.\n",
      "yawning is at index 39654\n",
      "Saved the embedding for yawning.\n",
      "yearning is at index 76\n",
      "Saved the embedding for yearning.\n",
      "yell is at index 28930\n",
      "Saved the embedding for yell.\n",
      "yelling is at index 16600\n",
      "Saved the embedding for yelling.\n",
      "yielding is at index 25438\n",
      "Saved the embedding for yielding.\n",
      "yuck is at index 1423\n",
      "Saved the embedding for yuck.\n",
      "zany is at index 992\n",
      "Saved the embedding for zany.\n",
      "zealous is at index 992\n",
      "Saved the embedding for zealous.\n",
      "zen is at index 992\n",
      "Saved the embedding for zen.\n",
      "zoned is at index 992\n",
      "Saved the embedding for zoned.\n"
     ]
    }
   ],
   "source": [
    "################################################\n",
    "# This cell will write out input embeddings    #\n",
    "# for all the words in my                      #\n",
    "# vocabulary, using RoBERTa fine-tuned once on #\n",
    "# Common Crawl training text.                  #\n",
    "################################################\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = RobertaTokenizer.from_pretrained('./output_CC-aa/')\n",
    "\n",
    "model = RobertaForMaskedLM.from_pretrained('./output_CC-aa/', config=config)\n",
    "\n",
    "config = RobertaConfig.from_pretrained('./output_CC-aa/')\n",
    "config.output_hidden_states = True\n",
    "input_embeddings = model.get_input_embeddings()\n",
    "embeddings_file = '/home/jupyter/Notebooks/crystal/NLP/nlp_testing/embeddings_context_vocab/roberta_input_CC_aa.txt'\n",
    "for v in vocab:\n",
    "    v_tensor = torch.tensor([tokenizer.encode(v)])\n",
    "    # Print the index of the test word.\n",
    "    print(f'{v} is at index {v_tensor[0][1].item()}')\n",
    "#     print(input_embeddings_test(torch.LongTensor([v_tensor[0][1].item()])))\n",
    "    v_embed = input_embeddings(torch.LongTensor([v_tensor[0][1].item()]))\n",
    "#     for n in range(v_embed.size()[1])\n",
    "    try:\n",
    "        with open(embeddings_file, 'a') as f:\n",
    "            f.write(v)\n",
    "            for value in v_embed[0]:\n",
    "                f.write(' ' + str(value.item()))\n",
    "            f.write('\\n')\n",
    "        print(f'Saved the embedding for {v}.')\n",
    "    except:\n",
    "        print('Oh no! Unable to write to the embeddings file.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aback is at index 36347\n",
      "Saved the embedding for aback.\n",
      "abashed is at index 4091\n",
      "Saved the embedding for abashed.\n",
      "abhor is at index 35350\n",
      "Saved the embedding for abhor.\n",
      "abhorred is at index 35350\n",
      "Saved the embedding for abhorred.\n",
      "abhorrence is at index 35350\n",
      "Saved the embedding for abhorrence.\n",
      "abhorrent is at index 35350\n",
      "Saved the embedding for abhorrent.\n",
      "abominable is at index 4091\n",
      "Saved the embedding for abominable.\n",
      "abound is at index 32937\n",
      "Saved the embedding for abound.\n",
      "absent is at index 11640\n",
      "Saved the embedding for absent.\n",
      "absorbed is at index 22416\n",
      "Saved the embedding for absorbed.\n",
      "acceptance is at index 10502\n",
      "Saved the embedding for acceptance.\n",
      "accepted is at index 3903\n",
      "Saved the embedding for accepted.\n",
      "accepting is at index 8394\n",
      "Saved the embedding for accepting.\n",
      "accommodating is at index 33681\n",
      "Saved the embedding for accommodating.\n",
      "accomplished is at index 9370\n",
      "Saved the embedding for accomplished.\n",
      "accordant is at index 10170\n",
      "Saved the embedding for accordant.\n",
      "accursed is at index 7678\n",
      "Saved the embedding for accursed.\n",
      "accusatory is at index 23123\n",
      "Saved the embedding for accusatory.\n",
      "accused is at index 1238\n",
      "Saved the embedding for accused.\n",
      "accusing is at index 8601\n",
      "Saved the embedding for accusing.\n",
      "acerbic is at index 4285\n",
      "Saved the embedding for acerbic.\n",
      "acidic is at index 41314\n",
      "Saved the embedding for acidic.\n",
      "active is at index 2171\n",
      "Saved the embedding for active.\n",
      "acute is at index 13827\n",
      "Saved the embedding for acute.\n",
      "adamant is at index 22668\n",
      "Saved the embedding for adamant.\n",
      "addled is at index 1606\n",
      "Saved the embedding for addled.\n",
      "admiration is at index 24287\n",
      "Saved the embedding for admiration.\n",
      "admit is at index 8109\n",
      "Saved the embedding for admit.\n",
      "adoration is at index 2329\n",
      "Saved the embedding for adoration.\n",
      "adoring is at index 2329\n",
      "Saved the embedding for adoring.\n",
      "adrift is at index 2329\n",
      "Saved the embedding for adrift.\n",
      "adversarial is at index 37930\n",
      "Saved the embedding for adversarial.\n",
      "affability is at index 11129\n",
      "Saved the embedding for affability.\n",
      "affected is at index 2132\n",
      "Saved the embedding for affected.\n",
      "affectionate is at index 15955\n",
      "Saved the embedding for affectionate.\n",
      "afflicted is at index 39234\n",
      "Saved the embedding for afflicted.\n",
      "affronted is at index 11129\n",
      "Saved the embedding for affronted.\n",
      "aflutter is at index 10\n",
      "Saved the embedding for aflutter.\n",
      "afraid is at index 6023\n",
      "Saved the embedding for afraid.\n",
      "agape is at index 5951\n",
      "Saved the embedding for agape.\n",
      "aggravated is at index 10040\n",
      "Saved the embedding for aggravated.\n",
      "aggravation is at index 29223\n",
      "Saved the embedding for aggravation.\n",
      "aggression is at index 14227\n",
      "Saved the embedding for aggression.\n",
      "aggressive is at index 4353\n",
      "Saved the embedding for aggressive.\n",
      "aggrieve is at index 28940\n",
      "Saved the embedding for aggrieve.\n",
      "aggrieved is at index 28940\n",
      "Saved the embedding for aggrieved.\n",
      "aghast is at index 10\n",
      "Saved the embedding for aghast.\n",
      "agitated is at index 33426\n",
      "Saved the embedding for agitated.\n",
      "agog is at index 5951\n",
      "Saved the embedding for agog.\n",
      "agonized is at index 27497\n",
      "Saved the embedding for agonized.\n",
      "agreeable is at index 43359\n",
      "Saved the embedding for agreeable.\n",
      "agressive is at index 5951\n",
      "Saved the embedding for agressive.\n",
      "airhead is at index 935\n",
      "Saved the embedding for airhead.\n",
      "alarm is at index 8054\n",
      "Saved the embedding for alarm.\n",
      "alarmed is at index 23438\n",
      "Saved the embedding for alarmed.\n",
      "alarming is at index 16156\n",
      "Saved the embedding for alarming.\n",
      "alert is at index 5439\n",
      "Saved the embedding for alert.\n",
      "alerted is at index 14588\n",
      "Saved the embedding for alerted.\n",
      "alienated is at index 36462\n",
      "Saved the embedding for alienated.\n",
      "allergic is at index 28349\n",
      "Saved the embedding for allergic.\n",
      "alleviated is at index 32216\n",
      "Saved the embedding for alleviated.\n",
      "alluring is at index 70\n",
      "Saved the embedding for alluring.\n",
      "aloof is at index 1076\n",
      "Saved the embedding for aloof.\n",
      "amatory is at index 524\n",
      "Saved the embedding for amatory.\n",
      "amazed is at index 22431\n",
      "Saved the embedding for amazed.\n",
      "amazement is at index 42402\n",
      "Saved the embedding for amazement.\n",
      "amazing is at index 2770\n",
      "Saved the embedding for amazing.\n",
      "ambition is at index 12831\n",
      "Saved the embedding for ambition.\n",
      "ambitious is at index 8263\n",
      "Saved the embedding for ambitious.\n",
      "ambivalence is at index 13569\n",
      "Saved the embedding for ambivalence.\n",
      "ambivalent is at index 13569\n",
      "Saved the embedding for ambivalent.\n",
      "amenable is at index 524\n",
      "Saved the embedding for amenable.\n",
      "amiable is at index 524\n",
      "Saved the embedding for amiable.\n",
      "amicable is at index 524\n",
      "Saved the embedding for amicable.\n",
      "amused is at index 36530\n",
      "Saved the embedding for amused.\n",
      "amusement is at index 28445\n",
      "Saved the embedding for amusement.\n",
      "analytical is at index 23554\n",
      "Saved the embedding for analytical.\n",
      "analyzing is at index 18999\n",
      "Saved the embedding for analyzing.\n",
      "anger is at index 6378\n",
      "Saved the embedding for anger.\n",
      "angered is at index 20166\n",
      "Saved the embedding for angered.\n",
      "angrily is at index 30302\n",
      "Saved the embedding for angrily.\n",
      "angry is at index 5800\n",
      "Saved the embedding for angry.\n",
      "angst is at index 33010\n",
      "Saved the embedding for angst.\n",
      "anguish is at index 32446\n",
      "Saved the embedding for anguish.\n",
      "anguished is at index 5667\n",
      "Saved the embedding for anguished.\n",
      "animated is at index 12847\n",
      "Saved the embedding for animated.\n",
      "animosity is at index 34351\n",
      "Saved the embedding for animosity.\n",
      "annoyance is at index 39341\n",
      "Saved the embedding for annoyance.\n",
      "annoyed is at index 26678\n",
      "Saved the embedding for annoyed.\n",
      "annoying is at index 19887\n",
      "Saved the embedding for annoying.\n",
      "antagonistic is at index 32726\n",
      "Saved the embedding for antagonistic.\n",
      "antagonized is at index 32726\n",
      "Saved the embedding for antagonized.\n",
      "anticipated is at index 5291\n",
      "Saved the embedding for anticipated.\n",
      "anticipating is at index 22535\n",
      "Saved the embedding for anticipating.\n",
      "anticipation is at index 14714\n",
      "Saved the embedding for anticipation.\n",
      "anticipative is at index 21428\n",
      "Saved the embedding for anticipative.\n",
      "anticipatory is at index 21428\n",
      "Saved the embedding for anticipatory.\n",
      "antipathy is at index 37554\n",
      "Saved the embedding for antipathy.\n",
      "antsy is at index 32855\n",
      "Saved the embedding for antsy.\n",
      "anxiety is at index 6882\n",
      "Saved the embedding for anxiety.\n",
      "anxious is at index 13473\n",
      "Saved the embedding for anxious.\n",
      "anxiously is at index 27442\n",
      "Saved the embedding for anxiously.\n",
      "apathetic is at index 6256\n",
      "Saved the embedding for apathetic.\n",
      "apathy is at index 6256\n",
      "Saved the embedding for apathy.\n",
      "apologetic is at index 23842\n",
      "Saved the embedding for apologetic.\n",
      "appalled is at index 31514\n",
      "Saved the embedding for appalled.\n",
      "appallingly is at index 1553\n",
      "Saved the embedding for appallingly.\n",
      "appeased is at index 44151\n",
      "Saved the embedding for appeased.\n",
      "appeasing is at index 44151\n",
      "Saved the embedding for appeasing.\n",
      "appreciative is at index 14137\n",
      "Saved the embedding for appreciative.\n",
      "apprehension is at index 34640\n",
      "Saved the embedding for apprehension.\n",
      "apprehensive is at index 33655\n",
      "Saved the embedding for apprehensive.\n",
      "approve is at index 7244\n",
      "Saved the embedding for approve.\n",
      "approved is at index 2033\n",
      "Saved the embedding for approved.\n",
      "approving is at index 20499\n",
      "Saved the embedding for approving.\n",
      "argue is at index 5848\n",
      "Saved the embedding for argue.\n",
      "argumentative is at index 4795\n",
      "Saved the embedding for argumentative.\n",
      "aroused is at index 42941\n",
      "Saved the embedding for aroused.\n",
      "arrogance is at index 32818\n",
      "Saved the embedding for arrogance.\n",
      "arrogant is at index 30967\n",
      "Saved the embedding for arrogant.\n",
      "arrogantly is at index 46553\n",
      "Saved the embedding for arrogantly.\n",
      "artificial is at index 7350\n",
      "Saved the embedding for artificial.\n",
      "ashamed is at index 20085\n",
      "Saved the embedding for ashamed.\n",
      "aspiring is at index 18885\n",
      "Saved the embedding for aspiring.\n",
      "assertive is at index 18088\n",
      "Saved the embedding for assertive.\n",
      "assertively is at index 18088\n",
      "Saved the embedding for assertively.\n",
      "assessing is at index 16629\n",
      "Saved the embedding for assessing.\n",
      "assured is at index 7189\n",
      "Saved the embedding for assured.\n",
      "astonished is at index 40788\n",
      "Saved the embedding for astonished.\n",
      "astonishment is at index 44434\n",
      "Saved the embedding for astonishment.\n",
      "astounded is at index 12976\n",
      "Saved the embedding for astounded.\n",
      "attempting is at index 6475\n",
      "Saved the embedding for attempting.\n",
      "attentive is at index 36670\n",
      "Saved the embedding for attentive.\n",
      "attentiveness is at index 39879\n",
      "Saved the embedding for attentiveness.\n",
      "attracted is at index 7671\n",
      "Saved the embedding for attracted.\n",
      "avenging is at index 38796\n",
      "Saved the embedding for avenging.\n",
      "averse is at index 10\n",
      "Saved the embedding for averse.\n",
      "aversion is at index 33814\n",
      "Saved the embedding for aversion.\n",
      "aversive is at index 10\n",
      "Saved the embedding for aversive.\n",
      "avid is at index 20137\n",
      "Saved the embedding for avid.\n",
      "avoiding is at index 11473\n",
      "Saved the embedding for avoiding.\n",
      "awaiting is at index 10254\n",
      "Saved the embedding for awaiting.\n",
      "awakened is at index 40593\n",
      "Saved the embedding for awakened.\n",
      "aware is at index 2542\n",
      "Saved the embedding for aware.\n",
      "awareness is at index 4199\n",
      "Saved the embedding for awareness.\n",
      "awe is at index 21531\n",
      "Saved the embedding for awe.\n",
      "awed is at index 19267\n",
      "Saved the embedding for awed.\n",
      "awestruck is at index 19267\n",
      "Saved the embedding for awestruck.\n",
      "awful is at index 11522\n",
      "Saved the embedding for awful.\n",
      "awkward is at index 11789\n",
      "Saved the embedding for awkward.\n",
      "awkwardness is at index 11789\n",
      "Saved the embedding for awkwardness.\n",
      "axed is at index 18884\n",
      "Saved the embedding for axed.\n",
      "backhanded is at index 124\n",
      "Saved the embedding for backhanded.\n",
      "badly is at index 7340\n",
      "Saved the embedding for badly.\n",
      "baffle is at index 33139\n",
      "Saved the embedding for baffle.\n",
      "baffled is at index 33396\n",
      "Saved the embedding for baffled.\n",
      "baffling is at index 33139\n",
      "Saved the embedding for baffling.\n",
      "baked is at index 17241\n",
      "Saved the embedding for baked.\n",
      "banal is at index 2020\n",
      "Saved the embedding for banal.\n",
      "barking is at index 35828\n",
      "Saved the embedding for barking.\n",
      "bashful is at index 12882\n",
      "Saved the embedding for bashful.\n",
      "beaming is at index 28\n",
      "Saved the embedding for beaming.\n",
      "bearish is at index 4649\n",
      "Saved the embedding for bearish.\n",
      "beat is at index 1451\n",
      "Saved the embedding for beat.\n",
      "beaten is at index 6432\n",
      "Saved the embedding for beaten.\n",
      "bedeviled is at index 3267\n",
      "Saved the embedding for bedeviled.\n",
      "befuddled is at index 28\n",
      "Saved the embedding for befuddled.\n",
      "begging is at index 22901\n",
      "Saved the embedding for begging.\n",
      "begrudge is at index 28\n",
      "Saved the embedding for begrudge.\n",
      "begrudging is at index 28\n",
      "Saved the embedding for begrudging.\n",
      "begrudgingly is at index 28\n",
      "Saved the embedding for begrudgingly.\n",
      "beguiled is at index 21422\n",
      "Saved the embedding for beguiled.\n",
      "belated is at index 12138\n",
      "Saved the embedding for belated.\n",
      "belittling is at index 12138\n",
      "Saved the embedding for belittling.\n",
      "belligerence is at index 35756\n",
      "Saved the embedding for belligerence.\n",
      "belligerent is at index 35756\n",
      "Saved the embedding for belligerent.\n",
      "belonging is at index 11441\n",
      "Saved the embedding for belonging.\n",
      "bemused is at index 28\n",
      "Saved the embedding for bemused.\n",
      "bemusement is at index 28\n",
      "Saved the embedding for bemusement.\n",
      "benevolence is at index 42364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for benevolence.\n",
      "benevolent is at index 43186\n",
      "Saved the embedding for benevolent.\n",
      "benumbed is at index 21576\n",
      "Saved the embedding for benumbed.\n",
      "berate is at index 14719\n",
      "Saved the embedding for berate.\n",
      "berating is at index 14719\n",
      "Saved the embedding for berating.\n",
      "bereaved is at index 17738\n",
      "Saved the embedding for bereaved.\n",
      "bereft is at index 17738\n",
      "Saved the embedding for bereft.\n",
      "beseeching is at index 9988\n",
      "Saved the embedding for beseeching.\n",
      "bested is at index 275\n",
      "Saved the embedding for bested.\n",
      "betrayal is at index 26760\n",
      "Saved the embedding for betrayal.\n",
      "betrayed is at index 26913\n",
      "Saved the embedding for betrayed.\n",
      "bewildered is at index 33304\n",
      "Saved the embedding for bewildered.\n",
      "bewilderment is at index 33304\n",
      "Saved the embedding for bewilderment.\n",
      "bi is at index 4003\n",
      "Saved the embedding for bi.\n",
      "bilious is at index 31617\n",
      "Saved the embedding for bilious.\n",
      "bit is at index 828\n",
      "Saved the embedding for bit.\n",
      "biting is at index 25609\n",
      "Saved the embedding for biting.\n",
      "bitter is at index 10513\n",
      "Saved the embedding for bitter.\n",
      "bittersweet is at index 28609\n",
      "Saved the embedding for bittersweet.\n",
      "blaming is at index 15249\n",
      "Saved the embedding for blaming.\n",
      "bland is at index 35063\n",
      "Saved the embedding for bland.\n",
      "blank is at index 15818\n",
      "Saved the embedding for blank.\n",
      "blase is at index 3089\n",
      "Saved the embedding for blase.\n",
      "blazed is at index 3089\n",
      "Saved the embedding for blazed.\n",
      "bleak is at index 23530\n",
      "Saved the embedding for bleak.\n",
      "bleary is at index 13819\n",
      "Saved the embedding for bleary.\n",
      "blessed is at index 12230\n",
      "Saved the embedding for blessed.\n",
      "blew is at index 10879\n",
      "Saved the embedding for blew.\n",
      "blinded is at index 40094\n",
      "Saved the embedding for blinded.\n",
      "blindsided is at index 7709\n",
      "Saved the embedding for blindsided.\n",
      "bliss is at index 30299\n",
      "Saved the embedding for bliss.\n",
      "blissful is at index 30299\n",
      "Saved the embedding for blissful.\n",
      "blissfully is at index 30299\n",
      "Saved the embedding for blissfully.\n",
      "blithe is at index 3089\n",
      "Saved the embedding for blithe.\n",
      "blown is at index 12315\n",
      "Saved the embedding for blown.\n",
      "blue is at index 2440\n",
      "Saved the embedding for blue.\n",
      "blues is at index 15629\n",
      "Saved the embedding for blues.\n",
      "bluffing is at index 37372\n",
      "Saved the embedding for bluffing.\n",
      "blunt is at index 18720\n",
      "Saved the embedding for blunt.\n",
      "blushing is at index 3089\n",
      "Saved the embedding for blushing.\n",
      "blustering is at index 3089\n",
      "Saved the embedding for blustering.\n",
      "boastful is at index 18639\n",
      "Saved the embedding for boastful.\n",
      "boggled is at index 741\n",
      "Saved the embedding for boggled.\n",
      "boiling is at index 27513\n",
      "Saved the embedding for boiling.\n",
      "boisterous is at index 5276\n",
      "Saved the embedding for boisterous.\n",
      "bold is at index 7457\n",
      "Saved the embedding for bold.\n",
      "bored is at index 23809\n",
      "Saved the embedding for bored.\n",
      "boredom is at index 40326\n",
      "Saved the embedding for boredom.\n",
      "boring is at index 15305\n",
      "Saved the embedding for boring.\n",
      "bothered is at index 18523\n",
      "Saved the embedding for bothered.\n",
      "bounder is at index 8191\n",
      "Saved the embedding for bounder.\n",
      "brashness is at index 5378\n",
      "Saved the embedding for brashness.\n",
      "bratty is at index 5378\n",
      "Saved the embedding for bratty.\n",
      "brave is at index 10025\n",
      "Saved the embedding for brave.\n",
      "bright is at index 4520\n",
      "Saved the embedding for bright.\n",
      "bristling is at index 37135\n",
      "Saved the embedding for bristling.\n",
      "broken is at index 3187\n",
      "Saved the embedding for broken.\n",
      "brokenhearted is at index 3187\n",
      "Saved the embedding for brokenhearted.\n",
      "brokenheartedly is at index 3187\n",
      "Saved the embedding for brokenheartedly.\n",
      "brooding is at index 11051\n",
      "Saved the embedding for brooding.\n",
      "broody is at index 11051\n",
      "Saved the embedding for broody.\n",
      "bruised is at index 26360\n",
      "Saved the embedding for bruised.\n",
      "brusque is at index 5378\n",
      "Saved the embedding for brusque.\n",
      "bug is at index 13673\n",
      "Saved the embedding for bug.\n",
      "bulging is at index 22382\n",
      "Saved the embedding for bulging.\n",
      "bully is at index 23934\n",
      "Saved the embedding for bully.\n",
      "bullying is at index 11902\n",
      "Saved the embedding for bullying.\n",
      "bummed is at index 29673\n",
      "Saved the embedding for bummed.\n",
      "buoyant is at index 15980\n",
      "Saved the embedding for buoyant.\n",
      "burdened is at index 32875\n",
      "Saved the embedding for burdened.\n",
      "burn is at index 7403\n",
      "Saved the embedding for burn.\n",
      "bursting is at index 28548\n",
      "Saved the embedding for bursting.\n",
      "bushed is at index 2353\n",
      "Saved the embedding for bushed.\n",
      "cagey is at index 16051\n",
      "Saved the embedding for cagey.\n",
      "cagy is at index 740\n",
      "Saved the embedding for cagy.\n",
      "calculating is at index 29770\n",
      "Saved the embedding for calculating.\n",
      "callous is at index 486\n",
      "Saved the embedding for callous.\n",
      "callused is at index 486\n",
      "Saved the embedding for callused.\n",
      "calm is at index 6327\n",
      "Saved the embedding for calm.\n",
      "calming is at index 31220\n",
      "Saved the embedding for calming.\n",
      "calmness is at index 6327\n",
      "Saved the embedding for calmness.\n",
      "canny is at index 64\n",
      "Saved the embedding for canny.\n",
      "cantankerous is at index 17672\n",
      "Saved the embedding for cantankerous.\n",
      "capable is at index 4453\n",
      "Saved the embedding for capable.\n",
      "capricious is at index 2927\n",
      "Saved the embedding for capricious.\n",
      "captivated is at index 13363\n",
      "Saved the embedding for captivated.\n",
      "captive is at index 24145\n",
      "Saved the embedding for captive.\n",
      "carefree is at index 575\n",
      "Saved the embedding for carefree.\n",
      "careful is at index 7316\n",
      "Saved the embedding for careful.\n",
      "careless is at index 29399\n",
      "Saved the embedding for careless.\n",
      "caring is at index 10837\n",
      "Saved the embedding for caring.\n",
      "catty is at index 4758\n",
      "Saved the embedding for catty.\n",
      "caustic is at index 6056\n",
      "Saved the embedding for caustic.\n",
      "cautionary is at index 8038\n",
      "Saved the embedding for cautionary.\n",
      "cautious is at index 9420\n",
      "Saved the embedding for cautious.\n",
      "cavalier is at index 41869\n",
      "Saved the embedding for cavalier.\n",
      "celebrating is at index 6146\n",
      "Saved the embedding for celebrating.\n",
      "celebration is at index 4821\n",
      "Saved the embedding for celebration.\n",
      "censure is at index 26489\n",
      "Saved the embedding for censure.\n",
      "centered is at index 14889\n",
      "Saved the embedding for centered.\n",
      "certain is at index 1402\n",
      "Saved the embedding for certain.\n",
      "chafed is at index 1855\n",
      "Saved the embedding for chafed.\n",
      "chagrin is at index 1855\n",
      "Saved the embedding for chagrin.\n",
      "chagrined is at index 1855\n",
      "Saved the embedding for chagrined.\n",
      "chagrinned is at index 1855\n",
      "Saved the embedding for chagrinned.\n",
      "challenge is at index 1539\n",
      "Saved the embedding for challenge.\n",
      "challenged is at index 6835\n",
      "Saved the embedding for challenged.\n",
      "challenging is at index 4087\n",
      "Saved the embedding for challenging.\n",
      "chaotic is at index 16529\n",
      "Saved the embedding for chaotic.\n",
      "charged is at index 1340\n",
      "Saved the embedding for charged.\n",
      "charmed is at index 16224\n",
      "Saved the embedding for charmed.\n",
      "charming is at index 18452\n",
      "Saved the embedding for charming.\n",
      "chary is at index 1855\n",
      "Saved the embedding for chary.\n",
      "cheated is at index 25177\n",
      "Saved the embedding for cheated.\n",
      "cheeky is at index 15401\n",
      "Saved the embedding for cheeky.\n",
      "cheered is at index 18643\n",
      "Saved the embedding for cheered.\n",
      "cheerful is at index 33928\n",
      "Saved the embedding for cheerful.\n",
      "cheering is at index 16765\n",
      "Saved the embedding for cheering.\n",
      "cheerless is at index 9450\n",
      "Saved the embedding for cheerless.\n",
      "cheery is at index 5851\n",
      "Saved the embedding for cheery.\n",
      "cheesy is at index 36331\n",
      "Saved the embedding for cheesy.\n",
      "chesty is at index 7050\n",
      "Saved the embedding for chesty.\n",
      "chide is at index 1855\n",
      "Saved the embedding for chide.\n",
      "chiding is at index 1855\n",
      "Saved the embedding for chiding.\n",
      "childish is at index 40531\n",
      "Saved the embedding for childish.\n",
      "childishly is at index 920\n",
      "Saved the embedding for childishly.\n",
      "childlike is at index 920\n",
      "Saved the embedding for childlike.\n",
      "chill is at index 13146\n",
      "Saved the embedding for chill.\n",
      "chilled is at index 32338\n",
      "Saved the embedding for chilled.\n",
      "chilling is at index 22577\n",
      "Saved the embedding for chilling.\n",
      "chipper is at index 1855\n",
      "Saved the embedding for chipper.\n",
      "chirpy is at index 1855\n",
      "Saved the embedding for chirpy.\n",
      "choleric is at index 1855\n",
      "Saved the embedding for choleric.\n",
      "chortling is at index 1855\n",
      "Saved the embedding for chortling.\n",
      "chuckle is at index 37496\n",
      "Saved the embedding for chuckle.\n",
      "chuckling is at index 34600\n",
      "Saved the embedding for chuckling.\n",
      "churlish is at index 1855\n",
      "Saved the embedding for churlish.\n",
      "circumspect is at index 38529\n",
      "Saved the embedding for circumspect.\n",
      "clamorous is at index 24045\n",
      "Saved the embedding for clamorous.\n",
      "clash is at index 6064\n",
      "Saved the embedding for clash.\n",
      "clear is at index 699\n",
      "Saved the embedding for clear.\n",
      "clenched is at index 44646\n",
      "Saved the embedding for clenched.\n",
      "clever is at index 13074\n",
      "Saved the embedding for clever.\n",
      "close is at index 593\n",
      "Saved the embedding for close.\n",
      "closed is at index 1367\n",
      "Saved the embedding for closed.\n",
      "closemouthed is at index 593\n",
      "Saved the embedding for closemouthed.\n",
      "cloy is at index 3741\n",
      "Saved the embedding for cloy.\n",
      "clueless is at index 36776\n",
      "Saved the embedding for clueless.\n",
      "clutched is at index 29409\n",
      "Saved the embedding for clutched.\n",
      "cluttered is at index 29409\n",
      "Saved the embedding for cluttered.\n",
      "cockeyed is at index 740\n",
      "Saved the embedding for cockeyed.\n",
      "cockiness is at index 24231\n",
      "Saved the embedding for cockiness.\n",
      "cocksure is at index 740\n",
      "Saved the embedding for cocksure.\n",
      "cocky is at index 24231\n",
      "Saved the embedding for cocky.\n",
      "cognizant is at index 28105\n",
      "Saved the embedding for cognizant.\n",
      "cold is at index 2569\n",
      "Saved the embedding for cold.\n",
      "collected is at index 4786\n",
      "Saved the embedding for collected.\n",
      "collusive is at index 9843\n",
      "Saved the embedding for collusive.\n",
      "colonized is at index 17735\n",
      "Saved the embedding for colonized.\n",
      "combative is at index 14960\n",
      "Saved the embedding for combative.\n",
      "comedic is at index 29045\n",
      "Saved the embedding for comedic.\n",
      "comfort is at index 5863\n",
      "Saved the embedding for comfort.\n",
      "comfortable is at index 3473\n",
      "Saved the embedding for comfortable.\n",
      "comforted is at index 5863\n",
      "Saved the embedding for comforted.\n",
      "comical is at index 3137\n",
      "Saved the embedding for comical.\n",
      "commanding is at index 20510\n",
      "Saved the embedding for commanding.\n",
      "commiserating is at index 7034\n",
      "Saved the embedding for commiserating.\n",
      "commiserative is at index 7034\n",
      "Saved the embedding for commiserative.\n",
      "communicative is at index 16759\n",
      "Saved the embedding for communicative.\n",
      "compassion is at index 14736\n",
      "Saved the embedding for compassion.\n",
      "compassionate is at index 23303\n",
      "Saved the embedding for compassionate.\n",
      "competent is at index 17451\n",
      "Saved the embedding for competent.\n",
      "competitive is at index 2695\n",
      "Saved the embedding for competitive.\n",
      "complacence is at index 13000\n",
      "Saved the embedding for complacence.\n",
      "complacency is at index 13000\n",
      "Saved the embedding for complacency.\n",
      "complacent is at index 13000\n",
      "Saved the embedding for complacent.\n",
      "complacently is at index 13000\n",
      "Saved the embedding for complacently.\n",
      "complain is at index 11316\n",
      "Saved the embedding for complain.\n",
      "complaining is at index 13689\n",
      "Saved the embedding for complaining.\n",
      "composed is at index 14092\n",
      "Saved the embedding for composed.\n",
      "comprehending is at index 30030\n",
      "Saved the embedding for comprehending.\n",
      "compulsive is at index 7753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for compulsive.\n",
      "concealed is at index 17180\n",
      "Saved the embedding for concealed.\n",
      "conceding is at index 24647\n",
      "Saved the embedding for conceding.\n",
      "conceited is at index 21177\n",
      "Saved the embedding for conceited.\n",
      "concentrated is at index 15450\n",
      "Saved the embedding for concentrated.\n",
      "concentrating is at index 28619\n",
      "Saved the embedding for concentrating.\n",
      "concentration is at index 11772\n",
      "Saved the embedding for concentration.\n",
      "concern is at index 2212\n",
      "Saved the embedding for concern.\n",
      "concerned is at index 2273\n",
      "Saved the embedding for concerned.\n",
      "conciliatory is at index 10146\n",
      "Saved the embedding for conciliatory.\n",
      "conclusive is at index 37847\n",
      "Saved the embedding for conclusive.\n",
      "condemning is at index 21856\n",
      "Saved the embedding for condemning.\n",
      "condescending is at index 40742\n",
      "Saved the embedding for condescending.\n",
      "condoling is at index 35279\n",
      "Saved the embedding for condoling.\n",
      "confidence is at index 2123\n",
      "Saved the embedding for confidence.\n",
      "confident is at index 3230\n",
      "Saved the embedding for confident.\n",
      "confidently is at index 27447\n",
      "Saved the embedding for confidently.\n",
      "conflicted is at index 34428\n",
      "Saved the embedding for conflicted.\n",
      "confound is at index 7856\n",
      "Saved the embedding for confound.\n",
      "confounded is at index 7856\n",
      "Saved the embedding for confounded.\n",
      "confrontational is at index 10749\n",
      "Saved the embedding for confrontational.\n",
      "confused is at index 10985\n",
      "Saved the embedding for confused.\n",
      "confusion is at index 9655\n",
      "Saved the embedding for confusion.\n",
      "congenial is at index 36764\n",
      "Saved the embedding for congenial.\n",
      "congratulatory is at index 26303\n",
      "Saved the embedding for congratulatory.\n",
      "conniving is at index 39277\n",
      "Saved the embedding for conniving.\n",
      "conscious is at index 13316\n",
      "Saved the embedding for conscious.\n",
      "conservative is at index 3354\n",
      "Saved the embedding for conservative.\n",
      "considerate is at index 1701\n",
      "Saved the embedding for considerate.\n",
      "considering is at index 2811\n",
      "Saved the embedding for considering.\n",
      "consoling is at index 7407\n",
      "Saved the embedding for consoling.\n",
      "conspiratorial is at index 31150\n",
      "Saved the embedding for conspiratorial.\n",
      "conspiring is at index 27230\n",
      "Saved the embedding for conspiring.\n",
      "consternation is at index 10759\n",
      "Saved the embedding for consternation.\n",
      "constipated is at index 10759\n",
      "Saved the embedding for constipated.\n",
      "constrained is at index 26525\n",
      "Saved the embedding for constrained.\n",
      "consumed is at index 13056\n",
      "Saved the embedding for consumed.\n",
      "consuming is at index 16997\n",
      "Saved the embedding for consuming.\n",
      "contained is at index 5558\n",
      "Saved the embedding for contained.\n",
      "contemplate is at index 32848\n",
      "Saved the embedding for contemplate.\n",
      "contemplating is at index 27744\n",
      "Saved the embedding for contemplating.\n",
      "contemplation is at index 44072\n",
      "Saved the embedding for contemplation.\n",
      "contemplative is at index 43580\n",
      "Saved the embedding for contemplative.\n",
      "contempt is at index 16176\n",
      "Saved the embedding for contempt.\n",
      "contemptuous is at index 16176\n",
      "Saved the embedding for contemptuous.\n",
      "content is at index 1383\n",
      "Saved the embedding for content.\n",
      "contented is at index 1383\n",
      "Saved the embedding for contented.\n",
      "contentious is at index 14883\n",
      "Saved the embedding for contentious.\n",
      "contently is at index 8541\n",
      "Saved the embedding for contently.\n",
      "contentment is at index 1383\n",
      "Saved the embedding for contentment.\n",
      "contradictory is at index 31515\n",
      "Saved the embedding for contradictory.\n",
      "contrary is at index 11159\n",
      "Saved the embedding for contrary.\n",
      "contrite is at index 17035\n",
      "Saved the embedding for contrite.\n",
      "controlled is at index 4875\n",
      "Saved the embedding for controlled.\n",
      "controlling is at index 10568\n",
      "Saved the embedding for controlling.\n",
      "controversial is at index 4456\n",
      "Saved the embedding for controversial.\n",
      "contumacious is at index 8541\n",
      "Saved the embedding for contumacious.\n",
      "convinced is at index 7013\n",
      "Saved the embedding for convinced.\n",
      "cool is at index 3035\n",
      "Saved the embedding for cool.\n",
      "cooperative is at index 18777\n",
      "Saved the embedding for cooperative.\n",
      "cordial is at index 13051\n",
      "Saved the embedding for cordial.\n",
      "courageous is at index 24219\n",
      "Saved the embedding for courageous.\n",
      "covert is at index 25523\n",
      "Saved the embedding for covert.\n",
      "cowardly is at index 36881\n",
      "Saved the embedding for cowardly.\n",
      "coy is at index 20176\n",
      "Saved the embedding for coy.\n",
      "crabby is at index 23320\n",
      "Saved the embedding for crabby.\n",
      "crafty is at index 6306\n",
      "Saved the embedding for crafty.\n",
      "cranky is at index 30952\n",
      "Saved the embedding for cranky.\n",
      "crazed is at index 26002\n",
      "Saved the embedding for crazed.\n",
      "crazy is at index 5373\n",
      "Saved the embedding for crazy.\n",
      "credulous is at index 18994\n",
      "Saved the embedding for credulous.\n",
      "creepy is at index 23814\n",
      "Saved the embedding for creepy.\n",
      "crestfallen is at index 32220\n",
      "Saved the embedding for crestfallen.\n",
      "cringing is at index 3977\n",
      "Saved the embedding for cringing.\n",
      "critical is at index 2008\n",
      "Saved the embedding for critical.\n",
      "cross is at index 2116\n",
      "Saved the embedding for cross.\n",
      "crotchety is at index 11398\n",
      "Saved the embedding for crotchety.\n",
      "crude is at index 2976\n",
      "Saved the embedding for crude.\n",
      "cruel is at index 15939\n",
      "Saved the embedding for cruel.\n",
      "crushed is at index 14045\n",
      "Saved the embedding for crushed.\n",
      "cry is at index 8930\n",
      "Saved the embedding for cry.\n",
      "crying is at index 9701\n",
      "Saved the embedding for crying.\n",
      "cryptic is at index 35916\n",
      "Saved the embedding for cryptic.\n",
      "culpable is at index 29410\n",
      "Saved the embedding for culpable.\n",
      "cunning is at index 41526\n",
      "Saved the embedding for cunning.\n",
      "curios is at index 5350\n",
      "Saved the embedding for curios.\n",
      "curiosity is at index 20610\n",
      "Saved the embedding for curiosity.\n",
      "curious is at index 10691\n",
      "Saved the embedding for curious.\n",
      "cutting is at index 3931\n",
      "Saved the embedding for cutting.\n",
      "cynic is at index 40240\n",
      "Saved the embedding for cynic.\n",
      "cynical is at index 27566\n",
      "Saved the embedding for cynical.\n",
      "cynicism is at index 39245\n",
      "Saved the embedding for cynicism.\n",
      "dalliance is at index 385\n",
      "Saved the embedding for dalliance.\n",
      "dandy is at index 385\n",
      "Saved the embedding for dandy.\n",
      "dangerous is at index 2702\n",
      "Saved the embedding for dangerous.\n",
      "darkly is at index 2933\n",
      "Saved the embedding for darkly.\n",
      "daunted is at index 385\n",
      "Saved the embedding for daunted.\n",
      "daydream is at index 183\n",
      "Saved the embedding for daydream.\n",
      "daydreaming is at index 183\n",
      "Saved the embedding for daydreaming.\n",
      "dazed is at index 385\n",
      "Saved the embedding for dazed.\n",
      "dazzled is at index 32614\n",
      "Saved the embedding for dazzled.\n",
      "deadly is at index 4847\n",
      "Saved the embedding for deadly.\n",
      "deadpan is at index 1462\n",
      "Saved the embedding for deadpan.\n",
      "debate is at index 2625\n",
      "Saved the embedding for debate.\n",
      "debating is at index 24996\n",
      "Saved the embedding for debating.\n",
      "debauched is at index 10189\n",
      "Saved the embedding for debauched.\n",
      "deceitful is at index 35049\n",
      "Saved the embedding for deceitful.\n",
      "deceived is at index 38079\n",
      "Saved the embedding for deceived.\n",
      "deceiving is at index 34575\n",
      "Saved the embedding for deceiving.\n",
      "deceivingly is at index 34575\n",
      "Saved the embedding for deceivingly.\n",
      "deception is at index 29244\n",
      "Saved the embedding for deception.\n",
      "deceptive is at index 31405\n",
      "Saved the embedding for deceptive.\n",
      "deciding is at index 8997\n",
      "Saved the embedding for deciding.\n",
      "decisive is at index 12703\n",
      "Saved the embedding for decisive.\n",
      "dedicated is at index 3688\n",
      "Saved the embedding for dedicated.\n",
      "defeat is at index 3002\n",
      "Saved the embedding for defeat.\n",
      "defeated is at index 5125\n",
      "Saved the embedding for defeated.\n",
      "defenseless is at index 3816\n",
      "Saved the embedding for defenseless.\n",
      "defensive is at index 2465\n",
      "Saved the embedding for defensive.\n",
      "defiance is at index 25442\n",
      "Saved the embedding for defiance.\n",
      "defiant is at index 23802\n",
      "Saved the embedding for defiant.\n",
      "deflated is at index 3816\n",
      "Saved the embedding for deflated.\n",
      "degage is at index 31295\n",
      "Saved the embedding for degage.\n",
      "degrading is at index 36892\n",
      "Saved the embedding for degrading.\n",
      "dejected is at index 263\n",
      "Saved the embedding for dejected.\n",
      "dejection is at index 263\n",
      "Saved the embedding for dejection.\n",
      "deliberate is at index 14775\n",
      "Saved the embedding for deliberate.\n",
      "deliberating is at index 21614\n",
      "Saved the embedding for deliberating.\n",
      "delight is at index 13213\n",
      "Saved the embedding for delight.\n",
      "delighted is at index 7808\n",
      "Saved the embedding for delighted.\n",
      "delightful is at index 24897\n",
      "Saved the embedding for delightful.\n",
      "delirious is at index 2424\n",
      "Saved the embedding for delirious.\n",
      "delirium is at index 2424\n",
      "Saved the embedding for delirium.\n",
      "delude is at index 2424\n",
      "Saved the embedding for delude.\n",
      "delusional is at index 40160\n",
      "Saved the embedding for delusional.\n",
      "demanding is at index 5783\n",
      "Saved the embedding for demanding.\n",
      "demeaning is at index 4410\n",
      "Saved the embedding for demeaning.\n",
      "demented is at index 44202\n",
      "Saved the embedding for demented.\n",
      "demised is at index 4410\n",
      "Saved the embedding for demised.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demoralized is at index 36810\n",
      "Saved the embedding for demoralized.\n",
      "demure is at index 4410\n",
      "Saved the embedding for demure.\n",
      "denied is at index 2296\n",
      "Saved the embedding for denied.\n",
      "denouncing is at index 32439\n",
      "Saved the embedding for denouncing.\n",
      "depleted is at index 26391\n",
      "Saved the embedding for depleted.\n",
      "deplorable is at index 28156\n",
      "Saved the embedding for deplorable.\n",
      "deprecating is at index 8273\n",
      "Saved the embedding for deprecating.\n",
      "depressed is at index 16658\n",
      "Saved the embedding for depressed.\n",
      "depression is at index 6943\n",
      "Saved the embedding for depression.\n",
      "deprived is at index 22632\n",
      "Saved the embedding for deprived.\n",
      "deranged is at index 1935\n",
      "Saved the embedding for deranged.\n",
      "derision is at index 1935\n",
      "Saved the embedding for derision.\n",
      "derisive is at index 1935\n",
      "Saved the embedding for derisive.\n",
      "derogatory is at index 30971\n",
      "Saved the embedding for derogatory.\n",
      "desire is at index 4724\n",
      "Saved the embedding for desire.\n",
      "desiring is at index 2694\n",
      "Saved the embedding for desiring.\n",
      "desirous is at index 2694\n",
      "Saved the embedding for desirous.\n",
      "desolate is at index 43177\n",
      "Saved the embedding for desolate.\n",
      "despair is at index 21508\n",
      "Saved the embedding for despair.\n",
      "despaired is at index 2694\n",
      "Saved the embedding for despaired.\n",
      "despairing is at index 21508\n",
      "Saved the embedding for despairing.\n",
      "desperate is at index 7764\n",
      "Saved the embedding for desperate.\n",
      "desperation is at index 24278\n",
      "Saved the embedding for desperation.\n",
      "despise is at index 43255\n",
      "Saved the embedding for despise.\n",
      "despondent is at index 18690\n",
      "Saved the embedding for despondent.\n",
      "destitute is at index 15357\n",
      "Saved the embedding for destitute.\n",
      "destroyed is at index 4957\n",
      "Saved the embedding for destroyed.\n",
      "detached is at index 27687\n",
      "Saved the embedding for detached.\n",
      "determination is at index 8964\n",
      "Saved the embedding for determination.\n",
      "determined is at index 3030\n",
      "Saved the embedding for determined.\n",
      "determining is at index 13684\n",
      "Saved the embedding for determining.\n",
      "deterred is at index 10922\n",
      "Saved the embedding for deterred.\n",
      "detest is at index 6769\n",
      "Saved the embedding for detest.\n",
      "detestable is at index 6769\n",
      "Saved the embedding for detestable.\n",
      "detesting is at index 6769\n",
      "Saved the embedding for detesting.\n",
      "detriment is at index 31969\n",
      "Saved the embedding for detriment.\n",
      "devastated is at index 11521\n",
      "Saved the embedding for devastated.\n",
      "deviant is at index 8709\n",
      "Saved the embedding for deviant.\n",
      "devilish is at index 22406\n",
      "Saved the embedding for devilish.\n",
      "devious is at index 263\n",
      "Saved the embedding for devious.\n",
      "devising is at index 8709\n",
      "Saved the embedding for devising.\n",
      "diffident is at index 25871\n",
      "Saved the embedding for diffident.\n",
      "dilatory is at index 14632\n",
      "Saved the embedding for dilatory.\n",
      "diligent is at index 33721\n",
      "Saved the embedding for diligent.\n",
      "dimwitted is at index 14548\n",
      "Saved the embedding for dimwitted.\n",
      "dire is at index 10697\n",
      "Saved the embedding for dire.\n",
      "disagree is at index 11967\n",
      "Saved the embedding for disagree.\n",
      "disagreeable is at index 11967\n",
      "Saved the embedding for disagreeable.\n",
      "disagreement is at index 20628\n",
      "Saved the embedding for disagreement.\n",
      "disappointed is at index 5779\n",
      "Saved the embedding for disappointed.\n",
      "disappointing is at index 6770\n",
      "Saved the embedding for disappointing.\n",
      "disappointment is at index 10208\n",
      "Saved the embedding for disappointment.\n",
      "disapproval is at index 32129\n",
      "Saved the embedding for disapproval.\n",
      "disapproving is at index 36631\n",
      "Saved the embedding for disapproving.\n",
      "disbelief is at index 26440\n",
      "Saved the embedding for disbelief.\n",
      "disbelieve is at index 45668\n",
      "Saved the embedding for disbelieve.\n",
      "disbelieving is at index 45668\n",
      "Saved the embedding for disbelieving.\n",
      "discerning is at index 9553\n",
      "Saved the embedding for discerning.\n",
      "discombobulated is at index 2982\n",
      "Saved the embedding for discombobulated.\n",
      "discomfited is at index 2982\n",
      "Saved the embedding for discomfited.\n",
      "discomfort is at index 19535\n",
      "Saved the embedding for discomfort.\n",
      "discomforted is at index 19535\n",
      "Saved the embedding for discomforted.\n",
      "disconcerted is at index 2982\n",
      "Saved the embedding for disconcerted.\n",
      "disconnected is at index 30005\n",
      "Saved the embedding for disconnected.\n",
      "disconsolate is at index 9553\n",
      "Saved the embedding for disconsolate.\n",
      "discontent is at index 27478\n",
      "Saved the embedding for discontent.\n",
      "discontented is at index 47772\n",
      "Saved the embedding for discontented.\n",
      "discounted is at index 17533\n",
      "Saved the embedding for discounted.\n",
      "discouraged is at index 25788\n",
      "Saved the embedding for discouraged.\n",
      "discovery is at index 6953\n",
      "Saved the embedding for discovery.\n",
      "discriminating is at index 38303\n",
      "Saved the embedding for discriminating.\n",
      "discussed is at index 3373\n",
      "Saved the embedding for discussed.\n",
      "disdain is at index 29512\n",
      "Saved the embedding for disdain.\n",
      "disdained is at index 2982\n",
      "Saved the embedding for disdained.\n",
      "disdainful is at index 29512\n",
      "Saved the embedding for disdainful.\n",
      "disdainfully is at index 29512\n",
      "Saved the embedding for disdainfully.\n",
      "disenchanted is at index 2982\n",
      "Saved the embedding for disenchanted.\n",
      "disengaged is at index 35170\n",
      "Saved the embedding for disengaged.\n",
      "disgraced is at index 25425\n",
      "Saved the embedding for disgraced.\n",
      "disgruntled is at index 29412\n",
      "Saved the embedding for disgruntled.\n",
      "disgruntlement is at index 25425\n",
      "Saved the embedding for disgruntlement.\n",
      "disgust is at index 30883\n",
      "Saved the embedding for disgust.\n",
      "disgusted is at index 32759\n",
      "Saved the embedding for disgusted.\n",
      "disgustedly is at index 32759\n",
      "Saved the embedding for disgustedly.\n",
      "disgusting is at index 21096\n",
      "Saved the embedding for disgusting.\n",
      "disheartened is at index 2982\n",
      "Saved the embedding for disheartened.\n",
      "dishonest is at index 27820\n",
      "Saved the embedding for dishonest.\n",
      "disillusioned is at index 33447\n",
      "Saved the embedding for disillusioned.\n",
      "disinclined is at index 2982\n",
      "Saved the embedding for disinclined.\n",
      "disingenuous is at index 39622\n",
      "Saved the embedding for disingenuous.\n",
      "disinterest is at index 2982\n",
      "Saved the embedding for disinterest.\n",
      "disinterested is at index 2982\n",
      "Saved the embedding for disinterested.\n",
      "disjointed is at index 2982\n",
      "Saved the embedding for disjointed.\n",
      "dislike is at index 28101\n",
      "Saved the embedding for dislike.\n",
      "disliked is at index 40891\n",
      "Saved the embedding for disliked.\n",
      "disliking is at index 19131\n",
      "Saved the embedding for disliking.\n",
      "dismal is at index 23446\n",
      "Saved the embedding for dismal.\n",
      "disman is at index 2982\n",
      "Saved the embedding for disman.\n",
      "dismay is at index 22135\n",
      "Saved the embedding for dismay.\n",
      "dismayed is at index 22135\n",
      "Saved the embedding for dismayed.\n",
      "dismissive is at index 37890\n",
      "Saved the embedding for dismissive.\n",
      "disobedient is at index 43738\n",
      "Saved the embedding for disobedient.\n",
      "disorderly is at index 23547\n",
      "Saved the embedding for disorderly.\n",
      "disoriented is at index 2982\n",
      "Saved the embedding for disoriented.\n",
      "dispair is at index 11734\n",
      "Saved the embedding for dispair.\n",
      "disparaging is at index 24331\n",
      "Saved the embedding for disparaging.\n",
      "dispassionate is at index 11734\n",
      "Saved the embedding for dispassionate.\n",
      "dispirited is at index 2982\n",
      "Saved the embedding for dispirited.\n",
      "dispiritedness is at index 2982\n",
      "Saved the embedding for dispiritedness.\n",
      "displeased is at index 43709\n",
      "Saved the embedding for displeased.\n",
      "displeasure is at index 30201\n",
      "Saved the embedding for displeasure.\n",
      "disquiet is at index 2982\n",
      "Saved the embedding for disquiet.\n",
      "disquieted is at index 2982\n",
      "Saved the embedding for disquieted.\n",
      "disregard is at index 21034\n",
      "Saved the embedding for disregard.\n",
      "disrespectful is at index 26401\n",
      "Saved the embedding for disrespectful.\n",
      "disrupted is at index 15902\n",
      "Saved the embedding for disrupted.\n",
      "disruptive is at index 17561\n",
      "Saved the embedding for disruptive.\n",
      "dissatisfaction is at index 31776\n",
      "Saved the embedding for dissatisfaction.\n",
      "dissatisfied is at index 37278\n",
      "Saved the embedding for dissatisfied.\n",
      "dissatisfy is at index 48830\n",
      "Saved the embedding for dissatisfy.\n",
      "dissecting is at index 33562\n",
      "Saved the embedding for dissecting.\n",
      "dissociated is at index 14863\n",
      "Saved the embedding for dissociated.\n",
      "dissonant is at index 43162\n",
      "Saved the embedding for dissonant.\n",
      "distain is at index 7018\n",
      "Saved the embedding for distain.\n",
      "distant is at index 13258\n",
      "Saved the embedding for distant.\n",
      "distaste is at index 7018\n",
      "Saved the embedding for distaste.\n",
      "distasteful is at index 7018\n",
      "Saved the embedding for distasteful.\n",
      "distracted is at index 16573\n",
      "Saved the embedding for distracted.\n",
      "distraught is at index 30719\n",
      "Saved the embedding for distraught.\n",
      "distress is at index 13250\n",
      "Saved the embedding for distress.\n",
      "distressed is at index 21460\n",
      "Saved the embedding for distressed.\n",
      "distressing is at index 7018\n",
      "Saved the embedding for distressing.\n",
      "distrust is at index 27948\n",
      "Saved the embedding for distrust.\n",
      "distrustful is at index 27948\n",
      "Saved the embedding for distrustful.\n",
      "distrusting is at index 27948\n",
      "Saved the embedding for distrusting.\n",
      "disturbed is at index 22938\n",
      "Saved the embedding for disturbed.\n",
      "diverted is at index 19070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for diverted.\n",
      "dodgy is at index 25744\n",
      "Saved the embedding for dodgy.\n",
      "doleful is at index 109\n",
      "Saved the embedding for doleful.\n",
      "doltish is at index 385\n",
      "Saved the embedding for doltish.\n",
      "dominant is at index 7353\n",
      "Saved the embedding for dominant.\n",
      "dominating is at index 17349\n",
      "Saved the embedding for dominating.\n",
      "domineering is at index 13567\n",
      "Saved the embedding for domineering.\n",
      "done is at index 626\n",
      "Saved the embedding for done.\n",
      "doomed is at index 23326\n",
      "Saved the embedding for doomed.\n",
      "dopey is at index 32331\n",
      "Saved the embedding for dopey.\n",
      "doting is at index 385\n",
      "Saved the embedding for doting.\n",
      "doubt is at index 2980\n",
      "Saved the embedding for doubt.\n",
      "doubter is at index 26463\n",
      "Saved the embedding for doubter.\n",
      "doubtful is at index 26645\n",
      "Saved the embedding for doubtful.\n",
      "doubtfully is at index 2980\n",
      "Saved the embedding for doubtfully.\n",
      "doubtfulness is at index 2980\n",
      "Saved the embedding for doubtfulness.\n",
      "doubting is at index 26463\n",
      "Saved the embedding for doubting.\n",
      "dour is at index 385\n",
      "Saved the embedding for dour.\n",
      "down is at index 159\n",
      "Saved the embedding for down.\n",
      "downcast is at index 159\n",
      "Saved the embedding for downcast.\n",
      "downhearted is at index 159\n",
      "Saved the embedding for downhearted.\n",
      "downheartedness is at index 159\n",
      "Saved the embedding for downheartedness.\n",
      "downtrodden is at index 29407\n",
      "Saved the embedding for downtrodden.\n",
      "dozing is at index 109\n",
      "Saved the embedding for dozing.\n",
      "drained is at index 23544\n",
      "Saved the embedding for drained.\n",
      "dramatic is at index 5386\n",
      "Saved the embedding for dramatic.\n",
      "drawn is at index 4777\n",
      "Saved the embedding for drawn.\n",
      "dread is at index 24506\n",
      "Saved the embedding for dread.\n",
      "dreadful is at index 31715\n",
      "Saved the embedding for dreadful.\n",
      "dreading is at index 24506\n",
      "Saved the embedding for dreading.\n",
      "dreaming is at index 26240\n",
      "Saved the embedding for dreaming.\n",
      "dreamy is at index 3366\n",
      "Saved the embedding for dreamy.\n",
      "dreary is at index 385\n",
      "Saved the embedding for dreary.\n",
      "driven is at index 3185\n",
      "Saved the embedding for driven.\n",
      "drowsy is at index 385\n",
      "Saved the embedding for drowsy.\n",
      "drugged is at index 385\n",
      "Saved the embedding for drugged.\n",
      "drunk is at index 10789\n",
      "Saved the embedding for drunk.\n",
      "drunkenness is at index 19835\n",
      "Saved the embedding for drunkenness.\n",
      "dubiety is at index 30180\n",
      "Saved the embedding for dubiety.\n",
      "dubious is at index 24381\n",
      "Saved the embedding for dubious.\n",
      "dubiously is at index 30180\n",
      "Saved the embedding for dubiously.\n",
      "dull is at index 22018\n",
      "Saved the embedding for dull.\n",
      "dumb is at index 16881\n",
      "Saved the embedding for dumb.\n",
      "dumbfound is at index 16881\n",
      "Saved the embedding for dumbfound.\n",
      "dumbfounded is at index 16881\n",
      "Saved the embedding for dumbfounded.\n",
      "dumbstruck is at index 16881\n",
      "Saved the embedding for dumbstruck.\n",
      "dumfounded is at index 385\n",
      "Saved the embedding for dumfounded.\n",
      "dupe is at index 4279\n",
      "Saved the embedding for dupe.\n",
      "duplicitous is at index 30501\n",
      "Saved the embedding for duplicitous.\n",
      "dysphoric is at index 44153\n",
      "Saved the embedding for dysphoric.\n",
      "eager is at index 7921\n",
      "Saved the embedding for eager.\n",
      "eagerness is at index 7921\n",
      "Saved the embedding for eagerness.\n",
      "earnest is at index 22623\n",
      "Saved the embedding for earnest.\n",
      "easy is at index 1365\n",
      "Saved the embedding for easy.\n",
      "ebullient is at index 364\n",
      "Saved the embedding for ebullient.\n",
      "ecstasy is at index 37695\n",
      "Saved the embedding for ecstasy.\n",
      "ecstatic is at index 30754\n",
      "Saved the embedding for ecstatic.\n",
      "ecstatically is at index 20508\n",
      "Saved the embedding for ecstatically.\n",
      "edgy is at index 4803\n",
      "Saved the embedding for edgy.\n",
      "eerie is at index 33960\n",
      "Saved the embedding for eerie.\n",
      "effulgent is at index 22089\n",
      "Saved the embedding for effulgent.\n",
      "egoistic is at index 21450\n",
      "Saved the embedding for egoistic.\n",
      "egotistical is at index 364\n",
      "Saved the embedding for egotistical.\n",
      "egregious is at index 28971\n",
      "Saved the embedding for egregious.\n",
      "elated is at index 1615\n",
      "Saved the embedding for elated.\n",
      "elation is at index 1615\n",
      "Saved the embedding for elation.\n",
      "electrified is at index 17995\n",
      "Saved the embedding for electrified.\n",
      "elusive is at index 21483\n",
      "Saved the embedding for elusive.\n",
      "embarrassed is at index 17319\n",
      "Saved the embedding for embarrassed.\n",
      "embarrassment is at index 19124\n",
      "Saved the embedding for embarrassment.\n",
      "embittered is at index 2841\n",
      "Saved the embedding for embittered.\n",
      "embody is at index 33865\n",
      "Saved the embedding for embody.\n",
      "emotional is at index 3722\n",
      "Saved the embedding for emotional.\n",
      "emotionless is at index 11926\n",
      "Saved the embedding for emotionless.\n",
      "empathetic is at index 2841\n",
      "Saved the embedding for empathetic.\n",
      "empathic is at index 2841\n",
      "Saved the embedding for empathic.\n",
      "empathy is at index 17805\n",
      "Saved the embedding for empathy.\n",
      "emptiness is at index 44480\n",
      "Saved the embedding for emptiness.\n",
      "empty is at index 5802\n",
      "Saved the embedding for empty.\n",
      "enamored is at index 1177\n",
      "Saved the embedding for enamored.\n",
      "enchanted is at index 44141\n",
      "Saved the embedding for enchanted.\n",
      "encouraged is at index 4446\n",
      "Saved the embedding for encouraged.\n",
      "encouragement is at index 18197\n",
      "Saved the embedding for encouragement.\n",
      "encouraging is at index 5513\n",
      "Saved the embedding for encouraging.\n",
      "endeared is at index 253\n",
      "Saved the embedding for endeared.\n",
      "endearing is at index 253\n",
      "Saved the embedding for endearing.\n",
      "enduring is at index 16480\n",
      "Saved the embedding for enduring.\n",
      "energetic is at index 20425\n",
      "Saved the embedding for energetic.\n",
      "energized is at index 15957\n",
      "Saved the embedding for energized.\n",
      "engaged is at index 4009\n",
      "Saved the embedding for engaged.\n",
      "engrossed is at index 20407\n",
      "Saved the embedding for engrossed.\n",
      "engrossment is at index 20407\n",
      "Saved the embedding for engrossment.\n",
      "enigmatic is at index 38910\n",
      "Saved the embedding for enigmatic.\n",
      "enjoy is at index 2254\n",
      "Saved the embedding for enjoy.\n",
      "enjoying is at index 6218\n",
      "Saved the embedding for enjoying.\n",
      "enjoyment is at index 26611\n",
      "Saved the embedding for enjoyment.\n",
      "enlightened is at index 38853\n",
      "Saved the embedding for enlightened.\n",
      "enmity is at index 1177\n",
      "Saved the embedding for enmity.\n",
      "ennui is at index 1177\n",
      "Saved the embedding for ennui.\n",
      "enraged is at index 33415\n",
      "Saved the embedding for enraged.\n",
      "enraging is at index 1177\n",
      "Saved the embedding for enraging.\n",
      "enraptured is at index 1177\n",
      "Saved the embedding for enraptured.\n",
      "entertained is at index 23979\n",
      "Saved the embedding for entertained.\n",
      "enthralled is at index 3838\n",
      "Saved the embedding for enthralled.\n",
      "enthused is at index 3838\n",
      "Saved the embedding for enthused.\n",
      "enthusiasm is at index 11240\n",
      "Saved the embedding for enthusiasm.\n",
      "enthusiastic is at index 15947\n",
      "Saved the embedding for enthusiastic.\n",
      "enticed is at index 3838\n",
      "Saved the embedding for enticed.\n",
      "entranced is at index 3838\n",
      "Saved the embedding for entranced.\n",
      "envious is at index 1177\n",
      "Saved the embedding for envious.\n",
      "envy is at index 29778\n",
      "Saved the embedding for envy.\n",
      "erotically is at index 3335\n",
      "Saved the embedding for erotically.\n",
      "estranged is at index 20599\n",
      "Saved the embedding for estranged.\n",
      "etched is at index 35542\n",
      "Saved the embedding for etched.\n",
      "euphoric is at index 30882\n",
      "Saved the embedding for euphoric.\n",
      "evaluating is at index 15190\n",
      "Saved the embedding for evaluating.\n",
      "evasive is at index 7630\n",
      "Saved the embedding for evasive.\n",
      "evil is at index 9247\n",
      "Saved the embedding for evil.\n",
      "evoke is at index 35334\n",
      "Saved the embedding for evoke.\n",
      "exacerbated is at index 24961\n",
      "Saved the embedding for exacerbated.\n",
      "exalted is at index 45514\n",
      "Saved the embedding for exalted.\n",
      "examining is at index 14951\n",
      "Saved the embedding for examining.\n",
      "exasperate is at index 1931\n",
      "Saved the embedding for exasperate.\n",
      "exasperated is at index 34698\n",
      "Saved the embedding for exasperated.\n",
      "exasperation is at index 34698\n",
      "Saved the embedding for exasperation.\n",
      "excited is at index 2283\n",
      "Saved the embedding for excited.\n",
      "excitedly is at index 2283\n",
      "Saved the embedding for excitedly.\n",
      "excitement is at index 8354\n",
      "Saved the embedding for excitement.\n",
      "exclamation is at index 1931\n",
      "Saved the embedding for exclamation.\n",
      "exclamatory is at index 1931\n",
      "Saved the embedding for exclamatory.\n",
      "exhausted is at index 17067\n",
      "Saved the embedding for exhausted.\n",
      "exhaustion is at index 30567\n",
      "Saved the embedding for exhaustion.\n",
      "exhaustive is at index 29180\n",
      "Saved the embedding for exhaustive.\n",
      "exhilarated is at index 32749\n",
      "Saved the embedding for exhilarated.\n",
      "exhilaration is at index 32749\n",
      "Saved the embedding for exhilaration.\n",
      "exited is at index 17469\n",
      "Saved the embedding for exited.\n",
      "expectant is at index 1057\n",
      "Saved the embedding for expectant.\n",
      "expectation is at index 9250\n",
      "Saved the embedding for expectation.\n",
      "expecting is at index 4804\n",
      "Saved the embedding for expecting.\n",
      "explain is at index 3922\n",
      "Saved the embedding for explain.\n",
      "explaining is at index 8926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for explaining.\n",
      "exploitive is at index 38984\n",
      "Saved the embedding for exploitive.\n",
      "explosive is at index 8560\n",
      "Saved the embedding for explosive.\n",
      "exposure is at index 4895\n",
      "Saved the embedding for exposure.\n",
      "expressive is at index 36340\n",
      "Saved the embedding for expressive.\n",
      "exuberant is at index 1931\n",
      "Saved the embedding for exuberant.\n",
      "exultant is at index 1931\n",
      "Saved the embedding for exultant.\n",
      "exulted is at index 1931\n",
      "Saved the embedding for exulted.\n",
      "eye is at index 2295\n",
      "Saved the embedding for eye.\n",
      "eyed is at index 36235\n",
      "Saved the embedding for eyed.\n",
      "faced is at index 2713\n",
      "Saved the embedding for faced.\n",
      "facetious is at index 34407\n",
      "Saved the embedding for facetious.\n",
      "failure is at index 2988\n",
      "Saved the embedding for failure.\n",
      "faint is at index 27922\n",
      "Saved the embedding for faint.\n",
      "fair is at index 2105\n",
      "Saved the embedding for fair.\n",
      "fake is at index 4486\n",
      "Saved the embedding for fake.\n",
      "faking is at index 856\n",
      "Saved the embedding for faking.\n",
      "falter is at index 14848\n",
      "Saved the embedding for falter.\n",
      "famished is at index 13403\n",
      "Saved the embedding for famished.\n",
      "fanatic is at index 38604\n",
      "Saved the embedding for fanatic.\n",
      "fanciful is at index 33639\n",
      "Saved the embedding for fanciful.\n",
      "fart is at index 36762\n",
      "Saved the embedding for fart.\n",
      "fascinated is at index 27025\n",
      "Saved the embedding for fascinated.\n",
      "fastidious is at index 1769\n",
      "Saved the embedding for fastidious.\n",
      "fatigue is at index 16069\n",
      "Saved the embedding for fatigue.\n",
      "fatigued is at index 36239\n",
      "Saved the embedding for fatigued.\n",
      "faultfinding is at index 7684\n",
      "Saved the embedding for faultfinding.\n",
      "favorable is at index 9879\n",
      "Saved the embedding for favorable.\n",
      "fawning is at index 856\n",
      "Saved the embedding for fawning.\n",
      "fazed is at index 856\n",
      "Saved the embedding for fazed.\n",
      "fear is at index 2490\n",
      "Saved the embedding for fear.\n",
      "feared is at index 9741\n",
      "Saved the embedding for feared.\n",
      "fearful is at index 23526\n",
      "Saved the embedding for fearful.\n",
      "fearing is at index 21510\n",
      "Saved the embedding for fearing.\n",
      "fearless is at index 29107\n",
      "Saved the embedding for fearless.\n",
      "fearsome is at index 39185\n",
      "Saved the embedding for fearsome.\n",
      "feckless is at index 10668\n",
      "Saved the embedding for feckless.\n",
      "fed is at index 9789\n",
      "Saved the embedding for fed.\n",
      "feeble is at index 42217\n",
      "Saved the embedding for feeble.\n",
      "feign is at index 10668\n",
      "Saved the embedding for feign.\n",
      "felicitous is at index 14383\n",
      "Saved the embedding for felicitous.\n",
      "ferocious is at index 31429\n",
      "Saved the embedding for ferocious.\n",
      "ferocity is at index 16022\n",
      "Saved the embedding for ferocity.\n",
      "festive is at index 12298\n",
      "Saved the embedding for festive.\n",
      "fidgety is at index 856\n",
      "Saved the embedding for fidgety.\n",
      "fiendish is at index 13383\n",
      "Saved the embedding for fiendish.\n",
      "fierce is at index 11039\n",
      "Saved the embedding for fierce.\n",
      "fiery is at index 19068\n",
      "Saved the embedding for fiery.\n",
      "fighting is at index 2190\n",
      "Saved the embedding for fighting.\n",
      "fine is at index 2051\n",
      "Saved the embedding for fine.\n",
      "finished is at index 1550\n",
      "Saved the embedding for finished.\n",
      "firm is at index 933\n",
      "Saved the embedding for firm.\n",
      "fishy is at index 3539\n",
      "Saved the embedding for fishy.\n",
      "fixated is at index 4190\n",
      "Saved the embedding for fixated.\n",
      "fixed is at index 4460\n",
      "Saved the embedding for fixed.\n",
      "flabbergasted is at index 2342\n",
      "Saved the embedding for flabbergasted.\n",
      "flaming is at index 37222\n",
      "Saved the embedding for flaming.\n",
      "flat is at index 3269\n",
      "Saved the embedding for flat.\n",
      "flaunting is at index 2342\n",
      "Saved the embedding for flaunting.\n",
      "flighty is at index 2524\n",
      "Saved the embedding for flighty.\n",
      "flippant is at index 2342\n",
      "Saved the embedding for flippant.\n",
      "flipped is at index 18626\n",
      "Saved the embedding for flipped.\n",
      "flirtation is at index 33743\n",
      "Saved the embedding for flirtation.\n",
      "flirtatious is at index 33743\n",
      "Saved the embedding for flirtatious.\n",
      "flirty is at index 2342\n",
      "Saved the embedding for flirty.\n",
      "floored is at index 27325\n",
      "Saved the embedding for floored.\n",
      "flummoxed is at index 2342\n",
      "Saved the embedding for flummoxed.\n",
      "flustered is at index 2342\n",
      "Saved the embedding for flustered.\n",
      "focus is at index 1056\n",
      "Saved the embedding for focus.\n",
      "focused is at index 2061\n",
      "Saved the embedding for focused.\n",
      "focusing is at index 5650\n",
      "Saved the embedding for focusing.\n",
      "foiled is at index 9565\n",
      "Saved the embedding for foiled.\n",
      "foolish is at index 22789\n",
      "Saved the embedding for foolish.\n",
      "forbearing is at index 34550\n",
      "Saved the embedding for forbearing.\n",
      "forbidding is at index 34550\n",
      "Saved the embedding for forbidding.\n",
      "forced is at index 1654\n",
      "Saved the embedding for forced.\n",
      "forceful is at index 32165\n",
      "Saved the embedding for forceful.\n",
      "forfeited is at index 31844\n",
      "Saved the embedding for forfeited.\n",
      "forlorn is at index 13\n",
      "Saved the embedding for forlorn.\n",
      "fortunate is at index 10583\n",
      "Saved the embedding for fortunate.\n",
      "forward is at index 556\n",
      "Saved the embedding for forward.\n",
      "foul is at index 6962\n",
      "Saved the embedding for foul.\n",
      "fractious is at index 38251\n",
      "Saved the embedding for fractious.\n",
      "fragile is at index 14283\n",
      "Saved the embedding for fragile.\n",
      "frantic is at index 27396\n",
      "Saved the embedding for frantic.\n",
      "fraudulent is at index 15381\n",
      "Saved the embedding for fraudulent.\n",
      "fraught is at index 25481\n",
      "Saved the embedding for fraught.\n",
      "frazzled is at index 26830\n",
      "Saved the embedding for frazzled.\n",
      "freaked is at index 7619\n",
      "Saved the embedding for freaked.\n",
      "frenzied is at index 26908\n",
      "Saved the embedding for frenzied.\n",
      "fretful is at index 31391\n",
      "Saved the embedding for fretful.\n",
      "friendliness is at index 1441\n",
      "Saved the embedding for friendliness.\n",
      "friendly is at index 5192\n",
      "Saved the embedding for friendly.\n",
      "fright is at index 32580\n",
      "Saved the embedding for fright.\n",
      "frightened is at index 26851\n",
      "Saved the embedding for frightened.\n",
      "frightening is at index 21111\n",
      "Saved the embedding for frightening.\n",
      "frigid is at index 25805\n",
      "Saved the embedding for frigid.\n",
      "frisky is at index 6664\n",
      "Saved the embedding for frisky.\n",
      "frolicker is at index 856\n",
      "Saved the embedding for frolicker.\n",
      "frown is at index 41588\n",
      "Saved the embedding for frown.\n",
      "frowning is at index 41588\n",
      "Saved the embedding for frowning.\n",
      "frozen is at index 9214\n",
      "Saved the embedding for frozen.\n",
      "frumpy is at index 6664\n",
      "Saved the embedding for frumpy.\n",
      "frustrated is at index 8164\n",
      "Saved the embedding for frustrated.\n",
      "frustration is at index 8413\n",
      "Saved the embedding for frustration.\n",
      "fulfilled is at index 20218\n",
      "Saved the embedding for fulfilled.\n",
      "fumed is at index 856\n",
      "Saved the embedding for fumed.\n",
      "fuming is at index 856\n",
      "Saved the embedding for fuming.\n",
      "fun is at index 1531\n",
      "Saved the embedding for fun.\n",
      "funny is at index 6269\n",
      "Saved the embedding for funny.\n",
      "furious is at index 15940\n",
      "Saved the embedding for furious.\n",
      "furiously is at index 39202\n",
      "Saved the embedding for furiously.\n",
      "furiousness is at index 15940\n",
      "Saved the embedding for furiousness.\n",
      "furrowed is at index 15503\n",
      "Saved the embedding for furrowed.\n",
      "furtive is at index 856\n",
      "Saved the embedding for furtive.\n",
      "fury is at index 22228\n",
      "Saved the embedding for fury.\n",
      "fussy is at index 856\n",
      "Saved the embedding for fussy.\n",
      "galled is at index 821\n",
      "Saved the embedding for galled.\n",
      "galling is at index 19869\n",
      "Saved the embedding for galling.\n",
      "gasp is at index 41681\n",
      "Saved the embedding for gasp.\n",
      "gasped is at index 44918\n",
      "Saved the embedding for gasped.\n",
      "gasping is at index 1123\n",
      "Saved the embedding for gasping.\n",
      "gay is at index 5100\n",
      "Saved the embedding for gay.\n",
      "gazing is at index 40804\n",
      "Saved the embedding for gazing.\n",
      "genial is at index 12358\n",
      "Saved the embedding for genial.\n",
      "gentle is at index 16634\n",
      "Saved the embedding for gentle.\n",
      "genuine is at index 8916\n",
      "Saved the embedding for genuine.\n",
      "ghastly is at index 34648\n",
      "Saved the embedding for ghastly.\n",
      "giddy is at index 821\n",
      "Saved the embedding for giddy.\n",
      "giggle is at index 821\n",
      "Saved the embedding for giggle.\n",
      "giggling is at index 33786\n",
      "Saved the embedding for giggling.\n",
      "glad is at index 7785\n",
      "Saved the embedding for glad.\n",
      "gladdened is at index 5921\n",
      "Saved the embedding for gladdened.\n",
      "gladiola is at index 7785\n",
      "Saved the embedding for gladiola.\n",
      "gladness is at index 7785\n",
      "Saved the embedding for gladness.\n",
      "gladsome is at index 5921\n",
      "Saved the embedding for gladsome.\n",
      "glare is at index 37355\n",
      "Saved the embedding for glare.\n",
      "glaring is at index 26077\n",
      "Saved the embedding for glaring.\n",
      "glazed is at index 5921\n",
      "Saved the embedding for glazed.\n",
      "glee is at index 821\n",
      "Saved the embedding for glee.\n",
      "gleeful is at index 22460\n",
      "Saved the embedding for gleeful.\n",
      "gleefully is at index 22460\n",
      "Saved the embedding for gleefully.\n",
      "glib is at index 5921\n",
      "Saved the embedding for glib.\n",
      "gloating is at index 5921\n",
      "Saved the embedding for gloating.\n",
      "gloom is at index 31752\n",
      "Saved the embedding for gloom.\n",
      "gloomy is at index 32627\n",
      "Saved the embedding for gloomy.\n",
      "glowering is at index 5921\n",
      "Saved the embedding for glowering.\n",
      "glowing is at index 22285\n",
      "Saved the embedding for glowing.\n",
      "glum is at index 5921\n",
      "Saved the embedding for glum.\n",
      "gnarl is at index 31021\n",
      "Saved the embedding for gnarl.\n",
      "gobsmacked is at index 213\n",
      "Saved the embedding for gobsmacked.\n",
      "good is at index 205\n",
      "Saved the embedding for good.\n",
      "goofy is at index 36302\n",
      "Saved the embedding for goofy.\n",
      "gossipy is at index 20445\n",
      "Saved the embedding for gossipy.\n",
      "grandiose is at index 2821\n",
      "Saved the embedding for grandiose.\n",
      "grateful is at index 6161\n",
      "Saved the embedding for grateful.\n",
      "gratified is at index 20153\n",
      "Saved the embedding for gratified.\n",
      "grave is at index 9753\n",
      "Saved the embedding for grave.\n",
      "great is at index 372\n",
      "Saved the embedding for great.\n",
      "greedy is at index 34405\n",
      "Saved the embedding for greedy.\n",
      "greeting is at index 25801\n",
      "Saved the embedding for greeting.\n",
      "grief is at index 12903\n",
      "Saved the embedding for grief.\n",
      "grieved is at index 821\n",
      "Saved the embedding for grieved.\n",
      "grieving is at index 22567\n",
      "Saved the embedding for grieving.\n",
      "grim is at index 17081\n",
      "Saved the embedding for grim.\n",
      "grimace is at index 17081\n",
      "Saved the embedding for grimace.\n",
      "grimacing is at index 17081\n",
      "Saved the embedding for grimacing.\n",
      "grin is at index 30986\n",
      "Saved the embedding for grin.\n",
      "grinning is at index 39662\n",
      "Saved the embedding for grinning.\n",
      "griping is at index 11155\n",
      "Saved the embedding for griping.\n",
      "gross is at index 4200\n",
      "Saved the embedding for gross.\n",
      "grossed is at index 4200\n",
      "Saved the embedding for grossed.\n",
      "grouchy is at index 22970\n",
      "Saved the embedding for grouchy.\n",
      "growl is at index 1733\n",
      "Saved the embedding for growl.\n",
      "growling is at index 1733\n",
      "Saved the embedding for growling.\n",
      "grudge is at index 4435\n",
      "Saved the embedding for grudge.\n",
      "grudging is at index 4435\n",
      "Saved the embedding for grudging.\n",
      "gruff is at index 15551\n",
      "Saved the embedding for gruff.\n",
      "grumbling is at index 4435\n",
      "Saved the embedding for grumbling.\n",
      "grumpy is at index 4435\n",
      "Saved the embedding for grumpy.\n",
      "grunt is at index 44376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for grunt.\n",
      "grunting is at index 39204\n",
      "Saved the embedding for grunting.\n",
      "guarded is at index 25853\n",
      "Saved the embedding for guarded.\n",
      "guilty is at index 2181\n",
      "Saved the embedding for guilty.\n",
      "gulp is at index 821\n",
      "Saved the embedding for gulp.\n",
      "haggard is at index 1368\n",
      "Saved the embedding for haggard.\n",
      "halfhearted is at index 457\n",
      "Saved the embedding for halfhearted.\n",
      "halted is at index 12856\n",
      "Saved the embedding for halted.\n",
      "hapless is at index 2489\n",
      "Saved the embedding for hapless.\n",
      "happiness is at index 11098\n",
      "Saved the embedding for happiness.\n",
      "happy is at index 1372\n",
      "Saved the embedding for happy.\n",
      "harassed is at index 16835\n",
      "Saved the embedding for harassed.\n",
      "hard is at index 543\n",
      "Saved the embedding for hard.\n",
      "hardened is at index 33631\n",
      "Saved the embedding for hardened.\n",
      "harmful is at index 11190\n",
      "Saved the embedding for harmful.\n",
      "harried is at index 12280\n",
      "Saved the embedding for harried.\n",
      "harsh is at index 9776\n",
      "Saved the embedding for harsh.\n",
      "hate is at index 4157\n",
      "Saved the embedding for hate.\n",
      "hateful is at index 26393\n",
      "Saved the embedding for hateful.\n",
      "hating is at index 40873\n",
      "Saved the embedding for hating.\n",
      "hatred is at index 13453\n",
      "Saved the embedding for hatred.\n",
      "haughty is at index 2489\n",
      "Saved the embedding for haughty.\n",
      "haunted is at index 22717\n",
      "Saved the embedding for haunted.\n",
      "hazy is at index 2489\n",
      "Saved the embedding for hazy.\n",
      "headshake is at index 471\n",
      "Saved the embedding for headshake.\n",
      "heartache is at index 1144\n",
      "Saved the embedding for heartache.\n",
      "heartbroken is at index 1144\n",
      "Saved the embedding for heartbroken.\n",
      "hearted is at index 1144\n",
      "Saved the embedding for hearted.\n",
      "heartsick is at index 7754\n",
      "Saved the embedding for heartsick.\n",
      "heated is at index 10819\n",
      "Saved the embedding for heated.\n",
      "heavyhearted is at index 2016\n",
      "Saved the embedding for heavyhearted.\n",
      "heckle is at index 17835\n",
      "Saved the embedding for heckle.\n",
      "heedful is at index 25432\n",
      "Saved the embedding for heedful.\n",
      "heinous is at index 30091\n",
      "Saved the embedding for heinous.\n",
      "helpful is at index 7163\n",
      "Saved the embedding for helpful.\n",
      "helpless is at index 22445\n",
      "Saved the embedding for helpless.\n",
      "hesitant is at index 24668\n",
      "Saved the embedding for hesitant.\n",
      "hesitantly is at index 36279\n",
      "Saved the embedding for hesitantly.\n",
      "hesitating is at index 36279\n",
      "Saved the embedding for hesitating.\n",
      "hesitation is at index 28946\n",
      "Saved the embedding for hesitation.\n",
      "high is at index 239\n",
      "Saved the embedding for high.\n",
      "hollering is at index 1368\n",
      "Saved the embedding for hollering.\n",
      "homicidal is at index 9486\n",
      "Saved the embedding for homicidal.\n",
      "honest is at index 5322\n",
      "Saved the embedding for honest.\n",
      "honorable is at index 28537\n",
      "Saved the embedding for honorable.\n",
      "hope is at index 1034\n",
      "Saved the embedding for hope.\n",
      "hopeful is at index 7917\n",
      "Saved the embedding for hopeful.\n",
      "hopefulness is at index 7917\n",
      "Saved the embedding for hopefulness.\n",
      "hopeless is at index 24418\n",
      "Saved the embedding for hopeless.\n",
      "hoping is at index 2818\n",
      "Saved the embedding for hoping.\n",
      "horny is at index 46216\n",
      "Saved the embedding for horny.\n",
      "horrible is at index 11385\n",
      "Saved the embedding for horrible.\n",
      "horrified is at index 27807\n",
      "Saved the embedding for horrified.\n",
      "horrify is at index 48067\n",
      "Saved the embedding for horrify.\n",
      "horrifying is at index 28242\n",
      "Saved the embedding for horrifying.\n",
      "horror is at index 8444\n",
      "Saved the embedding for horror.\n",
      "hostile is at index 11928\n",
      "Saved the embedding for hostile.\n",
      "hostility is at index 22069\n",
      "Saved the embedding for hostility.\n",
      "hot is at index 2131\n",
      "Saved the embedding for hot.\n",
      "hotshot is at index 2131\n",
      "Saved the embedding for hotshot.\n",
      "huffiness is at index 1368\n",
      "Saved the embedding for huffiness.\n",
      "huffy is at index 1368\n",
      "Saved the embedding for huffy.\n",
      "humble is at index 14083\n",
      "Saved the embedding for humble.\n",
      "humbled is at index 10080\n",
      "Saved the embedding for humbled.\n",
      "humdrum is at index 10080\n",
      "Saved the embedding for humdrum.\n",
      "humiliated is at index 32386\n",
      "Saved the embedding for humiliated.\n",
      "humility is at index 27352\n",
      "Saved the embedding for humility.\n",
      "humming is at index 35774\n",
      "Saved the embedding for humming.\n",
      "humor is at index 12073\n",
      "Saved the embedding for humor.\n",
      "humored is at index 10080\n",
      "Saved the embedding for humored.\n",
      "humorous is at index 31214\n",
      "Saved the embedding for humorous.\n",
      "hunger is at index 12226\n",
      "Saved the embedding for hunger.\n",
      "hungry is at index 11130\n",
      "Saved the embedding for hungry.\n",
      "hunted is at index 32602\n",
      "Saved the embedding for hunted.\n",
      "hurt is at index 2581\n",
      "Saved the embedding for hurt.\n",
      "hurtful is at index 2581\n",
      "Saved the embedding for hurtful.\n",
      "hurting is at index 12780\n",
      "Saved the embedding for hurting.\n",
      "hush is at index 1368\n",
      "Saved the embedding for hush.\n",
      "hushed is at index 33476\n",
      "Saved the embedding for hushed.\n",
      "hyper is at index 8944\n",
      "Saved the embedding for hyper.\n",
      "hyperactive is at index 8944\n",
      "Saved the embedding for hyperactive.\n",
      "hypnotized is at index 39040\n",
      "Saved the embedding for hypnotized.\n",
      "hypocritical is at index 37769\n",
      "Saved the embedding for hypocritical.\n",
      "hysteria is at index 35099\n",
      "Saved the embedding for hysteria.\n",
      "hysterical is at index 38561\n",
      "Saved the embedding for hysterical.\n",
      "idiotic is at index 13561\n",
      "Saved the embedding for idiotic.\n",
      "ignorant is at index 27726\n",
      "Saved the embedding for ignorant.\n",
      "ignoring is at index 15515\n",
      "Saved the embedding for ignoring.\n",
      "ill is at index 4812\n",
      "Saved the embedding for ill.\n",
      "imaginative is at index 35026\n",
      "Saved the embedding for imaginative.\n",
      "immature is at index 39001\n",
      "Saved the embedding for immature.\n",
      "immersed is at index 31971\n",
      "Saved the embedding for immersed.\n",
      "impacted is at index 7284\n",
      "Saved the embedding for impacted.\n",
      "impartial is at index 24283\n",
      "Saved the embedding for impartial.\n",
      "impassioned is at index 4023\n",
      "Saved the embedding for impassioned.\n",
      "impassive is at index 4023\n",
      "Saved the embedding for impassive.\n",
      "impatience is at index 43635\n",
      "Saved the embedding for impatience.\n",
      "impatient is at index 32601\n",
      "Saved the embedding for impatient.\n",
      "imperious is at index 21245\n",
      "Saved the embedding for imperious.\n",
      "impersonal is at index 23153\n",
      "Saved the embedding for impersonal.\n",
      "impertinent is at index 21245\n",
      "Saved the embedding for impertinent.\n",
      "impish is at index 4023\n",
      "Saved the embedding for impish.\n",
      "implicated is at index 23316\n",
      "Saved the embedding for implicated.\n",
      "imploring is at index 12956\n",
      "Saved the embedding for imploring.\n",
      "important is at index 505\n",
      "Saved the embedding for important.\n",
      "impressed is at index 6889\n",
      "Saved the embedding for impressed.\n",
      "impulsive is at index 4023\n",
      "Saved the embedding for impulsive.\n",
      "inactive is at index 25986\n",
      "Saved the embedding for inactive.\n",
      "inadequate is at index 15650\n",
      "Saved the embedding for inadequate.\n",
      "inarticulate is at index 11\n",
      "Saved the embedding for inarticulate.\n",
      "inattentive is at index 11\n",
      "Saved the embedding for inattentive.\n",
      "inaudible is at index 11\n",
      "Saved the embedding for inaudible.\n",
      "inauthentic is at index 11\n",
      "Saved the embedding for inauthentic.\n",
      "incapable is at index 30256\n",
      "Saved the embedding for incapable.\n",
      "incensed is at index 5853\n",
      "Saved the embedding for incensed.\n",
      "incertain is at index 5853\n",
      "Saved the embedding for incertain.\n",
      "incertitude is at index 5853\n",
      "Saved the embedding for incertitude.\n",
      "incited is at index 5853\n",
      "Saved the embedding for incited.\n",
      "incomprehensible is at index 42494\n",
      "Saved the embedding for incomprehensible.\n",
      "inconspicuous is at index 40817\n",
      "Saved the embedding for inconspicuous.\n",
      "incredulity is at index 38366\n",
      "Saved the embedding for incredulity.\n",
      "incredulous is at index 38366\n",
      "Saved the embedding for incredulous.\n",
      "incredulously is at index 38366\n",
      "Saved the embedding for incredulously.\n",
      "inculpate is at index 5853\n",
      "Saved the embedding for inculpate.\n",
      "incurious is at index 5853\n",
      "Saved the embedding for incurious.\n",
      "indecipherable is at index 32227\n",
      "Saved the embedding for indecipherable.\n",
      "indecision is at index 32227\n",
      "Saved the embedding for indecision.\n",
      "indecisive is at index 32227\n",
      "Saved the embedding for indecisive.\n",
      "indifferent is at index 34657\n",
      "Saved the embedding for indifferent.\n",
      "indifferently is at index 34657\n",
      "Saved the embedding for indifferently.\n",
      "indignant is at index 9473\n",
      "Saved the embedding for indignant.\n",
      "indolent is at index 9473\n",
      "Saved the embedding for indolent.\n",
      "inebriated is at index 11\n",
      "Saved the embedding for inebriated.\n",
      "inert is at index 43783\n",
      "Saved the embedding for inert.\n",
      "infatuating is at index 4047\n",
      "Saved the embedding for infatuating.\n",
      "inferior is at index 28510\n",
      "Saved the embedding for inferior.\n",
      "inferiority is at index 28510\n",
      "Saved the embedding for inferiority.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inflamed is at index 11411\n",
      "Saved the embedding for inflamed.\n",
      "informal is at index 14110\n",
      "Saved the embedding for informal.\n",
      "informing is at index 21835\n",
      "Saved the embedding for informing.\n",
      "infuriated is at index 26974\n",
      "Saved the embedding for infuriated.\n",
      "inhibited is at index 45427\n",
      "Saved the embedding for inhibited.\n",
      "inhibiting is at index 38512\n",
      "Saved the embedding for inhibiting.\n",
      "inimical is at index 11\n",
      "Saved the embedding for inimical.\n",
      "injured is at index 1710\n",
      "Saved the embedding for injured.\n",
      "innocent is at index 7850\n",
      "Saved the embedding for innocent.\n",
      "inpatient is at index 11\n",
      "Saved the embedding for inpatient.\n",
      "inquiring is at index 27874\n",
      "Saved the embedding for inquiring.\n",
      "inquisitive is at index 27874\n",
      "Saved the embedding for inquisitive.\n",
      "insane is at index 18544\n",
      "Saved the embedding for insane.\n",
      "inscrutable is at index 7540\n",
      "Saved the embedding for inscrutable.\n",
      "insecure is at index 27810\n",
      "Saved the embedding for insecure.\n",
      "insecurity is at index 19401\n",
      "Saved the embedding for insecurity.\n",
      "insensitive is at index 29401\n",
      "Saved the embedding for insensitive.\n",
      "insidious is at index 40012\n",
      "Saved the embedding for insidious.\n",
      "insinuating is at index 32016\n",
      "Saved the embedding for insinuating.\n",
      "insistence is at index 24974\n",
      "Saved the embedding for insistence.\n",
      "insistent is at index 7540\n",
      "Saved the embedding for insistent.\n",
      "insisting is at index 13875\n",
      "Saved the embedding for insisting.\n",
      "insolent is at index 23799\n",
      "Saved the embedding for insolent.\n",
      "insouciance is at index 7540\n",
      "Saved the embedding for insouciance.\n",
      "insouciant is at index 7540\n",
      "Saved the embedding for insouciant.\n",
      "inspired is at index 4083\n",
      "Saved the embedding for inspired.\n",
      "inspiring is at index 11653\n",
      "Saved the embedding for inspiring.\n",
      "instigating is at index 9084\n",
      "Saved the embedding for instigating.\n",
      "instructing is at index 20587\n",
      "Saved the embedding for instructing.\n",
      "insubordinate is at index 7540\n",
      "Saved the embedding for insubordinate.\n",
      "insular is at index 7540\n",
      "Saved the embedding for insular.\n",
      "insulted is at index 32149\n",
      "Saved the embedding for insulted.\n",
      "insulting is at index 22602\n",
      "Saved the embedding for insulting.\n",
      "intelligence is at index 2316\n",
      "Saved the embedding for intelligence.\n",
      "intense is at index 5676\n",
      "Saved the embedding for intense.\n",
      "intensely is at index 29727\n",
      "Saved the embedding for intensely.\n",
      "intensity is at index 10603\n",
      "Saved the embedding for intensity.\n",
      "intensive is at index 12296\n",
      "Saved the embedding for intensive.\n",
      "intent is at index 5927\n",
      "Saved the embedding for intent.\n",
      "intentional is at index 18797\n",
      "Saved the embedding for intentional.\n",
      "interacting is at index 23140\n",
      "Saved the embedding for interacting.\n",
      "interest is at index 773\n",
      "Saved the embedding for interest.\n",
      "interested is at index 2509\n",
      "Saved the embedding for interested.\n",
      "interjecting is at index 3222\n",
      "Saved the embedding for interjecting.\n",
      "internalizing is at index 3425\n",
      "Saved the embedding for internalizing.\n",
      "interrogating is at index 28592\n",
      "Saved the embedding for interrogating.\n",
      "interrupting is at index 22749\n",
      "Saved the embedding for interrupting.\n",
      "intimidated is at index 25443\n",
      "Saved the embedding for intimidated.\n",
      "intimidating is at index 23292\n",
      "Saved the embedding for intimidating.\n",
      "intolerant is at index 39348\n",
      "Saved the embedding for intolerant.\n",
      "intoxicated is at index 20600\n",
      "Saved the embedding for intoxicated.\n",
      "intrigue is at index 30368\n",
      "Saved the embedding for intrigue.\n",
      "intrigued is at index 28622\n",
      "Saved the embedding for intrigued.\n",
      "intriguing is at index 14816\n",
      "Saved the embedding for intriguing.\n",
      "introspective is at index 22845\n",
      "Saved the embedding for introspective.\n",
      "invested is at index 5221\n",
      "Saved the embedding for invested.\n",
      "investigate is at index 4830\n",
      "Saved the embedding for investigate.\n",
      "investigative is at index 13222\n",
      "Saved the embedding for investigative.\n",
      "investigatory is at index 25463\n",
      "Saved the embedding for investigatory.\n",
      "invigorated is at index 12259\n",
      "Saved the embedding for invigorated.\n",
      "involved is at index 963\n",
      "Saved the embedding for involved.\n",
      "irascible is at index 10209\n",
      "Saved the embedding for irascible.\n",
      "irate is at index 10209\n",
      "Saved the embedding for irate.\n",
      "ire is at index 25509\n",
      "Saved the embedding for ire.\n",
      "ireful is at index 25509\n",
      "Saved the embedding for ireful.\n",
      "irked is at index 10209\n",
      "Saved the embedding for irked.\n",
      "ironic is at index 25553\n",
      "Saved the embedding for ironic.\n",
      "irony is at index 21490\n",
      "Saved the embedding for irony.\n",
      "irresolute is at index 10209\n",
      "Saved the embedding for irresolute.\n",
      "irritable is at index 26570\n",
      "Saved the embedding for irritable.\n",
      "irritably is at index 26570\n",
      "Saved the embedding for irritably.\n",
      "irritated is at index 35270\n",
      "Saved the embedding for irritated.\n",
      "irritation is at index 32776\n",
      "Saved the embedding for irritation.\n",
      "isolated is at index 8067\n",
      "Saved the embedding for isolated.\n",
      "jabbed is at index 27916\n",
      "Saved the embedding for jabbed.\n",
      "jaded is at index 1236\n",
      "Saved the embedding for jaded.\n",
      "jarred is at index 25413\n",
      "Saved the embedding for jarred.\n",
      "jarring is at index 35659\n",
      "Saved the embedding for jarring.\n",
      "jaunty is at index 1236\n",
      "Saved the embedding for jaunty.\n",
      "jawed is at index 15345\n",
      "Saved the embedding for jawed.\n",
      "jealous is at index 27064\n",
      "Saved the embedding for jealous.\n",
      "jeering is at index 4112\n",
      "Saved the embedding for jeering.\n",
      "jesting is at index 1236\n",
      "Saved the embedding for jesting.\n",
      "jilted is at index 1236\n",
      "Saved the embedding for jilted.\n",
      "jittery is at index 1236\n",
      "Saved the embedding for jittery.\n",
      "jocular is at index 1236\n",
      "Saved the embedding for jocular.\n",
      "joking is at index 22024\n",
      "Saved the embedding for joking.\n",
      "jolly is at index 1236\n",
      "Saved the embedding for jolly.\n",
      "jolted is at index 1236\n",
      "Saved the embedding for jolted.\n",
      "jovial is at index 1236\n",
      "Saved the embedding for jovial.\n",
      "joy is at index 5823\n",
      "Saved the embedding for joy.\n",
      "joyful is at index 32076\n",
      "Saved the embedding for joyful.\n",
      "joyfulness is at index 5823\n",
      "Saved the embedding for joyfulness.\n",
      "joyless is at index 5823\n",
      "Saved the embedding for joyless.\n",
      "joyous is at index 5823\n",
      "Saved the embedding for joyous.\n",
      "jubilant is at index 1236\n",
      "Saved the embedding for jubilant.\n",
      "jubilation is at index 1236\n",
      "Saved the embedding for jubilation.\n",
      "judgemental is at index 17219\n",
      "Saved the embedding for judgemental.\n",
      "judging is at index 17298\n",
      "Saved the embedding for judging.\n",
      "judgmental is at index 7579\n",
      "Saved the embedding for judgmental.\n",
      "judicious is at index 21392\n",
      "Saved the embedding for judicious.\n",
      "jumpy is at index 3704\n",
      "Saved the embedding for jumpy.\n",
      "justified is at index 14267\n",
      "Saved the embedding for justified.\n",
      "keen is at index 5609\n",
      "Saved the embedding for keen.\n",
      "kind is at index 761\n",
      "Saved the embedding for kind.\n",
      "kindhearted is at index 761\n",
      "Saved the embedding for kindhearted.\n",
      "kiss is at index 13301\n",
      "Saved the embedding for kiss.\n",
      "knowing is at index 4730\n",
      "Saved the embedding for knowing.\n",
      "knowledgable is at index 216\n",
      "Saved the embedding for knowledgable.\n",
      "knowledgeable is at index 26782\n",
      "Saved the embedding for knowledgeable.\n",
      "kosher is at index 36930\n",
      "Saved the embedding for kosher.\n",
      "lackadaisical is at index 1762\n",
      "Saved the embedding for lackadaisical.\n",
      "lackluster is at index 28369\n",
      "Saved the embedding for lackluster.\n",
      "laconic is at index 784\n",
      "Saved the embedding for laconic.\n",
      "lambaste is at index 17988\n",
      "Saved the embedding for lambaste.\n",
      "lamentable is at index 25532\n",
      "Saved the embedding for lamentable.\n",
      "lamenting is at index 25532\n",
      "Saved the embedding for lamenting.\n",
      "lascivious is at index 784\n",
      "Saved the embedding for lascivious.\n",
      "laugh is at index 7923\n",
      "Saved the embedding for laugh.\n",
      "laughing is at index 11339\n",
      "Saved the embedding for laughing.\n",
      "laughter is at index 16805\n",
      "Saved the embedding for laughter.\n",
      "lazy is at index 22414\n",
      "Saved the embedding for lazy.\n",
      "leaving is at index 1618\n",
      "Saved the embedding for leaving.\n",
      "lecherous is at index 2084\n",
      "Saved the embedding for lecherous.\n",
      "lecturing is at index 25673\n",
      "Saved the embedding for lecturing.\n",
      "leering is at index 2084\n",
      "Saved the embedding for leering.\n",
      "leery is at index 2084\n",
      "Saved the embedding for leery.\n",
      "letdown is at index 905\n",
      "Saved the embedding for letdown.\n",
      "lethargic is at index 35370\n",
      "Saved the embedding for lethargic.\n",
      "levelheaded is at index 672\n",
      "Saved the embedding for levelheaded.\n",
      "lewd is at index 31942\n",
      "Saved the embedding for lewd.\n",
      "libidinous is at index 21748\n",
      "Saved the embedding for libidinous.\n",
      "lifeless is at index 37019\n",
      "Saved the embedding for lifeless.\n",
      "lighthearted is at index 1109\n",
      "Saved the embedding for lighthearted.\n",
      "lipped is at index 784\n",
      "Saved the embedding for lipped.\n",
      "listening is at index 6288\n",
      "Saved the embedding for listening.\n",
      "listless is at index 889\n",
      "Saved the embedding for listless.\n",
      "lively is at index 20902\n",
      "Saved the embedding for lively.\n",
      "livid is at index 784\n",
      "Saved the embedding for livid.\n",
      "loaded is at index 7973\n",
      "Saved the embedding for loaded.\n",
      "loath is at index 4600\n",
      "Saved the embedding for loath.\n",
      "loathe is at index 4600\n",
      "Saved the embedding for loathe.\n",
      "loathing is at index 4600\n",
      "Saved the embedding for loathing.\n",
      "loathsome is at index 4600\n",
      "Saved the embedding for loathsome.\n",
      "locked is at index 5930\n",
      "Saved the embedding for locked.\n",
      "loneliness is at index 27942\n",
      "Saved the embedding for loneliness.\n",
      "lonely is at index 20100\n",
      "Saved the embedding for lonely.\n",
      "longing is at index 36171\n",
      "Saved the embedding for longing.\n",
      "looking is at index 546\n",
      "Saved the embedding for looking.\n",
      "loony is at index 4600\n",
      "Saved the embedding for loony.\n",
      "loss is at index 872\n",
      "Saved the embedding for loss.\n",
      "lost is at index 685\n",
      "Saved the embedding for lost.\n",
      "loud is at index 7337\n",
      "Saved the embedding for loud.\n",
      "lousy is at index 38909\n",
      "Saved the embedding for lousy.\n",
      "love is at index 657\n",
      "Saved the embedding for love.\n",
      "loving is at index 8520\n",
      "Saved the embedding for loving.\n",
      "lowliness is at index 614\n",
      "Saved the embedding for lowliness.\n",
      "lurid is at index 30461\n",
      "Saved the embedding for lurid.\n",
      "lustful is at index 30864\n",
      "Saved the embedding for lustful.\n",
      "lusting is at index 30864\n",
      "Saved the embedding for lusting.\n",
      "lusty is at index 30864\n",
      "Saved the embedding for lusty.\n",
      "lying is at index 6480\n",
      "Saved the embedding for lying.\n",
      "mad is at index 7758\n",
      "Saved the embedding for mad.\n",
      "maddened is at index 475\n",
      "Saved the embedding for maddened.\n",
      "madness is at index 24714\n",
      "Saved the embedding for madness.\n",
      "malcontent is at index 8196\n",
      "Saved the embedding for malcontent.\n",
      "maleficent is at index 8196\n",
      "Saved the embedding for maleficent.\n",
      "malevolent is at index 2943\n",
      "Saved the embedding for malevolent.\n",
      "malice is at index 39625\n",
      "Saved the embedding for malice.\n",
      "malicious is at index 15237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for malicious.\n",
      "malignant is at index 8196\n",
      "Saved the embedding for malignant.\n",
      "maniacal is at index 41288\n",
      "Saved the embedding for maniacal.\n",
      "manipulative is at index 39802\n",
      "Saved the embedding for manipulative.\n",
      "marveled is at index 25591\n",
      "Saved the embedding for marveled.\n",
      "master is at index 4710\n",
      "Saved the embedding for master.\n",
      "mean is at index 1266\n",
      "Saved the embedding for mean.\n",
      "meaningful is at index 6667\n",
      "Saved the embedding for meaningful.\n",
      "meditative is at index 5679\n",
      "Saved the embedding for meditative.\n",
      "meek is at index 162\n",
      "Saved the embedding for meek.\n",
      "melancholic is at index 45565\n",
      "Saved the embedding for melancholic.\n",
      "melancholy is at index 40602\n",
      "Saved the embedding for melancholy.\n",
      "mellow is at index 34384\n",
      "Saved the embedding for mellow.\n",
      "menace is at index 24213\n",
      "Saved the embedding for menace.\n",
      "menacing is at index 32002\n",
      "Saved the embedding for menacing.\n",
      "mental is at index 2536\n",
      "Saved the embedding for mental.\n",
      "merrily is at index 9374\n",
      "Saved the embedding for merrily.\n",
      "merry is at index 35814\n",
      "Saved the embedding for merry.\n",
      "mesmerized is at index 31294\n",
      "Saved the embedding for mesmerized.\n",
      "miffed is at index 475\n",
      "Saved the embedding for miffed.\n",
      "mild is at index 10439\n",
      "Saved the embedding for mild.\n",
      "mincing is at index 5251\n",
      "Saved the embedding for mincing.\n",
      "mindful is at index 20807\n",
      "Saved the embedding for mindful.\n",
      "mindless is at index 41406\n",
      "Saved the embedding for mindless.\n",
      "mirrored is at index 31349\n",
      "Saved the embedding for mirrored.\n",
      "mirth is at index 475\n",
      "Saved the embedding for mirth.\n",
      "mirthful is at index 475\n",
      "Saved the embedding for mirthful.\n",
      "misanthropic is at index 3834\n",
      "Saved the embedding for misanthropic.\n",
      "mischief is at index 26245\n",
      "Saved the embedding for mischief.\n",
      "mischievous is at index 3834\n",
      "Saved the embedding for mischievous.\n",
      "mischievousness is at index 3834\n",
      "Saved the embedding for mischievousness.\n",
      "miserable is at index 20161\n",
      "Saved the embedding for miserable.\n",
      "misery is at index 23110\n",
      "Saved the embedding for misery.\n",
      "misgiving is at index 3834\n",
      "Saved the embedding for misgiving.\n",
      "mislead is at index 34747\n",
      "Saved the embedding for mislead.\n",
      "mistrust is at index 34873\n",
      "Saved the embedding for mistrust.\n",
      "mistrustful is at index 34873\n",
      "Saved the embedding for mistrustful.\n",
      "mistrusting is at index 34873\n",
      "Saved the embedding for mistrusting.\n",
      "misunderstood is at index 32085\n",
      "Saved the embedding for misunderstood.\n",
      "mockery is at index 34641\n",
      "Saved the embedding for mockery.\n",
      "mocking is at index 27813\n",
      "Saved the embedding for mocking.\n",
      "mockingly is at index 16177\n",
      "Saved the embedding for mockingly.\n",
      "modest is at index 6473\n",
      "Saved the embedding for modest.\n",
      "monotone is at index 6154\n",
      "Saved the embedding for monotone.\n",
      "monster is at index 13317\n",
      "Saved the embedding for monster.\n",
      "moody is at index 6711\n",
      "Saved the embedding for moody.\n",
      "mopey is at index 475\n",
      "Saved the embedding for mopey.\n",
      "morose is at index 14628\n",
      "Saved the embedding for morose.\n",
      "mortified is at index 18631\n",
      "Saved the embedding for mortified.\n",
      "motivated is at index 7958\n",
      "Saved the embedding for motivated.\n",
      "mournful is at index 15213\n",
      "Saved the embedding for mournful.\n",
      "mournfulness is at index 15213\n",
      "Saved the embedding for mournfulness.\n",
      "mourning is at index 19293\n",
      "Saved the embedding for mourning.\n",
      "mouthed is at index 475\n",
      "Saved the embedding for mouthed.\n",
      "moved is at index 1410\n",
      "Saved the embedding for moved.\n",
      "muddled is at index 475\n",
      "Saved the embedding for muddled.\n",
      "mum is at index 8562\n",
      "Saved the embedding for mum.\n",
      "murderous is at index 32883\n",
      "Saved the embedding for murderous.\n",
      "musical is at index 4388\n",
      "Saved the embedding for musical.\n",
      "musing is at index 11721\n",
      "Saved the embedding for musing.\n",
      "muster is at index 27665\n",
      "Saved the embedding for muster.\n",
      "mute is at index 33758\n",
      "Saved the embedding for mute.\n",
      "muted is at index 21677\n",
      "Saved the embedding for muted.\n",
      "muttering is at index 16119\n",
      "Saved the embedding for muttering.\n",
      "mysterious is at index 12754\n",
      "Saved the embedding for mysterious.\n",
      "mystical is at index 39795\n",
      "Saved the embedding for mystical.\n",
      "mystified is at index 37763\n",
      "Saved the embedding for mystified.\n",
      "naive is at index 25672\n",
      "Saved the embedding for naive.\n",
      "napping is at index 295\n",
      "Saved the embedding for napping.\n",
      "narrow is at index 6787\n",
      "Saved the embedding for narrow.\n",
      "nasty is at index 15455\n",
      "Saved the embedding for nasty.\n",
      "natural is at index 1632\n",
      "Saved the embedding for natural.\n",
      "natured is at index 23577\n",
      "Saved the embedding for natured.\n",
      "naughty is at index 38384\n",
      "Saved the embedding for naughty.\n",
      "nausea is at index 27214\n",
      "Saved the embedding for nausea.\n",
      "nauseated is at index 39117\n",
      "Saved the embedding for nauseated.\n",
      "nauseous is at index 39117\n",
      "Saved the embedding for nauseous.\n",
      "needy is at index 28166\n",
      "Saved the embedding for needy.\n",
      "nefarious is at index 33952\n",
      "Saved the embedding for nefarious.\n",
      "negating is at index 15183\n",
      "Saved the embedding for negating.\n",
      "negative is at index 2430\n",
      "Saved the embedding for negative.\n",
      "negativity is at index 30269\n",
      "Saved the embedding for negativity.\n",
      "neglected is at index 20428\n",
      "Saved the embedding for neglected.\n",
      "nerdy is at index 38286\n",
      "Saved the embedding for nerdy.\n",
      "nerved is at index 295\n",
      "Saved the embedding for nerved.\n",
      "nerves is at index 17358\n",
      "Saved the embedding for nerves.\n",
      "nervous is at index 7464\n",
      "Saved the embedding for nervous.\n",
      "nervously is at index 40968\n",
      "Saved the embedding for nervously.\n",
      "nervousness is at index 7464\n",
      "Saved the embedding for nervousness.\n",
      "nescient is at index 295\n",
      "Saved the embedding for nescient.\n",
      "nettled is at index 1161\n",
      "Saved the embedding for nettled.\n",
      "neutral is at index 7974\n",
      "Saved the embedding for neutral.\n",
      "neutrality is at index 18755\n",
      "Saved the embedding for neutrality.\n",
      "nice is at index 2579\n",
      "Saved the embedding for nice.\n",
      "noisy is at index 28269\n",
      "Saved the embedding for noisy.\n",
      "nonbelief is at index 786\n",
      "Saved the embedding for nonbelief.\n",
      "nonchalance is at index 786\n",
      "Saved the embedding for nonchalance.\n",
      "nonchalant is at index 786\n",
      "Saved the embedding for nonchalant.\n",
      "noncommittal is at index 786\n",
      "Saved the embedding for noncommittal.\n",
      "noncompliant is at index 786\n",
      "Saved the embedding for noncompliant.\n",
      "nonplussed is at index 786\n",
      "Saved the embedding for nonplussed.\n",
      "nonsensical is at index 42475\n",
      "Saved the embedding for nonsensical.\n",
      "normal is at index 2340\n",
      "Saved the embedding for normal.\n",
      "nosey is at index 8658\n",
      "Saved the embedding for nosey.\n",
      "nostalgic is at index 28055\n",
      "Saved the embedding for nostalgic.\n",
      "nosy is at index 13736\n",
      "Saved the embedding for nosy.\n",
      "numb is at index 31086\n",
      "Saved the embedding for numb.\n",
      "obedient is at index 44729\n",
      "Saved the embedding for obedient.\n",
      "objecting is at index 7626\n",
      "Saved the embedding for objecting.\n",
      "objection is at index 24763\n",
      "Saved the embedding for objection.\n",
      "objective is at index 4554\n",
      "Saved the embedding for objective.\n",
      "obliged is at index 23964\n",
      "Saved the embedding for obliged.\n",
      "obliging is at index 23762\n",
      "Saved the embedding for obliging.\n",
      "oblivious is at index 35606\n",
      "Saved the embedding for oblivious.\n",
      "observant is at index 20717\n",
      "Saved the embedding for observant.\n",
      "observing is at index 21981\n",
      "Saved the embedding for observing.\n",
      "obsessed is at index 17593\n",
      "Saved the embedding for obsessed.\n",
      "obstinate is at index 30896\n",
      "Saved the embedding for obstinate.\n",
      "occupied is at index 9533\n",
      "Saved the embedding for occupied.\n",
      "odd is at index 8372\n",
      "Saved the embedding for odd.\n",
      "odious is at index 7452\n",
      "Saved the embedding for odious.\n",
      "off is at index 160\n",
      "Saved the embedding for off.\n",
      "offended is at index 22169\n",
      "Saved the embedding for offended.\n",
      "offensive is at index 2555\n",
      "Saved the embedding for offensive.\n",
      "ogling is at index 1021\n",
      "Saved the embedding for ogling.\n",
      "okay is at index 8578\n",
      "Saved the embedding for okay.\n",
      "on is at index 15\n",
      "Saved the embedding for on.\n",
      "open is at index 490\n",
      "Saved the embedding for open.\n",
      "openness is at index 23163\n",
      "Saved the embedding for openness.\n",
      "opposed is at index 4340\n",
      "Saved the embedding for opposed.\n",
      "oppositional is at index 39734\n",
      "Saved the embedding for oppositional.\n",
      "oppressed is at index 32881\n",
      "Saved the embedding for oppressed.\n",
      "optimism is at index 9743\n",
      "Saved the embedding for optimism.\n",
      "optimistic is at index 7168\n",
      "Saved the embedding for optimistic.\n",
      "ordering is at index 12926\n",
      "Saved the embedding for ordering.\n",
      "orgasmic is at index 39396\n",
      "Saved the embedding for orgasmic.\n",
      "ornery is at index 50\n",
      "Saved the embedding for ornery.\n",
      "ouch is at index 1021\n",
      "Saved the embedding for ouch.\n",
      "out is at index 66\n",
      "Saved the embedding for out.\n",
      "outburst is at index 28999\n",
      "Saved the embedding for outburst.\n",
      "outcry is at index 19900\n",
      "Saved the embedding for outcry.\n",
      "outed is at index 66\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for outed.\n",
      "outlandish is at index 35785\n",
      "Saved the embedding for outlandish.\n",
      "outrage is at index 10618\n",
      "Saved the embedding for outrage.\n",
      "outraged is at index 22339\n",
      "Saved the embedding for outraged.\n",
      "outspoken is at index 16120\n",
      "Saved the embedding for outspoken.\n",
      "overbearing is at index 81\n",
      "Saved the embedding for overbearing.\n",
      "overexcited is at index 39919\n",
      "Saved the embedding for overexcited.\n",
      "overjoyed is at index 81\n",
      "Saved the embedding for overjoyed.\n",
      "overshadowed is at index 22140\n",
      "Saved the embedding for overshadowed.\n",
      "overstrung is at index 81\n",
      "Saved the embedding for overstrung.\n",
      "overwhelmed is at index 13203\n",
      "Saved the embedding for overwhelmed.\n",
      "overworked is at index 81\n",
      "Saved the embedding for overworked.\n",
      "overwrought is at index 42674\n",
      "Saved the embedding for overwrought.\n",
      "pain is at index 2400\n",
      "Saved the embedding for pain.\n",
      "pained is at index 181\n",
      "Saved the embedding for pained.\n",
      "painful is at index 8661\n",
      "Saved the embedding for painful.\n",
      "painfully is at index 32020\n",
      "Saved the embedding for painfully.\n",
      "panic is at index 9810\n",
      "Saved the embedding for panic.\n",
      "panicked is at index 28604\n",
      "Saved the embedding for panicked.\n",
      "panicky is at index 5730\n",
      "Saved the embedding for panicky.\n",
      "paralyzed is at index 28582\n",
      "Saved the embedding for paralyzed.\n",
      "paranoid is at index 33554\n",
      "Saved the embedding for paranoid.\n",
      "passionate is at index 8840\n",
      "Saved the embedding for passionate.\n",
      "passive is at index 18718\n",
      "Saved the embedding for passive.\n",
      "patience is at index 11383\n",
      "Saved the embedding for patience.\n",
      "patient is at index 3186\n",
      "Saved the embedding for patient.\n",
      "patronizing is at index 18528\n",
      "Saved the embedding for patronizing.\n",
      "pause is at index 13787\n",
      "Saved the embedding for pause.\n",
      "pausing is at index 6044\n",
      "Saved the embedding for pausing.\n",
      "peaceful is at index 7053\n",
      "Saved the embedding for peaceful.\n",
      "peculiar is at index 28178\n",
      "Saved the embedding for peculiar.\n",
      "peering is at index 3723\n",
      "Saved the embedding for peering.\n",
      "peeved is at index 32734\n",
      "Saved the embedding for peeved.\n",
      "peevish is at index 3723\n",
      "Saved the embedding for peevish.\n",
      "pensive is at index 181\n",
      "Saved the embedding for pensive.\n",
      "peppy is at index 3723\n",
      "Saved the embedding for peppy.\n",
      "perceptive is at index 228\n",
      "Saved the embedding for perceptive.\n",
      "perfidious is at index 32168\n",
      "Saved the embedding for perfidious.\n",
      "perky is at index 228\n",
      "Saved the embedding for perky.\n",
      "perplexed is at index 33708\n",
      "Saved the embedding for perplexed.\n",
      "perplexing is at index 33708\n",
      "Saved the embedding for perplexing.\n",
      "persistent is at index 13109\n",
      "Saved the embedding for persistent.\n",
      "personable is at index 621\n",
      "Saved the embedding for personable.\n",
      "perturbed is at index 32819\n",
      "Saved the embedding for perturbed.\n",
      "perverse is at index 41271\n",
      "Saved the embedding for perverse.\n",
      "pesky is at index 38432\n",
      "Saved the embedding for pesky.\n",
      "pessimism is at index 36494\n",
      "Saved the embedding for pessimism.\n",
      "pessimistic is at index 32415\n",
      "Saved the embedding for pessimistic.\n",
      "pestered is at index 19024\n",
      "Saved the embedding for pestered.\n",
      "petitioning is at index 5265\n",
      "Saved the embedding for petitioning.\n",
      "petrified is at index 4716\n",
      "Saved the embedding for petrified.\n",
      "petty is at index 25070\n",
      "Saved the embedding for petty.\n",
      "petulant is at index 4716\n",
      "Saved the embedding for petulant.\n",
      "picked is at index 2738\n",
      "Saved the embedding for picked.\n",
      "piercing is at index 38105\n",
      "Saved the embedding for piercing.\n",
      "pinched is at index 7756\n",
      "Saved the embedding for pinched.\n",
      "pious is at index 44843\n",
      "Saved the embedding for pious.\n",
      "piqued is at index 181\n",
      "Saved the embedding for piqued.\n",
      "pissed is at index 34449\n",
      "Saved the embedding for pissed.\n",
      "pitiable is at index 8516\n",
      "Saved the embedding for pitiable.\n",
      "pitiful is at index 8516\n",
      "Saved the embedding for pitiful.\n",
      "pity is at index 31373\n",
      "Saved the embedding for pity.\n",
      "pitying is at index 31373\n",
      "Saved the embedding for pitying.\n",
      "placated is at index 15155\n",
      "Saved the embedding for placated.\n",
      "placation is at index 15155\n",
      "Saved the embedding for placation.\n",
      "placid is at index 15155\n",
      "Saved the embedding for placid.\n",
      "plain is at index 10798\n",
      "Saved the embedding for plain.\n",
      "plaintive is at index 46560\n",
      "Saved the embedding for plaintive.\n",
      "planning is at index 1884\n",
      "Saved the embedding for planning.\n",
      "playful is at index 23317\n",
      "Saved the embedding for playful.\n",
      "playfully is at index 310\n",
      "Saved the embedding for playfully.\n",
      "pleading is at index 17532\n",
      "Saved the embedding for pleading.\n",
      "pleasant is at index 16219\n",
      "Saved the embedding for pleasant.\n",
      "pleased is at index 4343\n",
      "Saved the embedding for pleased.\n",
      "pleasing is at index 25234\n",
      "Saved the embedding for pleasing.\n",
      "pleasurable is at index 19518\n",
      "Saved the embedding for pleasurable.\n",
      "pleasure is at index 10483\n",
      "Saved the embedding for pleasure.\n",
      "pleasured is at index 19518\n",
      "Saved the embedding for pleasured.\n",
      "pliant is at index 2968\n",
      "Saved the embedding for pliant.\n",
      "plotting is at index 22849\n",
      "Saved the embedding for plotting.\n",
      "poignant is at index 27274\n",
      "Saved the embedding for poignant.\n",
      "pointed is at index 3273\n",
      "Saved the embedding for pointed.\n",
      "poised is at index 10137\n",
      "Saved the embedding for poised.\n",
      "polite is at index 24908\n",
      "Saved the embedding for polite.\n",
      "pompous is at index 34415\n",
      "Saved the embedding for pompous.\n",
      "ponder is at index 31930\n",
      "Saved the embedding for ponder.\n",
      "pondering is at index 13362\n",
      "Saved the embedding for pondering.\n",
      "pooping is at index 4202\n",
      "Saved the embedding for pooping.\n",
      "pop is at index 3495\n",
      "Saved the embedding for pop.\n",
      "posing is at index 12681\n",
      "Saved the embedding for posing.\n",
      "positive is at index 1313\n",
      "Saved the embedding for positive.\n",
      "positivity is at index 8593\n",
      "Saved the embedding for positivity.\n",
      "possibly is at index 3544\n",
      "Saved the embedding for possibly.\n",
      "pout is at index 181\n",
      "Saved the embedding for pout.\n",
      "pouting is at index 181\n",
      "Saved the embedding for pouting.\n",
      "pouty is at index 181\n",
      "Saved the embedding for pouty.\n",
      "powerful is at index 2247\n",
      "Saved the embedding for powerful.\n",
      "powerless is at index 33128\n",
      "Saved the embedding for powerless.\n",
      "pranking is at index 3349\n",
      "Saved the embedding for pranking.\n",
      "precarious is at index 27180\n",
      "Saved the embedding for precarious.\n",
      "predatory is at index 29216\n",
      "Saved the embedding for predatory.\n",
      "prejudiced is at index 34286\n",
      "Saved the embedding for prejudiced.\n",
      "preoccupied is at index 1198\n",
      "Saved the embedding for preoccupied.\n",
      "prepared is at index 2460\n",
      "Saved the embedding for prepared.\n",
      "preparing is at index 4568\n",
      "Saved the embedding for preparing.\n",
      "pretending is at index 23748\n",
      "Saved the embedding for pretending.\n",
      "pretentious is at index 11857\n",
      "Saved the embedding for pretentious.\n",
      "prideful is at index 7040\n",
      "Saved the embedding for prideful.\n",
      "priggish is at index 3349\n",
      "Saved the embedding for priggish.\n",
      "primed is at index 32575\n",
      "Saved the embedding for primed.\n",
      "private is at index 940\n",
      "Saved the embedding for private.\n",
      "processing is at index 5774\n",
      "Saved the embedding for processing.\n",
      "propositioning is at index 16104\n",
      "Saved the embedding for propositioning.\n",
      "proud is at index 2602\n",
      "Saved the embedding for proud.\n",
      "provocative is at index 21051\n",
      "Saved the embedding for provocative.\n",
      "provoke is at index 28184\n",
      "Saved the embedding for provoke.\n",
      "provoked is at index 24972\n",
      "Saved the embedding for provoked.\n",
      "provoking is at index 35359\n",
      "Saved the embedding for provoking.\n",
      "prying is at index 181\n",
      "Saved the embedding for prying.\n",
      "psycho is at index 37338\n",
      "Saved the embedding for psycho.\n",
      "psychotic is at index 41559\n",
      "Saved the embedding for psychotic.\n",
      "puckish is at index 9258\n",
      "Saved the embedding for puckish.\n",
      "puerile is at index 181\n",
      "Saved the embedding for puerile.\n",
      "pugnacious is at index 181\n",
      "Saved the embedding for pugnacious.\n",
      "punished is at index 14459\n",
      "Saved the embedding for punished.\n",
      "punishing is at index 23477\n",
      "Saved the embedding for punishing.\n",
      "punitive is at index 21987\n",
      "Saved the embedding for punitive.\n",
      "punk is at index 19742\n",
      "Saved the embedding for punk.\n",
      "puppyish is at index 20830\n",
      "Saved the embedding for puppyish.\n",
      "purposeful is at index 3508\n",
      "Saved the embedding for purposeful.\n",
      "pursed is at index 26934\n",
      "Saved the embedding for pursed.\n",
      "put is at index 342\n",
      "Saved the embedding for put.\n",
      "putting is at index 2057\n",
      "Saved the embedding for putting.\n",
      "puzzled is at index 36742\n",
      "Saved the embedding for puzzled.\n",
      "puzzlement is at index 47037\n",
      "Saved the embedding for puzzlement.\n",
      "qualms is at index 22043\n",
      "Saved the embedding for qualms.\n",
      "quarrelsome is at index 39486\n",
      "Saved the embedding for quarrelsome.\n",
      "queasy is at index 1192\n",
      "Saved the embedding for queasy.\n",
      "quenched is at index 2677\n",
      "Saved the embedding for quenched.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "questionable is at index 12474\n",
      "Saved the embedding for questionable.\n",
      "questioning is at index 8026\n",
      "Saved the embedding for questioning.\n",
      "questioningly is at index 864\n",
      "Saved the embedding for questioningly.\n",
      "quiet is at index 5128\n",
      "Saved the embedding for quiet.\n",
      "quietness is at index 5128\n",
      "Saved the embedding for quietness.\n",
      "quilt is at index 2677\n",
      "Saved the embedding for quilt.\n",
      "quirky is at index 22364\n",
      "Saved the embedding for quirky.\n",
      "quizzical is at index 29316\n",
      "Saved the embedding for quizzical.\n",
      "rabid is at index 39660\n",
      "Saved the embedding for rabid.\n",
      "racked is at index 20208\n",
      "Saved the embedding for racked.\n",
      "radiant is at index 35787\n",
      "Saved the embedding for radiant.\n",
      "rage is at index 14706\n",
      "Saved the embedding for rage.\n",
      "raged is at index 31927\n",
      "Saved the embedding for raged.\n",
      "ragged is at index 910\n",
      "Saved the embedding for ragged.\n",
      "raging is at index 23333\n",
      "Saved the embedding for raging.\n",
      "rancorous is at index 21560\n",
      "Saved the embedding for rancorous.\n",
      "randy is at index 910\n",
      "Saved the embedding for randy.\n",
      "rapt is at index 34524\n",
      "Saved the embedding for rapt.\n",
      "rattled is at index 21602\n",
      "Saved the embedding for rattled.\n",
      "raving is at index 910\n",
      "Saved the embedding for raving.\n",
      "reactive is at index 34729\n",
      "Saved the embedding for reactive.\n",
      "ready is at index 1227\n",
      "Saved the embedding for ready.\n",
      "realization is at index 24179\n",
      "Saved the embedding for realization.\n",
      "reassured is at index 29336\n",
      "Saved the embedding for reassured.\n",
      "rebellious is at index 38017\n",
      "Saved the embedding for rebellious.\n",
      "rebuke is at index 28155\n",
      "Saved the embedding for rebuke.\n",
      "recalling is at index 20239\n",
      "Saved the embedding for recalling.\n",
      "receptive is at index 33052\n",
      "Saved the embedding for receptive.\n",
      "reckless is at index 13508\n",
      "Saved the embedding for reckless.\n",
      "recoil is at index 44983\n",
      "Saved the embedding for recoil.\n",
      "recoiling is at index 3872\n",
      "Saved the embedding for recoiling.\n",
      "reflecting is at index 10811\n",
      "Saved the embedding for reflecting.\n",
      "reflection is at index 12456\n",
      "Saved the embedding for reflection.\n",
      "reflective is at index 22213\n",
      "Saved the embedding for reflective.\n",
      "refulgent is at index 769\n",
      "Saved the embedding for refulgent.\n",
      "refusing is at index 10520\n",
      "Saved the embedding for refusing.\n",
      "regret is at index 9917\n",
      "Saved the embedding for regret.\n",
      "regretful is at index 9917\n",
      "Saved the embedding for regretful.\n",
      "rejected is at index 3946\n",
      "Saved the embedding for rejected.\n",
      "rejecting is at index 19695\n",
      "Saved the embedding for rejecting.\n",
      "rejection is at index 16117\n",
      "Saved the embedding for rejection.\n",
      "rejoicing is at index 24586\n",
      "Saved the embedding for rejoicing.\n",
      "relaxation is at index 26545\n",
      "Saved the embedding for relaxation.\n",
      "relaxed is at index 11956\n",
      "Saved the embedding for relaxed.\n",
      "relentless is at index 16476\n",
      "Saved the embedding for relentless.\n",
      "relief is at index 3500\n",
      "Saved the embedding for relief.\n",
      "relieved is at index 15126\n",
      "Saved the embedding for relieved.\n",
      "relived is at index 6258\n",
      "Saved the embedding for relived.\n",
      "reluctant is at index 11923\n",
      "Saved the embedding for reluctant.\n",
      "reluctantly is at index 33146\n",
      "Saved the embedding for reluctantly.\n",
      "remorse is at index 23312\n",
      "Saved the embedding for remorse.\n",
      "remorseful is at index 23312\n",
      "Saved the embedding for remorseful.\n",
      "repelled is at index 25633\n",
      "Saved the embedding for repelled.\n",
      "repressed is at index 2851\n",
      "Saved the embedding for repressed.\n",
      "reproach is at index 2851\n",
      "Saved the embedding for reproach.\n",
      "reproachful is at index 2851\n",
      "Saved the embedding for reproachful.\n",
      "repugnance is at index 2851\n",
      "Saved the embedding for repugnance.\n",
      "repugnant is at index 2851\n",
      "Saved the embedding for repugnant.\n",
      "repulsed is at index 2851\n",
      "Saved the embedding for repulsed.\n",
      "repulsion is at index 2851\n",
      "Saved the embedding for repulsion.\n",
      "resent is at index 31379\n",
      "Saved the embedding for resent.\n",
      "resentful is at index 31379\n",
      "Saved the embedding for resentful.\n",
      "resenting is at index 31379\n",
      "Saved the embedding for resenting.\n",
      "resentment is at index 27111\n",
      "Saved the embedding for resentment.\n",
      "reserved is at index 1875\n",
      "Saved the embedding for reserved.\n",
      "resignation is at index 6985\n",
      "Saved the embedding for resignation.\n",
      "resigned is at index 6490\n",
      "Saved the embedding for resigned.\n",
      "resilience is at index 13790\n",
      "Saved the embedding for resilience.\n",
      "resistance is at index 5910\n",
      "Saved the embedding for resistance.\n",
      "resistant is at index 19152\n",
      "Saved the embedding for resistant.\n",
      "resistent is at index 11942\n",
      "Saved the embedding for resistent.\n",
      "resisting is at index 18907\n",
      "Saved the embedding for resisting.\n",
      "resolute is at index 5032\n",
      "Saved the embedding for resolute.\n",
      "resolved is at index 8179\n",
      "Saved the embedding for resolved.\n",
      "responsive is at index 20666\n",
      "Saved the embedding for responsive.\n",
      "restful is at index 1079\n",
      "Saved the embedding for restful.\n",
      "resting is at index 18403\n",
      "Saved the embedding for resting.\n",
      "restless is at index 36844\n",
      "Saved the embedding for restless.\n",
      "restlessness is at index 1079\n",
      "Saved the embedding for restlessness.\n",
      "restrained is at index 25063\n",
      "Saved the embedding for restrained.\n",
      "restraint is at index 20219\n",
      "Saved the embedding for restraint.\n",
      "retaliating is at index 18570\n",
      "Saved the embedding for retaliating.\n",
      "retaliatory is at index 18570\n",
      "Saved the embedding for retaliatory.\n",
      "rethinking is at index 769\n",
      "Saved the embedding for rethinking.\n",
      "reticence is at index 5494\n",
      "Saved the embedding for reticence.\n",
      "reticent is at index 5494\n",
      "Saved the embedding for reticent.\n",
      "revengeful is at index 13543\n",
      "Saved the embedding for revengeful.\n",
      "reverent is at index 26911\n",
      "Saved the embedding for reverent.\n",
      "revolted is at index 34633\n",
      "Saved the embedding for revolted.\n",
      "revulsion is at index 6910\n",
      "Saved the embedding for revulsion.\n",
      "righteous is at index 37909\n",
      "Saved the embedding for righteous.\n",
      "rigid is at index 24577\n",
      "Saved the embedding for rigid.\n",
      "riled is at index 910\n",
      "Saved the embedding for riled.\n",
      "riotous is at index 13069\n",
      "Saved the embedding for riotous.\n",
      "riveted is at index 32886\n",
      "Saved the embedding for riveted.\n",
      "roar is at index 31733\n",
      "Saved the embedding for roar.\n",
      "roguish is at index 4533\n",
      "Saved the embedding for roguish.\n",
      "roiled is at index 4533\n",
      "Saved the embedding for roiled.\n",
      "rough is at index 6744\n",
      "Saved the embedding for rough.\n",
      "roused is at index 910\n",
      "Saved the embedding for roused.\n",
      "rude is at index 21820\n",
      "Saved the embedding for rude.\n",
      "rueful is at index 910\n",
      "Saved the embedding for rueful.\n",
      "ruffled is at index 910\n",
      "Saved the embedding for ruffled.\n",
      "ruminating is at index 11122\n",
      "Saved the embedding for ruminating.\n",
      "rustled is at index 18309\n",
      "Saved the embedding for rustled.\n",
      "ruthless is at index 25597\n",
      "Saved the embedding for ruthless.\n",
      "sad is at index 5074\n",
      "Saved the embedding for sad.\n",
      "sadden is at index 23330\n",
      "Saved the embedding for sadden.\n",
      "saddened is at index 19934\n",
      "Saved the embedding for saddened.\n",
      "sadistic is at index 5074\n",
      "Saved the embedding for sadistic.\n",
      "sadness is at index 17437\n",
      "Saved the embedding for sadness.\n",
      "salacious is at index 6641\n",
      "Saved the embedding for salacious.\n",
      "salivating is at index 6641\n",
      "Saved the embedding for salivating.\n",
      "sanctimonious is at index 27600\n",
      "Saved the embedding for sanctimonious.\n",
      "sane is at index 37091\n",
      "Saved the embedding for sane.\n",
      "sanguine is at index 579\n",
      "Saved the embedding for sanguine.\n",
      "sappy is at index 2241\n",
      "Saved the embedding for sappy.\n",
      "sarcasm is at index 38522\n",
      "Saved the embedding for sarcasm.\n",
      "sarcastic is at index 39580\n",
      "Saved the embedding for sarcastic.\n",
      "sardonic is at index 579\n",
      "Saved the embedding for sardonic.\n",
      "sassy is at index 579\n",
      "Saved the embedding for sassy.\n",
      "sated is at index 579\n",
      "Saved the embedding for sated.\n",
      "satiated is at index 4005\n",
      "Saved the embedding for satiated.\n",
      "satirical is at index 33937\n",
      "Saved the embedding for satirical.\n",
      "satisfaction is at index 11658\n",
      "Saved the embedding for satisfaction.\n",
      "satisfied is at index 10028\n",
      "Saved the embedding for satisfied.\n",
      "satisfy is at index 15332\n",
      "Saved the embedding for satisfy.\n",
      "saturnine is at index 4005\n",
      "Saved the embedding for saturnine.\n",
      "saucy is at index 2241\n",
      "Saved the embedding for saucy.\n",
      "savage is at index 32264\n",
      "Saved the embedding for savage.\n",
      "scandalized is at index 4220\n",
      "Saved the embedding for scandalized.\n",
      "scare is at index 13207\n",
      "Saved the embedding for scare.\n",
      "scared is at index 8265\n",
      "Saved the embedding for scared.\n",
      "scary is at index 10222\n",
      "Saved the embedding for scary.\n",
      "scattered is at index 12827\n",
      "Saved the embedding for scattered.\n",
      "schadenfreude is at index 8447\n",
      "Saved the embedding for schadenfreude.\n",
      "scheming is at index 30315\n",
      "Saved the embedding for scheming.\n",
      "scoffer is at index 34564\n",
      "Saved the embedding for scoffer.\n",
      "scoffing is at index 34564\n",
      "Saved the embedding for scoffing.\n",
      "scorn is at index 38430\n",
      "Saved the embedding for scorn.\n",
      "scorned is at index 2850\n",
      "Saved the embedding for scorned.\n",
      "scornful is at index 38430\n",
      "Saved the embedding for scornful.\n",
      "scowl is at index 2850\n",
      "Saved the embedding for scowl.\n",
      "scowling is at index 2850\n",
      "Saved the embedding for scowling.\n",
      "scream is at index 22093\n",
      "Saved the embedding for scream.\n",
      "screaming is at index 11347\n",
      "Saved the embedding for screaming.\n",
      "scrutinizing is at index 18470\n",
      "Saved the embedding for scrutinizing.\n",
      "sealed is at index 10497\n",
      "Saved the embedding for sealed.\n",
      "searching is at index 6062\n",
      "Saved the embedding for searching.\n",
      "secretive is at index 27174\n",
      "Saved the embedding for secretive.\n",
      "secretively is at index 3556\n",
      "Saved the embedding for secretively.\n",
      "secure is at index 2823\n",
      "Saved the embedding for secure.\n",
      "sedate is at index 10195\n",
      "Saved the embedding for sedate.\n",
      "seduction is at index 10195\n",
      "Saved the embedding for seduction.\n",
      "seductive is at index 10195\n",
      "Saved the embedding for seductive.\n",
      "seething is at index 842\n",
      "Saved the embedding for seething.\n",
      "self is at index 1403\n",
      "Saved the embedding for self.\n",
      "sensual is at index 18105\n",
      "Saved the embedding for sensual.\n",
      "sentimental is at index 32693\n",
      "Saved the embedding for sentimental.\n",
      "serene is at index 842\n",
      "Saved the embedding for serene.\n",
      "serious is at index 1473\n",
      "Saved the embedding for serious.\n",
      "seriousness is at index 24146\n",
      "Saved the embedding for seriousness.\n",
      "servile is at index 18527\n",
      "Saved the embedding for servile.\n",
      "set is at index 278\n",
      "Saved the embedding for set.\n",
      "severe is at index 3814\n",
      "Saved the embedding for severe.\n",
      "shabby is at index 1481\n",
      "Saved the embedding for shabby.\n",
      "shady is at index 31665\n",
      "Saved the embedding for shady.\n",
      "shaken is at index 17548\n",
      "Saved the embedding for shaken.\n",
      "shaky is at index 22032\n",
      "Saved the embedding for shaky.\n",
      "shame is at index 9208\n",
      "Saved the embedding for shame.\n",
      "shamed is at index 1481\n",
      "Saved the embedding for shamed.\n",
      "shamefaced is at index 9208\n",
      "Saved the embedding for shamefaced.\n",
      "shameful is at index 26722\n",
      "Saved the embedding for shameful.\n",
      "shameless is at index 36778\n",
      "Saved the embedding for shameless.\n",
      "sharp is at index 4406\n",
      "Saved the embedding for sharp.\n",
      "sheepish is at index 14336\n",
      "Saved the embedding for sheepish.\n",
      "sheepishness is at index 14336\n",
      "Saved the embedding for sheepishness.\n",
      "shelled is at index 79\n",
      "Saved the embedding for shelled.\n",
      "shifty is at index 37503\n",
      "Saved the embedding for shifty.\n",
      "shock is at index 4817\n",
      "Saved the embedding for shock.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shocked is at index 6649\n",
      "Saved the embedding for shocked.\n",
      "shocking is at index 8777\n",
      "Saved the embedding for shocking.\n",
      "shockingly is at index 36804\n",
      "Saved the embedding for shockingly.\n",
      "shook is at index 14774\n",
      "Saved the embedding for shook.\n",
      "shout is at index 18066\n",
      "Saved the embedding for shout.\n",
      "shouting is at index 14487\n",
      "Saved the embedding for shouting.\n",
      "shrewd is at index 36943\n",
      "Saved the embedding for shrewd.\n",
      "shy is at index 9152\n",
      "Saved the embedding for shy.\n",
      "shyness is at index 9152\n",
      "Saved the embedding for shyness.\n",
      "sick is at index 4736\n",
      "Saved the embedding for sick.\n",
      "sicken is at index 579\n",
      "Saved the embedding for sicken.\n",
      "sickened is at index 4736\n",
      "Saved the embedding for sickened.\n",
      "sigh is at index 27305\n",
      "Saved the embedding for sigh.\n",
      "silenced is at index 30125\n",
      "Saved the embedding for silenced.\n",
      "silent is at index 8454\n",
      "Saved the embedding for silent.\n",
      "silliness is at index 38052\n",
      "Saved the embedding for silliness.\n",
      "silly is at index 15470\n",
      "Saved the embedding for silly.\n",
      "simmering is at index 25726\n",
      "Saved the embedding for simmering.\n",
      "simper is at index 16207\n",
      "Saved the embedding for simper.\n",
      "simpering is at index 16207\n",
      "Saved the embedding for simpering.\n",
      "simple is at index 2007\n",
      "Saved the embedding for simple.\n",
      "simplicity is at index 25342\n",
      "Saved the embedding for simplicity.\n",
      "sincere is at index 19255\n",
      "Saved the embedding for sincere.\n",
      "sinful is at index 44364\n",
      "Saved the embedding for sinful.\n",
      "singing is at index 6970\n",
      "Saved the embedding for singing.\n",
      "sinister is at index 27570\n",
      "Saved the embedding for sinister.\n",
      "sinisterly is at index 27570\n",
      "Saved the embedding for sinisterly.\n",
      "sizing is at index 39328\n",
      "Saved the embedding for sizing.\n",
      "skeptic is at index 42386\n",
      "Saved the embedding for skeptic.\n",
      "skeptical is at index 14992\n",
      "Saved the embedding for skeptical.\n",
      "skeptically is at index 42386\n",
      "Saved the embedding for skeptically.\n",
      "skepticism is at index 22222\n",
      "Saved the embedding for skepticism.\n",
      "sketchy is at index 15923\n",
      "Saved the embedding for sketchy.\n",
      "skittish is at index 2972\n",
      "Saved the embedding for skittish.\n",
      "slack is at index 25163\n",
      "Saved the embedding for slack.\n",
      "sleazy is at index 18388\n",
      "Saved the embedding for sleazy.\n",
      "sleepy is at index 33782\n",
      "Saved the embedding for sleepy.\n",
      "slick is at index 19038\n",
      "Saved the embedding for slick.\n",
      "slothful is at index 3369\n",
      "Saved the embedding for slothful.\n",
      "slow is at index 2635\n",
      "Saved the embedding for slow.\n",
      "sluggish is at index 16642\n",
      "Saved the embedding for sluggish.\n",
      "sly is at index 40568\n",
      "Saved the embedding for sly.\n",
      "smarmy is at index 5278\n",
      "Saved the embedding for smarmy.\n",
      "smart is at index 2793\n",
      "Saved the embedding for smart.\n",
      "smashed is at index 13263\n",
      "Saved the embedding for smashed.\n",
      "smile is at index 6675\n",
      "Saved the embedding for smile.\n",
      "smiley is at index 6675\n",
      "Saved the embedding for smiley.\n",
      "smiling is at index 12382\n",
      "Saved the embedding for smiling.\n",
      "smirk is at index 5278\n",
      "Saved the embedding for smirk.\n",
      "smirking is at index 44414\n",
      "Saved the embedding for smirking.\n",
      "smoldering is at index 5278\n",
      "Saved the embedding for smoldering.\n",
      "smooching is at index 5278\n",
      "Saved the embedding for smooching.\n",
      "smooth is at index 6921\n",
      "Saved the embedding for smooth.\n",
      "smug is at index 41283\n",
      "Saved the embedding for smug.\n",
      "smugness is at index 41283\n",
      "Saved the embedding for smugness.\n",
      "snake is at index 16173\n",
      "Saved the embedding for snake.\n",
      "snappy is at index 4543\n",
      "Saved the embedding for snappy.\n",
      "snarky is at index 4543\n",
      "Saved the embedding for snarky.\n",
      "snarl is at index 4543\n",
      "Saved the embedding for snarl.\n",
      "snarled is at index 4543\n",
      "Saved the embedding for snarled.\n",
      "snarling is at index 4543\n",
      "Saved the embedding for snarling.\n",
      "snarly is at index 4543\n",
      "Saved the embedding for snarly.\n",
      "sneaky is at index 39399\n",
      "Saved the embedding for sneaky.\n",
      "sneer is at index 18013\n",
      "Saved the embedding for sneer.\n",
      "sneering is at index 18013\n",
      "Saved the embedding for sneering.\n",
      "sneeze is at index 18013\n",
      "Saved the embedding for sneeze.\n",
      "sneezing is at index 18013\n",
      "Saved the embedding for sneezing.\n",
      "snicker is at index 4543\n",
      "Saved the embedding for snicker.\n",
      "snickering is at index 4543\n",
      "Saved the embedding for snickering.\n",
      "snide is at index 4543\n",
      "Saved the embedding for snide.\n",
      "sniggering is at index 4543\n",
      "Saved the embedding for sniggering.\n",
      "sniveling is at index 4543\n",
      "Saved the embedding for sniveling.\n",
      "snobbish is at index 4543\n",
      "Saved the embedding for snobbish.\n",
      "snobby is at index 4543\n",
      "Saved the embedding for snobby.\n",
      "snooty is at index 4543\n",
      "Saved the embedding for snooty.\n",
      "snotty is at index 579\n",
      "Saved the embedding for snotty.\n",
      "sociable is at index 17380\n",
      "Saved the embedding for sociable.\n",
      "soft is at index 3793\n",
      "Saved the embedding for soft.\n",
      "solemn is at index 29807\n",
      "Saved the embedding for solemn.\n",
      "solicitous is at index 22706\n",
      "Saved the embedding for solicitous.\n",
      "solitary is at index 24429\n",
      "Saved the embedding for solitary.\n",
      "solitude is at index 41813\n",
      "Saved the embedding for solitude.\n",
      "somber is at index 16487\n",
      "Saved the embedding for somber.\n",
      "somberly is at index 16487\n",
      "Saved the embedding for somberly.\n",
      "somnolent is at index 16487\n",
      "Saved the embedding for somnolent.\n",
      "soothed is at index 98\n",
      "Saved the embedding for soothed.\n",
      "sore is at index 12867\n",
      "Saved the embedding for sore.\n",
      "sorrow is at index 26130\n",
      "Saved the embedding for sorrow.\n",
      "sorrowful is at index 26130\n",
      "Saved the embedding for sorrowful.\n",
      "sorry is at index 6661\n",
      "Saved the embedding for sorry.\n",
      "sour is at index 16933\n",
      "Saved the embedding for sour.\n",
      "spaced is at index 42926\n",
      "Saved the embedding for spaced.\n",
      "spacing is at index 39152\n",
      "Saved the embedding for spacing.\n",
      "spastic is at index 2292\n",
      "Saved the embedding for spastic.\n",
      "speaking is at index 2686\n",
      "Saved the embedding for speaking.\n",
      "specious is at index 12002\n",
      "Saved the embedding for specious.\n",
      "speculative is at index 21779\n",
      "Saved the embedding for speculative.\n",
      "speechless is at index 1901\n",
      "Saved the embedding for speechless.\n",
      "spent is at index 1240\n",
      "Saved the embedding for spent.\n",
      "spirited is at index 27206\n",
      "Saved the embedding for spirited.\n",
      "spiritless is at index 4780\n",
      "Saved the embedding for spiritless.\n",
      "spite is at index 14117\n",
      "Saved the embedding for spite.\n",
      "spiteful is at index 14117\n",
      "Saved the embedding for spiteful.\n",
      "spoiled is at index 29136\n",
      "Saved the embedding for spoiled.\n",
      "spooked is at index 2292\n",
      "Saved the embedding for spooked.\n",
      "squeamish is at index 33380\n",
      "Saved the embedding for squeamish.\n",
      "staggered is at index 37646\n",
      "Saved the embedding for staggered.\n",
      "stalker is at index 1690\n",
      "Saved the embedding for stalker.\n",
      "stare is at index 27655\n",
      "Saved the embedding for stare.\n",
      "staring is at index 19311\n",
      "Saved the embedding for staring.\n",
      "starstruck is at index 999\n",
      "Saved the embedding for starstruck.\n",
      "started is at index 554\n",
      "Saved the embedding for started.\n",
      "startled is at index 37747\n",
      "Saved the embedding for startled.\n",
      "stately is at index 194\n",
      "Saved the embedding for stately.\n",
      "steadfast is at index 25781\n",
      "Saved the embedding for steadfast.\n",
      "steady is at index 5204\n",
      "Saved the embedding for steady.\n",
      "stealthy is at index 27026\n",
      "Saved the embedding for stealthy.\n",
      "steamed is at index 11235\n",
      "Saved the embedding for steamed.\n",
      "steaming is at index 11235\n",
      "Saved the embedding for steaming.\n",
      "steeling is at index 3689\n",
      "Saved the embedding for steeling.\n",
      "steely is at index 1690\n",
      "Saved the embedding for steely.\n",
      "stern is at index 23427\n",
      "Saved the embedding for stern.\n",
      "stiff is at index 13116\n",
      "Saved the embedding for stiff.\n",
      "stifled is at index 1690\n",
      "Saved the embedding for stifled.\n",
      "stifling is at index 1690\n",
      "Saved the embedding for stifling.\n",
      "still is at index 202\n",
      "Saved the embedding for still.\n",
      "stillness is at index 202\n",
      "Saved the embedding for stillness.\n",
      "stimulated is at index 42040\n",
      "Saved the embedding for stimulated.\n",
      "stinky is at index 1690\n",
      "Saved the embedding for stinky.\n",
      "stirred is at index 26158\n",
      "Saved the embedding for stirred.\n",
      "stoic is at index 20572\n",
      "Saved the embedding for stoic.\n",
      "stoical is at index 20572\n",
      "Saved the embedding for stoical.\n",
      "stolid is at index 1690\n",
      "Saved the embedding for stolid.\n",
      "stoned is at index 1690\n",
      "Saved the embedding for stoned.\n",
      "storming is at index 2130\n",
      "Saved the embedding for storming.\n",
      "stormy is at index 2130\n",
      "Saved the embedding for stormy.\n",
      "stout is at index 34636\n",
      "Saved the embedding for stout.\n",
      "straight is at index 1359\n",
      "Saved the embedding for straight.\n",
      "strained is at index 15718\n",
      "Saved the embedding for strained.\n",
      "strange is at index 7782\n",
      "Saved the embedding for strange.\n",
      "stressed is at index 5882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for stressed.\n",
      "stricken is at index 35876\n",
      "Saved the embedding for stricken.\n",
      "strict is at index 8414\n",
      "Saved the embedding for strict.\n",
      "strong is at index 670\n",
      "Saved the embedding for strong.\n",
      "struck is at index 2322\n",
      "Saved the embedding for struck.\n",
      "stubborn is at index 20476\n",
      "Saved the embedding for stubborn.\n",
      "stubbornness is at index 20476\n",
      "Saved the embedding for stubbornness.\n",
      "studious is at index 15863\n",
      "Saved the embedding for studious.\n",
      "studying is at index 7739\n",
      "Saved the embedding for studying.\n",
      "stumped is at index 1690\n",
      "Saved the embedding for stumped.\n",
      "stung is at index 1690\n",
      "Saved the embedding for stung.\n",
      "stunned is at index 12144\n",
      "Saved the embedding for stunned.\n",
      "stupefaction is at index 1690\n",
      "Saved the embedding for stupefaction.\n",
      "stupefied is at index 1690\n",
      "Saved the embedding for stupefied.\n",
      "stupefy is at index 1690\n",
      "Saved the embedding for stupefy.\n",
      "stupid is at index 12103\n",
      "Saved the embedding for stupid.\n",
      "stuporous is at index 1690\n",
      "Saved the embedding for stuporous.\n",
      "suave is at index 2628\n",
      "Saved the embedding for suave.\n",
      "subdued is at index 20247\n",
      "Saved the embedding for subdued.\n",
      "sublime is at index 32477\n",
      "Saved the embedding for sublime.\n",
      "submissive is at index 2849\n",
      "Saved the embedding for submissive.\n",
      "suffering is at index 3606\n",
      "Saved the embedding for suffering.\n",
      "suggestive is at index 38907\n",
      "Saved the embedding for suggestive.\n",
      "sulking is at index 26648\n",
      "Saved the embedding for sulking.\n",
      "sulky is at index 26648\n",
      "Saved the embedding for sulky.\n",
      "sullen is at index 2628\n",
      "Saved the embedding for sullen.\n",
      "sullenness is at index 2628\n",
      "Saved the embedding for sullenness.\n",
      "sunny is at index 5419\n",
      "Saved the embedding for sunny.\n",
      "superior is at index 10295\n",
      "Saved the embedding for superior.\n",
      "superiority is at index 32951\n",
      "Saved the embedding for superiority.\n",
      "suppressed is at index 31683\n",
      "Saved the embedding for suppressed.\n",
      "suppressing is at index 38919\n",
      "Saved the embedding for suppressing.\n",
      "suppression is at index 25276\n",
      "Saved the embedding for suppression.\n",
      "sure is at index 686\n",
      "Saved the embedding for sure.\n",
      "surly is at index 8113\n",
      "Saved the embedding for surly.\n",
      "surprise is at index 2755\n",
      "Saved the embedding for surprise.\n",
      "surprised is at index 3911\n",
      "Saved the embedding for surprised.\n",
      "surprising is at index 6167\n",
      "Saved the embedding for surprising.\n",
      "surprisingly is at index 10262\n",
      "Saved the embedding for surprisingly.\n",
      "surreptitious is at index 8113\n",
      "Saved the embedding for surreptitious.\n",
      "suspect is at index 1985\n",
      "Saved the embedding for suspect.\n",
      "suspecting is at index 1985\n",
      "Saved the embedding for suspecting.\n",
      "suspense is at index 31803\n",
      "Saved the embedding for suspense.\n",
      "suspicion is at index 8551\n",
      "Saved the embedding for suspicion.\n",
      "suspicious is at index 7775\n",
      "Saved the embedding for suspicious.\n",
      "suspiciously is at index 7775\n",
      "Saved the embedding for suspiciously.\n",
      "suspiciousness is at index 7775\n",
      "Saved the embedding for suspiciousness.\n",
      "swaggering is at index 3514\n",
      "Saved the embedding for swaggering.\n",
      "swearing is at index 21854\n",
      "Saved the embedding for swearing.\n",
      "sympathetic is at index 22869\n",
      "Saved the embedding for sympathetic.\n",
      "sympathizing is at index 19023\n",
      "Saved the embedding for sympathizing.\n",
      "sympathy is at index 16554\n",
      "Saved the embedding for sympathy.\n",
      "taciturn is at index 36502\n",
      "Saved the embedding for taciturn.\n",
      "talkative is at index 1067\n",
      "Saved the embedding for talkative.\n",
      "talking is at index 1686\n",
      "Saved the embedding for talking.\n",
      "tantalized is at index 33496\n",
      "Saved the embedding for tantalized.\n",
      "tart is at index 27468\n",
      "Saved the embedding for tart.\n",
      "tasteful is at index 24867\n",
      "Saved the embedding for tasteful.\n",
      "tattling is at index 45951\n",
      "Saved the embedding for tattling.\n",
      "taunt is at index 44048\n",
      "Saved the embedding for taunt.\n",
      "taunting is at index 326\n",
      "Saved the embedding for taunting.\n",
      "taut is at index 326\n",
      "Saved the embedding for taut.\n",
      "tearful is at index 7366\n",
      "Saved the embedding for tearful.\n",
      "teary is at index 7366\n",
      "Saved the embedding for teary.\n",
      "tease is at index 29993\n",
      "Saved the embedding for tease.\n",
      "teasing is at index 29752\n",
      "Saved the embedding for teasing.\n",
      "tempered is at index 31380\n",
      "Saved the embedding for tempered.\n",
      "tempest is at index 32196\n",
      "Saved the embedding for tempest.\n",
      "tempestuous is at index 32196\n",
      "Saved the embedding for tempestuous.\n",
      "tempted is at index 23448\n",
      "Saved the embedding for tempted.\n",
      "tenacious is at index 2724\n",
      "Saved the embedding for tenacious.\n",
      "tender is at index 8780\n",
      "Saved the embedding for tender.\n",
      "tenderness is at index 8780\n",
      "Saved the embedding for tenderness.\n",
      "tense is at index 13554\n",
      "Saved the embedding for tense.\n",
      "tensed is at index 7281\n",
      "Saved the embedding for tensed.\n",
      "tension is at index 8556\n",
      "Saved the embedding for tension.\n",
      "tentative is at index 22948\n",
      "Saved the embedding for tentative.\n",
      "terrified is at index 19419\n",
      "Saved the embedding for terrified.\n",
      "terror is at index 5231\n",
      "Saved the embedding for terror.\n",
      "terrorized is at index 5231\n",
      "Saved the embedding for terrorized.\n",
      "terrorizing is at index 5231\n",
      "Saved the embedding for terrorizing.\n",
      "terse is at index 8470\n",
      "Saved the embedding for terse.\n",
      "testy is at index 1296\n",
      "Saved the embedding for testy.\n",
      "tetchy is at index 326\n",
      "Saved the embedding for tetchy.\n",
      "thankful is at index 12025\n",
      "Saved the embedding for thankful.\n",
      "thinking is at index 2053\n",
      "Saved the embedding for thinking.\n",
      "thought is at index 802\n",
      "Saved the embedding for thought.\n",
      "thoughtful is at index 16801\n",
      "Saved the embedding for thoughtful.\n",
      "thoughtfulness is at index 802\n",
      "Saved the embedding for thoughtfulness.\n",
      "threat is at index 1856\n",
      "Saved the embedding for threat.\n",
      "threatened is at index 3711\n",
      "Saved the embedding for threatened.\n",
      "threatening is at index 5608\n",
      "Saved the embedding for threatening.\n",
      "thrilled is at index 8689\n",
      "Saved the embedding for thrilled.\n",
      "thrown is at index 5629\n",
      "Saved the embedding for thrown.\n",
      "thunderstruck is at index 4775\n",
      "Saved the embedding for thunderstruck.\n",
      "thwarted is at index 28299\n",
      "Saved the embedding for thwarted.\n",
      "ticked is at index 10457\n",
      "Saved the embedding for ticked.\n",
      "tickled is at index 10457\n",
      "Saved the embedding for tickled.\n",
      "tied is at index 3016\n",
      "Saved the embedding for tied.\n",
      "tiered is at index 3318\n",
      "Saved the embedding for tiered.\n",
      "tight is at index 3229\n",
      "Saved the embedding for tight.\n",
      "tightlipped is at index 3229\n",
      "Saved the embedding for tightlipped.\n",
      "timid is at index 39649\n",
      "Saved the embedding for timid.\n",
      "timidly is at index 39649\n",
      "Saved the embedding for timidly.\n",
      "timidness is at index 39649\n",
      "Saved the embedding for timidness.\n",
      "tired is at index 7428\n",
      "Saved the embedding for tired.\n",
      "tiredly is at index 7428\n",
      "Saved the embedding for tiredly.\n",
      "tiredness is at index 7428\n",
      "Saved the embedding for tiredness.\n",
      "titillated is at index 13515\n",
      "Saved the embedding for titillated.\n",
      "tolerant is at index 32836\n",
      "Saved the embedding for tolerant.\n",
      "tongue is at index 15686\n",
      "Saved the embedding for tongue.\n",
      "tormented is at index 16535\n",
      "Saved the embedding for tormented.\n",
      "touched is at index 6699\n",
      "Saved the embedding for touched.\n",
      "tough is at index 1828\n",
      "Saved the embedding for tough.\n",
      "toying is at index 7\n",
      "Saved the embedding for toying.\n",
      "tragic is at index 8805\n",
      "Saved the embedding for tragic.\n",
      "tragical is at index 2664\n",
      "Saved the embedding for tragical.\n",
      "tranquil is at index 33535\n",
      "Saved the embedding for tranquil.\n",
      "tranquility is at index 36474\n",
      "Saved the embedding for tranquility.\n",
      "transfixed is at index 30387\n",
      "Saved the embedding for transfixed.\n",
      "traumatized is at index 25178\n",
      "Saved the embedding for traumatized.\n",
      "trembling is at index 44912\n",
      "Saved the embedding for trembling.\n",
      "trepid is at index 6110\n",
      "Saved the embedding for trepid.\n",
      "trepidation is at index 6110\n",
      "Saved the embedding for trepidation.\n",
      "trickster is at index 7610\n",
      "Saved the embedding for trickster.\n",
      "tricky is at index 12792\n",
      "Saved the embedding for tricky.\n",
      "triumphant is at index 32025\n",
      "Saved the embedding for triumphant.\n",
      "troubled is at index 9895\n",
      "Saved the embedding for troubled.\n",
      "troublesome is at index 34056\n",
      "Saved the embedding for troublesome.\n",
      "troubling is at index 15554\n",
      "Saved the embedding for troubling.\n",
      "trusting is at index 28969\n",
      "Saved the embedding for trusting.\n",
      "trustworthy is at index 32101\n",
      "Saved the embedding for trustworthy.\n",
      "tumultuous is at index 23787\n",
      "Saved the embedding for tumultuous.\n",
      "turbulent is at index 23415\n",
      "Saved the embedding for turbulent.\n",
      "twinkly is at index 11901\n",
      "Saved the embedding for twinkly.\n",
      "umbrage is at index 7252\n",
      "Saved the embedding for umbrage.\n",
      "umbrageous is at index 7252\n",
      "Saved the embedding for umbrageous.\n",
      "unaffected is at index 32512\n",
      "Saved the embedding for unaffected.\n",
      "unagitated is at index 542\n",
      "Saved the embedding for unagitated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unamused is at index 542\n",
      "Saved the embedding for unamused.\n",
      "unappreciative is at index 542\n",
      "Saved the embedding for unappreciative.\n",
      "unapproachable is at index 542\n",
      "Saved the embedding for unapproachable.\n",
      "unassertive is at index 542\n",
      "Saved the embedding for unassertive.\n",
      "unassuming is at index 542\n",
      "Saved the embedding for unassuming.\n",
      "unaware is at index 14021\n",
      "Saved the embedding for unaware.\n",
      "unbelief is at index 46646\n",
      "Saved the embedding for unbelief.\n",
      "unbelievable is at index 14011\n",
      "Saved the embedding for unbelievable.\n",
      "unbelieving is at index 46646\n",
      "Saved the embedding for unbelieving.\n",
      "unbothered is at index 542\n",
      "Saved the embedding for unbothered.\n",
      "uncaring is at index 16511\n",
      "Saved the embedding for uncaring.\n",
      "uncertain is at index 9684\n",
      "Saved the embedding for uncertain.\n",
      "uncertainly is at index 9684\n",
      "Saved the embedding for uncertainly.\n",
      "uncertainty is at index 4983\n",
      "Saved the embedding for uncertainty.\n",
      "uncivil is at index 16511\n",
      "Saved the embedding for uncivil.\n",
      "uncomfortable is at index 9800\n",
      "Saved the embedding for uncomfortable.\n",
      "uncommitted is at index 32275\n",
      "Saved the embedding for uncommitted.\n",
      "uncommunicative is at index 32275\n",
      "Saved the embedding for uncommunicative.\n",
      "uncomprehending is at index 32275\n",
      "Saved the embedding for uncomprehending.\n",
      "uncompromising is at index 32213\n",
      "Saved the embedding for uncompromising.\n",
      "unconcerned is at index 28198\n",
      "Saved the embedding for unconcerned.\n",
      "unconfident is at index 542\n",
      "Saved the embedding for unconfident.\n",
      "unconvinced is at index 28198\n",
      "Saved the embedding for unconvinced.\n",
      "uncooperative is at index 542\n",
      "Saved the embedding for uncooperative.\n",
      "uncurious is at index 16511\n",
      "Saved the embedding for uncurious.\n",
      "undecided is at index 28598\n",
      "Saved the embedding for undecided.\n",
      "underhanded is at index 223\n",
      "Saved the embedding for underhanded.\n",
      "understanding is at index 2969\n",
      "Saved the embedding for understanding.\n",
      "undesirable is at index 39028\n",
      "Saved the embedding for undesirable.\n",
      "unease is at index 12515\n",
      "Saved the embedding for unease.\n",
      "uneasily is at index 12515\n",
      "Saved the embedding for uneasily.\n",
      "uneasiness is at index 12515\n",
      "Saved the embedding for uneasiness.\n",
      "uneasy is at index 29569\n",
      "Saved the embedding for uneasy.\n",
      "unemotional is at index 542\n",
      "Saved the embedding for unemotional.\n",
      "unenthusiastic is at index 542\n",
      "Saved the embedding for unenthusiastic.\n",
      "unexcited is at index 39432\n",
      "Saved the embedding for unexcited.\n",
      "unexpected is at index 7152\n",
      "Saved the embedding for unexpected.\n",
      "unfamiliar is at index 21942\n",
      "Saved the embedding for unfamiliar.\n",
      "unfathomable is at index 9515\n",
      "Saved the embedding for unfathomable.\n",
      "unfazed is at index 9515\n",
      "Saved the embedding for unfazed.\n",
      "unfeeling is at index 9515\n",
      "Saved the embedding for unfeeling.\n",
      "unfocused is at index 47306\n",
      "Saved the embedding for unfocused.\n",
      "unforeseen is at index 33257\n",
      "Saved the embedding for unforeseen.\n",
      "unforgiving is at index 34262\n",
      "Saved the embedding for unforgiving.\n",
      "unforthcoming is at index 9515\n",
      "Saved the embedding for unforthcoming.\n",
      "unfortunate is at index 9327\n",
      "Saved the embedding for unfortunate.\n",
      "unfriendly is at index 9515\n",
      "Saved the embedding for unfriendly.\n",
      "unhappy is at index 13865\n",
      "Saved the embedding for unhappy.\n",
      "unhinged is at index 542\n",
      "Saved the embedding for unhinged.\n",
      "unimpressed is at index 542\n",
      "Saved the embedding for unimpressed.\n",
      "uninformed is at index 21969\n",
      "Saved the embedding for uninformed.\n",
      "uninspired is at index 542\n",
      "Saved the embedding for uninspired.\n",
      "uninterested is at index 542\n",
      "Saved the embedding for uninterested.\n",
      "uninvolved is at index 542\n",
      "Saved the embedding for uninvolved.\n",
      "unique is at index 2216\n",
      "Saved the embedding for unique.\n",
      "unlikeable is at index 7328\n",
      "Saved the embedding for unlikeable.\n",
      "unmoved is at index 30780\n",
      "Saved the embedding for unmoved.\n",
      "unnerved is at index 31550\n",
      "Saved the embedding for unnerved.\n",
      "unpleasant is at index 26262\n",
      "Saved the embedding for unpleasant.\n",
      "unprepared is at index 35578\n",
      "Saved the embedding for unprepared.\n",
      "unquiet is at index 542\n",
      "Saved the embedding for unquiet.\n",
      "unreactive is at index 21153\n",
      "Saved the embedding for unreactive.\n",
      "unresolved is at index 29909\n",
      "Saved the embedding for unresolved.\n",
      "unrestrained is at index 12254\n",
      "Saved the embedding for unrestrained.\n",
      "unruffled is at index 542\n",
      "Saved the embedding for unruffled.\n",
      "unsatisfied is at index 36010\n",
      "Saved the embedding for unsatisfied.\n",
      "unsettled is at index 30933\n",
      "Saved the embedding for unsettled.\n",
      "unsociable is at index 9977\n",
      "Saved the embedding for unsociable.\n",
      "unspeaking is at index 542\n",
      "Saved the embedding for unspeaking.\n",
      "unspoken is at index 542\n",
      "Saved the embedding for unspoken.\n",
      "unstrung is at index 542\n",
      "Saved the embedding for unstrung.\n",
      "unsuccessful is at index 15943\n",
      "Saved the embedding for unsuccessful.\n",
      "unsure is at index 17118\n",
      "Saved the embedding for unsure.\n",
      "unsurprised is at index 36637\n",
      "Saved the embedding for unsurprised.\n",
      "unsuspecting is at index 32276\n",
      "Saved the embedding for unsuspecting.\n",
      "unswayed is at index 9977\n",
      "Saved the embedding for unswayed.\n",
      "unsympathetic is at index 542\n",
      "Saved the embedding for unsympathetic.\n",
      "untouched is at index 29929\n",
      "Saved the embedding for untouched.\n",
      "untroubled is at index 7587\n",
      "Saved the embedding for untroubled.\n",
      "untrusting is at index 7587\n",
      "Saved the embedding for untrusting.\n",
      "unwanted is at index 15067\n",
      "Saved the embedding for unwanted.\n",
      "unwavering is at index 10963\n",
      "Saved the embedding for unwavering.\n",
      "unwelcoming is at index 10963\n",
      "Saved the embedding for unwelcoming.\n",
      "unwell is at index 542\n",
      "Saved the embedding for unwell.\n",
      "unwilling is at index 20656\n",
      "Saved the embedding for unwilling.\n",
      "unyielding is at index 542\n",
      "Saved the embedding for unyielding.\n",
      "up is at index 62\n",
      "Saved the embedding for up.\n",
      "upbeat is at index 14899\n",
      "Saved the embedding for upbeat.\n",
      "uplifting is at index 17627\n",
      "Saved the embedding for uplifting.\n",
      "uppity is at index 1717\n",
      "Saved the embedding for uppity.\n",
      "upset is at index 4904\n",
      "Saved the embedding for upset.\n",
      "uptight is at index 18256\n",
      "Saved the embedding for uptight.\n",
      "useless is at index 23584\n",
      "Saved the embedding for useless.\n",
      "vacant is at index 11042\n",
      "Saved the embedding for vacant.\n",
      "vacuous is at index 18721\n",
      "Saved the embedding for vacuous.\n",
      "vanquished is at index 44400\n",
      "Saved the embedding for vanquished.\n",
      "vehement is at index 45373\n",
      "Saved the embedding for vehement.\n",
      "vengeful is at index 748\n",
      "Saved the embedding for vengeful.\n",
      "venomous is at index 32051\n",
      "Saved the embedding for venomous.\n",
      "vex is at index 37894\n",
      "Saved the embedding for vex.\n",
      "vexation is at index 37894\n",
      "Saved the embedding for vexation.\n",
      "vexed is at index 37894\n",
      "Saved the embedding for vexed.\n",
      "vicious is at index 16339\n",
      "Saved the embedding for vicious.\n",
      "victorious is at index 22518\n",
      "Saved the embedding for victorious.\n",
      "vigilant is at index 17258\n",
      "Saved the embedding for vigilant.\n",
      "vile is at index 32359\n",
      "Saved the embedding for vile.\n",
      "villainous is at index 17031\n",
      "Saved the embedding for villainous.\n",
      "vindictive is at index 21339\n",
      "Saved the embedding for vindictive.\n",
      "violence is at index 1476\n",
      "Saved the embedding for violence.\n",
      "violent is at index 4153\n",
      "Saved the embedding for violent.\n",
      "viperous is at index 748\n",
      "Saved the embedding for viperous.\n",
      "vituperative is at index 14306\n",
      "Saved the embedding for vituperative.\n",
      "vocal is at index 7578\n",
      "Saved the embedding for vocal.\n",
      "vocalized is at index 7578\n",
      "Saved the embedding for vocalized.\n",
      "vulgar is at index 28792\n",
      "Saved the embedding for vulgar.\n",
      "vulnerability is at index 15661\n",
      "Saved the embedding for vulnerability.\n",
      "vulnerable is at index 4478\n",
      "Saved the embedding for vulnerable.\n",
      "wacky is at index 885\n",
      "Saved the embedding for wacky.\n",
      "waiting is at index 2445\n",
      "Saved the embedding for waiting.\n",
      "wanted is at index 770\n",
      "Saved the embedding for wanted.\n",
      "wanting is at index 6923\n",
      "Saved the embedding for wanting.\n",
      "wanton is at index 236\n",
      "Saved the embedding for wanton.\n",
      "wariness is at index 997\n",
      "Saved the embedding for wariness.\n",
      "warm is at index 3279\n",
      "Saved the embedding for warm.\n",
      "wary is at index 13441\n",
      "Saved the embedding for wary.\n",
      "wasted is at index 14260\n",
      "Saved the embedding for wasted.\n",
      "watch is at index 1183\n",
      "Saved the embedding for watch.\n",
      "watchful is at index 1183\n",
      "Saved the embedding for watchful.\n",
      "watching is at index 2494\n",
      "Saved the embedding for watching.\n",
      "wavering is at index 13332\n",
      "Saved the embedding for wavering.\n",
      "weariness is at index 3568\n",
      "Saved the embedding for weariness.\n",
      "weary is at index 31554\n",
      "Saved the embedding for weary.\n",
      "weeping is at index 39423\n",
      "Saved the embedding for weeping.\n",
      "weird is at index 7735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for weird.\n",
      "welcome is at index 2814\n",
      "Saved the embedding for welcome.\n",
      "welcoming is at index 10423\n",
      "Saved the embedding for welcoming.\n",
      "whatever is at index 3046\n",
      "Saved the embedding for whatever.\n",
      "whimpering is at index 31754\n",
      "Saved the embedding for whimpering.\n",
      "whimsical is at index 29363\n",
      "Saved the embedding for whimsical.\n",
      "whisper is at index 37539\n",
      "Saved the embedding for whisper.\n",
      "whistle is at index 16867\n",
      "Saved the embedding for whistle.\n",
      "white is at index 1104\n",
      "Saved the embedding for white.\n",
      "wicked is at index 28418\n",
      "Saved the embedding for wicked.\n",
      "wild is at index 3418\n",
      "Saved the embedding for wild.\n",
      "willful is at index 40960\n",
      "Saved the embedding for willful.\n",
      "willing is at index 2882\n",
      "Saved the embedding for willing.\n",
      "wily is at index 885\n",
      "Saved the embedding for wily.\n",
      "wink is at index 39422\n",
      "Saved the embedding for wink.\n",
      "wired is at index 26977\n",
      "Saved the embedding for wired.\n",
      "wishful is at index 2813\n",
      "Saved the embedding for wishful.\n",
      "wistful is at index 885\n",
      "Saved the embedding for wistful.\n",
      "wistfully is at index 885\n",
      "Saved the embedding for wistfully.\n",
      "withdraw is at index 8202\n",
      "Saved the embedding for withdraw.\n",
      "withdrawn is at index 13375\n",
      "Saved the embedding for withdrawn.\n",
      "withheld is at index 22292\n",
      "Saved the embedding for withheld.\n",
      "withholding is at index 25661\n",
      "Saved the embedding for withholding.\n",
      "woe is at index 885\n",
      "Saved the embedding for woe.\n",
      "woeful is at index 19958\n",
      "Saved the embedding for woeful.\n",
      "wonder is at index 5170\n",
      "Saved the embedding for wonder.\n",
      "wondering is at index 8020\n",
      "Saved the embedding for wondering.\n",
      "wonderment is at index 5170\n",
      "Saved the embedding for wonderment.\n",
      "wooly is at index 24815\n",
      "Saved the embedding for wooly.\n",
      "woozy is at index 24815\n",
      "Saved the embedding for woozy.\n",
      "worn is at index 10610\n",
      "Saved the embedding for worn.\n",
      "worried is at index 3915\n",
      "Saved the embedding for worried.\n",
      "worrisome is at index 29611\n",
      "Saved the embedding for worrisome.\n",
      "worry is at index 4022\n",
      "Saved the embedding for worry.\n",
      "worrying is at index 12648\n",
      "Saved the embedding for worrying.\n",
      "worryingly is at index 4022\n",
      "Saved the embedding for worryingly.\n",
      "wounded is at index 5424\n",
      "Saved the embedding for wounded.\n",
      "wow is at index 26388\n",
      "Saved the embedding for wow.\n",
      "wrathful is at index 30220\n",
      "Saved the embedding for wrathful.\n",
      "wrathfully is at index 30220\n",
      "Saved the embedding for wrathfully.\n",
      "wrecked is at index 30090\n",
      "Saved the embedding for wrecked.\n",
      "wretched is at index 42824\n",
      "Saved the embedding for wretched.\n",
      "wronged is at index 1593\n",
      "Saved the embedding for wronged.\n",
      "wroth is at index 885\n",
      "Saved the embedding for wroth.\n",
      "wry is at index 885\n",
      "Saved the embedding for wry.\n",
      "yawn is at index 39654\n",
      "Saved the embedding for yawn.\n",
      "yawning is at index 39654\n",
      "Saved the embedding for yawning.\n",
      "yearning is at index 76\n",
      "Saved the embedding for yearning.\n",
      "yell is at index 28930\n",
      "Saved the embedding for yell.\n",
      "yelling is at index 16600\n",
      "Saved the embedding for yelling.\n",
      "yielding is at index 25438\n",
      "Saved the embedding for yielding.\n",
      "yuck is at index 1423\n",
      "Saved the embedding for yuck.\n",
      "zany is at index 992\n",
      "Saved the embedding for zany.\n",
      "zealous is at index 992\n",
      "Saved the embedding for zealous.\n",
      "zen is at index 992\n",
      "Saved the embedding for zen.\n",
      "zoned is at index 992\n",
      "Saved the embedding for zoned.\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "# This cell will write out output embeddings       #\n",
    "# for all the words in my vocabulary, using RoBERTa#\n",
    "# fine-tuned once on Common Crawl training text.   #\n",
    "####################################################\n",
    "\n",
    "# THESE EMBEDDINGS GIVE A SCORE OF 1.0 FOR ALL WORD PAIRS ON THE\n",
    "# SYNONYMY SCORING TASK: DO NOT USE!!!\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = RobertaTokenizer.from_pretrained('./output_CC-aa/')\n",
    "\n",
    "model = RobertaForMaskedLM.from_pretrained('./output_CC-aa/', config=config)\n",
    "\n",
    "config = RobertaConfig.from_pretrained('./output_CC-aa/')\n",
    "config.output_hidden_states = True\n",
    "embeddings_file = '/home/jupyter/Notebooks/crystal/NLP/nlp_testing/embeddings_context_vocab/roberta_output_CC_aa.txt'\n",
    "for v in vocab:\n",
    "    v_tensor = torch.tensor([tokenizer.encode(v)])\n",
    "    # Print the index of the test word.\n",
    "    print(f'{v} is at index {v_tensor[0][1].item()}')\n",
    "    v_embed = model.roberta.embeddings(v_tensor)\n",
    "#     print(v_embed)\n",
    "    try:\n",
    "        with open(embeddings_file, 'a') as f:\n",
    "            f.write(v)\n",
    "            for value in v_embed[0][0]:\n",
    "                f.write(' ' + str(value.item()))\n",
    "            f.write('\\n')\n",
    "        print(f'Saved the embedding for {v}.')\n",
    "    except:\n",
    "        print('Oh no! Unable to write to the embeddings file.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aback is at index 36347\n",
      "Saved the embedding for aback.\n",
      "abashed is at index 4091\n",
      "Saved the embedding for abashed.\n",
      "abhor is at index 35350\n",
      "Saved the embedding for abhor.\n",
      "abhorred is at index 35350\n",
      "Saved the embedding for abhorred.\n",
      "abhorrence is at index 35350\n",
      "Saved the embedding for abhorrence.\n",
      "abhorrent is at index 35350\n",
      "Saved the embedding for abhorrent.\n",
      "abominable is at index 4091\n",
      "Saved the embedding for abominable.\n",
      "abound is at index 32937\n",
      "Saved the embedding for abound.\n",
      "absent is at index 11640\n",
      "Saved the embedding for absent.\n",
      "absorbed is at index 22416\n",
      "Saved the embedding for absorbed.\n",
      "acceptance is at index 10502\n",
      "Saved the embedding for acceptance.\n",
      "accepted is at index 3903\n",
      "Saved the embedding for accepted.\n",
      "accepting is at index 8394\n",
      "Saved the embedding for accepting.\n",
      "accommodating is at index 33681\n",
      "Saved the embedding for accommodating.\n",
      "accomplished is at index 9370\n",
      "Saved the embedding for accomplished.\n",
      "accordant is at index 10170\n",
      "Saved the embedding for accordant.\n",
      "accursed is at index 7678\n",
      "Saved the embedding for accursed.\n",
      "accusatory is at index 23123\n",
      "Saved the embedding for accusatory.\n",
      "accused is at index 1238\n",
      "Saved the embedding for accused.\n",
      "accusing is at index 8601\n",
      "Saved the embedding for accusing.\n",
      "acerbic is at index 4285\n",
      "Saved the embedding for acerbic.\n",
      "acidic is at index 41314\n",
      "Saved the embedding for acidic.\n",
      "active is at index 2171\n",
      "Saved the embedding for active.\n",
      "acute is at index 13827\n",
      "Saved the embedding for acute.\n",
      "adamant is at index 22668\n",
      "Saved the embedding for adamant.\n",
      "addled is at index 1606\n",
      "Saved the embedding for addled.\n",
      "admiration is at index 24287\n",
      "Saved the embedding for admiration.\n",
      "admit is at index 8109\n",
      "Saved the embedding for admit.\n",
      "adoration is at index 2329\n",
      "Saved the embedding for adoration.\n",
      "adoring is at index 2329\n",
      "Saved the embedding for adoring.\n",
      "adrift is at index 2329\n",
      "Saved the embedding for adrift.\n",
      "adversarial is at index 37930\n",
      "Saved the embedding for adversarial.\n",
      "affability is at index 11129\n",
      "Saved the embedding for affability.\n",
      "affected is at index 2132\n",
      "Saved the embedding for affected.\n",
      "affectionate is at index 15955\n",
      "Saved the embedding for affectionate.\n",
      "afflicted is at index 39234\n",
      "Saved the embedding for afflicted.\n",
      "affronted is at index 11129\n",
      "Saved the embedding for affronted.\n",
      "aflutter is at index 10\n",
      "Saved the embedding for aflutter.\n",
      "afraid is at index 6023\n",
      "Saved the embedding for afraid.\n",
      "agape is at index 5951\n",
      "Saved the embedding for agape.\n",
      "aggravated is at index 10040\n",
      "Saved the embedding for aggravated.\n",
      "aggravation is at index 29223\n",
      "Saved the embedding for aggravation.\n",
      "aggression is at index 14227\n",
      "Saved the embedding for aggression.\n",
      "aggressive is at index 4353\n",
      "Saved the embedding for aggressive.\n",
      "aggrieve is at index 28940\n",
      "Saved the embedding for aggrieve.\n",
      "aggrieved is at index 28940\n",
      "Saved the embedding for aggrieved.\n",
      "aghast is at index 10\n",
      "Saved the embedding for aghast.\n",
      "agitated is at index 33426\n",
      "Saved the embedding for agitated.\n",
      "agog is at index 5951\n",
      "Saved the embedding for agog.\n",
      "agonized is at index 27497\n",
      "Saved the embedding for agonized.\n",
      "agreeable is at index 43359\n",
      "Saved the embedding for agreeable.\n",
      "agressive is at index 5951\n",
      "Saved the embedding for agressive.\n",
      "airhead is at index 935\n",
      "Saved the embedding for airhead.\n",
      "alarm is at index 8054\n",
      "Saved the embedding for alarm.\n",
      "alarmed is at index 23438\n",
      "Saved the embedding for alarmed.\n",
      "alarming is at index 16156\n",
      "Saved the embedding for alarming.\n",
      "alert is at index 5439\n",
      "Saved the embedding for alert.\n",
      "alerted is at index 14588\n",
      "Saved the embedding for alerted.\n",
      "alienated is at index 36462\n",
      "Saved the embedding for alienated.\n",
      "allergic is at index 28349\n",
      "Saved the embedding for allergic.\n",
      "alleviated is at index 32216\n",
      "Saved the embedding for alleviated.\n",
      "alluring is at index 70\n",
      "Saved the embedding for alluring.\n",
      "aloof is at index 1076\n",
      "Saved the embedding for aloof.\n",
      "amatory is at index 524\n",
      "Saved the embedding for amatory.\n",
      "amazed is at index 22431\n",
      "Saved the embedding for amazed.\n",
      "amazement is at index 42402\n",
      "Saved the embedding for amazement.\n",
      "amazing is at index 2770\n",
      "Saved the embedding for amazing.\n",
      "ambition is at index 12831\n",
      "Saved the embedding for ambition.\n",
      "ambitious is at index 8263\n",
      "Saved the embedding for ambitious.\n",
      "ambivalence is at index 13569\n",
      "Saved the embedding for ambivalence.\n",
      "ambivalent is at index 13569\n",
      "Saved the embedding for ambivalent.\n",
      "amenable is at index 524\n",
      "Saved the embedding for amenable.\n",
      "amiable is at index 524\n",
      "Saved the embedding for amiable.\n",
      "amicable is at index 524\n",
      "Saved the embedding for amicable.\n",
      "amused is at index 36530\n",
      "Saved the embedding for amused.\n",
      "amusement is at index 28445\n",
      "Saved the embedding for amusement.\n",
      "analytical is at index 23554\n",
      "Saved the embedding for analytical.\n",
      "analyzing is at index 18999\n",
      "Saved the embedding for analyzing.\n",
      "anger is at index 6378\n",
      "Saved the embedding for anger.\n",
      "angered is at index 20166\n",
      "Saved the embedding for angered.\n",
      "angrily is at index 30302\n",
      "Saved the embedding for angrily.\n",
      "angry is at index 5800\n",
      "Saved the embedding for angry.\n",
      "angst is at index 33010\n",
      "Saved the embedding for angst.\n",
      "anguish is at index 32446\n",
      "Saved the embedding for anguish.\n",
      "anguished is at index 5667\n",
      "Saved the embedding for anguished.\n",
      "animated is at index 12847\n",
      "Saved the embedding for animated.\n",
      "animosity is at index 34351\n",
      "Saved the embedding for animosity.\n",
      "annoyance is at index 39341\n",
      "Saved the embedding for annoyance.\n",
      "annoyed is at index 26678\n",
      "Saved the embedding for annoyed.\n",
      "annoying is at index 19887\n",
      "Saved the embedding for annoying.\n",
      "antagonistic is at index 32726\n",
      "Saved the embedding for antagonistic.\n",
      "antagonized is at index 32726\n",
      "Saved the embedding for antagonized.\n",
      "anticipated is at index 5291\n",
      "Saved the embedding for anticipated.\n",
      "anticipating is at index 22535\n",
      "Saved the embedding for anticipating.\n",
      "anticipation is at index 14714\n",
      "Saved the embedding for anticipation.\n",
      "anticipative is at index 21428\n",
      "Saved the embedding for anticipative.\n",
      "anticipatory is at index 21428\n",
      "Saved the embedding for anticipatory.\n",
      "antipathy is at index 37554\n",
      "Saved the embedding for antipathy.\n",
      "antsy is at index 32855\n",
      "Saved the embedding for antsy.\n",
      "anxiety is at index 6882\n",
      "Saved the embedding for anxiety.\n",
      "anxious is at index 13473\n",
      "Saved the embedding for anxious.\n",
      "anxiously is at index 27442\n",
      "Saved the embedding for anxiously.\n",
      "apathetic is at index 6256\n",
      "Saved the embedding for apathetic.\n",
      "apathy is at index 6256\n",
      "Saved the embedding for apathy.\n",
      "apologetic is at index 23842\n",
      "Saved the embedding for apologetic.\n",
      "appalled is at index 31514\n",
      "Saved the embedding for appalled.\n",
      "appallingly is at index 1553\n",
      "Saved the embedding for appallingly.\n",
      "appeased is at index 44151\n",
      "Saved the embedding for appeased.\n",
      "appeasing is at index 44151\n",
      "Saved the embedding for appeasing.\n",
      "appreciative is at index 14137\n",
      "Saved the embedding for appreciative.\n",
      "apprehension is at index 34640\n",
      "Saved the embedding for apprehension.\n",
      "apprehensive is at index 33655\n",
      "Saved the embedding for apprehensive.\n",
      "approve is at index 7244\n",
      "Saved the embedding for approve.\n",
      "approved is at index 2033\n",
      "Saved the embedding for approved.\n",
      "approving is at index 20499\n",
      "Saved the embedding for approving.\n",
      "argue is at index 5848\n",
      "Saved the embedding for argue.\n",
      "argumentative is at index 4795\n",
      "Saved the embedding for argumentative.\n",
      "aroused is at index 42941\n",
      "Saved the embedding for aroused.\n",
      "arrogance is at index 32818\n",
      "Saved the embedding for arrogance.\n",
      "arrogant is at index 30967\n",
      "Saved the embedding for arrogant.\n",
      "arrogantly is at index 46553\n",
      "Saved the embedding for arrogantly.\n",
      "artificial is at index 7350\n",
      "Saved the embedding for artificial.\n",
      "ashamed is at index 20085\n",
      "Saved the embedding for ashamed.\n",
      "aspiring is at index 18885\n",
      "Saved the embedding for aspiring.\n",
      "assertive is at index 18088\n",
      "Saved the embedding for assertive.\n",
      "assertively is at index 18088\n",
      "Saved the embedding for assertively.\n",
      "assessing is at index 16629\n",
      "Saved the embedding for assessing.\n",
      "assured is at index 7189\n",
      "Saved the embedding for assured.\n",
      "astonished is at index 40788\n",
      "Saved the embedding for astonished.\n",
      "astonishment is at index 44434\n",
      "Saved the embedding for astonishment.\n",
      "astounded is at index 12976\n",
      "Saved the embedding for astounded.\n",
      "attempting is at index 6475\n",
      "Saved the embedding for attempting.\n",
      "attentive is at index 36670\n",
      "Saved the embedding for attentive.\n",
      "attentiveness is at index 39879\n",
      "Saved the embedding for attentiveness.\n",
      "attracted is at index 7671\n",
      "Saved the embedding for attracted.\n",
      "avenging is at index 38796\n",
      "Saved the embedding for avenging.\n",
      "averse is at index 10\n",
      "Saved the embedding for averse.\n",
      "aversion is at index 33814\n",
      "Saved the embedding for aversion.\n",
      "aversive is at index 10\n",
      "Saved the embedding for aversive.\n",
      "avid is at index 20137\n",
      "Saved the embedding for avid.\n",
      "avoiding is at index 11473\n",
      "Saved the embedding for avoiding.\n",
      "awaiting is at index 10254\n",
      "Saved the embedding for awaiting.\n",
      "awakened is at index 40593\n",
      "Saved the embedding for awakened.\n",
      "aware is at index 2542\n",
      "Saved the embedding for aware.\n",
      "awareness is at index 4199\n",
      "Saved the embedding for awareness.\n",
      "awe is at index 21531\n",
      "Saved the embedding for awe.\n",
      "awed is at index 19267\n",
      "Saved the embedding for awed.\n",
      "awestruck is at index 19267\n",
      "Saved the embedding for awestruck.\n",
      "awful is at index 11522\n",
      "Saved the embedding for awful.\n",
      "awkward is at index 11789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for awkward.\n",
      "awkwardness is at index 11789\n",
      "Saved the embedding for awkwardness.\n",
      "axed is at index 18884\n",
      "Saved the embedding for axed.\n",
      "backhanded is at index 124\n",
      "Saved the embedding for backhanded.\n",
      "badly is at index 7340\n",
      "Saved the embedding for badly.\n",
      "baffle is at index 33139\n",
      "Saved the embedding for baffle.\n",
      "baffled is at index 33396\n",
      "Saved the embedding for baffled.\n",
      "baffling is at index 33139\n",
      "Saved the embedding for baffling.\n",
      "baked is at index 17241\n",
      "Saved the embedding for baked.\n",
      "banal is at index 2020\n",
      "Saved the embedding for banal.\n",
      "barking is at index 35828\n",
      "Saved the embedding for barking.\n",
      "bashful is at index 12882\n",
      "Saved the embedding for bashful.\n",
      "beaming is at index 28\n",
      "Saved the embedding for beaming.\n",
      "bearish is at index 4649\n",
      "Saved the embedding for bearish.\n",
      "beat is at index 1451\n",
      "Saved the embedding for beat.\n",
      "beaten is at index 6432\n",
      "Saved the embedding for beaten.\n",
      "bedeviled is at index 3267\n",
      "Saved the embedding for bedeviled.\n",
      "befuddled is at index 28\n",
      "Saved the embedding for befuddled.\n",
      "begging is at index 22901\n",
      "Saved the embedding for begging.\n",
      "begrudge is at index 28\n",
      "Saved the embedding for begrudge.\n",
      "begrudging is at index 28\n",
      "Saved the embedding for begrudging.\n",
      "begrudgingly is at index 28\n",
      "Saved the embedding for begrudgingly.\n",
      "beguiled is at index 21422\n",
      "Saved the embedding for beguiled.\n",
      "belated is at index 12138\n",
      "Saved the embedding for belated.\n",
      "belittling is at index 12138\n",
      "Saved the embedding for belittling.\n",
      "belligerence is at index 35756\n",
      "Saved the embedding for belligerence.\n",
      "belligerent is at index 35756\n",
      "Saved the embedding for belligerent.\n",
      "belonging is at index 11441\n",
      "Saved the embedding for belonging.\n",
      "bemused is at index 28\n",
      "Saved the embedding for bemused.\n",
      "bemusement is at index 28\n",
      "Saved the embedding for bemusement.\n",
      "benevolence is at index 42364\n",
      "Saved the embedding for benevolence.\n",
      "benevolent is at index 43186\n",
      "Saved the embedding for benevolent.\n",
      "benumbed is at index 21576\n",
      "Saved the embedding for benumbed.\n",
      "berate is at index 14719\n",
      "Saved the embedding for berate.\n",
      "berating is at index 14719\n",
      "Saved the embedding for berating.\n",
      "bereaved is at index 17738\n",
      "Saved the embedding for bereaved.\n",
      "bereft is at index 17738\n",
      "Saved the embedding for bereft.\n",
      "beseeching is at index 9988\n",
      "Saved the embedding for beseeching.\n",
      "bested is at index 275\n",
      "Saved the embedding for bested.\n",
      "betrayal is at index 26760\n",
      "Saved the embedding for betrayal.\n",
      "betrayed is at index 26913\n",
      "Saved the embedding for betrayed.\n",
      "bewildered is at index 33304\n",
      "Saved the embedding for bewildered.\n",
      "bewilderment is at index 33304\n",
      "Saved the embedding for bewilderment.\n",
      "bi is at index 4003\n",
      "Saved the embedding for bi.\n",
      "bilious is at index 31617\n",
      "Saved the embedding for bilious.\n",
      "bit is at index 828\n",
      "Saved the embedding for bit.\n",
      "biting is at index 25609\n",
      "Saved the embedding for biting.\n",
      "bitter is at index 10513\n",
      "Saved the embedding for bitter.\n",
      "bittersweet is at index 28609\n",
      "Saved the embedding for bittersweet.\n",
      "blaming is at index 15249\n",
      "Saved the embedding for blaming.\n",
      "bland is at index 35063\n",
      "Saved the embedding for bland.\n",
      "blank is at index 15818\n",
      "Saved the embedding for blank.\n",
      "blase is at index 3089\n",
      "Saved the embedding for blase.\n",
      "blazed is at index 3089\n",
      "Saved the embedding for blazed.\n",
      "bleak is at index 23530\n",
      "Saved the embedding for bleak.\n",
      "bleary is at index 13819\n",
      "Saved the embedding for bleary.\n",
      "blessed is at index 12230\n",
      "Saved the embedding for blessed.\n",
      "blew is at index 10879\n",
      "Saved the embedding for blew.\n",
      "blinded is at index 40094\n",
      "Saved the embedding for blinded.\n",
      "blindsided is at index 7709\n",
      "Saved the embedding for blindsided.\n",
      "bliss is at index 30299\n",
      "Saved the embedding for bliss.\n",
      "blissful is at index 30299\n",
      "Saved the embedding for blissful.\n",
      "blissfully is at index 30299\n",
      "Saved the embedding for blissfully.\n",
      "blithe is at index 3089\n",
      "Saved the embedding for blithe.\n",
      "blown is at index 12315\n",
      "Saved the embedding for blown.\n",
      "blue is at index 2440\n",
      "Saved the embedding for blue.\n",
      "blues is at index 15629\n",
      "Saved the embedding for blues.\n",
      "bluffing is at index 37372\n",
      "Saved the embedding for bluffing.\n",
      "blunt is at index 18720\n",
      "Saved the embedding for blunt.\n",
      "blushing is at index 3089\n",
      "Saved the embedding for blushing.\n",
      "blustering is at index 3089\n",
      "Saved the embedding for blustering.\n",
      "boastful is at index 18639\n",
      "Saved the embedding for boastful.\n",
      "boggled is at index 741\n",
      "Saved the embedding for boggled.\n",
      "boiling is at index 27513\n",
      "Saved the embedding for boiling.\n",
      "boisterous is at index 5276\n",
      "Saved the embedding for boisterous.\n",
      "bold is at index 7457\n",
      "Saved the embedding for bold.\n",
      "bored is at index 23809\n",
      "Saved the embedding for bored.\n",
      "boredom is at index 40326\n",
      "Saved the embedding for boredom.\n",
      "boring is at index 15305\n",
      "Saved the embedding for boring.\n",
      "bothered is at index 18523\n",
      "Saved the embedding for bothered.\n",
      "bounder is at index 8191\n",
      "Saved the embedding for bounder.\n",
      "brashness is at index 5378\n",
      "Saved the embedding for brashness.\n",
      "bratty is at index 5378\n",
      "Saved the embedding for bratty.\n",
      "brave is at index 10025\n",
      "Saved the embedding for brave.\n",
      "bright is at index 4520\n",
      "Saved the embedding for bright.\n",
      "bristling is at index 37135\n",
      "Saved the embedding for bristling.\n",
      "broken is at index 3187\n",
      "Saved the embedding for broken.\n",
      "brokenhearted is at index 3187\n",
      "Saved the embedding for brokenhearted.\n",
      "brokenheartedly is at index 3187\n",
      "Saved the embedding for brokenheartedly.\n",
      "brooding is at index 11051\n",
      "Saved the embedding for brooding.\n",
      "broody is at index 11051\n",
      "Saved the embedding for broody.\n",
      "bruised is at index 26360\n",
      "Saved the embedding for bruised.\n",
      "brusque is at index 5378\n",
      "Saved the embedding for brusque.\n",
      "bug is at index 13673\n",
      "Saved the embedding for bug.\n",
      "bulging is at index 22382\n",
      "Saved the embedding for bulging.\n",
      "bully is at index 23934\n",
      "Saved the embedding for bully.\n",
      "bullying is at index 11902\n",
      "Saved the embedding for bullying.\n",
      "bummed is at index 29673\n",
      "Saved the embedding for bummed.\n",
      "buoyant is at index 15980\n",
      "Saved the embedding for buoyant.\n",
      "burdened is at index 32875\n",
      "Saved the embedding for burdened.\n",
      "burn is at index 7403\n",
      "Saved the embedding for burn.\n",
      "bursting is at index 28548\n",
      "Saved the embedding for bursting.\n",
      "bushed is at index 2353\n",
      "Saved the embedding for bushed.\n",
      "cagey is at index 16051\n",
      "Saved the embedding for cagey.\n",
      "cagy is at index 740\n",
      "Saved the embedding for cagy.\n",
      "calculating is at index 29770\n",
      "Saved the embedding for calculating.\n",
      "callous is at index 486\n",
      "Saved the embedding for callous.\n",
      "callused is at index 486\n",
      "Saved the embedding for callused.\n",
      "calm is at index 6327\n",
      "Saved the embedding for calm.\n",
      "calming is at index 31220\n",
      "Saved the embedding for calming.\n",
      "calmness is at index 6327\n",
      "Saved the embedding for calmness.\n",
      "canny is at index 64\n",
      "Saved the embedding for canny.\n",
      "cantankerous is at index 17672\n",
      "Saved the embedding for cantankerous.\n",
      "capable is at index 4453\n",
      "Saved the embedding for capable.\n",
      "capricious is at index 2927\n",
      "Saved the embedding for capricious.\n",
      "captivated is at index 13363\n",
      "Saved the embedding for captivated.\n",
      "captive is at index 24145\n",
      "Saved the embedding for captive.\n",
      "carefree is at index 575\n",
      "Saved the embedding for carefree.\n",
      "careful is at index 7316\n",
      "Saved the embedding for careful.\n",
      "careless is at index 29399\n",
      "Saved the embedding for careless.\n",
      "caring is at index 10837\n",
      "Saved the embedding for caring.\n",
      "catty is at index 4758\n",
      "Saved the embedding for catty.\n",
      "caustic is at index 6056\n",
      "Saved the embedding for caustic.\n",
      "cautionary is at index 8038\n",
      "Saved the embedding for cautionary.\n",
      "cautious is at index 9420\n",
      "Saved the embedding for cautious.\n",
      "cavalier is at index 41869\n",
      "Saved the embedding for cavalier.\n",
      "celebrating is at index 6146\n",
      "Saved the embedding for celebrating.\n",
      "celebration is at index 4821\n",
      "Saved the embedding for celebration.\n",
      "censure is at index 26489\n",
      "Saved the embedding for censure.\n",
      "centered is at index 14889\n",
      "Saved the embedding for centered.\n",
      "certain is at index 1402\n",
      "Saved the embedding for certain.\n",
      "chafed is at index 1855\n",
      "Saved the embedding for chafed.\n",
      "chagrin is at index 1855\n",
      "Saved the embedding for chagrin.\n",
      "chagrined is at index 1855\n",
      "Saved the embedding for chagrined.\n",
      "chagrinned is at index 1855\n",
      "Saved the embedding for chagrinned.\n",
      "challenge is at index 1539\n",
      "Saved the embedding for challenge.\n",
      "challenged is at index 6835\n",
      "Saved the embedding for challenged.\n",
      "challenging is at index 4087\n",
      "Saved the embedding for challenging.\n",
      "chaotic is at index 16529\n",
      "Saved the embedding for chaotic.\n",
      "charged is at index 1340\n",
      "Saved the embedding for charged.\n",
      "charmed is at index 16224\n",
      "Saved the embedding for charmed.\n",
      "charming is at index 18452\n",
      "Saved the embedding for charming.\n",
      "chary is at index 1855\n",
      "Saved the embedding for chary.\n",
      "cheated is at index 25177\n",
      "Saved the embedding for cheated.\n",
      "cheeky is at index 15401\n",
      "Saved the embedding for cheeky.\n",
      "cheered is at index 18643\n",
      "Saved the embedding for cheered.\n",
      "cheerful is at index 33928\n",
      "Saved the embedding for cheerful.\n",
      "cheering is at index 16765\n",
      "Saved the embedding for cheering.\n",
      "cheerless is at index 9450\n",
      "Saved the embedding for cheerless.\n",
      "cheery is at index 5851\n",
      "Saved the embedding for cheery.\n",
      "cheesy is at index 36331\n",
      "Saved the embedding for cheesy.\n",
      "chesty is at index 7050\n",
      "Saved the embedding for chesty.\n",
      "chide is at index 1855\n",
      "Saved the embedding for chide.\n",
      "chiding is at index 1855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for chiding.\n",
      "childish is at index 40531\n",
      "Saved the embedding for childish.\n",
      "childishly is at index 920\n",
      "Saved the embedding for childishly.\n",
      "childlike is at index 920\n",
      "Saved the embedding for childlike.\n",
      "chill is at index 13146\n",
      "Saved the embedding for chill.\n",
      "chilled is at index 32338\n",
      "Saved the embedding for chilled.\n",
      "chilling is at index 22577\n",
      "Saved the embedding for chilling.\n",
      "chipper is at index 1855\n",
      "Saved the embedding for chipper.\n",
      "chirpy is at index 1855\n",
      "Saved the embedding for chirpy.\n",
      "choleric is at index 1855\n",
      "Saved the embedding for choleric.\n",
      "chortling is at index 1855\n",
      "Saved the embedding for chortling.\n",
      "chuckle is at index 37496\n",
      "Saved the embedding for chuckle.\n",
      "chuckling is at index 34600\n",
      "Saved the embedding for chuckling.\n",
      "churlish is at index 1855\n",
      "Saved the embedding for churlish.\n",
      "circumspect is at index 38529\n",
      "Saved the embedding for circumspect.\n",
      "clamorous is at index 24045\n",
      "Saved the embedding for clamorous.\n",
      "clash is at index 6064\n",
      "Saved the embedding for clash.\n",
      "clear is at index 699\n",
      "Saved the embedding for clear.\n",
      "clenched is at index 44646\n",
      "Saved the embedding for clenched.\n",
      "clever is at index 13074\n",
      "Saved the embedding for clever.\n",
      "close is at index 593\n",
      "Saved the embedding for close.\n",
      "closed is at index 1367\n",
      "Saved the embedding for closed.\n",
      "closemouthed is at index 593\n",
      "Saved the embedding for closemouthed.\n",
      "cloy is at index 3741\n",
      "Saved the embedding for cloy.\n",
      "clueless is at index 36776\n",
      "Saved the embedding for clueless.\n",
      "clutched is at index 29409\n",
      "Saved the embedding for clutched.\n",
      "cluttered is at index 29409\n",
      "Saved the embedding for cluttered.\n",
      "cockeyed is at index 740\n",
      "Saved the embedding for cockeyed.\n",
      "cockiness is at index 24231\n",
      "Saved the embedding for cockiness.\n",
      "cocksure is at index 740\n",
      "Saved the embedding for cocksure.\n",
      "cocky is at index 24231\n",
      "Saved the embedding for cocky.\n",
      "cognizant is at index 28105\n",
      "Saved the embedding for cognizant.\n",
      "cold is at index 2569\n",
      "Saved the embedding for cold.\n",
      "collected is at index 4786\n",
      "Saved the embedding for collected.\n",
      "collusive is at index 9843\n",
      "Saved the embedding for collusive.\n",
      "colonized is at index 17735\n",
      "Saved the embedding for colonized.\n",
      "combative is at index 14960\n",
      "Saved the embedding for combative.\n",
      "comedic is at index 29045\n",
      "Saved the embedding for comedic.\n",
      "comfort is at index 5863\n",
      "Saved the embedding for comfort.\n",
      "comfortable is at index 3473\n",
      "Saved the embedding for comfortable.\n",
      "comforted is at index 5863\n",
      "Saved the embedding for comforted.\n",
      "comical is at index 3137\n",
      "Saved the embedding for comical.\n",
      "commanding is at index 20510\n",
      "Saved the embedding for commanding.\n",
      "commiserating is at index 7034\n",
      "Saved the embedding for commiserating.\n",
      "commiserative is at index 7034\n",
      "Saved the embedding for commiserative.\n",
      "communicative is at index 16759\n",
      "Saved the embedding for communicative.\n",
      "compassion is at index 14736\n",
      "Saved the embedding for compassion.\n",
      "compassionate is at index 23303\n",
      "Saved the embedding for compassionate.\n",
      "competent is at index 17451\n",
      "Saved the embedding for competent.\n",
      "competitive is at index 2695\n",
      "Saved the embedding for competitive.\n",
      "complacence is at index 13000\n",
      "Saved the embedding for complacence.\n",
      "complacency is at index 13000\n",
      "Saved the embedding for complacency.\n",
      "complacent is at index 13000\n",
      "Saved the embedding for complacent.\n",
      "complacently is at index 13000\n",
      "Saved the embedding for complacently.\n",
      "complain is at index 11316\n",
      "Saved the embedding for complain.\n",
      "complaining is at index 13689\n",
      "Saved the embedding for complaining.\n",
      "composed is at index 14092\n",
      "Saved the embedding for composed.\n",
      "comprehending is at index 30030\n",
      "Saved the embedding for comprehending.\n",
      "compulsive is at index 7753\n",
      "Saved the embedding for compulsive.\n",
      "concealed is at index 17180\n",
      "Saved the embedding for concealed.\n",
      "conceding is at index 24647\n",
      "Saved the embedding for conceding.\n",
      "conceited is at index 21177\n",
      "Saved the embedding for conceited.\n",
      "concentrated is at index 15450\n",
      "Saved the embedding for concentrated.\n",
      "concentrating is at index 28619\n",
      "Saved the embedding for concentrating.\n",
      "concentration is at index 11772\n",
      "Saved the embedding for concentration.\n",
      "concern is at index 2212\n",
      "Saved the embedding for concern.\n",
      "concerned is at index 2273\n",
      "Saved the embedding for concerned.\n",
      "conciliatory is at index 10146\n",
      "Saved the embedding for conciliatory.\n",
      "conclusive is at index 37847\n",
      "Saved the embedding for conclusive.\n",
      "condemning is at index 21856\n",
      "Saved the embedding for condemning.\n",
      "condescending is at index 40742\n",
      "Saved the embedding for condescending.\n",
      "condoling is at index 35279\n",
      "Saved the embedding for condoling.\n",
      "confidence is at index 2123\n",
      "Saved the embedding for confidence.\n",
      "confident is at index 3230\n",
      "Saved the embedding for confident.\n",
      "confidently is at index 27447\n",
      "Saved the embedding for confidently.\n",
      "conflicted is at index 34428\n",
      "Saved the embedding for conflicted.\n",
      "confound is at index 7856\n",
      "Saved the embedding for confound.\n",
      "confounded is at index 7856\n",
      "Saved the embedding for confounded.\n",
      "confrontational is at index 10749\n",
      "Saved the embedding for confrontational.\n",
      "confused is at index 10985\n",
      "Saved the embedding for confused.\n",
      "confusion is at index 9655\n",
      "Saved the embedding for confusion.\n",
      "congenial is at index 36764\n",
      "Saved the embedding for congenial.\n",
      "congratulatory is at index 26303\n",
      "Saved the embedding for congratulatory.\n",
      "conniving is at index 39277\n",
      "Saved the embedding for conniving.\n",
      "conscious is at index 13316\n",
      "Saved the embedding for conscious.\n",
      "conservative is at index 3354\n",
      "Saved the embedding for conservative.\n",
      "considerate is at index 1701\n",
      "Saved the embedding for considerate.\n",
      "considering is at index 2811\n",
      "Saved the embedding for considering.\n",
      "consoling is at index 7407\n",
      "Saved the embedding for consoling.\n",
      "conspiratorial is at index 31150\n",
      "Saved the embedding for conspiratorial.\n",
      "conspiring is at index 27230\n",
      "Saved the embedding for conspiring.\n",
      "consternation is at index 10759\n",
      "Saved the embedding for consternation.\n",
      "constipated is at index 10759\n",
      "Saved the embedding for constipated.\n",
      "constrained is at index 26525\n",
      "Saved the embedding for constrained.\n",
      "consumed is at index 13056\n",
      "Saved the embedding for consumed.\n",
      "consuming is at index 16997\n",
      "Saved the embedding for consuming.\n",
      "contained is at index 5558\n",
      "Saved the embedding for contained.\n",
      "contemplate is at index 32848\n",
      "Saved the embedding for contemplate.\n",
      "contemplating is at index 27744\n",
      "Saved the embedding for contemplating.\n",
      "contemplation is at index 44072\n",
      "Saved the embedding for contemplation.\n",
      "contemplative is at index 43580\n",
      "Saved the embedding for contemplative.\n",
      "contempt is at index 16176\n",
      "Saved the embedding for contempt.\n",
      "contemptuous is at index 16176\n",
      "Saved the embedding for contemptuous.\n",
      "content is at index 1383\n",
      "Saved the embedding for content.\n",
      "contented is at index 1383\n",
      "Saved the embedding for contented.\n",
      "contentious is at index 14883\n",
      "Saved the embedding for contentious.\n",
      "contently is at index 8541\n",
      "Saved the embedding for contently.\n",
      "contentment is at index 1383\n",
      "Saved the embedding for contentment.\n",
      "contradictory is at index 31515\n",
      "Saved the embedding for contradictory.\n",
      "contrary is at index 11159\n",
      "Saved the embedding for contrary.\n",
      "contrite is at index 17035\n",
      "Saved the embedding for contrite.\n",
      "controlled is at index 4875\n",
      "Saved the embedding for controlled.\n",
      "controlling is at index 10568\n",
      "Saved the embedding for controlling.\n",
      "controversial is at index 4456\n",
      "Saved the embedding for controversial.\n",
      "contumacious is at index 8541\n",
      "Saved the embedding for contumacious.\n",
      "convinced is at index 7013\n",
      "Saved the embedding for convinced.\n",
      "cool is at index 3035\n",
      "Saved the embedding for cool.\n",
      "cooperative is at index 18777\n",
      "Saved the embedding for cooperative.\n",
      "cordial is at index 13051\n",
      "Saved the embedding for cordial.\n",
      "courageous is at index 24219\n",
      "Saved the embedding for courageous.\n",
      "covert is at index 25523\n",
      "Saved the embedding for covert.\n",
      "cowardly is at index 36881\n",
      "Saved the embedding for cowardly.\n",
      "coy is at index 20176\n",
      "Saved the embedding for coy.\n",
      "crabby is at index 23320\n",
      "Saved the embedding for crabby.\n",
      "crafty is at index 6306\n",
      "Saved the embedding for crafty.\n",
      "cranky is at index 30952\n",
      "Saved the embedding for cranky.\n",
      "crazed is at index 26002\n",
      "Saved the embedding for crazed.\n",
      "crazy is at index 5373\n",
      "Saved the embedding for crazy.\n",
      "credulous is at index 18994\n",
      "Saved the embedding for credulous.\n",
      "creepy is at index 23814\n",
      "Saved the embedding for creepy.\n",
      "crestfallen is at index 32220\n",
      "Saved the embedding for crestfallen.\n",
      "cringing is at index 3977\n",
      "Saved the embedding for cringing.\n",
      "critical is at index 2008\n",
      "Saved the embedding for critical.\n",
      "cross is at index 2116\n",
      "Saved the embedding for cross.\n",
      "crotchety is at index 11398\n",
      "Saved the embedding for crotchety.\n",
      "crude is at index 2976\n",
      "Saved the embedding for crude.\n",
      "cruel is at index 15939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for cruel.\n",
      "crushed is at index 14045\n",
      "Saved the embedding for crushed.\n",
      "cry is at index 8930\n",
      "Saved the embedding for cry.\n",
      "crying is at index 9701\n",
      "Saved the embedding for crying.\n",
      "cryptic is at index 35916\n",
      "Saved the embedding for cryptic.\n",
      "culpable is at index 29410\n",
      "Saved the embedding for culpable.\n",
      "cunning is at index 41526\n",
      "Saved the embedding for cunning.\n",
      "curios is at index 5350\n",
      "Saved the embedding for curios.\n",
      "curiosity is at index 20610\n",
      "Saved the embedding for curiosity.\n",
      "curious is at index 10691\n",
      "Saved the embedding for curious.\n",
      "cutting is at index 3931\n",
      "Saved the embedding for cutting.\n",
      "cynic is at index 40240\n",
      "Saved the embedding for cynic.\n",
      "cynical is at index 27566\n",
      "Saved the embedding for cynical.\n",
      "cynicism is at index 39245\n",
      "Saved the embedding for cynicism.\n",
      "dalliance is at index 385\n",
      "Saved the embedding for dalliance.\n",
      "dandy is at index 385\n",
      "Saved the embedding for dandy.\n",
      "dangerous is at index 2702\n",
      "Saved the embedding for dangerous.\n",
      "darkly is at index 2933\n",
      "Saved the embedding for darkly.\n",
      "daunted is at index 385\n",
      "Saved the embedding for daunted.\n",
      "daydream is at index 183\n",
      "Saved the embedding for daydream.\n",
      "daydreaming is at index 183\n",
      "Saved the embedding for daydreaming.\n",
      "dazed is at index 385\n",
      "Saved the embedding for dazed.\n",
      "dazzled is at index 32614\n",
      "Saved the embedding for dazzled.\n",
      "deadly is at index 4847\n",
      "Saved the embedding for deadly.\n",
      "deadpan is at index 1462\n",
      "Saved the embedding for deadpan.\n",
      "debate is at index 2625\n",
      "Saved the embedding for debate.\n",
      "debating is at index 24996\n",
      "Saved the embedding for debating.\n",
      "debauched is at index 10189\n",
      "Saved the embedding for debauched.\n",
      "deceitful is at index 35049\n",
      "Saved the embedding for deceitful.\n",
      "deceived is at index 38079\n",
      "Saved the embedding for deceived.\n",
      "deceiving is at index 34575\n",
      "Saved the embedding for deceiving.\n",
      "deceivingly is at index 34575\n",
      "Saved the embedding for deceivingly.\n",
      "deception is at index 29244\n",
      "Saved the embedding for deception.\n",
      "deceptive is at index 31405\n",
      "Saved the embedding for deceptive.\n",
      "deciding is at index 8997\n",
      "Saved the embedding for deciding.\n",
      "decisive is at index 12703\n",
      "Saved the embedding for decisive.\n",
      "dedicated is at index 3688\n",
      "Saved the embedding for dedicated.\n",
      "defeat is at index 3002\n",
      "Saved the embedding for defeat.\n",
      "defeated is at index 5125\n",
      "Saved the embedding for defeated.\n",
      "defenseless is at index 3816\n",
      "Saved the embedding for defenseless.\n",
      "defensive is at index 2465\n",
      "Saved the embedding for defensive.\n",
      "defiance is at index 25442\n",
      "Saved the embedding for defiance.\n",
      "defiant is at index 23802\n",
      "Saved the embedding for defiant.\n",
      "deflated is at index 3816\n",
      "Saved the embedding for deflated.\n",
      "degage is at index 31295\n",
      "Saved the embedding for degage.\n",
      "degrading is at index 36892\n",
      "Saved the embedding for degrading.\n",
      "dejected is at index 263\n",
      "Saved the embedding for dejected.\n",
      "dejection is at index 263\n",
      "Saved the embedding for dejection.\n",
      "deliberate is at index 14775\n",
      "Saved the embedding for deliberate.\n",
      "deliberating is at index 21614\n",
      "Saved the embedding for deliberating.\n",
      "delight is at index 13213\n",
      "Saved the embedding for delight.\n",
      "delighted is at index 7808\n",
      "Saved the embedding for delighted.\n",
      "delightful is at index 24897\n",
      "Saved the embedding for delightful.\n",
      "delirious is at index 2424\n",
      "Saved the embedding for delirious.\n",
      "delirium is at index 2424\n",
      "Saved the embedding for delirium.\n",
      "delude is at index 2424\n",
      "Saved the embedding for delude.\n",
      "delusional is at index 40160\n",
      "Saved the embedding for delusional.\n",
      "demanding is at index 5783\n",
      "Saved the embedding for demanding.\n",
      "demeaning is at index 4410\n",
      "Saved the embedding for demeaning.\n",
      "demented is at index 44202\n",
      "Saved the embedding for demented.\n",
      "demised is at index 4410\n",
      "Saved the embedding for demised.\n",
      "demoralized is at index 36810\n",
      "Saved the embedding for demoralized.\n",
      "demure is at index 4410\n",
      "Saved the embedding for demure.\n",
      "denied is at index 2296\n",
      "Saved the embedding for denied.\n",
      "denouncing is at index 32439\n",
      "Saved the embedding for denouncing.\n",
      "depleted is at index 26391\n",
      "Saved the embedding for depleted.\n",
      "deplorable is at index 28156\n",
      "Saved the embedding for deplorable.\n",
      "deprecating is at index 8273\n",
      "Saved the embedding for deprecating.\n",
      "depressed is at index 16658\n",
      "Saved the embedding for depressed.\n",
      "depression is at index 6943\n",
      "Saved the embedding for depression.\n",
      "deprived is at index 22632\n",
      "Saved the embedding for deprived.\n",
      "deranged is at index 1935\n",
      "Saved the embedding for deranged.\n",
      "derision is at index 1935\n",
      "Saved the embedding for derision.\n",
      "derisive is at index 1935\n",
      "Saved the embedding for derisive.\n",
      "derogatory is at index 30971\n",
      "Saved the embedding for derogatory.\n",
      "desire is at index 4724\n",
      "Saved the embedding for desire.\n",
      "desiring is at index 2694\n",
      "Saved the embedding for desiring.\n",
      "desirous is at index 2694\n",
      "Saved the embedding for desirous.\n",
      "desolate is at index 43177\n",
      "Saved the embedding for desolate.\n",
      "despair is at index 21508\n",
      "Saved the embedding for despair.\n",
      "despaired is at index 2694\n",
      "Saved the embedding for despaired.\n",
      "despairing is at index 21508\n",
      "Saved the embedding for despairing.\n",
      "desperate is at index 7764\n",
      "Saved the embedding for desperate.\n",
      "desperation is at index 24278\n",
      "Saved the embedding for desperation.\n",
      "despise is at index 43255\n",
      "Saved the embedding for despise.\n",
      "despondent is at index 18690\n",
      "Saved the embedding for despondent.\n",
      "destitute is at index 15357\n",
      "Saved the embedding for destitute.\n",
      "destroyed is at index 4957\n",
      "Saved the embedding for destroyed.\n",
      "detached is at index 27687\n",
      "Saved the embedding for detached.\n",
      "determination is at index 8964\n",
      "Saved the embedding for determination.\n",
      "determined is at index 3030\n",
      "Saved the embedding for determined.\n",
      "determining is at index 13684\n",
      "Saved the embedding for determining.\n",
      "deterred is at index 10922\n",
      "Saved the embedding for deterred.\n",
      "detest is at index 6769\n",
      "Saved the embedding for detest.\n",
      "detestable is at index 6769\n",
      "Saved the embedding for detestable.\n",
      "detesting is at index 6769\n",
      "Saved the embedding for detesting.\n",
      "detriment is at index 31969\n",
      "Saved the embedding for detriment.\n",
      "devastated is at index 11521\n",
      "Saved the embedding for devastated.\n",
      "deviant is at index 8709\n",
      "Saved the embedding for deviant.\n",
      "devilish is at index 22406\n",
      "Saved the embedding for devilish.\n",
      "devious is at index 263\n",
      "Saved the embedding for devious.\n",
      "devising is at index 8709\n",
      "Saved the embedding for devising.\n",
      "diffident is at index 25871\n",
      "Saved the embedding for diffident.\n",
      "dilatory is at index 14632\n",
      "Saved the embedding for dilatory.\n",
      "diligent is at index 33721\n",
      "Saved the embedding for diligent.\n",
      "dimwitted is at index 14548\n",
      "Saved the embedding for dimwitted.\n",
      "dire is at index 10697\n",
      "Saved the embedding for dire.\n",
      "disagree is at index 11967\n",
      "Saved the embedding for disagree.\n",
      "disagreeable is at index 11967\n",
      "Saved the embedding for disagreeable.\n",
      "disagreement is at index 20628\n",
      "Saved the embedding for disagreement.\n",
      "disappointed is at index 5779\n",
      "Saved the embedding for disappointed.\n",
      "disappointing is at index 6770\n",
      "Saved the embedding for disappointing.\n",
      "disappointment is at index 10208\n",
      "Saved the embedding for disappointment.\n",
      "disapproval is at index 32129\n",
      "Saved the embedding for disapproval.\n",
      "disapproving is at index 36631\n",
      "Saved the embedding for disapproving.\n",
      "disbelief is at index 26440\n",
      "Saved the embedding for disbelief.\n",
      "disbelieve is at index 45668\n",
      "Saved the embedding for disbelieve.\n",
      "disbelieving is at index 45668\n",
      "Saved the embedding for disbelieving.\n",
      "discerning is at index 9553\n",
      "Saved the embedding for discerning.\n",
      "discombobulated is at index 2982\n",
      "Saved the embedding for discombobulated.\n",
      "discomfited is at index 2982\n",
      "Saved the embedding for discomfited.\n",
      "discomfort is at index 19535\n",
      "Saved the embedding for discomfort.\n",
      "discomforted is at index 19535\n",
      "Saved the embedding for discomforted.\n",
      "disconcerted is at index 2982\n",
      "Saved the embedding for disconcerted.\n",
      "disconnected is at index 30005\n",
      "Saved the embedding for disconnected.\n",
      "disconsolate is at index 9553\n",
      "Saved the embedding for disconsolate.\n",
      "discontent is at index 27478\n",
      "Saved the embedding for discontent.\n",
      "discontented is at index 47772\n",
      "Saved the embedding for discontented.\n",
      "discounted is at index 17533\n",
      "Saved the embedding for discounted.\n",
      "discouraged is at index 25788\n",
      "Saved the embedding for discouraged.\n",
      "discovery is at index 6953\n",
      "Saved the embedding for discovery.\n",
      "discriminating is at index 38303\n",
      "Saved the embedding for discriminating.\n",
      "discussed is at index 3373\n",
      "Saved the embedding for discussed.\n",
      "disdain is at index 29512\n",
      "Saved the embedding for disdain.\n",
      "disdained is at index 2982\n",
      "Saved the embedding for disdained.\n",
      "disdainful is at index 29512\n",
      "Saved the embedding for disdainful.\n",
      "disdainfully is at index 29512\n",
      "Saved the embedding for disdainfully.\n",
      "disenchanted is at index 2982\n",
      "Saved the embedding for disenchanted.\n",
      "disengaged is at index 35170\n",
      "Saved the embedding for disengaged.\n",
      "disgraced is at index 25425\n",
      "Saved the embedding for disgraced.\n",
      "disgruntled is at index 29412\n",
      "Saved the embedding for disgruntled.\n",
      "disgruntlement is at index 25425\n",
      "Saved the embedding for disgruntlement.\n",
      "disgust is at index 30883\n",
      "Saved the embedding for disgust.\n",
      "disgusted is at index 32759\n",
      "Saved the embedding for disgusted.\n",
      "disgustedly is at index 32759\n",
      "Saved the embedding for disgustedly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disgusting is at index 21096\n",
      "Saved the embedding for disgusting.\n",
      "disheartened is at index 2982\n",
      "Saved the embedding for disheartened.\n",
      "dishonest is at index 27820\n",
      "Saved the embedding for dishonest.\n",
      "disillusioned is at index 33447\n",
      "Saved the embedding for disillusioned.\n",
      "disinclined is at index 2982\n",
      "Saved the embedding for disinclined.\n",
      "disingenuous is at index 39622\n",
      "Saved the embedding for disingenuous.\n",
      "disinterest is at index 2982\n",
      "Saved the embedding for disinterest.\n",
      "disinterested is at index 2982\n",
      "Saved the embedding for disinterested.\n",
      "disjointed is at index 2982\n",
      "Saved the embedding for disjointed.\n",
      "dislike is at index 28101\n",
      "Saved the embedding for dislike.\n",
      "disliked is at index 40891\n",
      "Saved the embedding for disliked.\n",
      "disliking is at index 19131\n",
      "Saved the embedding for disliking.\n",
      "dismal is at index 23446\n",
      "Saved the embedding for dismal.\n",
      "disman is at index 2982\n",
      "Saved the embedding for disman.\n",
      "dismay is at index 22135\n",
      "Saved the embedding for dismay.\n",
      "dismayed is at index 22135\n",
      "Saved the embedding for dismayed.\n",
      "dismissive is at index 37890\n",
      "Saved the embedding for dismissive.\n",
      "disobedient is at index 43738\n",
      "Saved the embedding for disobedient.\n",
      "disorderly is at index 23547\n",
      "Saved the embedding for disorderly.\n",
      "disoriented is at index 2982\n",
      "Saved the embedding for disoriented.\n",
      "dispair is at index 11734\n",
      "Saved the embedding for dispair.\n",
      "disparaging is at index 24331\n",
      "Saved the embedding for disparaging.\n",
      "dispassionate is at index 11734\n",
      "Saved the embedding for dispassionate.\n",
      "dispirited is at index 2982\n",
      "Saved the embedding for dispirited.\n",
      "dispiritedness is at index 2982\n",
      "Saved the embedding for dispiritedness.\n",
      "displeased is at index 43709\n",
      "Saved the embedding for displeased.\n",
      "displeasure is at index 30201\n",
      "Saved the embedding for displeasure.\n",
      "disquiet is at index 2982\n",
      "Saved the embedding for disquiet.\n",
      "disquieted is at index 2982\n",
      "Saved the embedding for disquieted.\n",
      "disregard is at index 21034\n",
      "Saved the embedding for disregard.\n",
      "disrespectful is at index 26401\n",
      "Saved the embedding for disrespectful.\n",
      "disrupted is at index 15902\n",
      "Saved the embedding for disrupted.\n",
      "disruptive is at index 17561\n",
      "Saved the embedding for disruptive.\n",
      "dissatisfaction is at index 31776\n",
      "Saved the embedding for dissatisfaction.\n",
      "dissatisfied is at index 37278\n",
      "Saved the embedding for dissatisfied.\n",
      "dissatisfy is at index 48830\n",
      "Saved the embedding for dissatisfy.\n",
      "dissecting is at index 33562\n",
      "Saved the embedding for dissecting.\n",
      "dissociated is at index 14863\n",
      "Saved the embedding for dissociated.\n",
      "dissonant is at index 43162\n",
      "Saved the embedding for dissonant.\n",
      "distain is at index 7018\n",
      "Saved the embedding for distain.\n",
      "distant is at index 13258\n",
      "Saved the embedding for distant.\n",
      "distaste is at index 7018\n",
      "Saved the embedding for distaste.\n",
      "distasteful is at index 7018\n",
      "Saved the embedding for distasteful.\n",
      "distracted is at index 16573\n",
      "Saved the embedding for distracted.\n",
      "distraught is at index 30719\n",
      "Saved the embedding for distraught.\n",
      "distress is at index 13250\n",
      "Saved the embedding for distress.\n",
      "distressed is at index 21460\n",
      "Saved the embedding for distressed.\n",
      "distressing is at index 7018\n",
      "Saved the embedding for distressing.\n",
      "distrust is at index 27948\n",
      "Saved the embedding for distrust.\n",
      "distrustful is at index 27948\n",
      "Saved the embedding for distrustful.\n",
      "distrusting is at index 27948\n",
      "Saved the embedding for distrusting.\n",
      "disturbed is at index 22938\n",
      "Saved the embedding for disturbed.\n",
      "diverted is at index 19070\n",
      "Saved the embedding for diverted.\n",
      "dodgy is at index 25744\n",
      "Saved the embedding for dodgy.\n",
      "doleful is at index 109\n",
      "Saved the embedding for doleful.\n",
      "doltish is at index 385\n",
      "Saved the embedding for doltish.\n",
      "dominant is at index 7353\n",
      "Saved the embedding for dominant.\n",
      "dominating is at index 17349\n",
      "Saved the embedding for dominating.\n",
      "domineering is at index 13567\n",
      "Saved the embedding for domineering.\n",
      "done is at index 626\n",
      "Saved the embedding for done.\n",
      "doomed is at index 23326\n",
      "Saved the embedding for doomed.\n",
      "dopey is at index 32331\n",
      "Saved the embedding for dopey.\n",
      "doting is at index 385\n",
      "Saved the embedding for doting.\n",
      "doubt is at index 2980\n",
      "Saved the embedding for doubt.\n",
      "doubter is at index 26463\n",
      "Saved the embedding for doubter.\n",
      "doubtful is at index 26645\n",
      "Saved the embedding for doubtful.\n",
      "doubtfully is at index 2980\n",
      "Saved the embedding for doubtfully.\n",
      "doubtfulness is at index 2980\n",
      "Saved the embedding for doubtfulness.\n",
      "doubting is at index 26463\n",
      "Saved the embedding for doubting.\n",
      "dour is at index 385\n",
      "Saved the embedding for dour.\n",
      "down is at index 159\n",
      "Saved the embedding for down.\n",
      "downcast is at index 159\n",
      "Saved the embedding for downcast.\n",
      "downhearted is at index 159\n",
      "Saved the embedding for downhearted.\n",
      "downheartedness is at index 159\n",
      "Saved the embedding for downheartedness.\n",
      "downtrodden is at index 29407\n",
      "Saved the embedding for downtrodden.\n",
      "dozing is at index 109\n",
      "Saved the embedding for dozing.\n",
      "drained is at index 23544\n",
      "Saved the embedding for drained.\n",
      "dramatic is at index 5386\n",
      "Saved the embedding for dramatic.\n",
      "drawn is at index 4777\n",
      "Saved the embedding for drawn.\n",
      "dread is at index 24506\n",
      "Saved the embedding for dread.\n",
      "dreadful is at index 31715\n",
      "Saved the embedding for dreadful.\n",
      "dreading is at index 24506\n",
      "Saved the embedding for dreading.\n",
      "dreaming is at index 26240\n",
      "Saved the embedding for dreaming.\n",
      "dreamy is at index 3366\n",
      "Saved the embedding for dreamy.\n",
      "dreary is at index 385\n",
      "Saved the embedding for dreary.\n",
      "driven is at index 3185\n",
      "Saved the embedding for driven.\n",
      "drowsy is at index 385\n",
      "Saved the embedding for drowsy.\n",
      "drugged is at index 385\n",
      "Saved the embedding for drugged.\n",
      "drunk is at index 10789\n",
      "Saved the embedding for drunk.\n",
      "drunkenness is at index 19835\n",
      "Saved the embedding for drunkenness.\n",
      "dubiety is at index 30180\n",
      "Saved the embedding for dubiety.\n",
      "dubious is at index 24381\n",
      "Saved the embedding for dubious.\n",
      "dubiously is at index 30180\n",
      "Saved the embedding for dubiously.\n",
      "dull is at index 22018\n",
      "Saved the embedding for dull.\n",
      "dumb is at index 16881\n",
      "Saved the embedding for dumb.\n",
      "dumbfound is at index 16881\n",
      "Saved the embedding for dumbfound.\n",
      "dumbfounded is at index 16881\n",
      "Saved the embedding for dumbfounded.\n",
      "dumbstruck is at index 16881\n",
      "Saved the embedding for dumbstruck.\n",
      "dumfounded is at index 385\n",
      "Saved the embedding for dumfounded.\n",
      "dupe is at index 4279\n",
      "Saved the embedding for dupe.\n",
      "duplicitous is at index 30501\n",
      "Saved the embedding for duplicitous.\n",
      "dysphoric is at index 44153\n",
      "Saved the embedding for dysphoric.\n",
      "eager is at index 7921\n",
      "Saved the embedding for eager.\n",
      "eagerness is at index 7921\n",
      "Saved the embedding for eagerness.\n",
      "earnest is at index 22623\n",
      "Saved the embedding for earnest.\n",
      "easy is at index 1365\n",
      "Saved the embedding for easy.\n",
      "ebullient is at index 364\n",
      "Saved the embedding for ebullient.\n",
      "ecstasy is at index 37695\n",
      "Saved the embedding for ecstasy.\n",
      "ecstatic is at index 30754\n",
      "Saved the embedding for ecstatic.\n",
      "ecstatically is at index 20508\n",
      "Saved the embedding for ecstatically.\n",
      "edgy is at index 4803\n",
      "Saved the embedding for edgy.\n",
      "eerie is at index 33960\n",
      "Saved the embedding for eerie.\n",
      "effulgent is at index 22089\n",
      "Saved the embedding for effulgent.\n",
      "egoistic is at index 21450\n",
      "Saved the embedding for egoistic.\n",
      "egotistical is at index 364\n",
      "Saved the embedding for egotistical.\n",
      "egregious is at index 28971\n",
      "Saved the embedding for egregious.\n",
      "elated is at index 1615\n",
      "Saved the embedding for elated.\n",
      "elation is at index 1615\n",
      "Saved the embedding for elation.\n",
      "electrified is at index 17995\n",
      "Saved the embedding for electrified.\n",
      "elusive is at index 21483\n",
      "Saved the embedding for elusive.\n",
      "embarrassed is at index 17319\n",
      "Saved the embedding for embarrassed.\n",
      "embarrassment is at index 19124\n",
      "Saved the embedding for embarrassment.\n",
      "embittered is at index 2841\n",
      "Saved the embedding for embittered.\n",
      "embody is at index 33865\n",
      "Saved the embedding for embody.\n",
      "emotional is at index 3722\n",
      "Saved the embedding for emotional.\n",
      "emotionless is at index 11926\n",
      "Saved the embedding for emotionless.\n",
      "empathetic is at index 2841\n",
      "Saved the embedding for empathetic.\n",
      "empathic is at index 2841\n",
      "Saved the embedding for empathic.\n",
      "empathy is at index 17805\n",
      "Saved the embedding for empathy.\n",
      "emptiness is at index 44480\n",
      "Saved the embedding for emptiness.\n",
      "empty is at index 5802\n",
      "Saved the embedding for empty.\n",
      "enamored is at index 1177\n",
      "Saved the embedding for enamored.\n",
      "enchanted is at index 44141\n",
      "Saved the embedding for enchanted.\n",
      "encouraged is at index 4446\n",
      "Saved the embedding for encouraged.\n",
      "encouragement is at index 18197\n",
      "Saved the embedding for encouragement.\n",
      "encouraging is at index 5513\n",
      "Saved the embedding for encouraging.\n",
      "endeared is at index 253\n",
      "Saved the embedding for endeared.\n",
      "endearing is at index 253\n",
      "Saved the embedding for endearing.\n",
      "enduring is at index 16480\n",
      "Saved the embedding for enduring.\n",
      "energetic is at index 20425\n",
      "Saved the embedding for energetic.\n",
      "energized is at index 15957\n",
      "Saved the embedding for energized.\n",
      "engaged is at index 4009\n",
      "Saved the embedding for engaged.\n",
      "engrossed is at index 20407\n",
      "Saved the embedding for engrossed.\n",
      "engrossment is at index 20407\n",
      "Saved the embedding for engrossment.\n",
      "enigmatic is at index 38910\n",
      "Saved the embedding for enigmatic.\n",
      "enjoy is at index 2254\n",
      "Saved the embedding for enjoy.\n",
      "enjoying is at index 6218\n",
      "Saved the embedding for enjoying.\n",
      "enjoyment is at index 26611\n",
      "Saved the embedding for enjoyment.\n",
      "enlightened is at index 38853\n",
      "Saved the embedding for enlightened.\n",
      "enmity is at index 1177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for enmity.\n",
      "ennui is at index 1177\n",
      "Saved the embedding for ennui.\n",
      "enraged is at index 33415\n",
      "Saved the embedding for enraged.\n",
      "enraging is at index 1177\n",
      "Saved the embedding for enraging.\n",
      "enraptured is at index 1177\n",
      "Saved the embedding for enraptured.\n",
      "entertained is at index 23979\n",
      "Saved the embedding for entertained.\n",
      "enthralled is at index 3838\n",
      "Saved the embedding for enthralled.\n",
      "enthused is at index 3838\n",
      "Saved the embedding for enthused.\n",
      "enthusiasm is at index 11240\n",
      "Saved the embedding for enthusiasm.\n",
      "enthusiastic is at index 15947\n",
      "Saved the embedding for enthusiastic.\n",
      "enticed is at index 3838\n",
      "Saved the embedding for enticed.\n",
      "entranced is at index 3838\n",
      "Saved the embedding for entranced.\n",
      "envious is at index 1177\n",
      "Saved the embedding for envious.\n",
      "envy is at index 29778\n",
      "Saved the embedding for envy.\n",
      "erotically is at index 3335\n",
      "Saved the embedding for erotically.\n",
      "estranged is at index 20599\n",
      "Saved the embedding for estranged.\n",
      "etched is at index 35542\n",
      "Saved the embedding for etched.\n",
      "euphoric is at index 30882\n",
      "Saved the embedding for euphoric.\n",
      "evaluating is at index 15190\n",
      "Saved the embedding for evaluating.\n",
      "evasive is at index 7630\n",
      "Saved the embedding for evasive.\n",
      "evil is at index 9247\n",
      "Saved the embedding for evil.\n",
      "evoke is at index 35334\n",
      "Saved the embedding for evoke.\n",
      "exacerbated is at index 24961\n",
      "Saved the embedding for exacerbated.\n",
      "exalted is at index 45514\n",
      "Saved the embedding for exalted.\n",
      "examining is at index 14951\n",
      "Saved the embedding for examining.\n",
      "exasperate is at index 1931\n",
      "Saved the embedding for exasperate.\n",
      "exasperated is at index 34698\n",
      "Saved the embedding for exasperated.\n",
      "exasperation is at index 34698\n",
      "Saved the embedding for exasperation.\n",
      "excited is at index 2283\n",
      "Saved the embedding for excited.\n",
      "excitedly is at index 2283\n",
      "Saved the embedding for excitedly.\n",
      "excitement is at index 8354\n",
      "Saved the embedding for excitement.\n",
      "exclamation is at index 1931\n",
      "Saved the embedding for exclamation.\n",
      "exclamatory is at index 1931\n",
      "Saved the embedding for exclamatory.\n",
      "exhausted is at index 17067\n",
      "Saved the embedding for exhausted.\n",
      "exhaustion is at index 30567\n",
      "Saved the embedding for exhaustion.\n",
      "exhaustive is at index 29180\n",
      "Saved the embedding for exhaustive.\n",
      "exhilarated is at index 32749\n",
      "Saved the embedding for exhilarated.\n",
      "exhilaration is at index 32749\n",
      "Saved the embedding for exhilaration.\n",
      "exited is at index 17469\n",
      "Saved the embedding for exited.\n",
      "expectant is at index 1057\n",
      "Saved the embedding for expectant.\n",
      "expectation is at index 9250\n",
      "Saved the embedding for expectation.\n",
      "expecting is at index 4804\n",
      "Saved the embedding for expecting.\n",
      "explain is at index 3922\n",
      "Saved the embedding for explain.\n",
      "explaining is at index 8926\n",
      "Saved the embedding for explaining.\n",
      "exploitive is at index 38984\n",
      "Saved the embedding for exploitive.\n",
      "explosive is at index 8560\n",
      "Saved the embedding for explosive.\n",
      "exposure is at index 4895\n",
      "Saved the embedding for exposure.\n",
      "expressive is at index 36340\n",
      "Saved the embedding for expressive.\n",
      "exuberant is at index 1931\n",
      "Saved the embedding for exuberant.\n",
      "exultant is at index 1931\n",
      "Saved the embedding for exultant.\n",
      "exulted is at index 1931\n",
      "Saved the embedding for exulted.\n",
      "eye is at index 2295\n",
      "Saved the embedding for eye.\n",
      "eyed is at index 36235\n",
      "Saved the embedding for eyed.\n",
      "faced is at index 2713\n",
      "Saved the embedding for faced.\n",
      "facetious is at index 34407\n",
      "Saved the embedding for facetious.\n",
      "failure is at index 2988\n",
      "Saved the embedding for failure.\n",
      "faint is at index 27922\n",
      "Saved the embedding for faint.\n",
      "fair is at index 2105\n",
      "Saved the embedding for fair.\n",
      "fake is at index 4486\n",
      "Saved the embedding for fake.\n",
      "faking is at index 856\n",
      "Saved the embedding for faking.\n",
      "falter is at index 14848\n",
      "Saved the embedding for falter.\n",
      "famished is at index 13403\n",
      "Saved the embedding for famished.\n",
      "fanatic is at index 38604\n",
      "Saved the embedding for fanatic.\n",
      "fanciful is at index 33639\n",
      "Saved the embedding for fanciful.\n",
      "fart is at index 36762\n",
      "Saved the embedding for fart.\n",
      "fascinated is at index 27025\n",
      "Saved the embedding for fascinated.\n",
      "fastidious is at index 1769\n",
      "Saved the embedding for fastidious.\n",
      "fatigue is at index 16069\n",
      "Saved the embedding for fatigue.\n",
      "fatigued is at index 36239\n",
      "Saved the embedding for fatigued.\n",
      "faultfinding is at index 7684\n",
      "Saved the embedding for faultfinding.\n",
      "favorable is at index 9879\n",
      "Saved the embedding for favorable.\n",
      "fawning is at index 856\n",
      "Saved the embedding for fawning.\n",
      "fazed is at index 856\n",
      "Saved the embedding for fazed.\n",
      "fear is at index 2490\n",
      "Saved the embedding for fear.\n",
      "feared is at index 9741\n",
      "Saved the embedding for feared.\n",
      "fearful is at index 23526\n",
      "Saved the embedding for fearful.\n",
      "fearing is at index 21510\n",
      "Saved the embedding for fearing.\n",
      "fearless is at index 29107\n",
      "Saved the embedding for fearless.\n",
      "fearsome is at index 39185\n",
      "Saved the embedding for fearsome.\n",
      "feckless is at index 10668\n",
      "Saved the embedding for feckless.\n",
      "fed is at index 9789\n",
      "Saved the embedding for fed.\n",
      "feeble is at index 42217\n",
      "Saved the embedding for feeble.\n",
      "feign is at index 10668\n",
      "Saved the embedding for feign.\n",
      "felicitous is at index 14383\n",
      "Saved the embedding for felicitous.\n",
      "ferocious is at index 31429\n",
      "Saved the embedding for ferocious.\n",
      "ferocity is at index 16022\n",
      "Saved the embedding for ferocity.\n",
      "festive is at index 12298\n",
      "Saved the embedding for festive.\n",
      "fidgety is at index 856\n",
      "Saved the embedding for fidgety.\n",
      "fiendish is at index 13383\n",
      "Saved the embedding for fiendish.\n",
      "fierce is at index 11039\n",
      "Saved the embedding for fierce.\n",
      "fiery is at index 19068\n",
      "Saved the embedding for fiery.\n",
      "fighting is at index 2190\n",
      "Saved the embedding for fighting.\n",
      "fine is at index 2051\n",
      "Saved the embedding for fine.\n",
      "finished is at index 1550\n",
      "Saved the embedding for finished.\n",
      "firm is at index 933\n",
      "Saved the embedding for firm.\n",
      "fishy is at index 3539\n",
      "Saved the embedding for fishy.\n",
      "fixated is at index 4190\n",
      "Saved the embedding for fixated.\n",
      "fixed is at index 4460\n",
      "Saved the embedding for fixed.\n",
      "flabbergasted is at index 2342\n",
      "Saved the embedding for flabbergasted.\n",
      "flaming is at index 37222\n",
      "Saved the embedding for flaming.\n",
      "flat is at index 3269\n",
      "Saved the embedding for flat.\n",
      "flaunting is at index 2342\n",
      "Saved the embedding for flaunting.\n",
      "flighty is at index 2524\n",
      "Saved the embedding for flighty.\n",
      "flippant is at index 2342\n",
      "Saved the embedding for flippant.\n",
      "flipped is at index 18626\n",
      "Saved the embedding for flipped.\n",
      "flirtation is at index 33743\n",
      "Saved the embedding for flirtation.\n",
      "flirtatious is at index 33743\n",
      "Saved the embedding for flirtatious.\n",
      "flirty is at index 2342\n",
      "Saved the embedding for flirty.\n",
      "floored is at index 27325\n",
      "Saved the embedding for floored.\n",
      "flummoxed is at index 2342\n",
      "Saved the embedding for flummoxed.\n",
      "flustered is at index 2342\n",
      "Saved the embedding for flustered.\n",
      "focus is at index 1056\n",
      "Saved the embedding for focus.\n",
      "focused is at index 2061\n",
      "Saved the embedding for focused.\n",
      "focusing is at index 5650\n",
      "Saved the embedding for focusing.\n",
      "foiled is at index 9565\n",
      "Saved the embedding for foiled.\n",
      "foolish is at index 22789\n",
      "Saved the embedding for foolish.\n",
      "forbearing is at index 34550\n",
      "Saved the embedding for forbearing.\n",
      "forbidding is at index 34550\n",
      "Saved the embedding for forbidding.\n",
      "forced is at index 1654\n",
      "Saved the embedding for forced.\n",
      "forceful is at index 32165\n",
      "Saved the embedding for forceful.\n",
      "forfeited is at index 31844\n",
      "Saved the embedding for forfeited.\n",
      "forlorn is at index 13\n",
      "Saved the embedding for forlorn.\n",
      "fortunate is at index 10583\n",
      "Saved the embedding for fortunate.\n",
      "forward is at index 556\n",
      "Saved the embedding for forward.\n",
      "foul is at index 6962\n",
      "Saved the embedding for foul.\n",
      "fractious is at index 38251\n",
      "Saved the embedding for fractious.\n",
      "fragile is at index 14283\n",
      "Saved the embedding for fragile.\n",
      "frantic is at index 27396\n",
      "Saved the embedding for frantic.\n",
      "fraudulent is at index 15381\n",
      "Saved the embedding for fraudulent.\n",
      "fraught is at index 25481\n",
      "Saved the embedding for fraught.\n",
      "frazzled is at index 26830\n",
      "Saved the embedding for frazzled.\n",
      "freaked is at index 7619\n",
      "Saved the embedding for freaked.\n",
      "frenzied is at index 26908\n",
      "Saved the embedding for frenzied.\n",
      "fretful is at index 31391\n",
      "Saved the embedding for fretful.\n",
      "friendliness is at index 1441\n",
      "Saved the embedding for friendliness.\n",
      "friendly is at index 5192\n",
      "Saved the embedding for friendly.\n",
      "fright is at index 32580\n",
      "Saved the embedding for fright.\n",
      "frightened is at index 26851\n",
      "Saved the embedding for frightened.\n",
      "frightening is at index 21111\n",
      "Saved the embedding for frightening.\n",
      "frigid is at index 25805\n",
      "Saved the embedding for frigid.\n",
      "frisky is at index 6664\n",
      "Saved the embedding for frisky.\n",
      "frolicker is at index 856\n",
      "Saved the embedding for frolicker.\n",
      "frown is at index 41588\n",
      "Saved the embedding for frown.\n",
      "frowning is at index 41588\n",
      "Saved the embedding for frowning.\n",
      "frozen is at index 9214\n",
      "Saved the embedding for frozen.\n",
      "frumpy is at index 6664\n",
      "Saved the embedding for frumpy.\n",
      "frustrated is at index 8164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for frustrated.\n",
      "frustration is at index 8413\n",
      "Saved the embedding for frustration.\n",
      "fulfilled is at index 20218\n",
      "Saved the embedding for fulfilled.\n",
      "fumed is at index 856\n",
      "Saved the embedding for fumed.\n",
      "fuming is at index 856\n",
      "Saved the embedding for fuming.\n",
      "fun is at index 1531\n",
      "Saved the embedding for fun.\n",
      "funny is at index 6269\n",
      "Saved the embedding for funny.\n",
      "furious is at index 15940\n",
      "Saved the embedding for furious.\n",
      "furiously is at index 39202\n",
      "Saved the embedding for furiously.\n",
      "furiousness is at index 15940\n",
      "Saved the embedding for furiousness.\n",
      "furrowed is at index 15503\n",
      "Saved the embedding for furrowed.\n",
      "furtive is at index 856\n",
      "Saved the embedding for furtive.\n",
      "fury is at index 22228\n",
      "Saved the embedding for fury.\n",
      "fussy is at index 856\n",
      "Saved the embedding for fussy.\n",
      "galled is at index 821\n",
      "Saved the embedding for galled.\n",
      "galling is at index 19869\n",
      "Saved the embedding for galling.\n",
      "gasp is at index 41681\n",
      "Saved the embedding for gasp.\n",
      "gasped is at index 44918\n",
      "Saved the embedding for gasped.\n",
      "gasping is at index 1123\n",
      "Saved the embedding for gasping.\n",
      "gay is at index 5100\n",
      "Saved the embedding for gay.\n",
      "gazing is at index 40804\n",
      "Saved the embedding for gazing.\n",
      "genial is at index 12358\n",
      "Saved the embedding for genial.\n",
      "gentle is at index 16634\n",
      "Saved the embedding for gentle.\n",
      "genuine is at index 8916\n",
      "Saved the embedding for genuine.\n",
      "ghastly is at index 34648\n",
      "Saved the embedding for ghastly.\n",
      "giddy is at index 821\n",
      "Saved the embedding for giddy.\n",
      "giggle is at index 821\n",
      "Saved the embedding for giggle.\n",
      "giggling is at index 33786\n",
      "Saved the embedding for giggling.\n",
      "glad is at index 7785\n",
      "Saved the embedding for glad.\n",
      "gladdened is at index 5921\n",
      "Saved the embedding for gladdened.\n",
      "gladiola is at index 7785\n",
      "Saved the embedding for gladiola.\n",
      "gladness is at index 7785\n",
      "Saved the embedding for gladness.\n",
      "gladsome is at index 5921\n",
      "Saved the embedding for gladsome.\n",
      "glare is at index 37355\n",
      "Saved the embedding for glare.\n",
      "glaring is at index 26077\n",
      "Saved the embedding for glaring.\n",
      "glazed is at index 5921\n",
      "Saved the embedding for glazed.\n",
      "glee is at index 821\n",
      "Saved the embedding for glee.\n",
      "gleeful is at index 22460\n",
      "Saved the embedding for gleeful.\n",
      "gleefully is at index 22460\n",
      "Saved the embedding for gleefully.\n",
      "glib is at index 5921\n",
      "Saved the embedding for glib.\n",
      "gloating is at index 5921\n",
      "Saved the embedding for gloating.\n",
      "gloom is at index 31752\n",
      "Saved the embedding for gloom.\n",
      "gloomy is at index 32627\n",
      "Saved the embedding for gloomy.\n",
      "glowering is at index 5921\n",
      "Saved the embedding for glowering.\n",
      "glowing is at index 22285\n",
      "Saved the embedding for glowing.\n",
      "glum is at index 5921\n",
      "Saved the embedding for glum.\n",
      "gnarl is at index 31021\n",
      "Saved the embedding for gnarl.\n",
      "gobsmacked is at index 213\n",
      "Saved the embedding for gobsmacked.\n",
      "good is at index 205\n",
      "Saved the embedding for good.\n",
      "goofy is at index 36302\n",
      "Saved the embedding for goofy.\n",
      "gossipy is at index 20445\n",
      "Saved the embedding for gossipy.\n",
      "grandiose is at index 2821\n",
      "Saved the embedding for grandiose.\n",
      "grateful is at index 6161\n",
      "Saved the embedding for grateful.\n",
      "gratified is at index 20153\n",
      "Saved the embedding for gratified.\n",
      "grave is at index 9753\n",
      "Saved the embedding for grave.\n",
      "great is at index 372\n",
      "Saved the embedding for great.\n",
      "greedy is at index 34405\n",
      "Saved the embedding for greedy.\n",
      "greeting is at index 25801\n",
      "Saved the embedding for greeting.\n",
      "grief is at index 12903\n",
      "Saved the embedding for grief.\n",
      "grieved is at index 821\n",
      "Saved the embedding for grieved.\n",
      "grieving is at index 22567\n",
      "Saved the embedding for grieving.\n",
      "grim is at index 17081\n",
      "Saved the embedding for grim.\n",
      "grimace is at index 17081\n",
      "Saved the embedding for grimace.\n",
      "grimacing is at index 17081\n",
      "Saved the embedding for grimacing.\n",
      "grin is at index 30986\n",
      "Saved the embedding for grin.\n",
      "grinning is at index 39662\n",
      "Saved the embedding for grinning.\n",
      "griping is at index 11155\n",
      "Saved the embedding for griping.\n",
      "gross is at index 4200\n",
      "Saved the embedding for gross.\n",
      "grossed is at index 4200\n",
      "Saved the embedding for grossed.\n",
      "grouchy is at index 22970\n",
      "Saved the embedding for grouchy.\n",
      "growl is at index 1733\n",
      "Saved the embedding for growl.\n",
      "growling is at index 1733\n",
      "Saved the embedding for growling.\n",
      "grudge is at index 4435\n",
      "Saved the embedding for grudge.\n",
      "grudging is at index 4435\n",
      "Saved the embedding for grudging.\n",
      "gruff is at index 15551\n",
      "Saved the embedding for gruff.\n",
      "grumbling is at index 4435\n",
      "Saved the embedding for grumbling.\n",
      "grumpy is at index 4435\n",
      "Saved the embedding for grumpy.\n",
      "grunt is at index 44376\n",
      "Saved the embedding for grunt.\n",
      "grunting is at index 39204\n",
      "Saved the embedding for grunting.\n",
      "guarded is at index 25853\n",
      "Saved the embedding for guarded.\n",
      "guilty is at index 2181\n",
      "Saved the embedding for guilty.\n",
      "gulp is at index 821\n",
      "Saved the embedding for gulp.\n",
      "haggard is at index 1368\n",
      "Saved the embedding for haggard.\n",
      "halfhearted is at index 457\n",
      "Saved the embedding for halfhearted.\n",
      "halted is at index 12856\n",
      "Saved the embedding for halted.\n",
      "hapless is at index 2489\n",
      "Saved the embedding for hapless.\n",
      "happiness is at index 11098\n",
      "Saved the embedding for happiness.\n",
      "happy is at index 1372\n",
      "Saved the embedding for happy.\n",
      "harassed is at index 16835\n",
      "Saved the embedding for harassed.\n",
      "hard is at index 543\n",
      "Saved the embedding for hard.\n",
      "hardened is at index 33631\n",
      "Saved the embedding for hardened.\n",
      "harmful is at index 11190\n",
      "Saved the embedding for harmful.\n",
      "harried is at index 12280\n",
      "Saved the embedding for harried.\n",
      "harsh is at index 9776\n",
      "Saved the embedding for harsh.\n",
      "hate is at index 4157\n",
      "Saved the embedding for hate.\n",
      "hateful is at index 26393\n",
      "Saved the embedding for hateful.\n",
      "hating is at index 40873\n",
      "Saved the embedding for hating.\n",
      "hatred is at index 13453\n",
      "Saved the embedding for hatred.\n",
      "haughty is at index 2489\n",
      "Saved the embedding for haughty.\n",
      "haunted is at index 22717\n",
      "Saved the embedding for haunted.\n",
      "hazy is at index 2489\n",
      "Saved the embedding for hazy.\n",
      "headshake is at index 471\n",
      "Saved the embedding for headshake.\n",
      "heartache is at index 1144\n",
      "Saved the embedding for heartache.\n",
      "heartbroken is at index 1144\n",
      "Saved the embedding for heartbroken.\n",
      "hearted is at index 1144\n",
      "Saved the embedding for hearted.\n",
      "heartsick is at index 7754\n",
      "Saved the embedding for heartsick.\n",
      "heated is at index 10819\n",
      "Saved the embedding for heated.\n",
      "heavyhearted is at index 2016\n",
      "Saved the embedding for heavyhearted.\n",
      "heckle is at index 17835\n",
      "Saved the embedding for heckle.\n",
      "heedful is at index 25432\n",
      "Saved the embedding for heedful.\n",
      "heinous is at index 30091\n",
      "Saved the embedding for heinous.\n",
      "helpful is at index 7163\n",
      "Saved the embedding for helpful.\n",
      "helpless is at index 22445\n",
      "Saved the embedding for helpless.\n",
      "hesitant is at index 24668\n",
      "Saved the embedding for hesitant.\n",
      "hesitantly is at index 36279\n",
      "Saved the embedding for hesitantly.\n",
      "hesitating is at index 36279\n",
      "Saved the embedding for hesitating.\n",
      "hesitation is at index 28946\n",
      "Saved the embedding for hesitation.\n",
      "high is at index 239\n",
      "Saved the embedding for high.\n",
      "hollering is at index 1368\n",
      "Saved the embedding for hollering.\n",
      "homicidal is at index 9486\n",
      "Saved the embedding for homicidal.\n",
      "honest is at index 5322\n",
      "Saved the embedding for honest.\n",
      "honorable is at index 28537\n",
      "Saved the embedding for honorable.\n",
      "hope is at index 1034\n",
      "Saved the embedding for hope.\n",
      "hopeful is at index 7917\n",
      "Saved the embedding for hopeful.\n",
      "hopefulness is at index 7917\n",
      "Saved the embedding for hopefulness.\n",
      "hopeless is at index 24418\n",
      "Saved the embedding for hopeless.\n",
      "hoping is at index 2818\n",
      "Saved the embedding for hoping.\n",
      "horny is at index 46216\n",
      "Saved the embedding for horny.\n",
      "horrible is at index 11385\n",
      "Saved the embedding for horrible.\n",
      "horrified is at index 27807\n",
      "Saved the embedding for horrified.\n",
      "horrify is at index 48067\n",
      "Saved the embedding for horrify.\n",
      "horrifying is at index 28242\n",
      "Saved the embedding for horrifying.\n",
      "horror is at index 8444\n",
      "Saved the embedding for horror.\n",
      "hostile is at index 11928\n",
      "Saved the embedding for hostile.\n",
      "hostility is at index 22069\n",
      "Saved the embedding for hostility.\n",
      "hot is at index 2131\n",
      "Saved the embedding for hot.\n",
      "hotshot is at index 2131\n",
      "Saved the embedding for hotshot.\n",
      "huffiness is at index 1368\n",
      "Saved the embedding for huffiness.\n",
      "huffy is at index 1368\n",
      "Saved the embedding for huffy.\n",
      "humble is at index 14083\n",
      "Saved the embedding for humble.\n",
      "humbled is at index 10080\n",
      "Saved the embedding for humbled.\n",
      "humdrum is at index 10080\n",
      "Saved the embedding for humdrum.\n",
      "humiliated is at index 32386\n",
      "Saved the embedding for humiliated.\n",
      "humility is at index 27352\n",
      "Saved the embedding for humility.\n",
      "humming is at index 35774\n",
      "Saved the embedding for humming.\n",
      "humor is at index 12073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for humor.\n",
      "humored is at index 10080\n",
      "Saved the embedding for humored.\n",
      "humorous is at index 31214\n",
      "Saved the embedding for humorous.\n",
      "hunger is at index 12226\n",
      "Saved the embedding for hunger.\n",
      "hungry is at index 11130\n",
      "Saved the embedding for hungry.\n",
      "hunted is at index 32602\n",
      "Saved the embedding for hunted.\n",
      "hurt is at index 2581\n",
      "Saved the embedding for hurt.\n",
      "hurtful is at index 2581\n",
      "Saved the embedding for hurtful.\n",
      "hurting is at index 12780\n",
      "Saved the embedding for hurting.\n",
      "hush is at index 1368\n",
      "Saved the embedding for hush.\n",
      "hushed is at index 33476\n",
      "Saved the embedding for hushed.\n",
      "hyper is at index 8944\n",
      "Saved the embedding for hyper.\n",
      "hyperactive is at index 8944\n",
      "Saved the embedding for hyperactive.\n",
      "hypnotized is at index 39040\n",
      "Saved the embedding for hypnotized.\n",
      "hypocritical is at index 37769\n",
      "Saved the embedding for hypocritical.\n",
      "hysteria is at index 35099\n",
      "Saved the embedding for hysteria.\n",
      "hysterical is at index 38561\n",
      "Saved the embedding for hysterical.\n",
      "idiotic is at index 13561\n",
      "Saved the embedding for idiotic.\n",
      "ignorant is at index 27726\n",
      "Saved the embedding for ignorant.\n",
      "ignoring is at index 15515\n",
      "Saved the embedding for ignoring.\n",
      "ill is at index 4812\n",
      "Saved the embedding for ill.\n",
      "imaginative is at index 35026\n",
      "Saved the embedding for imaginative.\n",
      "immature is at index 39001\n",
      "Saved the embedding for immature.\n",
      "immersed is at index 31971\n",
      "Saved the embedding for immersed.\n",
      "impacted is at index 7284\n",
      "Saved the embedding for impacted.\n",
      "impartial is at index 24283\n",
      "Saved the embedding for impartial.\n",
      "impassioned is at index 4023\n",
      "Saved the embedding for impassioned.\n",
      "impassive is at index 4023\n",
      "Saved the embedding for impassive.\n",
      "impatience is at index 43635\n",
      "Saved the embedding for impatience.\n",
      "impatient is at index 32601\n",
      "Saved the embedding for impatient.\n",
      "imperious is at index 21245\n",
      "Saved the embedding for imperious.\n",
      "impersonal is at index 23153\n",
      "Saved the embedding for impersonal.\n",
      "impertinent is at index 21245\n",
      "Saved the embedding for impertinent.\n",
      "impish is at index 4023\n",
      "Saved the embedding for impish.\n",
      "implicated is at index 23316\n",
      "Saved the embedding for implicated.\n",
      "imploring is at index 12956\n",
      "Saved the embedding for imploring.\n",
      "important is at index 505\n",
      "Saved the embedding for important.\n",
      "impressed is at index 6889\n",
      "Saved the embedding for impressed.\n",
      "impulsive is at index 4023\n",
      "Saved the embedding for impulsive.\n",
      "inactive is at index 25986\n",
      "Saved the embedding for inactive.\n",
      "inadequate is at index 15650\n",
      "Saved the embedding for inadequate.\n",
      "inarticulate is at index 11\n",
      "Saved the embedding for inarticulate.\n",
      "inattentive is at index 11\n",
      "Saved the embedding for inattentive.\n",
      "inaudible is at index 11\n",
      "Saved the embedding for inaudible.\n",
      "inauthentic is at index 11\n",
      "Saved the embedding for inauthentic.\n",
      "incapable is at index 30256\n",
      "Saved the embedding for incapable.\n",
      "incensed is at index 5853\n",
      "Saved the embedding for incensed.\n",
      "incertain is at index 5853\n",
      "Saved the embedding for incertain.\n",
      "incertitude is at index 5853\n",
      "Saved the embedding for incertitude.\n",
      "incited is at index 5853\n",
      "Saved the embedding for incited.\n",
      "incomprehensible is at index 42494\n",
      "Saved the embedding for incomprehensible.\n",
      "inconspicuous is at index 40817\n",
      "Saved the embedding for inconspicuous.\n",
      "incredulity is at index 38366\n",
      "Saved the embedding for incredulity.\n",
      "incredulous is at index 38366\n",
      "Saved the embedding for incredulous.\n",
      "incredulously is at index 38366\n",
      "Saved the embedding for incredulously.\n",
      "inculpate is at index 5853\n",
      "Saved the embedding for inculpate.\n",
      "incurious is at index 5853\n",
      "Saved the embedding for incurious.\n",
      "indecipherable is at index 32227\n",
      "Saved the embedding for indecipherable.\n",
      "indecision is at index 32227\n",
      "Saved the embedding for indecision.\n",
      "indecisive is at index 32227\n",
      "Saved the embedding for indecisive.\n",
      "indifferent is at index 34657\n",
      "Saved the embedding for indifferent.\n",
      "indifferently is at index 34657\n",
      "Saved the embedding for indifferently.\n",
      "indignant is at index 9473\n",
      "Saved the embedding for indignant.\n",
      "indolent is at index 9473\n",
      "Saved the embedding for indolent.\n",
      "inebriated is at index 11\n",
      "Saved the embedding for inebriated.\n",
      "inert is at index 43783\n",
      "Saved the embedding for inert.\n",
      "infatuating is at index 4047\n",
      "Saved the embedding for infatuating.\n",
      "inferior is at index 28510\n",
      "Saved the embedding for inferior.\n",
      "inferiority is at index 28510\n",
      "Saved the embedding for inferiority.\n",
      "inflamed is at index 11411\n",
      "Saved the embedding for inflamed.\n",
      "informal is at index 14110\n",
      "Saved the embedding for informal.\n",
      "informing is at index 21835\n",
      "Saved the embedding for informing.\n",
      "infuriated is at index 26974\n",
      "Saved the embedding for infuriated.\n",
      "inhibited is at index 45427\n",
      "Saved the embedding for inhibited.\n",
      "inhibiting is at index 38512\n",
      "Saved the embedding for inhibiting.\n",
      "inimical is at index 11\n",
      "Saved the embedding for inimical.\n",
      "injured is at index 1710\n",
      "Saved the embedding for injured.\n",
      "innocent is at index 7850\n",
      "Saved the embedding for innocent.\n",
      "inpatient is at index 11\n",
      "Saved the embedding for inpatient.\n",
      "inquiring is at index 27874\n",
      "Saved the embedding for inquiring.\n",
      "inquisitive is at index 27874\n",
      "Saved the embedding for inquisitive.\n",
      "insane is at index 18544\n",
      "Saved the embedding for insane.\n",
      "inscrutable is at index 7540\n",
      "Saved the embedding for inscrutable.\n",
      "insecure is at index 27810\n",
      "Saved the embedding for insecure.\n",
      "insecurity is at index 19401\n",
      "Saved the embedding for insecurity.\n",
      "insensitive is at index 29401\n",
      "Saved the embedding for insensitive.\n",
      "insidious is at index 40012\n",
      "Saved the embedding for insidious.\n",
      "insinuating is at index 32016\n",
      "Saved the embedding for insinuating.\n",
      "insistence is at index 24974\n",
      "Saved the embedding for insistence.\n",
      "insistent is at index 7540\n",
      "Saved the embedding for insistent.\n",
      "insisting is at index 13875\n",
      "Saved the embedding for insisting.\n",
      "insolent is at index 23799\n",
      "Saved the embedding for insolent.\n",
      "insouciance is at index 7540\n",
      "Saved the embedding for insouciance.\n",
      "insouciant is at index 7540\n",
      "Saved the embedding for insouciant.\n",
      "inspired is at index 4083\n",
      "Saved the embedding for inspired.\n",
      "inspiring is at index 11653\n",
      "Saved the embedding for inspiring.\n",
      "instigating is at index 9084\n",
      "Saved the embedding for instigating.\n",
      "instructing is at index 20587\n",
      "Saved the embedding for instructing.\n",
      "insubordinate is at index 7540\n",
      "Saved the embedding for insubordinate.\n",
      "insular is at index 7540\n",
      "Saved the embedding for insular.\n",
      "insulted is at index 32149\n",
      "Saved the embedding for insulted.\n",
      "insulting is at index 22602\n",
      "Saved the embedding for insulting.\n",
      "intelligence is at index 2316\n",
      "Saved the embedding for intelligence.\n",
      "intense is at index 5676\n",
      "Saved the embedding for intense.\n",
      "intensely is at index 29727\n",
      "Saved the embedding for intensely.\n",
      "intensity is at index 10603\n",
      "Saved the embedding for intensity.\n",
      "intensive is at index 12296\n",
      "Saved the embedding for intensive.\n",
      "intent is at index 5927\n",
      "Saved the embedding for intent.\n",
      "intentional is at index 18797\n",
      "Saved the embedding for intentional.\n",
      "interacting is at index 23140\n",
      "Saved the embedding for interacting.\n",
      "interest is at index 773\n",
      "Saved the embedding for interest.\n",
      "interested is at index 2509\n",
      "Saved the embedding for interested.\n",
      "interjecting is at index 3222\n",
      "Saved the embedding for interjecting.\n",
      "internalizing is at index 3425\n",
      "Saved the embedding for internalizing.\n",
      "interrogating is at index 28592\n",
      "Saved the embedding for interrogating.\n",
      "interrupting is at index 22749\n",
      "Saved the embedding for interrupting.\n",
      "intimidated is at index 25443\n",
      "Saved the embedding for intimidated.\n",
      "intimidating is at index 23292\n",
      "Saved the embedding for intimidating.\n",
      "intolerant is at index 39348\n",
      "Saved the embedding for intolerant.\n",
      "intoxicated is at index 20600\n",
      "Saved the embedding for intoxicated.\n",
      "intrigue is at index 30368\n",
      "Saved the embedding for intrigue.\n",
      "intrigued is at index 28622\n",
      "Saved the embedding for intrigued.\n",
      "intriguing is at index 14816\n",
      "Saved the embedding for intriguing.\n",
      "introspective is at index 22845\n",
      "Saved the embedding for introspective.\n",
      "invested is at index 5221\n",
      "Saved the embedding for invested.\n",
      "investigate is at index 4830\n",
      "Saved the embedding for investigate.\n",
      "investigative is at index 13222\n",
      "Saved the embedding for investigative.\n",
      "investigatory is at index 25463\n",
      "Saved the embedding for investigatory.\n",
      "invigorated is at index 12259\n",
      "Saved the embedding for invigorated.\n",
      "involved is at index 963\n",
      "Saved the embedding for involved.\n",
      "irascible is at index 10209\n",
      "Saved the embedding for irascible.\n",
      "irate is at index 10209\n",
      "Saved the embedding for irate.\n",
      "ire is at index 25509\n",
      "Saved the embedding for ire.\n",
      "ireful is at index 25509\n",
      "Saved the embedding for ireful.\n",
      "irked is at index 10209\n",
      "Saved the embedding for irked.\n",
      "ironic is at index 25553\n",
      "Saved the embedding for ironic.\n",
      "irony is at index 21490\n",
      "Saved the embedding for irony.\n",
      "irresolute is at index 10209\n",
      "Saved the embedding for irresolute.\n",
      "irritable is at index 26570\n",
      "Saved the embedding for irritable.\n",
      "irritably is at index 26570\n",
      "Saved the embedding for irritably.\n",
      "irritated is at index 35270\n",
      "Saved the embedding for irritated.\n",
      "irritation is at index 32776\n",
      "Saved the embedding for irritation.\n",
      "isolated is at index 8067\n",
      "Saved the embedding for isolated.\n",
      "jabbed is at index 27916\n",
      "Saved the embedding for jabbed.\n",
      "jaded is at index 1236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for jaded.\n",
      "jarred is at index 25413\n",
      "Saved the embedding for jarred.\n",
      "jarring is at index 35659\n",
      "Saved the embedding for jarring.\n",
      "jaunty is at index 1236\n",
      "Saved the embedding for jaunty.\n",
      "jawed is at index 15345\n",
      "Saved the embedding for jawed.\n",
      "jealous is at index 27064\n",
      "Saved the embedding for jealous.\n",
      "jeering is at index 4112\n",
      "Saved the embedding for jeering.\n",
      "jesting is at index 1236\n",
      "Saved the embedding for jesting.\n",
      "jilted is at index 1236\n",
      "Saved the embedding for jilted.\n",
      "jittery is at index 1236\n",
      "Saved the embedding for jittery.\n",
      "jocular is at index 1236\n",
      "Saved the embedding for jocular.\n",
      "joking is at index 22024\n",
      "Saved the embedding for joking.\n",
      "jolly is at index 1236\n",
      "Saved the embedding for jolly.\n",
      "jolted is at index 1236\n",
      "Saved the embedding for jolted.\n",
      "jovial is at index 1236\n",
      "Saved the embedding for jovial.\n",
      "joy is at index 5823\n",
      "Saved the embedding for joy.\n",
      "joyful is at index 32076\n",
      "Saved the embedding for joyful.\n",
      "joyfulness is at index 5823\n",
      "Saved the embedding for joyfulness.\n",
      "joyless is at index 5823\n",
      "Saved the embedding for joyless.\n",
      "joyous is at index 5823\n",
      "Saved the embedding for joyous.\n",
      "jubilant is at index 1236\n",
      "Saved the embedding for jubilant.\n",
      "jubilation is at index 1236\n",
      "Saved the embedding for jubilation.\n",
      "judgemental is at index 17219\n",
      "Saved the embedding for judgemental.\n",
      "judging is at index 17298\n",
      "Saved the embedding for judging.\n",
      "judgmental is at index 7579\n",
      "Saved the embedding for judgmental.\n",
      "judicious is at index 21392\n",
      "Saved the embedding for judicious.\n",
      "jumpy is at index 3704\n",
      "Saved the embedding for jumpy.\n",
      "justified is at index 14267\n",
      "Saved the embedding for justified.\n",
      "keen is at index 5609\n",
      "Saved the embedding for keen.\n",
      "kind is at index 761\n",
      "Saved the embedding for kind.\n",
      "kindhearted is at index 761\n",
      "Saved the embedding for kindhearted.\n",
      "kiss is at index 13301\n",
      "Saved the embedding for kiss.\n",
      "knowing is at index 4730\n",
      "Saved the embedding for knowing.\n",
      "knowledgable is at index 216\n",
      "Saved the embedding for knowledgable.\n",
      "knowledgeable is at index 26782\n",
      "Saved the embedding for knowledgeable.\n",
      "kosher is at index 36930\n",
      "Saved the embedding for kosher.\n",
      "lackadaisical is at index 1762\n",
      "Saved the embedding for lackadaisical.\n",
      "lackluster is at index 28369\n",
      "Saved the embedding for lackluster.\n",
      "laconic is at index 784\n",
      "Saved the embedding for laconic.\n",
      "lambaste is at index 17988\n",
      "Saved the embedding for lambaste.\n",
      "lamentable is at index 25532\n",
      "Saved the embedding for lamentable.\n",
      "lamenting is at index 25532\n",
      "Saved the embedding for lamenting.\n",
      "lascivious is at index 784\n",
      "Saved the embedding for lascivious.\n",
      "laugh is at index 7923\n",
      "Saved the embedding for laugh.\n",
      "laughing is at index 11339\n",
      "Saved the embedding for laughing.\n",
      "laughter is at index 16805\n",
      "Saved the embedding for laughter.\n",
      "lazy is at index 22414\n",
      "Saved the embedding for lazy.\n",
      "leaving is at index 1618\n",
      "Saved the embedding for leaving.\n",
      "lecherous is at index 2084\n",
      "Saved the embedding for lecherous.\n",
      "lecturing is at index 25673\n",
      "Saved the embedding for lecturing.\n",
      "leering is at index 2084\n",
      "Saved the embedding for leering.\n",
      "leery is at index 2084\n",
      "Saved the embedding for leery.\n",
      "letdown is at index 905\n",
      "Saved the embedding for letdown.\n",
      "lethargic is at index 35370\n",
      "Saved the embedding for lethargic.\n",
      "levelheaded is at index 672\n",
      "Saved the embedding for levelheaded.\n",
      "lewd is at index 31942\n",
      "Saved the embedding for lewd.\n",
      "libidinous is at index 21748\n",
      "Saved the embedding for libidinous.\n",
      "lifeless is at index 37019\n",
      "Saved the embedding for lifeless.\n",
      "lighthearted is at index 1109\n",
      "Saved the embedding for lighthearted.\n",
      "lipped is at index 784\n",
      "Saved the embedding for lipped.\n",
      "listening is at index 6288\n",
      "Saved the embedding for listening.\n",
      "listless is at index 889\n",
      "Saved the embedding for listless.\n",
      "lively is at index 20902\n",
      "Saved the embedding for lively.\n",
      "livid is at index 784\n",
      "Saved the embedding for livid.\n",
      "loaded is at index 7973\n",
      "Saved the embedding for loaded.\n",
      "loath is at index 4600\n",
      "Saved the embedding for loath.\n",
      "loathe is at index 4600\n",
      "Saved the embedding for loathe.\n",
      "loathing is at index 4600\n",
      "Saved the embedding for loathing.\n",
      "loathsome is at index 4600\n",
      "Saved the embedding for loathsome.\n",
      "locked is at index 5930\n",
      "Saved the embedding for locked.\n",
      "loneliness is at index 27942\n",
      "Saved the embedding for loneliness.\n",
      "lonely is at index 20100\n",
      "Saved the embedding for lonely.\n",
      "longing is at index 36171\n",
      "Saved the embedding for longing.\n",
      "looking is at index 546\n",
      "Saved the embedding for looking.\n",
      "loony is at index 4600\n",
      "Saved the embedding for loony.\n",
      "loss is at index 872\n",
      "Saved the embedding for loss.\n",
      "lost is at index 685\n",
      "Saved the embedding for lost.\n",
      "loud is at index 7337\n",
      "Saved the embedding for loud.\n",
      "lousy is at index 38909\n",
      "Saved the embedding for lousy.\n",
      "love is at index 657\n",
      "Saved the embedding for love.\n",
      "loving is at index 8520\n",
      "Saved the embedding for loving.\n",
      "lowliness is at index 614\n",
      "Saved the embedding for lowliness.\n",
      "lurid is at index 30461\n",
      "Saved the embedding for lurid.\n",
      "lustful is at index 30864\n",
      "Saved the embedding for lustful.\n",
      "lusting is at index 30864\n",
      "Saved the embedding for lusting.\n",
      "lusty is at index 30864\n",
      "Saved the embedding for lusty.\n",
      "lying is at index 6480\n",
      "Saved the embedding for lying.\n",
      "mad is at index 7758\n",
      "Saved the embedding for mad.\n",
      "maddened is at index 475\n",
      "Saved the embedding for maddened.\n",
      "madness is at index 24714\n",
      "Saved the embedding for madness.\n",
      "malcontent is at index 8196\n",
      "Saved the embedding for malcontent.\n",
      "maleficent is at index 8196\n",
      "Saved the embedding for maleficent.\n",
      "malevolent is at index 2943\n",
      "Saved the embedding for malevolent.\n",
      "malice is at index 39625\n",
      "Saved the embedding for malice.\n",
      "malicious is at index 15237\n",
      "Saved the embedding for malicious.\n",
      "malignant is at index 8196\n",
      "Saved the embedding for malignant.\n",
      "maniacal is at index 41288\n",
      "Saved the embedding for maniacal.\n",
      "manipulative is at index 39802\n",
      "Saved the embedding for manipulative.\n",
      "marveled is at index 25591\n",
      "Saved the embedding for marveled.\n",
      "master is at index 4710\n",
      "Saved the embedding for master.\n",
      "mean is at index 1266\n",
      "Saved the embedding for mean.\n",
      "meaningful is at index 6667\n",
      "Saved the embedding for meaningful.\n",
      "meditative is at index 5679\n",
      "Saved the embedding for meditative.\n",
      "meek is at index 162\n",
      "Saved the embedding for meek.\n",
      "melancholic is at index 45565\n",
      "Saved the embedding for melancholic.\n",
      "melancholy is at index 40602\n",
      "Saved the embedding for melancholy.\n",
      "mellow is at index 34384\n",
      "Saved the embedding for mellow.\n",
      "menace is at index 24213\n",
      "Saved the embedding for menace.\n",
      "menacing is at index 32002\n",
      "Saved the embedding for menacing.\n",
      "mental is at index 2536\n",
      "Saved the embedding for mental.\n",
      "merrily is at index 9374\n",
      "Saved the embedding for merrily.\n",
      "merry is at index 35814\n",
      "Saved the embedding for merry.\n",
      "mesmerized is at index 31294\n",
      "Saved the embedding for mesmerized.\n",
      "miffed is at index 475\n",
      "Saved the embedding for miffed.\n",
      "mild is at index 10439\n",
      "Saved the embedding for mild.\n",
      "mincing is at index 5251\n",
      "Saved the embedding for mincing.\n",
      "mindful is at index 20807\n",
      "Saved the embedding for mindful.\n",
      "mindless is at index 41406\n",
      "Saved the embedding for mindless.\n",
      "mirrored is at index 31349\n",
      "Saved the embedding for mirrored.\n",
      "mirth is at index 475\n",
      "Saved the embedding for mirth.\n",
      "mirthful is at index 475\n",
      "Saved the embedding for mirthful.\n",
      "misanthropic is at index 3834\n",
      "Saved the embedding for misanthropic.\n",
      "mischief is at index 26245\n",
      "Saved the embedding for mischief.\n",
      "mischievous is at index 3834\n",
      "Saved the embedding for mischievous.\n",
      "mischievousness is at index 3834\n",
      "Saved the embedding for mischievousness.\n",
      "miserable is at index 20161\n",
      "Saved the embedding for miserable.\n",
      "misery is at index 23110\n",
      "Saved the embedding for misery.\n",
      "misgiving is at index 3834\n",
      "Saved the embedding for misgiving.\n",
      "mislead is at index 34747\n",
      "Saved the embedding for mislead.\n",
      "mistrust is at index 34873\n",
      "Saved the embedding for mistrust.\n",
      "mistrustful is at index 34873\n",
      "Saved the embedding for mistrustful.\n",
      "mistrusting is at index 34873\n",
      "Saved the embedding for mistrusting.\n",
      "misunderstood is at index 32085\n",
      "Saved the embedding for misunderstood.\n",
      "mockery is at index 34641\n",
      "Saved the embedding for mockery.\n",
      "mocking is at index 27813\n",
      "Saved the embedding for mocking.\n",
      "mockingly is at index 16177\n",
      "Saved the embedding for mockingly.\n",
      "modest is at index 6473\n",
      "Saved the embedding for modest.\n",
      "monotone is at index 6154\n",
      "Saved the embedding for monotone.\n",
      "monster is at index 13317\n",
      "Saved the embedding for monster.\n",
      "moody is at index 6711\n",
      "Saved the embedding for moody.\n",
      "mopey is at index 475\n",
      "Saved the embedding for mopey.\n",
      "morose is at index 14628\n",
      "Saved the embedding for morose.\n",
      "mortified is at index 18631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for mortified.\n",
      "motivated is at index 7958\n",
      "Saved the embedding for motivated.\n",
      "mournful is at index 15213\n",
      "Saved the embedding for mournful.\n",
      "mournfulness is at index 15213\n",
      "Saved the embedding for mournfulness.\n",
      "mourning is at index 19293\n",
      "Saved the embedding for mourning.\n",
      "mouthed is at index 475\n",
      "Saved the embedding for mouthed.\n",
      "moved is at index 1410\n",
      "Saved the embedding for moved.\n",
      "muddled is at index 475\n",
      "Saved the embedding for muddled.\n",
      "mum is at index 8562\n",
      "Saved the embedding for mum.\n",
      "murderous is at index 32883\n",
      "Saved the embedding for murderous.\n",
      "musical is at index 4388\n",
      "Saved the embedding for musical.\n",
      "musing is at index 11721\n",
      "Saved the embedding for musing.\n",
      "muster is at index 27665\n",
      "Saved the embedding for muster.\n",
      "mute is at index 33758\n",
      "Saved the embedding for mute.\n",
      "muted is at index 21677\n",
      "Saved the embedding for muted.\n",
      "muttering is at index 16119\n",
      "Saved the embedding for muttering.\n",
      "mysterious is at index 12754\n",
      "Saved the embedding for mysterious.\n",
      "mystical is at index 39795\n",
      "Saved the embedding for mystical.\n",
      "mystified is at index 37763\n",
      "Saved the embedding for mystified.\n",
      "naive is at index 25672\n",
      "Saved the embedding for naive.\n",
      "napping is at index 295\n",
      "Saved the embedding for napping.\n",
      "narrow is at index 6787\n",
      "Saved the embedding for narrow.\n",
      "nasty is at index 15455\n",
      "Saved the embedding for nasty.\n",
      "natural is at index 1632\n",
      "Saved the embedding for natural.\n",
      "natured is at index 23577\n",
      "Saved the embedding for natured.\n",
      "naughty is at index 38384\n",
      "Saved the embedding for naughty.\n",
      "nausea is at index 27214\n",
      "Saved the embedding for nausea.\n",
      "nauseated is at index 39117\n",
      "Saved the embedding for nauseated.\n",
      "nauseous is at index 39117\n",
      "Saved the embedding for nauseous.\n",
      "needy is at index 28166\n",
      "Saved the embedding for needy.\n",
      "nefarious is at index 33952\n",
      "Saved the embedding for nefarious.\n",
      "negating is at index 15183\n",
      "Saved the embedding for negating.\n",
      "negative is at index 2430\n",
      "Saved the embedding for negative.\n",
      "negativity is at index 30269\n",
      "Saved the embedding for negativity.\n",
      "neglected is at index 20428\n",
      "Saved the embedding for neglected.\n",
      "nerdy is at index 38286\n",
      "Saved the embedding for nerdy.\n",
      "nerved is at index 295\n",
      "Saved the embedding for nerved.\n",
      "nerves is at index 17358\n",
      "Saved the embedding for nerves.\n",
      "nervous is at index 7464\n",
      "Saved the embedding for nervous.\n",
      "nervously is at index 40968\n",
      "Saved the embedding for nervously.\n",
      "nervousness is at index 7464\n",
      "Saved the embedding for nervousness.\n",
      "nescient is at index 295\n",
      "Saved the embedding for nescient.\n",
      "nettled is at index 1161\n",
      "Saved the embedding for nettled.\n",
      "neutral is at index 7974\n",
      "Saved the embedding for neutral.\n",
      "neutrality is at index 18755\n",
      "Saved the embedding for neutrality.\n",
      "nice is at index 2579\n",
      "Saved the embedding for nice.\n",
      "noisy is at index 28269\n",
      "Saved the embedding for noisy.\n",
      "nonbelief is at index 786\n",
      "Saved the embedding for nonbelief.\n",
      "nonchalance is at index 786\n",
      "Saved the embedding for nonchalance.\n",
      "nonchalant is at index 786\n",
      "Saved the embedding for nonchalant.\n",
      "noncommittal is at index 786\n",
      "Saved the embedding for noncommittal.\n",
      "noncompliant is at index 786\n",
      "Saved the embedding for noncompliant.\n",
      "nonplussed is at index 786\n",
      "Saved the embedding for nonplussed.\n",
      "nonsensical is at index 42475\n",
      "Saved the embedding for nonsensical.\n",
      "normal is at index 2340\n",
      "Saved the embedding for normal.\n",
      "nosey is at index 8658\n",
      "Saved the embedding for nosey.\n",
      "nostalgic is at index 28055\n",
      "Saved the embedding for nostalgic.\n",
      "nosy is at index 13736\n",
      "Saved the embedding for nosy.\n",
      "numb is at index 31086\n",
      "Saved the embedding for numb.\n",
      "obedient is at index 44729\n",
      "Saved the embedding for obedient.\n",
      "objecting is at index 7626\n",
      "Saved the embedding for objecting.\n",
      "objection is at index 24763\n",
      "Saved the embedding for objection.\n",
      "objective is at index 4554\n",
      "Saved the embedding for objective.\n",
      "obliged is at index 23964\n",
      "Saved the embedding for obliged.\n",
      "obliging is at index 23762\n",
      "Saved the embedding for obliging.\n",
      "oblivious is at index 35606\n",
      "Saved the embedding for oblivious.\n",
      "observant is at index 20717\n",
      "Saved the embedding for observant.\n",
      "observing is at index 21981\n",
      "Saved the embedding for observing.\n",
      "obsessed is at index 17593\n",
      "Saved the embedding for obsessed.\n",
      "obstinate is at index 30896\n",
      "Saved the embedding for obstinate.\n",
      "occupied is at index 9533\n",
      "Saved the embedding for occupied.\n",
      "odd is at index 8372\n",
      "Saved the embedding for odd.\n",
      "odious is at index 7452\n",
      "Saved the embedding for odious.\n",
      "off is at index 160\n",
      "Saved the embedding for off.\n",
      "offended is at index 22169\n",
      "Saved the embedding for offended.\n",
      "offensive is at index 2555\n",
      "Saved the embedding for offensive.\n",
      "ogling is at index 1021\n",
      "Saved the embedding for ogling.\n",
      "okay is at index 8578\n",
      "Saved the embedding for okay.\n",
      "on is at index 15\n",
      "Saved the embedding for on.\n",
      "open is at index 490\n",
      "Saved the embedding for open.\n",
      "openness is at index 23163\n",
      "Saved the embedding for openness.\n",
      "opposed is at index 4340\n",
      "Saved the embedding for opposed.\n",
      "oppositional is at index 39734\n",
      "Saved the embedding for oppositional.\n",
      "oppressed is at index 32881\n",
      "Saved the embedding for oppressed.\n",
      "optimism is at index 9743\n",
      "Saved the embedding for optimism.\n",
      "optimistic is at index 7168\n",
      "Saved the embedding for optimistic.\n",
      "ordering is at index 12926\n",
      "Saved the embedding for ordering.\n",
      "orgasmic is at index 39396\n",
      "Saved the embedding for orgasmic.\n",
      "ornery is at index 50\n",
      "Saved the embedding for ornery.\n",
      "ouch is at index 1021\n",
      "Saved the embedding for ouch.\n",
      "out is at index 66\n",
      "Saved the embedding for out.\n",
      "outburst is at index 28999\n",
      "Saved the embedding for outburst.\n",
      "outcry is at index 19900\n",
      "Saved the embedding for outcry.\n",
      "outed is at index 66\n",
      "Saved the embedding for outed.\n",
      "outlandish is at index 35785\n",
      "Saved the embedding for outlandish.\n",
      "outrage is at index 10618\n",
      "Saved the embedding for outrage.\n",
      "outraged is at index 22339\n",
      "Saved the embedding for outraged.\n",
      "outspoken is at index 16120\n",
      "Saved the embedding for outspoken.\n",
      "overbearing is at index 81\n",
      "Saved the embedding for overbearing.\n",
      "overexcited is at index 39919\n",
      "Saved the embedding for overexcited.\n",
      "overjoyed is at index 81\n",
      "Saved the embedding for overjoyed.\n",
      "overshadowed is at index 22140\n",
      "Saved the embedding for overshadowed.\n",
      "overstrung is at index 81\n",
      "Saved the embedding for overstrung.\n",
      "overwhelmed is at index 13203\n",
      "Saved the embedding for overwhelmed.\n",
      "overworked is at index 81\n",
      "Saved the embedding for overworked.\n",
      "overwrought is at index 42674\n",
      "Saved the embedding for overwrought.\n",
      "pain is at index 2400\n",
      "Saved the embedding for pain.\n",
      "pained is at index 181\n",
      "Saved the embedding for pained.\n",
      "painful is at index 8661\n",
      "Saved the embedding for painful.\n",
      "painfully is at index 32020\n",
      "Saved the embedding for painfully.\n",
      "panic is at index 9810\n",
      "Saved the embedding for panic.\n",
      "panicked is at index 28604\n",
      "Saved the embedding for panicked.\n",
      "panicky is at index 5730\n",
      "Saved the embedding for panicky.\n",
      "paralyzed is at index 28582\n",
      "Saved the embedding for paralyzed.\n",
      "paranoid is at index 33554\n",
      "Saved the embedding for paranoid.\n",
      "passionate is at index 8840\n",
      "Saved the embedding for passionate.\n",
      "passive is at index 18718\n",
      "Saved the embedding for passive.\n",
      "patience is at index 11383\n",
      "Saved the embedding for patience.\n",
      "patient is at index 3186\n",
      "Saved the embedding for patient.\n",
      "patronizing is at index 18528\n",
      "Saved the embedding for patronizing.\n",
      "pause is at index 13787\n",
      "Saved the embedding for pause.\n",
      "pausing is at index 6044\n",
      "Saved the embedding for pausing.\n",
      "peaceful is at index 7053\n",
      "Saved the embedding for peaceful.\n",
      "peculiar is at index 28178\n",
      "Saved the embedding for peculiar.\n",
      "peering is at index 3723\n",
      "Saved the embedding for peering.\n",
      "peeved is at index 32734\n",
      "Saved the embedding for peeved.\n",
      "peevish is at index 3723\n",
      "Saved the embedding for peevish.\n",
      "pensive is at index 181\n",
      "Saved the embedding for pensive.\n",
      "peppy is at index 3723\n",
      "Saved the embedding for peppy.\n",
      "perceptive is at index 228\n",
      "Saved the embedding for perceptive.\n",
      "perfidious is at index 32168\n",
      "Saved the embedding for perfidious.\n",
      "perky is at index 228\n",
      "Saved the embedding for perky.\n",
      "perplexed is at index 33708\n",
      "Saved the embedding for perplexed.\n",
      "perplexing is at index 33708\n",
      "Saved the embedding for perplexing.\n",
      "persistent is at index 13109\n",
      "Saved the embedding for persistent.\n",
      "personable is at index 621\n",
      "Saved the embedding for personable.\n",
      "perturbed is at index 32819\n",
      "Saved the embedding for perturbed.\n",
      "perverse is at index 41271\n",
      "Saved the embedding for perverse.\n",
      "pesky is at index 38432\n",
      "Saved the embedding for pesky.\n",
      "pessimism is at index 36494\n",
      "Saved the embedding for pessimism.\n",
      "pessimistic is at index 32415\n",
      "Saved the embedding for pessimistic.\n",
      "pestered is at index 19024\n",
      "Saved the embedding for pestered.\n",
      "petitioning is at index 5265\n",
      "Saved the embedding for petitioning.\n",
      "petrified is at index 4716\n",
      "Saved the embedding for petrified.\n",
      "petty is at index 25070\n",
      "Saved the embedding for petty.\n",
      "petulant is at index 4716\n",
      "Saved the embedding for petulant.\n",
      "picked is at index 2738\n",
      "Saved the embedding for picked.\n",
      "piercing is at index 38105\n",
      "Saved the embedding for piercing.\n",
      "pinched is at index 7756\n",
      "Saved the embedding for pinched.\n",
      "pious is at index 44843\n",
      "Saved the embedding for pious.\n",
      "piqued is at index 181\n",
      "Saved the embedding for piqued.\n",
      "pissed is at index 34449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for pissed.\n",
      "pitiable is at index 8516\n",
      "Saved the embedding for pitiable.\n",
      "pitiful is at index 8516\n",
      "Saved the embedding for pitiful.\n",
      "pity is at index 31373\n",
      "Saved the embedding for pity.\n",
      "pitying is at index 31373\n",
      "Saved the embedding for pitying.\n",
      "placated is at index 15155\n",
      "Saved the embedding for placated.\n",
      "placation is at index 15155\n",
      "Saved the embedding for placation.\n",
      "placid is at index 15155\n",
      "Saved the embedding for placid.\n",
      "plain is at index 10798\n",
      "Saved the embedding for plain.\n",
      "plaintive is at index 46560\n",
      "Saved the embedding for plaintive.\n",
      "planning is at index 1884\n",
      "Saved the embedding for planning.\n",
      "playful is at index 23317\n",
      "Saved the embedding for playful.\n",
      "playfully is at index 310\n",
      "Saved the embedding for playfully.\n",
      "pleading is at index 17532\n",
      "Saved the embedding for pleading.\n",
      "pleasant is at index 16219\n",
      "Saved the embedding for pleasant.\n",
      "pleased is at index 4343\n",
      "Saved the embedding for pleased.\n",
      "pleasing is at index 25234\n",
      "Saved the embedding for pleasing.\n",
      "pleasurable is at index 19518\n",
      "Saved the embedding for pleasurable.\n",
      "pleasure is at index 10483\n",
      "Saved the embedding for pleasure.\n",
      "pleasured is at index 19518\n",
      "Saved the embedding for pleasured.\n",
      "pliant is at index 2968\n",
      "Saved the embedding for pliant.\n",
      "plotting is at index 22849\n",
      "Saved the embedding for plotting.\n",
      "poignant is at index 27274\n",
      "Saved the embedding for poignant.\n",
      "pointed is at index 3273\n",
      "Saved the embedding for pointed.\n",
      "poised is at index 10137\n",
      "Saved the embedding for poised.\n",
      "polite is at index 24908\n",
      "Saved the embedding for polite.\n",
      "pompous is at index 34415\n",
      "Saved the embedding for pompous.\n",
      "ponder is at index 31930\n",
      "Saved the embedding for ponder.\n",
      "pondering is at index 13362\n",
      "Saved the embedding for pondering.\n",
      "pooping is at index 4202\n",
      "Saved the embedding for pooping.\n",
      "pop is at index 3495\n",
      "Saved the embedding for pop.\n",
      "posing is at index 12681\n",
      "Saved the embedding for posing.\n",
      "positive is at index 1313\n",
      "Saved the embedding for positive.\n",
      "positivity is at index 8593\n",
      "Saved the embedding for positivity.\n",
      "possibly is at index 3544\n",
      "Saved the embedding for possibly.\n",
      "pout is at index 181\n",
      "Saved the embedding for pout.\n",
      "pouting is at index 181\n",
      "Saved the embedding for pouting.\n",
      "pouty is at index 181\n",
      "Saved the embedding for pouty.\n",
      "powerful is at index 2247\n",
      "Saved the embedding for powerful.\n",
      "powerless is at index 33128\n",
      "Saved the embedding for powerless.\n",
      "pranking is at index 3349\n",
      "Saved the embedding for pranking.\n",
      "precarious is at index 27180\n",
      "Saved the embedding for precarious.\n",
      "predatory is at index 29216\n",
      "Saved the embedding for predatory.\n",
      "prejudiced is at index 34286\n",
      "Saved the embedding for prejudiced.\n",
      "preoccupied is at index 1198\n",
      "Saved the embedding for preoccupied.\n",
      "prepared is at index 2460\n",
      "Saved the embedding for prepared.\n",
      "preparing is at index 4568\n",
      "Saved the embedding for preparing.\n",
      "pretending is at index 23748\n",
      "Saved the embedding for pretending.\n",
      "pretentious is at index 11857\n",
      "Saved the embedding for pretentious.\n",
      "prideful is at index 7040\n",
      "Saved the embedding for prideful.\n",
      "priggish is at index 3349\n",
      "Saved the embedding for priggish.\n",
      "primed is at index 32575\n",
      "Saved the embedding for primed.\n",
      "private is at index 940\n",
      "Saved the embedding for private.\n",
      "processing is at index 5774\n",
      "Saved the embedding for processing.\n",
      "propositioning is at index 16104\n",
      "Saved the embedding for propositioning.\n",
      "proud is at index 2602\n",
      "Saved the embedding for proud.\n",
      "provocative is at index 21051\n",
      "Saved the embedding for provocative.\n",
      "provoke is at index 28184\n",
      "Saved the embedding for provoke.\n",
      "provoked is at index 24972\n",
      "Saved the embedding for provoked.\n",
      "provoking is at index 35359\n",
      "Saved the embedding for provoking.\n",
      "prying is at index 181\n",
      "Saved the embedding for prying.\n",
      "psycho is at index 37338\n",
      "Saved the embedding for psycho.\n",
      "psychotic is at index 41559\n",
      "Saved the embedding for psychotic.\n",
      "puckish is at index 9258\n",
      "Saved the embedding for puckish.\n",
      "puerile is at index 181\n",
      "Saved the embedding for puerile.\n",
      "pugnacious is at index 181\n",
      "Saved the embedding for pugnacious.\n",
      "punished is at index 14459\n",
      "Saved the embedding for punished.\n",
      "punishing is at index 23477\n",
      "Saved the embedding for punishing.\n",
      "punitive is at index 21987\n",
      "Saved the embedding for punitive.\n",
      "punk is at index 19742\n",
      "Saved the embedding for punk.\n",
      "puppyish is at index 20830\n",
      "Saved the embedding for puppyish.\n",
      "purposeful is at index 3508\n",
      "Saved the embedding for purposeful.\n",
      "pursed is at index 26934\n",
      "Saved the embedding for pursed.\n",
      "put is at index 342\n",
      "Saved the embedding for put.\n",
      "putting is at index 2057\n",
      "Saved the embedding for putting.\n",
      "puzzled is at index 36742\n",
      "Saved the embedding for puzzled.\n",
      "puzzlement is at index 47037\n",
      "Saved the embedding for puzzlement.\n",
      "qualms is at index 22043\n",
      "Saved the embedding for qualms.\n",
      "quarrelsome is at index 39486\n",
      "Saved the embedding for quarrelsome.\n",
      "queasy is at index 1192\n",
      "Saved the embedding for queasy.\n",
      "quenched is at index 2677\n",
      "Saved the embedding for quenched.\n",
      "questionable is at index 12474\n",
      "Saved the embedding for questionable.\n",
      "questioning is at index 8026\n",
      "Saved the embedding for questioning.\n",
      "questioningly is at index 864\n",
      "Saved the embedding for questioningly.\n",
      "quiet is at index 5128\n",
      "Saved the embedding for quiet.\n",
      "quietness is at index 5128\n",
      "Saved the embedding for quietness.\n",
      "quilt is at index 2677\n",
      "Saved the embedding for quilt.\n",
      "quirky is at index 22364\n",
      "Saved the embedding for quirky.\n",
      "quizzical is at index 29316\n",
      "Saved the embedding for quizzical.\n",
      "rabid is at index 39660\n",
      "Saved the embedding for rabid.\n",
      "racked is at index 20208\n",
      "Saved the embedding for racked.\n",
      "radiant is at index 35787\n",
      "Saved the embedding for radiant.\n",
      "rage is at index 14706\n",
      "Saved the embedding for rage.\n",
      "raged is at index 31927\n",
      "Saved the embedding for raged.\n",
      "ragged is at index 910\n",
      "Saved the embedding for ragged.\n",
      "raging is at index 23333\n",
      "Saved the embedding for raging.\n",
      "rancorous is at index 21560\n",
      "Saved the embedding for rancorous.\n",
      "randy is at index 910\n",
      "Saved the embedding for randy.\n",
      "rapt is at index 34524\n",
      "Saved the embedding for rapt.\n",
      "rattled is at index 21602\n",
      "Saved the embedding for rattled.\n",
      "raving is at index 910\n",
      "Saved the embedding for raving.\n",
      "reactive is at index 34729\n",
      "Saved the embedding for reactive.\n",
      "ready is at index 1227\n",
      "Saved the embedding for ready.\n",
      "realization is at index 24179\n",
      "Saved the embedding for realization.\n",
      "reassured is at index 29336\n",
      "Saved the embedding for reassured.\n",
      "rebellious is at index 38017\n",
      "Saved the embedding for rebellious.\n",
      "rebuke is at index 28155\n",
      "Saved the embedding for rebuke.\n",
      "recalling is at index 20239\n",
      "Saved the embedding for recalling.\n",
      "receptive is at index 33052\n",
      "Saved the embedding for receptive.\n",
      "reckless is at index 13508\n",
      "Saved the embedding for reckless.\n",
      "recoil is at index 44983\n",
      "Saved the embedding for recoil.\n",
      "recoiling is at index 3872\n",
      "Saved the embedding for recoiling.\n",
      "reflecting is at index 10811\n",
      "Saved the embedding for reflecting.\n",
      "reflection is at index 12456\n",
      "Saved the embedding for reflection.\n",
      "reflective is at index 22213\n",
      "Saved the embedding for reflective.\n",
      "refulgent is at index 769\n",
      "Saved the embedding for refulgent.\n",
      "refusing is at index 10520\n",
      "Saved the embedding for refusing.\n",
      "regret is at index 9917\n",
      "Saved the embedding for regret.\n",
      "regretful is at index 9917\n",
      "Saved the embedding for regretful.\n",
      "rejected is at index 3946\n",
      "Saved the embedding for rejected.\n",
      "rejecting is at index 19695\n",
      "Saved the embedding for rejecting.\n",
      "rejection is at index 16117\n",
      "Saved the embedding for rejection.\n",
      "rejoicing is at index 24586\n",
      "Saved the embedding for rejoicing.\n",
      "relaxation is at index 26545\n",
      "Saved the embedding for relaxation.\n",
      "relaxed is at index 11956\n",
      "Saved the embedding for relaxed.\n",
      "relentless is at index 16476\n",
      "Saved the embedding for relentless.\n",
      "relief is at index 3500\n",
      "Saved the embedding for relief.\n",
      "relieved is at index 15126\n",
      "Saved the embedding for relieved.\n",
      "relived is at index 6258\n",
      "Saved the embedding for relived.\n",
      "reluctant is at index 11923\n",
      "Saved the embedding for reluctant.\n",
      "reluctantly is at index 33146\n",
      "Saved the embedding for reluctantly.\n",
      "remorse is at index 23312\n",
      "Saved the embedding for remorse.\n",
      "remorseful is at index 23312\n",
      "Saved the embedding for remorseful.\n",
      "repelled is at index 25633\n",
      "Saved the embedding for repelled.\n",
      "repressed is at index 2851\n",
      "Saved the embedding for repressed.\n",
      "reproach is at index 2851\n",
      "Saved the embedding for reproach.\n",
      "reproachful is at index 2851\n",
      "Saved the embedding for reproachful.\n",
      "repugnance is at index 2851\n",
      "Saved the embedding for repugnance.\n",
      "repugnant is at index 2851\n",
      "Saved the embedding for repugnant.\n",
      "repulsed is at index 2851\n",
      "Saved the embedding for repulsed.\n",
      "repulsion is at index 2851\n",
      "Saved the embedding for repulsion.\n",
      "resent is at index 31379\n",
      "Saved the embedding for resent.\n",
      "resentful is at index 31379\n",
      "Saved the embedding for resentful.\n",
      "resenting is at index 31379\n",
      "Saved the embedding for resenting.\n",
      "resentment is at index 27111\n",
      "Saved the embedding for resentment.\n",
      "reserved is at index 1875\n",
      "Saved the embedding for reserved.\n",
      "resignation is at index 6985\n",
      "Saved the embedding for resignation.\n",
      "resigned is at index 6490\n",
      "Saved the embedding for resigned.\n",
      "resilience is at index 13790\n",
      "Saved the embedding for resilience.\n",
      "resistance is at index 5910\n",
      "Saved the embedding for resistance.\n",
      "resistant is at index 19152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for resistant.\n",
      "resistent is at index 11942\n",
      "Saved the embedding for resistent.\n",
      "resisting is at index 18907\n",
      "Saved the embedding for resisting.\n",
      "resolute is at index 5032\n",
      "Saved the embedding for resolute.\n",
      "resolved is at index 8179\n",
      "Saved the embedding for resolved.\n",
      "responsive is at index 20666\n",
      "Saved the embedding for responsive.\n",
      "restful is at index 1079\n",
      "Saved the embedding for restful.\n",
      "resting is at index 18403\n",
      "Saved the embedding for resting.\n",
      "restless is at index 36844\n",
      "Saved the embedding for restless.\n",
      "restlessness is at index 1079\n",
      "Saved the embedding for restlessness.\n",
      "restrained is at index 25063\n",
      "Saved the embedding for restrained.\n",
      "restraint is at index 20219\n",
      "Saved the embedding for restraint.\n",
      "retaliating is at index 18570\n",
      "Saved the embedding for retaliating.\n",
      "retaliatory is at index 18570\n",
      "Saved the embedding for retaliatory.\n",
      "rethinking is at index 769\n",
      "Saved the embedding for rethinking.\n",
      "reticence is at index 5494\n",
      "Saved the embedding for reticence.\n",
      "reticent is at index 5494\n",
      "Saved the embedding for reticent.\n",
      "revengeful is at index 13543\n",
      "Saved the embedding for revengeful.\n",
      "reverent is at index 26911\n",
      "Saved the embedding for reverent.\n",
      "revolted is at index 34633\n",
      "Saved the embedding for revolted.\n",
      "revulsion is at index 6910\n",
      "Saved the embedding for revulsion.\n",
      "righteous is at index 37909\n",
      "Saved the embedding for righteous.\n",
      "rigid is at index 24577\n",
      "Saved the embedding for rigid.\n",
      "riled is at index 910\n",
      "Saved the embedding for riled.\n",
      "riotous is at index 13069\n",
      "Saved the embedding for riotous.\n",
      "riveted is at index 32886\n",
      "Saved the embedding for riveted.\n",
      "roar is at index 31733\n",
      "Saved the embedding for roar.\n",
      "roguish is at index 4533\n",
      "Saved the embedding for roguish.\n",
      "roiled is at index 4533\n",
      "Saved the embedding for roiled.\n",
      "rough is at index 6744\n",
      "Saved the embedding for rough.\n",
      "roused is at index 910\n",
      "Saved the embedding for roused.\n",
      "rude is at index 21820\n",
      "Saved the embedding for rude.\n",
      "rueful is at index 910\n",
      "Saved the embedding for rueful.\n",
      "ruffled is at index 910\n",
      "Saved the embedding for ruffled.\n",
      "ruminating is at index 11122\n",
      "Saved the embedding for ruminating.\n",
      "rustled is at index 18309\n",
      "Saved the embedding for rustled.\n",
      "ruthless is at index 25597\n",
      "Saved the embedding for ruthless.\n",
      "sad is at index 5074\n",
      "Saved the embedding for sad.\n",
      "sadden is at index 23330\n",
      "Saved the embedding for sadden.\n",
      "saddened is at index 19934\n",
      "Saved the embedding for saddened.\n",
      "sadistic is at index 5074\n",
      "Saved the embedding for sadistic.\n",
      "sadness is at index 17437\n",
      "Saved the embedding for sadness.\n",
      "salacious is at index 6641\n",
      "Saved the embedding for salacious.\n",
      "salivating is at index 6641\n",
      "Saved the embedding for salivating.\n",
      "sanctimonious is at index 27600\n",
      "Saved the embedding for sanctimonious.\n",
      "sane is at index 37091\n",
      "Saved the embedding for sane.\n",
      "sanguine is at index 579\n",
      "Saved the embedding for sanguine.\n",
      "sappy is at index 2241\n",
      "Saved the embedding for sappy.\n",
      "sarcasm is at index 38522\n",
      "Saved the embedding for sarcasm.\n",
      "sarcastic is at index 39580\n",
      "Saved the embedding for sarcastic.\n",
      "sardonic is at index 579\n",
      "Saved the embedding for sardonic.\n",
      "sassy is at index 579\n",
      "Saved the embedding for sassy.\n",
      "sated is at index 579\n",
      "Saved the embedding for sated.\n",
      "satiated is at index 4005\n",
      "Saved the embedding for satiated.\n",
      "satirical is at index 33937\n",
      "Saved the embedding for satirical.\n",
      "satisfaction is at index 11658\n",
      "Saved the embedding for satisfaction.\n",
      "satisfied is at index 10028\n",
      "Saved the embedding for satisfied.\n",
      "satisfy is at index 15332\n",
      "Saved the embedding for satisfy.\n",
      "saturnine is at index 4005\n",
      "Saved the embedding for saturnine.\n",
      "saucy is at index 2241\n",
      "Saved the embedding for saucy.\n",
      "savage is at index 32264\n",
      "Saved the embedding for savage.\n",
      "scandalized is at index 4220\n",
      "Saved the embedding for scandalized.\n",
      "scare is at index 13207\n",
      "Saved the embedding for scare.\n",
      "scared is at index 8265\n",
      "Saved the embedding for scared.\n",
      "scary is at index 10222\n",
      "Saved the embedding for scary.\n",
      "scattered is at index 12827\n",
      "Saved the embedding for scattered.\n",
      "schadenfreude is at index 8447\n",
      "Saved the embedding for schadenfreude.\n",
      "scheming is at index 30315\n",
      "Saved the embedding for scheming.\n",
      "scoffer is at index 34564\n",
      "Saved the embedding for scoffer.\n",
      "scoffing is at index 34564\n",
      "Saved the embedding for scoffing.\n",
      "scorn is at index 38430\n",
      "Saved the embedding for scorn.\n",
      "scorned is at index 2850\n",
      "Saved the embedding for scorned.\n",
      "scornful is at index 38430\n",
      "Saved the embedding for scornful.\n",
      "scowl is at index 2850\n",
      "Saved the embedding for scowl.\n",
      "scowling is at index 2850\n",
      "Saved the embedding for scowling.\n",
      "scream is at index 22093\n",
      "Saved the embedding for scream.\n",
      "screaming is at index 11347\n",
      "Saved the embedding for screaming.\n",
      "scrutinizing is at index 18470\n",
      "Saved the embedding for scrutinizing.\n",
      "sealed is at index 10497\n",
      "Saved the embedding for sealed.\n",
      "searching is at index 6062\n",
      "Saved the embedding for searching.\n",
      "secretive is at index 27174\n",
      "Saved the embedding for secretive.\n",
      "secretively is at index 3556\n",
      "Saved the embedding for secretively.\n",
      "secure is at index 2823\n",
      "Saved the embedding for secure.\n",
      "sedate is at index 10195\n",
      "Saved the embedding for sedate.\n",
      "seduction is at index 10195\n",
      "Saved the embedding for seduction.\n",
      "seductive is at index 10195\n",
      "Saved the embedding for seductive.\n",
      "seething is at index 842\n",
      "Saved the embedding for seething.\n",
      "self is at index 1403\n",
      "Saved the embedding for self.\n",
      "sensual is at index 18105\n",
      "Saved the embedding for sensual.\n",
      "sentimental is at index 32693\n",
      "Saved the embedding for sentimental.\n",
      "serene is at index 842\n",
      "Saved the embedding for serene.\n",
      "serious is at index 1473\n",
      "Saved the embedding for serious.\n",
      "seriousness is at index 24146\n",
      "Saved the embedding for seriousness.\n",
      "servile is at index 18527\n",
      "Saved the embedding for servile.\n",
      "set is at index 278\n",
      "Saved the embedding for set.\n",
      "severe is at index 3814\n",
      "Saved the embedding for severe.\n",
      "shabby is at index 1481\n",
      "Saved the embedding for shabby.\n",
      "shady is at index 31665\n",
      "Saved the embedding for shady.\n",
      "shaken is at index 17548\n",
      "Saved the embedding for shaken.\n",
      "shaky is at index 22032\n",
      "Saved the embedding for shaky.\n",
      "shame is at index 9208\n",
      "Saved the embedding for shame.\n",
      "shamed is at index 1481\n",
      "Saved the embedding for shamed.\n",
      "shamefaced is at index 9208\n",
      "Saved the embedding for shamefaced.\n",
      "shameful is at index 26722\n",
      "Saved the embedding for shameful.\n",
      "shameless is at index 36778\n",
      "Saved the embedding for shameless.\n",
      "sharp is at index 4406\n",
      "Saved the embedding for sharp.\n",
      "sheepish is at index 14336\n",
      "Saved the embedding for sheepish.\n",
      "sheepishness is at index 14336\n",
      "Saved the embedding for sheepishness.\n",
      "shelled is at index 79\n",
      "Saved the embedding for shelled.\n",
      "shifty is at index 37503\n",
      "Saved the embedding for shifty.\n",
      "shock is at index 4817\n",
      "Saved the embedding for shock.\n",
      "shocked is at index 6649\n",
      "Saved the embedding for shocked.\n",
      "shocking is at index 8777\n",
      "Saved the embedding for shocking.\n",
      "shockingly is at index 36804\n",
      "Saved the embedding for shockingly.\n",
      "shook is at index 14774\n",
      "Saved the embedding for shook.\n",
      "shout is at index 18066\n",
      "Saved the embedding for shout.\n",
      "shouting is at index 14487\n",
      "Saved the embedding for shouting.\n",
      "shrewd is at index 36943\n",
      "Saved the embedding for shrewd.\n",
      "shy is at index 9152\n",
      "Saved the embedding for shy.\n",
      "shyness is at index 9152\n",
      "Saved the embedding for shyness.\n",
      "sick is at index 4736\n",
      "Saved the embedding for sick.\n",
      "sicken is at index 579\n",
      "Saved the embedding for sicken.\n",
      "sickened is at index 4736\n",
      "Saved the embedding for sickened.\n",
      "sigh is at index 27305\n",
      "Saved the embedding for sigh.\n",
      "silenced is at index 30125\n",
      "Saved the embedding for silenced.\n",
      "silent is at index 8454\n",
      "Saved the embedding for silent.\n",
      "silliness is at index 38052\n",
      "Saved the embedding for silliness.\n",
      "silly is at index 15470\n",
      "Saved the embedding for silly.\n",
      "simmering is at index 25726\n",
      "Saved the embedding for simmering.\n",
      "simper is at index 16207\n",
      "Saved the embedding for simper.\n",
      "simpering is at index 16207\n",
      "Saved the embedding for simpering.\n",
      "simple is at index 2007\n",
      "Saved the embedding for simple.\n",
      "simplicity is at index 25342\n",
      "Saved the embedding for simplicity.\n",
      "sincere is at index 19255\n",
      "Saved the embedding for sincere.\n",
      "sinful is at index 44364\n",
      "Saved the embedding for sinful.\n",
      "singing is at index 6970\n",
      "Saved the embedding for singing.\n",
      "sinister is at index 27570\n",
      "Saved the embedding for sinister.\n",
      "sinisterly is at index 27570\n",
      "Saved the embedding for sinisterly.\n",
      "sizing is at index 39328\n",
      "Saved the embedding for sizing.\n",
      "skeptic is at index 42386\n",
      "Saved the embedding for skeptic.\n",
      "skeptical is at index 14992\n",
      "Saved the embedding for skeptical.\n",
      "skeptically is at index 42386\n",
      "Saved the embedding for skeptically.\n",
      "skepticism is at index 22222\n",
      "Saved the embedding for skepticism.\n",
      "sketchy is at index 15923\n",
      "Saved the embedding for sketchy.\n",
      "skittish is at index 2972\n",
      "Saved the embedding for skittish.\n",
      "slack is at index 25163\n",
      "Saved the embedding for slack.\n",
      "sleazy is at index 18388\n",
      "Saved the embedding for sleazy.\n",
      "sleepy is at index 33782\n",
      "Saved the embedding for sleepy.\n",
      "slick is at index 19038\n",
      "Saved the embedding for slick.\n",
      "slothful is at index 3369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for slothful.\n",
      "slow is at index 2635\n",
      "Saved the embedding for slow.\n",
      "sluggish is at index 16642\n",
      "Saved the embedding for sluggish.\n",
      "sly is at index 40568\n",
      "Saved the embedding for sly.\n",
      "smarmy is at index 5278\n",
      "Saved the embedding for smarmy.\n",
      "smart is at index 2793\n",
      "Saved the embedding for smart.\n",
      "smashed is at index 13263\n",
      "Saved the embedding for smashed.\n",
      "smile is at index 6675\n",
      "Saved the embedding for smile.\n",
      "smiley is at index 6675\n",
      "Saved the embedding for smiley.\n",
      "smiling is at index 12382\n",
      "Saved the embedding for smiling.\n",
      "smirk is at index 5278\n",
      "Saved the embedding for smirk.\n",
      "smirking is at index 44414\n",
      "Saved the embedding for smirking.\n",
      "smoldering is at index 5278\n",
      "Saved the embedding for smoldering.\n",
      "smooching is at index 5278\n",
      "Saved the embedding for smooching.\n",
      "smooth is at index 6921\n",
      "Saved the embedding for smooth.\n",
      "smug is at index 41283\n",
      "Saved the embedding for smug.\n",
      "smugness is at index 41283\n",
      "Saved the embedding for smugness.\n",
      "snake is at index 16173\n",
      "Saved the embedding for snake.\n",
      "snappy is at index 4543\n",
      "Saved the embedding for snappy.\n",
      "snarky is at index 4543\n",
      "Saved the embedding for snarky.\n",
      "snarl is at index 4543\n",
      "Saved the embedding for snarl.\n",
      "snarled is at index 4543\n",
      "Saved the embedding for snarled.\n",
      "snarling is at index 4543\n",
      "Saved the embedding for snarling.\n",
      "snarly is at index 4543\n",
      "Saved the embedding for snarly.\n",
      "sneaky is at index 39399\n",
      "Saved the embedding for sneaky.\n",
      "sneer is at index 18013\n",
      "Saved the embedding for sneer.\n",
      "sneering is at index 18013\n",
      "Saved the embedding for sneering.\n",
      "sneeze is at index 18013\n",
      "Saved the embedding for sneeze.\n",
      "sneezing is at index 18013\n",
      "Saved the embedding for sneezing.\n",
      "snicker is at index 4543\n",
      "Saved the embedding for snicker.\n",
      "snickering is at index 4543\n",
      "Saved the embedding for snickering.\n",
      "snide is at index 4543\n",
      "Saved the embedding for snide.\n",
      "sniggering is at index 4543\n",
      "Saved the embedding for sniggering.\n",
      "sniveling is at index 4543\n",
      "Saved the embedding for sniveling.\n",
      "snobbish is at index 4543\n",
      "Saved the embedding for snobbish.\n",
      "snobby is at index 4543\n",
      "Saved the embedding for snobby.\n",
      "snooty is at index 4543\n",
      "Saved the embedding for snooty.\n",
      "snotty is at index 579\n",
      "Saved the embedding for snotty.\n",
      "sociable is at index 17380\n",
      "Saved the embedding for sociable.\n",
      "soft is at index 3793\n",
      "Saved the embedding for soft.\n",
      "solemn is at index 29807\n",
      "Saved the embedding for solemn.\n",
      "solicitous is at index 22706\n",
      "Saved the embedding for solicitous.\n",
      "solitary is at index 24429\n",
      "Saved the embedding for solitary.\n",
      "solitude is at index 41813\n",
      "Saved the embedding for solitude.\n",
      "somber is at index 16487\n",
      "Saved the embedding for somber.\n",
      "somberly is at index 16487\n",
      "Saved the embedding for somberly.\n",
      "somnolent is at index 16487\n",
      "Saved the embedding for somnolent.\n",
      "soothed is at index 98\n",
      "Saved the embedding for soothed.\n",
      "sore is at index 12867\n",
      "Saved the embedding for sore.\n",
      "sorrow is at index 26130\n",
      "Saved the embedding for sorrow.\n",
      "sorrowful is at index 26130\n",
      "Saved the embedding for sorrowful.\n",
      "sorry is at index 6661\n",
      "Saved the embedding for sorry.\n",
      "sour is at index 16933\n",
      "Saved the embedding for sour.\n",
      "spaced is at index 42926\n",
      "Saved the embedding for spaced.\n",
      "spacing is at index 39152\n",
      "Saved the embedding for spacing.\n",
      "spastic is at index 2292\n",
      "Saved the embedding for spastic.\n",
      "speaking is at index 2686\n",
      "Saved the embedding for speaking.\n",
      "specious is at index 12002\n",
      "Saved the embedding for specious.\n",
      "speculative is at index 21779\n",
      "Saved the embedding for speculative.\n",
      "speechless is at index 1901\n",
      "Saved the embedding for speechless.\n",
      "spent is at index 1240\n",
      "Saved the embedding for spent.\n",
      "spirited is at index 27206\n",
      "Saved the embedding for spirited.\n",
      "spiritless is at index 4780\n",
      "Saved the embedding for spiritless.\n",
      "spite is at index 14117\n",
      "Saved the embedding for spite.\n",
      "spiteful is at index 14117\n",
      "Saved the embedding for spiteful.\n",
      "spoiled is at index 29136\n",
      "Saved the embedding for spoiled.\n",
      "spooked is at index 2292\n",
      "Saved the embedding for spooked.\n",
      "squeamish is at index 33380\n",
      "Saved the embedding for squeamish.\n",
      "staggered is at index 37646\n",
      "Saved the embedding for staggered.\n",
      "stalker is at index 1690\n",
      "Saved the embedding for stalker.\n",
      "stare is at index 27655\n",
      "Saved the embedding for stare.\n",
      "staring is at index 19311\n",
      "Saved the embedding for staring.\n",
      "starstruck is at index 999\n",
      "Saved the embedding for starstruck.\n",
      "started is at index 554\n",
      "Saved the embedding for started.\n",
      "startled is at index 37747\n",
      "Saved the embedding for startled.\n",
      "stately is at index 194\n",
      "Saved the embedding for stately.\n",
      "steadfast is at index 25781\n",
      "Saved the embedding for steadfast.\n",
      "steady is at index 5204\n",
      "Saved the embedding for steady.\n",
      "stealthy is at index 27026\n",
      "Saved the embedding for stealthy.\n",
      "steamed is at index 11235\n",
      "Saved the embedding for steamed.\n",
      "steaming is at index 11235\n",
      "Saved the embedding for steaming.\n",
      "steeling is at index 3689\n",
      "Saved the embedding for steeling.\n",
      "steely is at index 1690\n",
      "Saved the embedding for steely.\n",
      "stern is at index 23427\n",
      "Saved the embedding for stern.\n",
      "stiff is at index 13116\n",
      "Saved the embedding for stiff.\n",
      "stifled is at index 1690\n",
      "Saved the embedding for stifled.\n",
      "stifling is at index 1690\n",
      "Saved the embedding for stifling.\n",
      "still is at index 202\n",
      "Saved the embedding for still.\n",
      "stillness is at index 202\n",
      "Saved the embedding for stillness.\n",
      "stimulated is at index 42040\n",
      "Saved the embedding for stimulated.\n",
      "stinky is at index 1690\n",
      "Saved the embedding for stinky.\n",
      "stirred is at index 26158\n",
      "Saved the embedding for stirred.\n",
      "stoic is at index 20572\n",
      "Saved the embedding for stoic.\n",
      "stoical is at index 20572\n",
      "Saved the embedding for stoical.\n",
      "stolid is at index 1690\n",
      "Saved the embedding for stolid.\n",
      "stoned is at index 1690\n",
      "Saved the embedding for stoned.\n",
      "storming is at index 2130\n",
      "Saved the embedding for storming.\n",
      "stormy is at index 2130\n",
      "Saved the embedding for stormy.\n",
      "stout is at index 34636\n",
      "Saved the embedding for stout.\n",
      "straight is at index 1359\n",
      "Saved the embedding for straight.\n",
      "strained is at index 15718\n",
      "Saved the embedding for strained.\n",
      "strange is at index 7782\n",
      "Saved the embedding for strange.\n",
      "stressed is at index 5882\n",
      "Saved the embedding for stressed.\n",
      "stricken is at index 35876\n",
      "Saved the embedding for stricken.\n",
      "strict is at index 8414\n",
      "Saved the embedding for strict.\n",
      "strong is at index 670\n",
      "Saved the embedding for strong.\n",
      "struck is at index 2322\n",
      "Saved the embedding for struck.\n",
      "stubborn is at index 20476\n",
      "Saved the embedding for stubborn.\n",
      "stubbornness is at index 20476\n",
      "Saved the embedding for stubbornness.\n",
      "studious is at index 15863\n",
      "Saved the embedding for studious.\n",
      "studying is at index 7739\n",
      "Saved the embedding for studying.\n",
      "stumped is at index 1690\n",
      "Saved the embedding for stumped.\n",
      "stung is at index 1690\n",
      "Saved the embedding for stung.\n",
      "stunned is at index 12144\n",
      "Saved the embedding for stunned.\n",
      "stupefaction is at index 1690\n",
      "Saved the embedding for stupefaction.\n",
      "stupefied is at index 1690\n",
      "Saved the embedding for stupefied.\n",
      "stupefy is at index 1690\n",
      "Saved the embedding for stupefy.\n",
      "stupid is at index 12103\n",
      "Saved the embedding for stupid.\n",
      "stuporous is at index 1690\n",
      "Saved the embedding for stuporous.\n",
      "suave is at index 2628\n",
      "Saved the embedding for suave.\n",
      "subdued is at index 20247\n",
      "Saved the embedding for subdued.\n",
      "sublime is at index 32477\n",
      "Saved the embedding for sublime.\n",
      "submissive is at index 2849\n",
      "Saved the embedding for submissive.\n",
      "suffering is at index 3606\n",
      "Saved the embedding for suffering.\n",
      "suggestive is at index 38907\n",
      "Saved the embedding for suggestive.\n",
      "sulking is at index 26648\n",
      "Saved the embedding for sulking.\n",
      "sulky is at index 26648\n",
      "Saved the embedding for sulky.\n",
      "sullen is at index 2628\n",
      "Saved the embedding for sullen.\n",
      "sullenness is at index 2628\n",
      "Saved the embedding for sullenness.\n",
      "sunny is at index 5419\n",
      "Saved the embedding for sunny.\n",
      "superior is at index 10295\n",
      "Saved the embedding for superior.\n",
      "superiority is at index 32951\n",
      "Saved the embedding for superiority.\n",
      "suppressed is at index 31683\n",
      "Saved the embedding for suppressed.\n",
      "suppressing is at index 38919\n",
      "Saved the embedding for suppressing.\n",
      "suppression is at index 25276\n",
      "Saved the embedding for suppression.\n",
      "sure is at index 686\n",
      "Saved the embedding for sure.\n",
      "surly is at index 8113\n",
      "Saved the embedding for surly.\n",
      "surprise is at index 2755\n",
      "Saved the embedding for surprise.\n",
      "surprised is at index 3911\n",
      "Saved the embedding for surprised.\n",
      "surprising is at index 6167\n",
      "Saved the embedding for surprising.\n",
      "surprisingly is at index 10262\n",
      "Saved the embedding for surprisingly.\n",
      "surreptitious is at index 8113\n",
      "Saved the embedding for surreptitious.\n",
      "suspect is at index 1985\n",
      "Saved the embedding for suspect.\n",
      "suspecting is at index 1985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for suspecting.\n",
      "suspense is at index 31803\n",
      "Saved the embedding for suspense.\n",
      "suspicion is at index 8551\n",
      "Saved the embedding for suspicion.\n",
      "suspicious is at index 7775\n",
      "Saved the embedding for suspicious.\n",
      "suspiciously is at index 7775\n",
      "Saved the embedding for suspiciously.\n",
      "suspiciousness is at index 7775\n",
      "Saved the embedding for suspiciousness.\n",
      "swaggering is at index 3514\n",
      "Saved the embedding for swaggering.\n",
      "swearing is at index 21854\n",
      "Saved the embedding for swearing.\n",
      "sympathetic is at index 22869\n",
      "Saved the embedding for sympathetic.\n",
      "sympathizing is at index 19023\n",
      "Saved the embedding for sympathizing.\n",
      "sympathy is at index 16554\n",
      "Saved the embedding for sympathy.\n",
      "taciturn is at index 36502\n",
      "Saved the embedding for taciturn.\n",
      "talkative is at index 1067\n",
      "Saved the embedding for talkative.\n",
      "talking is at index 1686\n",
      "Saved the embedding for talking.\n",
      "tantalized is at index 33496\n",
      "Saved the embedding for tantalized.\n",
      "tart is at index 27468\n",
      "Saved the embedding for tart.\n",
      "tasteful is at index 24867\n",
      "Saved the embedding for tasteful.\n",
      "tattling is at index 45951\n",
      "Saved the embedding for tattling.\n",
      "taunt is at index 44048\n",
      "Saved the embedding for taunt.\n",
      "taunting is at index 326\n",
      "Saved the embedding for taunting.\n",
      "taut is at index 326\n",
      "Saved the embedding for taut.\n",
      "tearful is at index 7366\n",
      "Saved the embedding for tearful.\n",
      "teary is at index 7366\n",
      "Saved the embedding for teary.\n",
      "tease is at index 29993\n",
      "Saved the embedding for tease.\n",
      "teasing is at index 29752\n",
      "Saved the embedding for teasing.\n",
      "tempered is at index 31380\n",
      "Saved the embedding for tempered.\n",
      "tempest is at index 32196\n",
      "Saved the embedding for tempest.\n",
      "tempestuous is at index 32196\n",
      "Saved the embedding for tempestuous.\n",
      "tempted is at index 23448\n",
      "Saved the embedding for tempted.\n",
      "tenacious is at index 2724\n",
      "Saved the embedding for tenacious.\n",
      "tender is at index 8780\n",
      "Saved the embedding for tender.\n",
      "tenderness is at index 8780\n",
      "Saved the embedding for tenderness.\n",
      "tense is at index 13554\n",
      "Saved the embedding for tense.\n",
      "tensed is at index 7281\n",
      "Saved the embedding for tensed.\n",
      "tension is at index 8556\n",
      "Saved the embedding for tension.\n",
      "tentative is at index 22948\n",
      "Saved the embedding for tentative.\n",
      "terrified is at index 19419\n",
      "Saved the embedding for terrified.\n",
      "terror is at index 5231\n",
      "Saved the embedding for terror.\n",
      "terrorized is at index 5231\n",
      "Saved the embedding for terrorized.\n",
      "terrorizing is at index 5231\n",
      "Saved the embedding for terrorizing.\n",
      "terse is at index 8470\n",
      "Saved the embedding for terse.\n",
      "testy is at index 1296\n",
      "Saved the embedding for testy.\n",
      "tetchy is at index 326\n",
      "Saved the embedding for tetchy.\n",
      "thankful is at index 12025\n",
      "Saved the embedding for thankful.\n",
      "thinking is at index 2053\n",
      "Saved the embedding for thinking.\n",
      "thought is at index 802\n",
      "Saved the embedding for thought.\n",
      "thoughtful is at index 16801\n",
      "Saved the embedding for thoughtful.\n",
      "thoughtfulness is at index 802\n",
      "Saved the embedding for thoughtfulness.\n",
      "threat is at index 1856\n",
      "Saved the embedding for threat.\n",
      "threatened is at index 3711\n",
      "Saved the embedding for threatened.\n",
      "threatening is at index 5608\n",
      "Saved the embedding for threatening.\n",
      "thrilled is at index 8689\n",
      "Saved the embedding for thrilled.\n",
      "thrown is at index 5629\n",
      "Saved the embedding for thrown.\n",
      "thunderstruck is at index 4775\n",
      "Saved the embedding for thunderstruck.\n",
      "thwarted is at index 28299\n",
      "Saved the embedding for thwarted.\n",
      "ticked is at index 10457\n",
      "Saved the embedding for ticked.\n",
      "tickled is at index 10457\n",
      "Saved the embedding for tickled.\n",
      "tied is at index 3016\n",
      "Saved the embedding for tied.\n",
      "tiered is at index 3318\n",
      "Saved the embedding for tiered.\n",
      "tight is at index 3229\n",
      "Saved the embedding for tight.\n",
      "tightlipped is at index 3229\n",
      "Saved the embedding for tightlipped.\n",
      "timid is at index 39649\n",
      "Saved the embedding for timid.\n",
      "timidly is at index 39649\n",
      "Saved the embedding for timidly.\n",
      "timidness is at index 39649\n",
      "Saved the embedding for timidness.\n",
      "tired is at index 7428\n",
      "Saved the embedding for tired.\n",
      "tiredly is at index 7428\n",
      "Saved the embedding for tiredly.\n",
      "tiredness is at index 7428\n",
      "Saved the embedding for tiredness.\n",
      "titillated is at index 13515\n",
      "Saved the embedding for titillated.\n",
      "tolerant is at index 32836\n",
      "Saved the embedding for tolerant.\n",
      "tongue is at index 15686\n",
      "Saved the embedding for tongue.\n",
      "tormented is at index 16535\n",
      "Saved the embedding for tormented.\n",
      "touched is at index 6699\n",
      "Saved the embedding for touched.\n",
      "tough is at index 1828\n",
      "Saved the embedding for tough.\n",
      "toying is at index 7\n",
      "Saved the embedding for toying.\n",
      "tragic is at index 8805\n",
      "Saved the embedding for tragic.\n",
      "tragical is at index 2664\n",
      "Saved the embedding for tragical.\n",
      "tranquil is at index 33535\n",
      "Saved the embedding for tranquil.\n",
      "tranquility is at index 36474\n",
      "Saved the embedding for tranquility.\n",
      "transfixed is at index 30387\n",
      "Saved the embedding for transfixed.\n",
      "traumatized is at index 25178\n",
      "Saved the embedding for traumatized.\n",
      "trembling is at index 44912\n",
      "Saved the embedding for trembling.\n",
      "trepid is at index 6110\n",
      "Saved the embedding for trepid.\n",
      "trepidation is at index 6110\n",
      "Saved the embedding for trepidation.\n",
      "trickster is at index 7610\n",
      "Saved the embedding for trickster.\n",
      "tricky is at index 12792\n",
      "Saved the embedding for tricky.\n",
      "triumphant is at index 32025\n",
      "Saved the embedding for triumphant.\n",
      "troubled is at index 9895\n",
      "Saved the embedding for troubled.\n",
      "troublesome is at index 34056\n",
      "Saved the embedding for troublesome.\n",
      "troubling is at index 15554\n",
      "Saved the embedding for troubling.\n",
      "trusting is at index 28969\n",
      "Saved the embedding for trusting.\n",
      "trustworthy is at index 32101\n",
      "Saved the embedding for trustworthy.\n",
      "tumultuous is at index 23787\n",
      "Saved the embedding for tumultuous.\n",
      "turbulent is at index 23415\n",
      "Saved the embedding for turbulent.\n",
      "twinkly is at index 11901\n",
      "Saved the embedding for twinkly.\n",
      "umbrage is at index 7252\n",
      "Saved the embedding for umbrage.\n",
      "umbrageous is at index 7252\n",
      "Saved the embedding for umbrageous.\n",
      "unaffected is at index 32512\n",
      "Saved the embedding for unaffected.\n",
      "unagitated is at index 542\n",
      "Saved the embedding for unagitated.\n",
      "unamused is at index 542\n",
      "Saved the embedding for unamused.\n",
      "unappreciative is at index 542\n",
      "Saved the embedding for unappreciative.\n",
      "unapproachable is at index 542\n",
      "Saved the embedding for unapproachable.\n",
      "unassertive is at index 542\n",
      "Saved the embedding for unassertive.\n",
      "unassuming is at index 542\n",
      "Saved the embedding for unassuming.\n",
      "unaware is at index 14021\n",
      "Saved the embedding for unaware.\n",
      "unbelief is at index 46646\n",
      "Saved the embedding for unbelief.\n",
      "unbelievable is at index 14011\n",
      "Saved the embedding for unbelievable.\n",
      "unbelieving is at index 46646\n",
      "Saved the embedding for unbelieving.\n",
      "unbothered is at index 542\n",
      "Saved the embedding for unbothered.\n",
      "uncaring is at index 16511\n",
      "Saved the embedding for uncaring.\n",
      "uncertain is at index 9684\n",
      "Saved the embedding for uncertain.\n",
      "uncertainly is at index 9684\n",
      "Saved the embedding for uncertainly.\n",
      "uncertainty is at index 4983\n",
      "Saved the embedding for uncertainty.\n",
      "uncivil is at index 16511\n",
      "Saved the embedding for uncivil.\n",
      "uncomfortable is at index 9800\n",
      "Saved the embedding for uncomfortable.\n",
      "uncommitted is at index 32275\n",
      "Saved the embedding for uncommitted.\n",
      "uncommunicative is at index 32275\n",
      "Saved the embedding for uncommunicative.\n",
      "uncomprehending is at index 32275\n",
      "Saved the embedding for uncomprehending.\n",
      "uncompromising is at index 32213\n",
      "Saved the embedding for uncompromising.\n",
      "unconcerned is at index 28198\n",
      "Saved the embedding for unconcerned.\n",
      "unconfident is at index 542\n",
      "Saved the embedding for unconfident.\n",
      "unconvinced is at index 28198\n",
      "Saved the embedding for unconvinced.\n",
      "uncooperative is at index 542\n",
      "Saved the embedding for uncooperative.\n",
      "uncurious is at index 16511\n",
      "Saved the embedding for uncurious.\n",
      "undecided is at index 28598\n",
      "Saved the embedding for undecided.\n",
      "underhanded is at index 223\n",
      "Saved the embedding for underhanded.\n",
      "understanding is at index 2969\n",
      "Saved the embedding for understanding.\n",
      "undesirable is at index 39028\n",
      "Saved the embedding for undesirable.\n",
      "unease is at index 12515\n",
      "Saved the embedding for unease.\n",
      "uneasily is at index 12515\n",
      "Saved the embedding for uneasily.\n",
      "uneasiness is at index 12515\n",
      "Saved the embedding for uneasiness.\n",
      "uneasy is at index 29569\n",
      "Saved the embedding for uneasy.\n",
      "unemotional is at index 542\n",
      "Saved the embedding for unemotional.\n",
      "unenthusiastic is at index 542\n",
      "Saved the embedding for unenthusiastic.\n",
      "unexcited is at index 39432\n",
      "Saved the embedding for unexcited.\n",
      "unexpected is at index 7152\n",
      "Saved the embedding for unexpected.\n",
      "unfamiliar is at index 21942\n",
      "Saved the embedding for unfamiliar.\n",
      "unfathomable is at index 9515\n",
      "Saved the embedding for unfathomable.\n",
      "unfazed is at index 9515\n",
      "Saved the embedding for unfazed.\n",
      "unfeeling is at index 9515\n",
      "Saved the embedding for unfeeling.\n",
      "unfocused is at index 47306\n",
      "Saved the embedding for unfocused.\n",
      "unforeseen is at index 33257\n",
      "Saved the embedding for unforeseen.\n",
      "unforgiving is at index 34262\n",
      "Saved the embedding for unforgiving.\n",
      "unforthcoming is at index 9515\n",
      "Saved the embedding for unforthcoming.\n",
      "unfortunate is at index 9327\n",
      "Saved the embedding for unfortunate.\n",
      "unfriendly is at index 9515\n",
      "Saved the embedding for unfriendly.\n",
      "unhappy is at index 13865\n",
      "Saved the embedding for unhappy.\n",
      "unhinged is at index 542\n",
      "Saved the embedding for unhinged.\n",
      "unimpressed is at index 542\n",
      "Saved the embedding for unimpressed.\n",
      "uninformed is at index 21969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for uninformed.\n",
      "uninspired is at index 542\n",
      "Saved the embedding for uninspired.\n",
      "uninterested is at index 542\n",
      "Saved the embedding for uninterested.\n",
      "uninvolved is at index 542\n",
      "Saved the embedding for uninvolved.\n",
      "unique is at index 2216\n",
      "Saved the embedding for unique.\n",
      "unlikeable is at index 7328\n",
      "Saved the embedding for unlikeable.\n",
      "unmoved is at index 30780\n",
      "Saved the embedding for unmoved.\n",
      "unnerved is at index 31550\n",
      "Saved the embedding for unnerved.\n",
      "unpleasant is at index 26262\n",
      "Saved the embedding for unpleasant.\n",
      "unprepared is at index 35578\n",
      "Saved the embedding for unprepared.\n",
      "unquiet is at index 542\n",
      "Saved the embedding for unquiet.\n",
      "unreactive is at index 21153\n",
      "Saved the embedding for unreactive.\n",
      "unresolved is at index 29909\n",
      "Saved the embedding for unresolved.\n",
      "unrestrained is at index 12254\n",
      "Saved the embedding for unrestrained.\n",
      "unruffled is at index 542\n",
      "Saved the embedding for unruffled.\n",
      "unsatisfied is at index 36010\n",
      "Saved the embedding for unsatisfied.\n",
      "unsettled is at index 30933\n",
      "Saved the embedding for unsettled.\n",
      "unsociable is at index 9977\n",
      "Saved the embedding for unsociable.\n",
      "unspeaking is at index 542\n",
      "Saved the embedding for unspeaking.\n",
      "unspoken is at index 542\n",
      "Saved the embedding for unspoken.\n",
      "unstrung is at index 542\n",
      "Saved the embedding for unstrung.\n",
      "unsuccessful is at index 15943\n",
      "Saved the embedding for unsuccessful.\n",
      "unsure is at index 17118\n",
      "Saved the embedding for unsure.\n",
      "unsurprised is at index 36637\n",
      "Saved the embedding for unsurprised.\n",
      "unsuspecting is at index 32276\n",
      "Saved the embedding for unsuspecting.\n",
      "unswayed is at index 9977\n",
      "Saved the embedding for unswayed.\n",
      "unsympathetic is at index 542\n",
      "Saved the embedding for unsympathetic.\n",
      "untouched is at index 29929\n",
      "Saved the embedding for untouched.\n",
      "untroubled is at index 7587\n",
      "Saved the embedding for untroubled.\n",
      "untrusting is at index 7587\n",
      "Saved the embedding for untrusting.\n",
      "unwanted is at index 15067\n",
      "Saved the embedding for unwanted.\n",
      "unwavering is at index 10963\n",
      "Saved the embedding for unwavering.\n",
      "unwelcoming is at index 10963\n",
      "Saved the embedding for unwelcoming.\n",
      "unwell is at index 542\n",
      "Saved the embedding for unwell.\n",
      "unwilling is at index 20656\n",
      "Saved the embedding for unwilling.\n",
      "unyielding is at index 542\n",
      "Saved the embedding for unyielding.\n",
      "up is at index 62\n",
      "Saved the embedding for up.\n",
      "upbeat is at index 14899\n",
      "Saved the embedding for upbeat.\n",
      "uplifting is at index 17627\n",
      "Saved the embedding for uplifting.\n",
      "uppity is at index 1717\n",
      "Saved the embedding for uppity.\n",
      "upset is at index 4904\n",
      "Saved the embedding for upset.\n",
      "uptight is at index 18256\n",
      "Saved the embedding for uptight.\n",
      "useless is at index 23584\n",
      "Saved the embedding for useless.\n",
      "vacant is at index 11042\n",
      "Saved the embedding for vacant.\n",
      "vacuous is at index 18721\n",
      "Saved the embedding for vacuous.\n",
      "vanquished is at index 44400\n",
      "Saved the embedding for vanquished.\n",
      "vehement is at index 45373\n",
      "Saved the embedding for vehement.\n",
      "vengeful is at index 748\n",
      "Saved the embedding for vengeful.\n",
      "venomous is at index 32051\n",
      "Saved the embedding for venomous.\n",
      "vex is at index 37894\n",
      "Saved the embedding for vex.\n",
      "vexation is at index 37894\n",
      "Saved the embedding for vexation.\n",
      "vexed is at index 37894\n",
      "Saved the embedding for vexed.\n",
      "vicious is at index 16339\n",
      "Saved the embedding for vicious.\n",
      "victorious is at index 22518\n",
      "Saved the embedding for victorious.\n",
      "vigilant is at index 17258\n",
      "Saved the embedding for vigilant.\n",
      "vile is at index 32359\n",
      "Saved the embedding for vile.\n",
      "villainous is at index 17031\n",
      "Saved the embedding for villainous.\n",
      "vindictive is at index 21339\n",
      "Saved the embedding for vindictive.\n",
      "violence is at index 1476\n",
      "Saved the embedding for violence.\n",
      "violent is at index 4153\n",
      "Saved the embedding for violent.\n",
      "viperous is at index 748\n",
      "Saved the embedding for viperous.\n",
      "vituperative is at index 14306\n",
      "Saved the embedding for vituperative.\n",
      "vocal is at index 7578\n",
      "Saved the embedding for vocal.\n",
      "vocalized is at index 7578\n",
      "Saved the embedding for vocalized.\n",
      "vulgar is at index 28792\n",
      "Saved the embedding for vulgar.\n",
      "vulnerability is at index 15661\n",
      "Saved the embedding for vulnerability.\n",
      "vulnerable is at index 4478\n",
      "Saved the embedding for vulnerable.\n",
      "wacky is at index 885\n",
      "Saved the embedding for wacky.\n",
      "waiting is at index 2445\n",
      "Saved the embedding for waiting.\n",
      "wanted is at index 770\n",
      "Saved the embedding for wanted.\n",
      "wanting is at index 6923\n",
      "Saved the embedding for wanting.\n",
      "wanton is at index 236\n",
      "Saved the embedding for wanton.\n",
      "wariness is at index 997\n",
      "Saved the embedding for wariness.\n",
      "warm is at index 3279\n",
      "Saved the embedding for warm.\n",
      "wary is at index 13441\n",
      "Saved the embedding for wary.\n",
      "wasted is at index 14260\n",
      "Saved the embedding for wasted.\n",
      "watch is at index 1183\n",
      "Saved the embedding for watch.\n",
      "watchful is at index 1183\n",
      "Saved the embedding for watchful.\n",
      "watching is at index 2494\n",
      "Saved the embedding for watching.\n",
      "wavering is at index 13332\n",
      "Saved the embedding for wavering.\n",
      "weariness is at index 3568\n",
      "Saved the embedding for weariness.\n",
      "weary is at index 31554\n",
      "Saved the embedding for weary.\n",
      "weeping is at index 39423\n",
      "Saved the embedding for weeping.\n",
      "weird is at index 7735\n",
      "Saved the embedding for weird.\n",
      "welcome is at index 2814\n",
      "Saved the embedding for welcome.\n",
      "welcoming is at index 10423\n",
      "Saved the embedding for welcoming.\n",
      "whatever is at index 3046\n",
      "Saved the embedding for whatever.\n",
      "whimpering is at index 31754\n",
      "Saved the embedding for whimpering.\n",
      "whimsical is at index 29363\n",
      "Saved the embedding for whimsical.\n",
      "whisper is at index 37539\n",
      "Saved the embedding for whisper.\n",
      "whistle is at index 16867\n",
      "Saved the embedding for whistle.\n",
      "white is at index 1104\n",
      "Saved the embedding for white.\n",
      "wicked is at index 28418\n",
      "Saved the embedding for wicked.\n",
      "wild is at index 3418\n",
      "Saved the embedding for wild.\n",
      "willful is at index 40960\n",
      "Saved the embedding for willful.\n",
      "willing is at index 2882\n",
      "Saved the embedding for willing.\n",
      "wily is at index 885\n",
      "Saved the embedding for wily.\n",
      "wink is at index 39422\n",
      "Saved the embedding for wink.\n",
      "wired is at index 26977\n",
      "Saved the embedding for wired.\n",
      "wishful is at index 2813\n",
      "Saved the embedding for wishful.\n",
      "wistful is at index 885\n",
      "Saved the embedding for wistful.\n",
      "wistfully is at index 885\n",
      "Saved the embedding for wistfully.\n",
      "withdraw is at index 8202\n",
      "Saved the embedding for withdraw.\n",
      "withdrawn is at index 13375\n",
      "Saved the embedding for withdrawn.\n",
      "withheld is at index 22292\n",
      "Saved the embedding for withheld.\n",
      "withholding is at index 25661\n",
      "Saved the embedding for withholding.\n",
      "woe is at index 885\n",
      "Saved the embedding for woe.\n",
      "woeful is at index 19958\n",
      "Saved the embedding for woeful.\n",
      "wonder is at index 5170\n",
      "Saved the embedding for wonder.\n",
      "wondering is at index 8020\n",
      "Saved the embedding for wondering.\n",
      "wonderment is at index 5170\n",
      "Saved the embedding for wonderment.\n",
      "wooly is at index 24815\n",
      "Saved the embedding for wooly.\n",
      "woozy is at index 24815\n",
      "Saved the embedding for woozy.\n",
      "worn is at index 10610\n",
      "Saved the embedding for worn.\n",
      "worried is at index 3915\n",
      "Saved the embedding for worried.\n",
      "worrisome is at index 29611\n",
      "Saved the embedding for worrisome.\n",
      "worry is at index 4022\n",
      "Saved the embedding for worry.\n",
      "worrying is at index 12648\n",
      "Saved the embedding for worrying.\n",
      "worryingly is at index 4022\n",
      "Saved the embedding for worryingly.\n",
      "wounded is at index 5424\n",
      "Saved the embedding for wounded.\n",
      "wow is at index 26388\n",
      "Saved the embedding for wow.\n",
      "wrathful is at index 30220\n",
      "Saved the embedding for wrathful.\n",
      "wrathfully is at index 30220\n",
      "Saved the embedding for wrathfully.\n",
      "wrecked is at index 30090\n",
      "Saved the embedding for wrecked.\n",
      "wretched is at index 42824\n",
      "Saved the embedding for wretched.\n",
      "wronged is at index 1593\n",
      "Saved the embedding for wronged.\n",
      "wroth is at index 885\n",
      "Saved the embedding for wroth.\n",
      "wry is at index 885\n",
      "Saved the embedding for wry.\n",
      "yawn is at index 39654\n",
      "Saved the embedding for yawn.\n",
      "yawning is at index 39654\n",
      "Saved the embedding for yawning.\n",
      "yearning is at index 76\n",
      "Saved the embedding for yearning.\n",
      "yell is at index 28930\n",
      "Saved the embedding for yell.\n",
      "yelling is at index 16600\n",
      "Saved the embedding for yelling.\n",
      "yielding is at index 25438\n",
      "Saved the embedding for yielding.\n",
      "yuck is at index 1423\n",
      "Saved the embedding for yuck.\n",
      "zany is at index 992\n",
      "Saved the embedding for zany.\n",
      "zealous is at index 992\n",
      "Saved the embedding for zealous.\n",
      "zen is at index 992\n",
      "Saved the embedding for zen.\n",
      "zoned is at index 992\n",
      "Saved the embedding for zoned.\n"
     ]
    }
   ],
   "source": [
    "################################################\n",
    "# This cell will write out input embeddings    #\n",
    "# for all the words in my                      #\n",
    "# vocabulary, using RoBERTa fine-tuned twice on#\n",
    "# Common Crawl training text.                  #\n",
    "# !!!USE INPUT EMBEDDINGS!!!!!                 #\n",
    "################################################\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = RobertaTokenizer.from_pretrained('./output_CC-ab/')\n",
    "\n",
    "model = RobertaForMaskedLM.from_pretrained('./output_CC-ab/', config=config)\n",
    "\n",
    "config = RobertaConfig.from_pretrained('./output_CC-ab/')\n",
    "config.output_hidden_states = True\n",
    "input_embeddings = model.get_input_embeddings()\n",
    "embeddings_file = '/home/jupyter/Notebooks/crystal/NLP/nlp_testing/embeddings_context_vocab/roberta_input_CC_ab.txt'\n",
    "for v in vocab:\n",
    "    v_tensor = torch.tensor([tokenizer.encode(v)])\n",
    "    # Print the index of the test word.\n",
    "    print(f'{v} is at index {v_tensor[0][1].item()}')\n",
    "#     print(input_embeddings_test(torch.LongTensor([v_tensor[0][1].item()])))\n",
    "    v_embed = input_embeddings(torch.LongTensor([v_tensor[0][1].item()]))\n",
    "#     for n in range(v_embed.size()[1])\n",
    "    try:\n",
    "        with open(embeddings_file, 'a') as f:\n",
    "            f.write(v)\n",
    "            for value in v_embed[0]:\n",
    "                f.write(' ' + str(value.item()))\n",
    "            f.write('\\n')\n",
    "        print(f'Saved the embedding for {v}.')\n",
    "    except:\n",
    "        print('Oh no! Unable to write to the embeddings file.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aback is at index 36347\n",
      "Saved the embedding for aback.\n",
      "abashed is at index 4091\n",
      "Saved the embedding for abashed.\n",
      "abhor is at index 35350\n",
      "Saved the embedding for abhor.\n",
      "abhorred is at index 35350\n",
      "Saved the embedding for abhorred.\n",
      "abhorrence is at index 35350\n",
      "Saved the embedding for abhorrence.\n",
      "abhorrent is at index 35350\n",
      "Saved the embedding for abhorrent.\n",
      "abominable is at index 4091\n",
      "Saved the embedding for abominable.\n",
      "abound is at index 32937\n",
      "Saved the embedding for abound.\n",
      "absent is at index 11640\n",
      "Saved the embedding for absent.\n",
      "absorbed is at index 22416\n",
      "Saved the embedding for absorbed.\n",
      "acceptance is at index 10502\n",
      "Saved the embedding for acceptance.\n",
      "accepted is at index 3903\n",
      "Saved the embedding for accepted.\n",
      "accepting is at index 8394\n",
      "Saved the embedding for accepting.\n",
      "accommodating is at index 33681\n",
      "Saved the embedding for accommodating.\n",
      "accomplished is at index 9370\n",
      "Saved the embedding for accomplished.\n",
      "accordant is at index 10170\n",
      "Saved the embedding for accordant.\n",
      "accursed is at index 7678\n",
      "Saved the embedding for accursed.\n",
      "accusatory is at index 23123\n",
      "Saved the embedding for accusatory.\n",
      "accused is at index 1238\n",
      "Saved the embedding for accused.\n",
      "accusing is at index 8601\n",
      "Saved the embedding for accusing.\n",
      "acerbic is at index 4285\n",
      "Saved the embedding for acerbic.\n",
      "acidic is at index 41314\n",
      "Saved the embedding for acidic.\n",
      "active is at index 2171\n",
      "Saved the embedding for active.\n",
      "acute is at index 13827\n",
      "Saved the embedding for acute.\n",
      "adamant is at index 22668\n",
      "Saved the embedding for adamant.\n",
      "addled is at index 1606\n",
      "Saved the embedding for addled.\n",
      "admiration is at index 24287\n",
      "Saved the embedding for admiration.\n",
      "admit is at index 8109\n",
      "Saved the embedding for admit.\n",
      "adoration is at index 2329\n",
      "Saved the embedding for adoration.\n",
      "adoring is at index 2329\n",
      "Saved the embedding for adoring.\n",
      "adrift is at index 2329\n",
      "Saved the embedding for adrift.\n",
      "adversarial is at index 37930\n",
      "Saved the embedding for adversarial.\n",
      "affability is at index 11129\n",
      "Saved the embedding for affability.\n",
      "affected is at index 2132\n",
      "Saved the embedding for affected.\n",
      "affectionate is at index 15955\n",
      "Saved the embedding for affectionate.\n",
      "afflicted is at index 39234\n",
      "Saved the embedding for afflicted.\n",
      "affronted is at index 11129\n",
      "Saved the embedding for affronted.\n",
      "aflutter is at index 10\n",
      "Saved the embedding for aflutter.\n",
      "afraid is at index 6023\n",
      "Saved the embedding for afraid.\n",
      "agape is at index 5951\n",
      "Saved the embedding for agape.\n",
      "aggravated is at index 10040\n",
      "Saved the embedding for aggravated.\n",
      "aggravation is at index 29223\n",
      "Saved the embedding for aggravation.\n",
      "aggression is at index 14227\n",
      "Saved the embedding for aggression.\n",
      "aggressive is at index 4353\n",
      "Saved the embedding for aggressive.\n",
      "aggrieve is at index 28940\n",
      "Saved the embedding for aggrieve.\n",
      "aggrieved is at index 28940\n",
      "Saved the embedding for aggrieved.\n",
      "aghast is at index 10\n",
      "Saved the embedding for aghast.\n",
      "agitated is at index 33426\n",
      "Saved the embedding for agitated.\n",
      "agog is at index 5951\n",
      "Saved the embedding for agog.\n",
      "agonized is at index 27497\n",
      "Saved the embedding for agonized.\n",
      "agreeable is at index 43359\n",
      "Saved the embedding for agreeable.\n",
      "agressive is at index 5951\n",
      "Saved the embedding for agressive.\n",
      "airhead is at index 935\n",
      "Saved the embedding for airhead.\n",
      "alarm is at index 8054\n",
      "Saved the embedding for alarm.\n",
      "alarmed is at index 23438\n",
      "Saved the embedding for alarmed.\n",
      "alarming is at index 16156\n",
      "Saved the embedding for alarming.\n",
      "alert is at index 5439\n",
      "Saved the embedding for alert.\n",
      "alerted is at index 14588\n",
      "Saved the embedding for alerted.\n",
      "alienated is at index 36462\n",
      "Saved the embedding for alienated.\n",
      "allergic is at index 28349\n",
      "Saved the embedding for allergic.\n",
      "alleviated is at index 32216\n",
      "Saved the embedding for alleviated.\n",
      "alluring is at index 70\n",
      "Saved the embedding for alluring.\n",
      "aloof is at index 1076\n",
      "Saved the embedding for aloof.\n",
      "amatory is at index 524\n",
      "Saved the embedding for amatory.\n",
      "amazed is at index 22431\n",
      "Saved the embedding for amazed.\n",
      "amazement is at index 42402\n",
      "Saved the embedding for amazement.\n",
      "amazing is at index 2770\n",
      "Saved the embedding for amazing.\n",
      "ambition is at index 12831\n",
      "Saved the embedding for ambition.\n",
      "ambitious is at index 8263\n",
      "Saved the embedding for ambitious.\n",
      "ambivalence is at index 13569\n",
      "Saved the embedding for ambivalence.\n",
      "ambivalent is at index 13569\n",
      "Saved the embedding for ambivalent.\n",
      "amenable is at index 524\n",
      "Saved the embedding for amenable.\n",
      "amiable is at index 524\n",
      "Saved the embedding for amiable.\n",
      "amicable is at index 524\n",
      "Saved the embedding for amicable.\n",
      "amused is at index 36530\n",
      "Saved the embedding for amused.\n",
      "amusement is at index 28445\n",
      "Saved the embedding for amusement.\n",
      "analytical is at index 23554\n",
      "Saved the embedding for analytical.\n",
      "analyzing is at index 18999\n",
      "Saved the embedding for analyzing.\n",
      "anger is at index 6378\n",
      "Saved the embedding for anger.\n",
      "angered is at index 20166\n",
      "Saved the embedding for angered.\n",
      "angrily is at index 30302\n",
      "Saved the embedding for angrily.\n",
      "angry is at index 5800\n",
      "Saved the embedding for angry.\n",
      "angst is at index 33010\n",
      "Saved the embedding for angst.\n",
      "anguish is at index 32446\n",
      "Saved the embedding for anguish.\n",
      "anguished is at index 5667\n",
      "Saved the embedding for anguished.\n",
      "animated is at index 12847\n",
      "Saved the embedding for animated.\n",
      "animosity is at index 34351\n",
      "Saved the embedding for animosity.\n",
      "annoyance is at index 39341\n",
      "Saved the embedding for annoyance.\n",
      "annoyed is at index 26678\n",
      "Saved the embedding for annoyed.\n",
      "annoying is at index 19887\n",
      "Saved the embedding for annoying.\n",
      "antagonistic is at index 32726\n",
      "Saved the embedding for antagonistic.\n",
      "antagonized is at index 32726\n",
      "Saved the embedding for antagonized.\n",
      "anticipated is at index 5291\n",
      "Saved the embedding for anticipated.\n",
      "anticipating is at index 22535\n",
      "Saved the embedding for anticipating.\n",
      "anticipation is at index 14714\n",
      "Saved the embedding for anticipation.\n",
      "anticipative is at index 21428\n",
      "Saved the embedding for anticipative.\n",
      "anticipatory is at index 21428\n",
      "Saved the embedding for anticipatory.\n",
      "antipathy is at index 37554\n",
      "Saved the embedding for antipathy.\n",
      "antsy is at index 32855\n",
      "Saved the embedding for antsy.\n",
      "anxiety is at index 6882\n",
      "Saved the embedding for anxiety.\n",
      "anxious is at index 13473\n",
      "Saved the embedding for anxious.\n",
      "anxiously is at index 27442\n",
      "Saved the embedding for anxiously.\n",
      "apathetic is at index 6256\n",
      "Saved the embedding for apathetic.\n",
      "apathy is at index 6256\n",
      "Saved the embedding for apathy.\n",
      "apologetic is at index 23842\n",
      "Saved the embedding for apologetic.\n",
      "appalled is at index 31514\n",
      "Saved the embedding for appalled.\n",
      "appallingly is at index 1553\n",
      "Saved the embedding for appallingly.\n",
      "appeased is at index 44151\n",
      "Saved the embedding for appeased.\n",
      "appeasing is at index 44151\n",
      "Saved the embedding for appeasing.\n",
      "appreciative is at index 14137\n",
      "Saved the embedding for appreciative.\n",
      "apprehension is at index 34640\n",
      "Saved the embedding for apprehension.\n",
      "apprehensive is at index 33655\n",
      "Saved the embedding for apprehensive.\n",
      "approve is at index 7244\n",
      "Saved the embedding for approve.\n",
      "approved is at index 2033\n",
      "Saved the embedding for approved.\n",
      "approving is at index 20499\n",
      "Saved the embedding for approving.\n",
      "argue is at index 5848\n",
      "Saved the embedding for argue.\n",
      "argumentative is at index 4795\n",
      "Saved the embedding for argumentative.\n",
      "aroused is at index 42941\n",
      "Saved the embedding for aroused.\n",
      "arrogance is at index 32818\n",
      "Saved the embedding for arrogance.\n",
      "arrogant is at index 30967\n",
      "Saved the embedding for arrogant.\n",
      "arrogantly is at index 46553\n",
      "Saved the embedding for arrogantly.\n",
      "artificial is at index 7350\n",
      "Saved the embedding for artificial.\n",
      "ashamed is at index 20085\n",
      "Saved the embedding for ashamed.\n",
      "aspiring is at index 18885\n",
      "Saved the embedding for aspiring.\n",
      "assertive is at index 18088\n",
      "Saved the embedding for assertive.\n",
      "assertively is at index 18088\n",
      "Saved the embedding for assertively.\n",
      "assessing is at index 16629\n",
      "Saved the embedding for assessing.\n",
      "assured is at index 7189\n",
      "Saved the embedding for assured.\n",
      "astonished is at index 40788\n",
      "Saved the embedding for astonished.\n",
      "astonishment is at index 44434\n",
      "Saved the embedding for astonishment.\n",
      "astounded is at index 12976\n",
      "Saved the embedding for astounded.\n",
      "attempting is at index 6475\n",
      "Saved the embedding for attempting.\n",
      "attentive is at index 36670\n",
      "Saved the embedding for attentive.\n",
      "attentiveness is at index 39879\n",
      "Saved the embedding for attentiveness.\n",
      "attracted is at index 7671\n",
      "Saved the embedding for attracted.\n",
      "avenging is at index 38796\n",
      "Saved the embedding for avenging.\n",
      "averse is at index 10\n",
      "Saved the embedding for averse.\n",
      "aversion is at index 33814\n",
      "Saved the embedding for aversion.\n",
      "aversive is at index 10\n",
      "Saved the embedding for aversive.\n",
      "avid is at index 20137\n",
      "Saved the embedding for avid.\n",
      "avoiding is at index 11473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for avoiding.\n",
      "awaiting is at index 10254\n",
      "Saved the embedding for awaiting.\n",
      "awakened is at index 40593\n",
      "Saved the embedding for awakened.\n",
      "aware is at index 2542\n",
      "Saved the embedding for aware.\n",
      "awareness is at index 4199\n",
      "Saved the embedding for awareness.\n",
      "awe is at index 21531\n",
      "Saved the embedding for awe.\n",
      "awed is at index 19267\n",
      "Saved the embedding for awed.\n",
      "awestruck is at index 19267\n",
      "Saved the embedding for awestruck.\n",
      "awful is at index 11522\n",
      "Saved the embedding for awful.\n",
      "awkward is at index 11789\n",
      "Saved the embedding for awkward.\n",
      "awkwardness is at index 11789\n",
      "Saved the embedding for awkwardness.\n",
      "axed is at index 18884\n",
      "Saved the embedding for axed.\n",
      "backhanded is at index 124\n",
      "Saved the embedding for backhanded.\n",
      "badly is at index 7340\n",
      "Saved the embedding for badly.\n",
      "baffle is at index 33139\n",
      "Saved the embedding for baffle.\n",
      "baffled is at index 33396\n",
      "Saved the embedding for baffled.\n",
      "baffling is at index 33139\n",
      "Saved the embedding for baffling.\n",
      "baked is at index 17241\n",
      "Saved the embedding for baked.\n",
      "banal is at index 2020\n",
      "Saved the embedding for banal.\n",
      "barking is at index 35828\n",
      "Saved the embedding for barking.\n",
      "bashful is at index 12882\n",
      "Saved the embedding for bashful.\n",
      "beaming is at index 28\n",
      "Saved the embedding for beaming.\n",
      "bearish is at index 4649\n",
      "Saved the embedding for bearish.\n",
      "beat is at index 1451\n",
      "Saved the embedding for beat.\n",
      "beaten is at index 6432\n",
      "Saved the embedding for beaten.\n",
      "bedeviled is at index 3267\n",
      "Saved the embedding for bedeviled.\n",
      "befuddled is at index 28\n",
      "Saved the embedding for befuddled.\n",
      "begging is at index 22901\n",
      "Saved the embedding for begging.\n",
      "begrudge is at index 28\n",
      "Saved the embedding for begrudge.\n",
      "begrudging is at index 28\n",
      "Saved the embedding for begrudging.\n",
      "begrudgingly is at index 28\n",
      "Saved the embedding for begrudgingly.\n",
      "beguiled is at index 21422\n",
      "Saved the embedding for beguiled.\n",
      "belated is at index 12138\n",
      "Saved the embedding for belated.\n",
      "belittling is at index 12138\n",
      "Saved the embedding for belittling.\n",
      "belligerence is at index 35756\n",
      "Saved the embedding for belligerence.\n",
      "belligerent is at index 35756\n",
      "Saved the embedding for belligerent.\n",
      "belonging is at index 11441\n",
      "Saved the embedding for belonging.\n",
      "bemused is at index 28\n",
      "Saved the embedding for bemused.\n",
      "bemusement is at index 28\n",
      "Saved the embedding for bemusement.\n",
      "benevolence is at index 42364\n",
      "Saved the embedding for benevolence.\n",
      "benevolent is at index 43186\n",
      "Saved the embedding for benevolent.\n",
      "benumbed is at index 21576\n",
      "Saved the embedding for benumbed.\n",
      "berate is at index 14719\n",
      "Saved the embedding for berate.\n",
      "berating is at index 14719\n",
      "Saved the embedding for berating.\n",
      "bereaved is at index 17738\n",
      "Saved the embedding for bereaved.\n",
      "bereft is at index 17738\n",
      "Saved the embedding for bereft.\n",
      "beseeching is at index 9988\n",
      "Saved the embedding for beseeching.\n",
      "bested is at index 275\n",
      "Saved the embedding for bested.\n",
      "betrayal is at index 26760\n",
      "Saved the embedding for betrayal.\n",
      "betrayed is at index 26913\n",
      "Saved the embedding for betrayed.\n",
      "bewildered is at index 33304\n",
      "Saved the embedding for bewildered.\n",
      "bewilderment is at index 33304\n",
      "Saved the embedding for bewilderment.\n",
      "bi is at index 4003\n",
      "Saved the embedding for bi.\n",
      "bilious is at index 31617\n",
      "Saved the embedding for bilious.\n",
      "bit is at index 828\n",
      "Saved the embedding for bit.\n",
      "biting is at index 25609\n",
      "Saved the embedding for biting.\n",
      "bitter is at index 10513\n",
      "Saved the embedding for bitter.\n",
      "bittersweet is at index 28609\n",
      "Saved the embedding for bittersweet.\n",
      "blaming is at index 15249\n",
      "Saved the embedding for blaming.\n",
      "bland is at index 35063\n",
      "Saved the embedding for bland.\n",
      "blank is at index 15818\n",
      "Saved the embedding for blank.\n",
      "blase is at index 3089\n",
      "Saved the embedding for blase.\n",
      "blazed is at index 3089\n",
      "Saved the embedding for blazed.\n",
      "bleak is at index 23530\n",
      "Saved the embedding for bleak.\n",
      "bleary is at index 13819\n",
      "Saved the embedding for bleary.\n",
      "blessed is at index 12230\n",
      "Saved the embedding for blessed.\n",
      "blew is at index 10879\n",
      "Saved the embedding for blew.\n",
      "blinded is at index 40094\n",
      "Saved the embedding for blinded.\n",
      "blindsided is at index 7709\n",
      "Saved the embedding for blindsided.\n",
      "bliss is at index 30299\n",
      "Saved the embedding for bliss.\n",
      "blissful is at index 30299\n",
      "Saved the embedding for blissful.\n",
      "blissfully is at index 30299\n",
      "Saved the embedding for blissfully.\n",
      "blithe is at index 3089\n",
      "Saved the embedding for blithe.\n",
      "blown is at index 12315\n",
      "Saved the embedding for blown.\n",
      "blue is at index 2440\n",
      "Saved the embedding for blue.\n",
      "blues is at index 15629\n",
      "Saved the embedding for blues.\n",
      "bluffing is at index 37372\n",
      "Saved the embedding for bluffing.\n",
      "blunt is at index 18720\n",
      "Saved the embedding for blunt.\n",
      "blushing is at index 3089\n",
      "Saved the embedding for blushing.\n",
      "blustering is at index 3089\n",
      "Saved the embedding for blustering.\n",
      "boastful is at index 18639\n",
      "Saved the embedding for boastful.\n",
      "boggled is at index 741\n",
      "Saved the embedding for boggled.\n",
      "boiling is at index 27513\n",
      "Saved the embedding for boiling.\n",
      "boisterous is at index 5276\n",
      "Saved the embedding for boisterous.\n",
      "bold is at index 7457\n",
      "Saved the embedding for bold.\n",
      "bored is at index 23809\n",
      "Saved the embedding for bored.\n",
      "boredom is at index 40326\n",
      "Saved the embedding for boredom.\n",
      "boring is at index 15305\n",
      "Saved the embedding for boring.\n",
      "bothered is at index 18523\n",
      "Saved the embedding for bothered.\n",
      "bounder is at index 8191\n",
      "Saved the embedding for bounder.\n",
      "brashness is at index 5378\n",
      "Saved the embedding for brashness.\n",
      "bratty is at index 5378\n",
      "Saved the embedding for bratty.\n",
      "brave is at index 10025\n",
      "Saved the embedding for brave.\n",
      "bright is at index 4520\n",
      "Saved the embedding for bright.\n",
      "bristling is at index 37135\n",
      "Saved the embedding for bristling.\n",
      "broken is at index 3187\n",
      "Saved the embedding for broken.\n",
      "brokenhearted is at index 3187\n",
      "Saved the embedding for brokenhearted.\n",
      "brokenheartedly is at index 3187\n",
      "Saved the embedding for brokenheartedly.\n",
      "brooding is at index 11051\n",
      "Saved the embedding for brooding.\n",
      "broody is at index 11051\n",
      "Saved the embedding for broody.\n",
      "bruised is at index 26360\n",
      "Saved the embedding for bruised.\n",
      "brusque is at index 5378\n",
      "Saved the embedding for brusque.\n",
      "bug is at index 13673\n",
      "Saved the embedding for bug.\n",
      "bulging is at index 22382\n",
      "Saved the embedding for bulging.\n",
      "bully is at index 23934\n",
      "Saved the embedding for bully.\n",
      "bullying is at index 11902\n",
      "Saved the embedding for bullying.\n",
      "bummed is at index 29673\n",
      "Saved the embedding for bummed.\n",
      "buoyant is at index 15980\n",
      "Saved the embedding for buoyant.\n",
      "burdened is at index 32875\n",
      "Saved the embedding for burdened.\n",
      "burn is at index 7403\n",
      "Saved the embedding for burn.\n",
      "bursting is at index 28548\n",
      "Saved the embedding for bursting.\n",
      "bushed is at index 2353\n",
      "Saved the embedding for bushed.\n",
      "cagey is at index 16051\n",
      "Saved the embedding for cagey.\n",
      "cagy is at index 740\n",
      "Saved the embedding for cagy.\n",
      "calculating is at index 29770\n",
      "Saved the embedding for calculating.\n",
      "callous is at index 486\n",
      "Saved the embedding for callous.\n",
      "callused is at index 486\n",
      "Saved the embedding for callused.\n",
      "calm is at index 6327\n",
      "Saved the embedding for calm.\n",
      "calming is at index 31220\n",
      "Saved the embedding for calming.\n",
      "calmness is at index 6327\n",
      "Saved the embedding for calmness.\n",
      "canny is at index 64\n",
      "Saved the embedding for canny.\n",
      "cantankerous is at index 17672\n",
      "Saved the embedding for cantankerous.\n",
      "capable is at index 4453\n",
      "Saved the embedding for capable.\n",
      "capricious is at index 2927\n",
      "Saved the embedding for capricious.\n",
      "captivated is at index 13363\n",
      "Saved the embedding for captivated.\n",
      "captive is at index 24145\n",
      "Saved the embedding for captive.\n",
      "carefree is at index 575\n",
      "Saved the embedding for carefree.\n",
      "careful is at index 7316\n",
      "Saved the embedding for careful.\n",
      "careless is at index 29399\n",
      "Saved the embedding for careless.\n",
      "caring is at index 10837\n",
      "Saved the embedding for caring.\n",
      "catty is at index 4758\n",
      "Saved the embedding for catty.\n",
      "caustic is at index 6056\n",
      "Saved the embedding for caustic.\n",
      "cautionary is at index 8038\n",
      "Saved the embedding for cautionary.\n",
      "cautious is at index 9420\n",
      "Saved the embedding for cautious.\n",
      "cavalier is at index 41869\n",
      "Saved the embedding for cavalier.\n",
      "celebrating is at index 6146\n",
      "Saved the embedding for celebrating.\n",
      "celebration is at index 4821\n",
      "Saved the embedding for celebration.\n",
      "censure is at index 26489\n",
      "Saved the embedding for censure.\n",
      "centered is at index 14889\n",
      "Saved the embedding for centered.\n",
      "certain is at index 1402\n",
      "Saved the embedding for certain.\n",
      "chafed is at index 1855\n",
      "Saved the embedding for chafed.\n",
      "chagrin is at index 1855\n",
      "Saved the embedding for chagrin.\n",
      "chagrined is at index 1855\n",
      "Saved the embedding for chagrined.\n",
      "chagrinned is at index 1855\n",
      "Saved the embedding for chagrinned.\n",
      "challenge is at index 1539\n",
      "Saved the embedding for challenge.\n",
      "challenged is at index 6835\n",
      "Saved the embedding for challenged.\n",
      "challenging is at index 4087\n",
      "Saved the embedding for challenging.\n",
      "chaotic is at index 16529\n",
      "Saved the embedding for chaotic.\n",
      "charged is at index 1340\n",
      "Saved the embedding for charged.\n",
      "charmed is at index 16224\n",
      "Saved the embedding for charmed.\n",
      "charming is at index 18452\n",
      "Saved the embedding for charming.\n",
      "chary is at index 1855\n",
      "Saved the embedding for chary.\n",
      "cheated is at index 25177\n",
      "Saved the embedding for cheated.\n",
      "cheeky is at index 15401\n",
      "Saved the embedding for cheeky.\n",
      "cheered is at index 18643\n",
      "Saved the embedding for cheered.\n",
      "cheerful is at index 33928\n",
      "Saved the embedding for cheerful.\n",
      "cheering is at index 16765\n",
      "Saved the embedding for cheering.\n",
      "cheerless is at index 9450\n",
      "Saved the embedding for cheerless.\n",
      "cheery is at index 5851\n",
      "Saved the embedding for cheery.\n",
      "cheesy is at index 36331\n",
      "Saved the embedding for cheesy.\n",
      "chesty is at index 7050\n",
      "Saved the embedding for chesty.\n",
      "chide is at index 1855\n",
      "Saved the embedding for chide.\n",
      "chiding is at index 1855\n",
      "Saved the embedding for chiding.\n",
      "childish is at index 40531\n",
      "Saved the embedding for childish.\n",
      "childishly is at index 920\n",
      "Saved the embedding for childishly.\n",
      "childlike is at index 920\n",
      "Saved the embedding for childlike.\n",
      "chill is at index 13146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for chill.\n",
      "chilled is at index 32338\n",
      "Saved the embedding for chilled.\n",
      "chilling is at index 22577\n",
      "Saved the embedding for chilling.\n",
      "chipper is at index 1855\n",
      "Saved the embedding for chipper.\n",
      "chirpy is at index 1855\n",
      "Saved the embedding for chirpy.\n",
      "choleric is at index 1855\n",
      "Saved the embedding for choleric.\n",
      "chortling is at index 1855\n",
      "Saved the embedding for chortling.\n",
      "chuckle is at index 37496\n",
      "Saved the embedding for chuckle.\n",
      "chuckling is at index 34600\n",
      "Saved the embedding for chuckling.\n",
      "churlish is at index 1855\n",
      "Saved the embedding for churlish.\n",
      "circumspect is at index 38529\n",
      "Saved the embedding for circumspect.\n",
      "clamorous is at index 24045\n",
      "Saved the embedding for clamorous.\n",
      "clash is at index 6064\n",
      "Saved the embedding for clash.\n",
      "clear is at index 699\n",
      "Saved the embedding for clear.\n",
      "clenched is at index 44646\n",
      "Saved the embedding for clenched.\n",
      "clever is at index 13074\n",
      "Saved the embedding for clever.\n",
      "close is at index 593\n",
      "Saved the embedding for close.\n",
      "closed is at index 1367\n",
      "Saved the embedding for closed.\n",
      "closemouthed is at index 593\n",
      "Saved the embedding for closemouthed.\n",
      "cloy is at index 3741\n",
      "Saved the embedding for cloy.\n",
      "clueless is at index 36776\n",
      "Saved the embedding for clueless.\n",
      "clutched is at index 29409\n",
      "Saved the embedding for clutched.\n",
      "cluttered is at index 29409\n",
      "Saved the embedding for cluttered.\n",
      "cockeyed is at index 740\n",
      "Saved the embedding for cockeyed.\n",
      "cockiness is at index 24231\n",
      "Saved the embedding for cockiness.\n",
      "cocksure is at index 740\n",
      "Saved the embedding for cocksure.\n",
      "cocky is at index 24231\n",
      "Saved the embedding for cocky.\n",
      "cognizant is at index 28105\n",
      "Saved the embedding for cognizant.\n",
      "cold is at index 2569\n",
      "Saved the embedding for cold.\n",
      "collected is at index 4786\n",
      "Saved the embedding for collected.\n",
      "collusive is at index 9843\n",
      "Saved the embedding for collusive.\n",
      "colonized is at index 17735\n",
      "Saved the embedding for colonized.\n",
      "combative is at index 14960\n",
      "Saved the embedding for combative.\n",
      "comedic is at index 29045\n",
      "Saved the embedding for comedic.\n",
      "comfort is at index 5863\n",
      "Saved the embedding for comfort.\n",
      "comfortable is at index 3473\n",
      "Saved the embedding for comfortable.\n",
      "comforted is at index 5863\n",
      "Saved the embedding for comforted.\n",
      "comical is at index 3137\n",
      "Saved the embedding for comical.\n",
      "commanding is at index 20510\n",
      "Saved the embedding for commanding.\n",
      "commiserating is at index 7034\n",
      "Saved the embedding for commiserating.\n",
      "commiserative is at index 7034\n",
      "Saved the embedding for commiserative.\n",
      "communicative is at index 16759\n",
      "Saved the embedding for communicative.\n",
      "compassion is at index 14736\n",
      "Saved the embedding for compassion.\n",
      "compassionate is at index 23303\n",
      "Saved the embedding for compassionate.\n",
      "competent is at index 17451\n",
      "Saved the embedding for competent.\n",
      "competitive is at index 2695\n",
      "Saved the embedding for competitive.\n",
      "complacence is at index 13000\n",
      "Saved the embedding for complacence.\n",
      "complacency is at index 13000\n",
      "Saved the embedding for complacency.\n",
      "complacent is at index 13000\n",
      "Saved the embedding for complacent.\n",
      "complacently is at index 13000\n",
      "Saved the embedding for complacently.\n",
      "complain is at index 11316\n",
      "Saved the embedding for complain.\n",
      "complaining is at index 13689\n",
      "Saved the embedding for complaining.\n",
      "composed is at index 14092\n",
      "Saved the embedding for composed.\n",
      "comprehending is at index 30030\n",
      "Saved the embedding for comprehending.\n",
      "compulsive is at index 7753\n",
      "Saved the embedding for compulsive.\n",
      "concealed is at index 17180\n",
      "Saved the embedding for concealed.\n",
      "conceding is at index 24647\n",
      "Saved the embedding for conceding.\n",
      "conceited is at index 21177\n",
      "Saved the embedding for conceited.\n",
      "concentrated is at index 15450\n",
      "Saved the embedding for concentrated.\n",
      "concentrating is at index 28619\n",
      "Saved the embedding for concentrating.\n",
      "concentration is at index 11772\n",
      "Saved the embedding for concentration.\n",
      "concern is at index 2212\n",
      "Saved the embedding for concern.\n",
      "concerned is at index 2273\n",
      "Saved the embedding for concerned.\n",
      "conciliatory is at index 10146\n",
      "Saved the embedding for conciliatory.\n",
      "conclusive is at index 37847\n",
      "Saved the embedding for conclusive.\n",
      "condemning is at index 21856\n",
      "Saved the embedding for condemning.\n",
      "condescending is at index 40742\n",
      "Saved the embedding for condescending.\n",
      "condoling is at index 35279\n",
      "Saved the embedding for condoling.\n",
      "confidence is at index 2123\n",
      "Saved the embedding for confidence.\n",
      "confident is at index 3230\n",
      "Saved the embedding for confident.\n",
      "confidently is at index 27447\n",
      "Saved the embedding for confidently.\n",
      "conflicted is at index 34428\n",
      "Saved the embedding for conflicted.\n",
      "confound is at index 7856\n",
      "Saved the embedding for confound.\n",
      "confounded is at index 7856\n",
      "Saved the embedding for confounded.\n",
      "confrontational is at index 10749\n",
      "Saved the embedding for confrontational.\n",
      "confused is at index 10985\n",
      "Saved the embedding for confused.\n",
      "confusion is at index 9655\n",
      "Saved the embedding for confusion.\n",
      "congenial is at index 36764\n",
      "Saved the embedding for congenial.\n",
      "congratulatory is at index 26303\n",
      "Saved the embedding for congratulatory.\n",
      "conniving is at index 39277\n",
      "Saved the embedding for conniving.\n",
      "conscious is at index 13316\n",
      "Saved the embedding for conscious.\n",
      "conservative is at index 3354\n",
      "Saved the embedding for conservative.\n",
      "considerate is at index 1701\n",
      "Saved the embedding for considerate.\n",
      "considering is at index 2811\n",
      "Saved the embedding for considering.\n",
      "consoling is at index 7407\n",
      "Saved the embedding for consoling.\n",
      "conspiratorial is at index 31150\n",
      "Saved the embedding for conspiratorial.\n",
      "conspiring is at index 27230\n",
      "Saved the embedding for conspiring.\n",
      "consternation is at index 10759\n",
      "Saved the embedding for consternation.\n",
      "constipated is at index 10759\n",
      "Saved the embedding for constipated.\n",
      "constrained is at index 26525\n",
      "Saved the embedding for constrained.\n",
      "consumed is at index 13056\n",
      "Saved the embedding for consumed.\n",
      "consuming is at index 16997\n",
      "Saved the embedding for consuming.\n",
      "contained is at index 5558\n",
      "Saved the embedding for contained.\n",
      "contemplate is at index 32848\n",
      "Saved the embedding for contemplate.\n",
      "contemplating is at index 27744\n",
      "Saved the embedding for contemplating.\n",
      "contemplation is at index 44072\n",
      "Saved the embedding for contemplation.\n",
      "contemplative is at index 43580\n",
      "Saved the embedding for contemplative.\n",
      "contempt is at index 16176\n",
      "Saved the embedding for contempt.\n",
      "contemptuous is at index 16176\n",
      "Saved the embedding for contemptuous.\n",
      "content is at index 1383\n",
      "Saved the embedding for content.\n",
      "contented is at index 1383\n",
      "Saved the embedding for contented.\n",
      "contentious is at index 14883\n",
      "Saved the embedding for contentious.\n",
      "contently is at index 8541\n",
      "Saved the embedding for contently.\n",
      "contentment is at index 1383\n",
      "Saved the embedding for contentment.\n",
      "contradictory is at index 31515\n",
      "Saved the embedding for contradictory.\n",
      "contrary is at index 11159\n",
      "Saved the embedding for contrary.\n",
      "contrite is at index 17035\n",
      "Saved the embedding for contrite.\n",
      "controlled is at index 4875\n",
      "Saved the embedding for controlled.\n",
      "controlling is at index 10568\n",
      "Saved the embedding for controlling.\n",
      "controversial is at index 4456\n",
      "Saved the embedding for controversial.\n",
      "contumacious is at index 8541\n",
      "Saved the embedding for contumacious.\n",
      "convinced is at index 7013\n",
      "Saved the embedding for convinced.\n",
      "cool is at index 3035\n",
      "Saved the embedding for cool.\n",
      "cooperative is at index 18777\n",
      "Saved the embedding for cooperative.\n",
      "cordial is at index 13051\n",
      "Saved the embedding for cordial.\n",
      "courageous is at index 24219\n",
      "Saved the embedding for courageous.\n",
      "covert is at index 25523\n",
      "Saved the embedding for covert.\n",
      "cowardly is at index 36881\n",
      "Saved the embedding for cowardly.\n",
      "coy is at index 20176\n",
      "Saved the embedding for coy.\n",
      "crabby is at index 23320\n",
      "Saved the embedding for crabby.\n",
      "crafty is at index 6306\n",
      "Saved the embedding for crafty.\n",
      "cranky is at index 30952\n",
      "Saved the embedding for cranky.\n",
      "crazed is at index 26002\n",
      "Saved the embedding for crazed.\n",
      "crazy is at index 5373\n",
      "Saved the embedding for crazy.\n",
      "credulous is at index 18994\n",
      "Saved the embedding for credulous.\n",
      "creepy is at index 23814\n",
      "Saved the embedding for creepy.\n",
      "crestfallen is at index 32220\n",
      "Saved the embedding for crestfallen.\n",
      "cringing is at index 3977\n",
      "Saved the embedding for cringing.\n",
      "critical is at index 2008\n",
      "Saved the embedding for critical.\n",
      "cross is at index 2116\n",
      "Saved the embedding for cross.\n",
      "crotchety is at index 11398\n",
      "Saved the embedding for crotchety.\n",
      "crude is at index 2976\n",
      "Saved the embedding for crude.\n",
      "cruel is at index 15939\n",
      "Saved the embedding for cruel.\n",
      "crushed is at index 14045\n",
      "Saved the embedding for crushed.\n",
      "cry is at index 8930\n",
      "Saved the embedding for cry.\n",
      "crying is at index 9701\n",
      "Saved the embedding for crying.\n",
      "cryptic is at index 35916\n",
      "Saved the embedding for cryptic.\n",
      "culpable is at index 29410\n",
      "Saved the embedding for culpable.\n",
      "cunning is at index 41526\n",
      "Saved the embedding for cunning.\n",
      "curios is at index 5350\n",
      "Saved the embedding for curios.\n",
      "curiosity is at index 20610\n",
      "Saved the embedding for curiosity.\n",
      "curious is at index 10691\n",
      "Saved the embedding for curious.\n",
      "cutting is at index 3931\n",
      "Saved the embedding for cutting.\n",
      "cynic is at index 40240\n",
      "Saved the embedding for cynic.\n",
      "cynical is at index 27566\n",
      "Saved the embedding for cynical.\n",
      "cynicism is at index 39245\n",
      "Saved the embedding for cynicism.\n",
      "dalliance is at index 385\n",
      "Saved the embedding for dalliance.\n",
      "dandy is at index 385\n",
      "Saved the embedding for dandy.\n",
      "dangerous is at index 2702\n",
      "Saved the embedding for dangerous.\n",
      "darkly is at index 2933\n",
      "Saved the embedding for darkly.\n",
      "daunted is at index 385\n",
      "Saved the embedding for daunted.\n",
      "daydream is at index 183\n",
      "Saved the embedding for daydream.\n",
      "daydreaming is at index 183\n",
      "Saved the embedding for daydreaming.\n",
      "dazed is at index 385\n",
      "Saved the embedding for dazed.\n",
      "dazzled is at index 32614\n",
      "Saved the embedding for dazzled.\n",
      "deadly is at index 4847\n",
      "Saved the embedding for deadly.\n",
      "deadpan is at index 1462\n",
      "Saved the embedding for deadpan.\n",
      "debate is at index 2625\n",
      "Saved the embedding for debate.\n",
      "debating is at index 24996\n",
      "Saved the embedding for debating.\n",
      "debauched is at index 10189\n",
      "Saved the embedding for debauched.\n",
      "deceitful is at index 35049\n",
      "Saved the embedding for deceitful.\n",
      "deceived is at index 38079\n",
      "Saved the embedding for deceived.\n",
      "deceiving is at index 34575\n",
      "Saved the embedding for deceiving.\n",
      "deceivingly is at index 34575\n",
      "Saved the embedding for deceivingly.\n",
      "deception is at index 29244\n",
      "Saved the embedding for deception.\n",
      "deceptive is at index 31405\n",
      "Saved the embedding for deceptive.\n",
      "deciding is at index 8997\n",
      "Saved the embedding for deciding.\n",
      "decisive is at index 12703\n",
      "Saved the embedding for decisive.\n",
      "dedicated is at index 3688\n",
      "Saved the embedding for dedicated.\n",
      "defeat is at index 3002\n",
      "Saved the embedding for defeat.\n",
      "defeated is at index 5125\n",
      "Saved the embedding for defeated.\n",
      "defenseless is at index 3816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for defenseless.\n",
      "defensive is at index 2465\n",
      "Saved the embedding for defensive.\n",
      "defiance is at index 25442\n",
      "Saved the embedding for defiance.\n",
      "defiant is at index 23802\n",
      "Saved the embedding for defiant.\n",
      "deflated is at index 3816\n",
      "Saved the embedding for deflated.\n",
      "degage is at index 31295\n",
      "Saved the embedding for degage.\n",
      "degrading is at index 36892\n",
      "Saved the embedding for degrading.\n",
      "dejected is at index 263\n",
      "Saved the embedding for dejected.\n",
      "dejection is at index 263\n",
      "Saved the embedding for dejection.\n",
      "deliberate is at index 14775\n",
      "Saved the embedding for deliberate.\n",
      "deliberating is at index 21614\n",
      "Saved the embedding for deliberating.\n",
      "delight is at index 13213\n",
      "Saved the embedding for delight.\n",
      "delighted is at index 7808\n",
      "Saved the embedding for delighted.\n",
      "delightful is at index 24897\n",
      "Saved the embedding for delightful.\n",
      "delirious is at index 2424\n",
      "Saved the embedding for delirious.\n",
      "delirium is at index 2424\n",
      "Saved the embedding for delirium.\n",
      "delude is at index 2424\n",
      "Saved the embedding for delude.\n",
      "delusional is at index 40160\n",
      "Saved the embedding for delusional.\n",
      "demanding is at index 5783\n",
      "Saved the embedding for demanding.\n",
      "demeaning is at index 4410\n",
      "Saved the embedding for demeaning.\n",
      "demented is at index 44202\n",
      "Saved the embedding for demented.\n",
      "demised is at index 4410\n",
      "Saved the embedding for demised.\n",
      "demoralized is at index 36810\n",
      "Saved the embedding for demoralized.\n",
      "demure is at index 4410\n",
      "Saved the embedding for demure.\n",
      "denied is at index 2296\n",
      "Saved the embedding for denied.\n",
      "denouncing is at index 32439\n",
      "Saved the embedding for denouncing.\n",
      "depleted is at index 26391\n",
      "Saved the embedding for depleted.\n",
      "deplorable is at index 28156\n",
      "Saved the embedding for deplorable.\n",
      "deprecating is at index 8273\n",
      "Saved the embedding for deprecating.\n",
      "depressed is at index 16658\n",
      "Saved the embedding for depressed.\n",
      "depression is at index 6943\n",
      "Saved the embedding for depression.\n",
      "deprived is at index 22632\n",
      "Saved the embedding for deprived.\n",
      "deranged is at index 1935\n",
      "Saved the embedding for deranged.\n",
      "derision is at index 1935\n",
      "Saved the embedding for derision.\n",
      "derisive is at index 1935\n",
      "Saved the embedding for derisive.\n",
      "derogatory is at index 30971\n",
      "Saved the embedding for derogatory.\n",
      "desire is at index 4724\n",
      "Saved the embedding for desire.\n",
      "desiring is at index 2694\n",
      "Saved the embedding for desiring.\n",
      "desirous is at index 2694\n",
      "Saved the embedding for desirous.\n",
      "desolate is at index 43177\n",
      "Saved the embedding for desolate.\n",
      "despair is at index 21508\n",
      "Saved the embedding for despair.\n",
      "despaired is at index 2694\n",
      "Saved the embedding for despaired.\n",
      "despairing is at index 21508\n",
      "Saved the embedding for despairing.\n",
      "desperate is at index 7764\n",
      "Saved the embedding for desperate.\n",
      "desperation is at index 24278\n",
      "Saved the embedding for desperation.\n",
      "despise is at index 43255\n",
      "Saved the embedding for despise.\n",
      "despondent is at index 18690\n",
      "Saved the embedding for despondent.\n",
      "destitute is at index 15357\n",
      "Saved the embedding for destitute.\n",
      "destroyed is at index 4957\n",
      "Saved the embedding for destroyed.\n",
      "detached is at index 27687\n",
      "Saved the embedding for detached.\n",
      "determination is at index 8964\n",
      "Saved the embedding for determination.\n",
      "determined is at index 3030\n",
      "Saved the embedding for determined.\n",
      "determining is at index 13684\n",
      "Saved the embedding for determining.\n",
      "deterred is at index 10922\n",
      "Saved the embedding for deterred.\n",
      "detest is at index 6769\n",
      "Saved the embedding for detest.\n",
      "detestable is at index 6769\n",
      "Saved the embedding for detestable.\n",
      "detesting is at index 6769\n",
      "Saved the embedding for detesting.\n",
      "detriment is at index 31969\n",
      "Saved the embedding for detriment.\n",
      "devastated is at index 11521\n",
      "Saved the embedding for devastated.\n",
      "deviant is at index 8709\n",
      "Saved the embedding for deviant.\n",
      "devilish is at index 22406\n",
      "Saved the embedding for devilish.\n",
      "devious is at index 263\n",
      "Saved the embedding for devious.\n",
      "devising is at index 8709\n",
      "Saved the embedding for devising.\n",
      "diffident is at index 25871\n",
      "Saved the embedding for diffident.\n",
      "dilatory is at index 14632\n",
      "Saved the embedding for dilatory.\n",
      "diligent is at index 33721\n",
      "Saved the embedding for diligent.\n",
      "dimwitted is at index 14548\n",
      "Saved the embedding for dimwitted.\n",
      "dire is at index 10697\n",
      "Saved the embedding for dire.\n",
      "disagree is at index 11967\n",
      "Saved the embedding for disagree.\n",
      "disagreeable is at index 11967\n",
      "Saved the embedding for disagreeable.\n",
      "disagreement is at index 20628\n",
      "Saved the embedding for disagreement.\n",
      "disappointed is at index 5779\n",
      "Saved the embedding for disappointed.\n",
      "disappointing is at index 6770\n",
      "Saved the embedding for disappointing.\n",
      "disappointment is at index 10208\n",
      "Saved the embedding for disappointment.\n",
      "disapproval is at index 32129\n",
      "Saved the embedding for disapproval.\n",
      "disapproving is at index 36631\n",
      "Saved the embedding for disapproving.\n",
      "disbelief is at index 26440\n",
      "Saved the embedding for disbelief.\n",
      "disbelieve is at index 45668\n",
      "Saved the embedding for disbelieve.\n",
      "disbelieving is at index 45668\n",
      "Saved the embedding for disbelieving.\n",
      "discerning is at index 9553\n",
      "Saved the embedding for discerning.\n",
      "discombobulated is at index 2982\n",
      "Saved the embedding for discombobulated.\n",
      "discomfited is at index 2982\n",
      "Saved the embedding for discomfited.\n",
      "discomfort is at index 19535\n",
      "Saved the embedding for discomfort.\n",
      "discomforted is at index 19535\n",
      "Saved the embedding for discomforted.\n",
      "disconcerted is at index 2982\n",
      "Saved the embedding for disconcerted.\n",
      "disconnected is at index 30005\n",
      "Saved the embedding for disconnected.\n",
      "disconsolate is at index 9553\n",
      "Saved the embedding for disconsolate.\n",
      "discontent is at index 27478\n",
      "Saved the embedding for discontent.\n",
      "discontented is at index 47772\n",
      "Saved the embedding for discontented.\n",
      "discounted is at index 17533\n",
      "Saved the embedding for discounted.\n",
      "discouraged is at index 25788\n",
      "Saved the embedding for discouraged.\n",
      "discovery is at index 6953\n",
      "Saved the embedding for discovery.\n",
      "discriminating is at index 38303\n",
      "Saved the embedding for discriminating.\n",
      "discussed is at index 3373\n",
      "Saved the embedding for discussed.\n",
      "disdain is at index 29512\n",
      "Saved the embedding for disdain.\n",
      "disdained is at index 2982\n",
      "Saved the embedding for disdained.\n",
      "disdainful is at index 29512\n",
      "Saved the embedding for disdainful.\n",
      "disdainfully is at index 29512\n",
      "Saved the embedding for disdainfully.\n",
      "disenchanted is at index 2982\n",
      "Saved the embedding for disenchanted.\n",
      "disengaged is at index 35170\n",
      "Saved the embedding for disengaged.\n",
      "disgraced is at index 25425\n",
      "Saved the embedding for disgraced.\n",
      "disgruntled is at index 29412\n",
      "Saved the embedding for disgruntled.\n",
      "disgruntlement is at index 25425\n",
      "Saved the embedding for disgruntlement.\n",
      "disgust is at index 30883\n",
      "Saved the embedding for disgust.\n",
      "disgusted is at index 32759\n",
      "Saved the embedding for disgusted.\n",
      "disgustedly is at index 32759\n",
      "Saved the embedding for disgustedly.\n",
      "disgusting is at index 21096\n",
      "Saved the embedding for disgusting.\n",
      "disheartened is at index 2982\n",
      "Saved the embedding for disheartened.\n",
      "dishonest is at index 27820\n",
      "Saved the embedding for dishonest.\n",
      "disillusioned is at index 33447\n",
      "Saved the embedding for disillusioned.\n",
      "disinclined is at index 2982\n",
      "Saved the embedding for disinclined.\n",
      "disingenuous is at index 39622\n",
      "Saved the embedding for disingenuous.\n",
      "disinterest is at index 2982\n",
      "Saved the embedding for disinterest.\n",
      "disinterested is at index 2982\n",
      "Saved the embedding for disinterested.\n",
      "disjointed is at index 2982\n",
      "Saved the embedding for disjointed.\n",
      "dislike is at index 28101\n",
      "Saved the embedding for dislike.\n",
      "disliked is at index 40891\n",
      "Saved the embedding for disliked.\n",
      "disliking is at index 19131\n",
      "Saved the embedding for disliking.\n",
      "dismal is at index 23446\n",
      "Saved the embedding for dismal.\n",
      "disman is at index 2982\n",
      "Saved the embedding for disman.\n",
      "dismay is at index 22135\n",
      "Saved the embedding for dismay.\n",
      "dismayed is at index 22135\n",
      "Saved the embedding for dismayed.\n",
      "dismissive is at index 37890\n",
      "Saved the embedding for dismissive.\n",
      "disobedient is at index 43738\n",
      "Saved the embedding for disobedient.\n",
      "disorderly is at index 23547\n",
      "Saved the embedding for disorderly.\n",
      "disoriented is at index 2982\n",
      "Saved the embedding for disoriented.\n",
      "dispair is at index 11734\n",
      "Saved the embedding for dispair.\n",
      "disparaging is at index 24331\n",
      "Saved the embedding for disparaging.\n",
      "dispassionate is at index 11734\n",
      "Saved the embedding for dispassionate.\n",
      "dispirited is at index 2982\n",
      "Saved the embedding for dispirited.\n",
      "dispiritedness is at index 2982\n",
      "Saved the embedding for dispiritedness.\n",
      "displeased is at index 43709\n",
      "Saved the embedding for displeased.\n",
      "displeasure is at index 30201\n",
      "Saved the embedding for displeasure.\n",
      "disquiet is at index 2982\n",
      "Saved the embedding for disquiet.\n",
      "disquieted is at index 2982\n",
      "Saved the embedding for disquieted.\n",
      "disregard is at index 21034\n",
      "Saved the embedding for disregard.\n",
      "disrespectful is at index 26401\n",
      "Saved the embedding for disrespectful.\n",
      "disrupted is at index 15902\n",
      "Saved the embedding for disrupted.\n",
      "disruptive is at index 17561\n",
      "Saved the embedding for disruptive.\n",
      "dissatisfaction is at index 31776\n",
      "Saved the embedding for dissatisfaction.\n",
      "dissatisfied is at index 37278\n",
      "Saved the embedding for dissatisfied.\n",
      "dissatisfy is at index 48830\n",
      "Saved the embedding for dissatisfy.\n",
      "dissecting is at index 33562\n",
      "Saved the embedding for dissecting.\n",
      "dissociated is at index 14863\n",
      "Saved the embedding for dissociated.\n",
      "dissonant is at index 43162\n",
      "Saved the embedding for dissonant.\n",
      "distain is at index 7018\n",
      "Saved the embedding for distain.\n",
      "distant is at index 13258\n",
      "Saved the embedding for distant.\n",
      "distaste is at index 7018\n",
      "Saved the embedding for distaste.\n",
      "distasteful is at index 7018\n",
      "Saved the embedding for distasteful.\n",
      "distracted is at index 16573\n",
      "Saved the embedding for distracted.\n",
      "distraught is at index 30719\n",
      "Saved the embedding for distraught.\n",
      "distress is at index 13250\n",
      "Saved the embedding for distress.\n",
      "distressed is at index 21460\n",
      "Saved the embedding for distressed.\n",
      "distressing is at index 7018\n",
      "Saved the embedding for distressing.\n",
      "distrust is at index 27948\n",
      "Saved the embedding for distrust.\n",
      "distrustful is at index 27948\n",
      "Saved the embedding for distrustful.\n",
      "distrusting is at index 27948\n",
      "Saved the embedding for distrusting.\n",
      "disturbed is at index 22938\n",
      "Saved the embedding for disturbed.\n",
      "diverted is at index 19070\n",
      "Saved the embedding for diverted.\n",
      "dodgy is at index 25744\n",
      "Saved the embedding for dodgy.\n",
      "doleful is at index 109\n",
      "Saved the embedding for doleful.\n",
      "doltish is at index 385\n",
      "Saved the embedding for doltish.\n",
      "dominant is at index 7353\n",
      "Saved the embedding for dominant.\n",
      "dominating is at index 17349\n",
      "Saved the embedding for dominating.\n",
      "domineering is at index 13567\n",
      "Saved the embedding for domineering.\n",
      "done is at index 626\n",
      "Saved the embedding for done.\n",
      "doomed is at index 23326\n",
      "Saved the embedding for doomed.\n",
      "dopey is at index 32331\n",
      "Saved the embedding for dopey.\n",
      "doting is at index 385\n",
      "Saved the embedding for doting.\n",
      "doubt is at index 2980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for doubt.\n",
      "doubter is at index 26463\n",
      "Saved the embedding for doubter.\n",
      "doubtful is at index 26645\n",
      "Saved the embedding for doubtful.\n",
      "doubtfully is at index 2980\n",
      "Saved the embedding for doubtfully.\n",
      "doubtfulness is at index 2980\n",
      "Saved the embedding for doubtfulness.\n",
      "doubting is at index 26463\n",
      "Saved the embedding for doubting.\n",
      "dour is at index 385\n",
      "Saved the embedding for dour.\n",
      "down is at index 159\n",
      "Saved the embedding for down.\n",
      "downcast is at index 159\n",
      "Saved the embedding for downcast.\n",
      "downhearted is at index 159\n",
      "Saved the embedding for downhearted.\n",
      "downheartedness is at index 159\n",
      "Saved the embedding for downheartedness.\n",
      "downtrodden is at index 29407\n",
      "Saved the embedding for downtrodden.\n",
      "dozing is at index 109\n",
      "Saved the embedding for dozing.\n",
      "drained is at index 23544\n",
      "Saved the embedding for drained.\n",
      "dramatic is at index 5386\n",
      "Saved the embedding for dramatic.\n",
      "drawn is at index 4777\n",
      "Saved the embedding for drawn.\n",
      "dread is at index 24506\n",
      "Saved the embedding for dread.\n",
      "dreadful is at index 31715\n",
      "Saved the embedding for dreadful.\n",
      "dreading is at index 24506\n",
      "Saved the embedding for dreading.\n",
      "dreaming is at index 26240\n",
      "Saved the embedding for dreaming.\n",
      "dreamy is at index 3366\n",
      "Saved the embedding for dreamy.\n",
      "dreary is at index 385\n",
      "Saved the embedding for dreary.\n",
      "driven is at index 3185\n",
      "Saved the embedding for driven.\n",
      "drowsy is at index 385\n",
      "Saved the embedding for drowsy.\n",
      "drugged is at index 385\n",
      "Saved the embedding for drugged.\n",
      "drunk is at index 10789\n",
      "Saved the embedding for drunk.\n",
      "drunkenness is at index 19835\n",
      "Saved the embedding for drunkenness.\n",
      "dubiety is at index 30180\n",
      "Saved the embedding for dubiety.\n",
      "dubious is at index 24381\n",
      "Saved the embedding for dubious.\n",
      "dubiously is at index 30180\n",
      "Saved the embedding for dubiously.\n",
      "dull is at index 22018\n",
      "Saved the embedding for dull.\n",
      "dumb is at index 16881\n",
      "Saved the embedding for dumb.\n",
      "dumbfound is at index 16881\n",
      "Saved the embedding for dumbfound.\n",
      "dumbfounded is at index 16881\n",
      "Saved the embedding for dumbfounded.\n",
      "dumbstruck is at index 16881\n",
      "Saved the embedding for dumbstruck.\n",
      "dumfounded is at index 385\n",
      "Saved the embedding for dumfounded.\n",
      "dupe is at index 4279\n",
      "Saved the embedding for dupe.\n",
      "duplicitous is at index 30501\n",
      "Saved the embedding for duplicitous.\n",
      "dysphoric is at index 44153\n",
      "Saved the embedding for dysphoric.\n",
      "eager is at index 7921\n",
      "Saved the embedding for eager.\n",
      "eagerness is at index 7921\n",
      "Saved the embedding for eagerness.\n",
      "earnest is at index 22623\n",
      "Saved the embedding for earnest.\n",
      "easy is at index 1365\n",
      "Saved the embedding for easy.\n",
      "ebullient is at index 364\n",
      "Saved the embedding for ebullient.\n",
      "ecstasy is at index 37695\n",
      "Saved the embedding for ecstasy.\n",
      "ecstatic is at index 30754\n",
      "Saved the embedding for ecstatic.\n",
      "ecstatically is at index 20508\n",
      "Saved the embedding for ecstatically.\n",
      "edgy is at index 4803\n",
      "Saved the embedding for edgy.\n",
      "eerie is at index 33960\n",
      "Saved the embedding for eerie.\n",
      "effulgent is at index 22089\n",
      "Saved the embedding for effulgent.\n",
      "egoistic is at index 21450\n",
      "Saved the embedding for egoistic.\n",
      "egotistical is at index 364\n",
      "Saved the embedding for egotistical.\n",
      "egregious is at index 28971\n",
      "Saved the embedding for egregious.\n",
      "elated is at index 1615\n",
      "Saved the embedding for elated.\n",
      "elation is at index 1615\n",
      "Saved the embedding for elation.\n",
      "electrified is at index 17995\n",
      "Saved the embedding for electrified.\n",
      "elusive is at index 21483\n",
      "Saved the embedding for elusive.\n",
      "embarrassed is at index 17319\n",
      "Saved the embedding for embarrassed.\n",
      "embarrassment is at index 19124\n",
      "Saved the embedding for embarrassment.\n",
      "embittered is at index 2841\n",
      "Saved the embedding for embittered.\n",
      "embody is at index 33865\n",
      "Saved the embedding for embody.\n",
      "emotional is at index 3722\n",
      "Saved the embedding for emotional.\n",
      "emotionless is at index 11926\n",
      "Saved the embedding for emotionless.\n",
      "empathetic is at index 2841\n",
      "Saved the embedding for empathetic.\n",
      "empathic is at index 2841\n",
      "Saved the embedding for empathic.\n",
      "empathy is at index 17805\n",
      "Saved the embedding for empathy.\n",
      "emptiness is at index 44480\n",
      "Saved the embedding for emptiness.\n",
      "empty is at index 5802\n",
      "Saved the embedding for empty.\n",
      "enamored is at index 1177\n",
      "Saved the embedding for enamored.\n",
      "enchanted is at index 44141\n",
      "Saved the embedding for enchanted.\n",
      "encouraged is at index 4446\n",
      "Saved the embedding for encouraged.\n",
      "encouragement is at index 18197\n",
      "Saved the embedding for encouragement.\n",
      "encouraging is at index 5513\n",
      "Saved the embedding for encouraging.\n",
      "endeared is at index 253\n",
      "Saved the embedding for endeared.\n",
      "endearing is at index 253\n",
      "Saved the embedding for endearing.\n",
      "enduring is at index 16480\n",
      "Saved the embedding for enduring.\n",
      "energetic is at index 20425\n",
      "Saved the embedding for energetic.\n",
      "energized is at index 15957\n",
      "Saved the embedding for energized.\n",
      "engaged is at index 4009\n",
      "Saved the embedding for engaged.\n",
      "engrossed is at index 20407\n",
      "Saved the embedding for engrossed.\n",
      "engrossment is at index 20407\n",
      "Saved the embedding for engrossment.\n",
      "enigmatic is at index 38910\n",
      "Saved the embedding for enigmatic.\n",
      "enjoy is at index 2254\n",
      "Saved the embedding for enjoy.\n",
      "enjoying is at index 6218\n",
      "Saved the embedding for enjoying.\n",
      "enjoyment is at index 26611\n",
      "Saved the embedding for enjoyment.\n",
      "enlightened is at index 38853\n",
      "Saved the embedding for enlightened.\n",
      "enmity is at index 1177\n",
      "Saved the embedding for enmity.\n",
      "ennui is at index 1177\n",
      "Saved the embedding for ennui.\n",
      "enraged is at index 33415\n",
      "Saved the embedding for enraged.\n",
      "enraging is at index 1177\n",
      "Saved the embedding for enraging.\n",
      "enraptured is at index 1177\n",
      "Saved the embedding for enraptured.\n",
      "entertained is at index 23979\n",
      "Saved the embedding for entertained.\n",
      "enthralled is at index 3838\n",
      "Saved the embedding for enthralled.\n",
      "enthused is at index 3838\n",
      "Saved the embedding for enthused.\n",
      "enthusiasm is at index 11240\n",
      "Saved the embedding for enthusiasm.\n",
      "enthusiastic is at index 15947\n",
      "Saved the embedding for enthusiastic.\n",
      "enticed is at index 3838\n",
      "Saved the embedding for enticed.\n",
      "entranced is at index 3838\n",
      "Saved the embedding for entranced.\n",
      "envious is at index 1177\n",
      "Saved the embedding for envious.\n",
      "envy is at index 29778\n",
      "Saved the embedding for envy.\n",
      "erotically is at index 3335\n",
      "Saved the embedding for erotically.\n",
      "estranged is at index 20599\n",
      "Saved the embedding for estranged.\n",
      "etched is at index 35542\n",
      "Saved the embedding for etched.\n",
      "euphoric is at index 30882\n",
      "Saved the embedding for euphoric.\n",
      "evaluating is at index 15190\n",
      "Saved the embedding for evaluating.\n",
      "evasive is at index 7630\n",
      "Saved the embedding for evasive.\n",
      "evil is at index 9247\n",
      "Saved the embedding for evil.\n",
      "evoke is at index 35334\n",
      "Saved the embedding for evoke.\n",
      "exacerbated is at index 24961\n",
      "Saved the embedding for exacerbated.\n",
      "exalted is at index 45514\n",
      "Saved the embedding for exalted.\n",
      "examining is at index 14951\n",
      "Saved the embedding for examining.\n",
      "exasperate is at index 1931\n",
      "Saved the embedding for exasperate.\n",
      "exasperated is at index 34698\n",
      "Saved the embedding for exasperated.\n",
      "exasperation is at index 34698\n",
      "Saved the embedding for exasperation.\n",
      "excited is at index 2283\n",
      "Saved the embedding for excited.\n",
      "excitedly is at index 2283\n",
      "Saved the embedding for excitedly.\n",
      "excitement is at index 8354\n",
      "Saved the embedding for excitement.\n",
      "exclamation is at index 1931\n",
      "Saved the embedding for exclamation.\n",
      "exclamatory is at index 1931\n",
      "Saved the embedding for exclamatory.\n",
      "exhausted is at index 17067\n",
      "Saved the embedding for exhausted.\n",
      "exhaustion is at index 30567\n",
      "Saved the embedding for exhaustion.\n",
      "exhaustive is at index 29180\n",
      "Saved the embedding for exhaustive.\n",
      "exhilarated is at index 32749\n",
      "Saved the embedding for exhilarated.\n",
      "exhilaration is at index 32749\n",
      "Saved the embedding for exhilaration.\n",
      "exited is at index 17469\n",
      "Saved the embedding for exited.\n",
      "expectant is at index 1057\n",
      "Saved the embedding for expectant.\n",
      "expectation is at index 9250\n",
      "Saved the embedding for expectation.\n",
      "expecting is at index 4804\n",
      "Saved the embedding for expecting.\n",
      "explain is at index 3922\n",
      "Saved the embedding for explain.\n",
      "explaining is at index 8926\n",
      "Saved the embedding for explaining.\n",
      "exploitive is at index 38984\n",
      "Saved the embedding for exploitive.\n",
      "explosive is at index 8560\n",
      "Saved the embedding for explosive.\n",
      "exposure is at index 4895\n",
      "Saved the embedding for exposure.\n",
      "expressive is at index 36340\n",
      "Saved the embedding for expressive.\n",
      "exuberant is at index 1931\n",
      "Saved the embedding for exuberant.\n",
      "exultant is at index 1931\n",
      "Saved the embedding for exultant.\n",
      "exulted is at index 1931\n",
      "Saved the embedding for exulted.\n",
      "eye is at index 2295\n",
      "Saved the embedding for eye.\n",
      "eyed is at index 36235\n",
      "Saved the embedding for eyed.\n",
      "faced is at index 2713\n",
      "Saved the embedding for faced.\n",
      "facetious is at index 34407\n",
      "Saved the embedding for facetious.\n",
      "failure is at index 2988\n",
      "Saved the embedding for failure.\n",
      "faint is at index 27922\n",
      "Saved the embedding for faint.\n",
      "fair is at index 2105\n",
      "Saved the embedding for fair.\n",
      "fake is at index 4486\n",
      "Saved the embedding for fake.\n",
      "faking is at index 856\n",
      "Saved the embedding for faking.\n",
      "falter is at index 14848\n",
      "Saved the embedding for falter.\n",
      "famished is at index 13403\n",
      "Saved the embedding for famished.\n",
      "fanatic is at index 38604\n",
      "Saved the embedding for fanatic.\n",
      "fanciful is at index 33639\n",
      "Saved the embedding for fanciful.\n",
      "fart is at index 36762\n",
      "Saved the embedding for fart.\n",
      "fascinated is at index 27025\n",
      "Saved the embedding for fascinated.\n",
      "fastidious is at index 1769\n",
      "Saved the embedding for fastidious.\n",
      "fatigue is at index 16069\n",
      "Saved the embedding for fatigue.\n",
      "fatigued is at index 36239\n",
      "Saved the embedding for fatigued.\n",
      "faultfinding is at index 7684\n",
      "Saved the embedding for faultfinding.\n",
      "favorable is at index 9879\n",
      "Saved the embedding for favorable.\n",
      "fawning is at index 856\n",
      "Saved the embedding for fawning.\n",
      "fazed is at index 856\n",
      "Saved the embedding for fazed.\n",
      "fear is at index 2490\n",
      "Saved the embedding for fear.\n",
      "feared is at index 9741\n",
      "Saved the embedding for feared.\n",
      "fearful is at index 23526\n",
      "Saved the embedding for fearful.\n",
      "fearing is at index 21510\n",
      "Saved the embedding for fearing.\n",
      "fearless is at index 29107\n",
      "Saved the embedding for fearless.\n",
      "fearsome is at index 39185\n",
      "Saved the embedding for fearsome.\n",
      "feckless is at index 10668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for feckless.\n",
      "fed is at index 9789\n",
      "Saved the embedding for fed.\n",
      "feeble is at index 42217\n",
      "Saved the embedding for feeble.\n",
      "feign is at index 10668\n",
      "Saved the embedding for feign.\n",
      "felicitous is at index 14383\n",
      "Saved the embedding for felicitous.\n",
      "ferocious is at index 31429\n",
      "Saved the embedding for ferocious.\n",
      "ferocity is at index 16022\n",
      "Saved the embedding for ferocity.\n",
      "festive is at index 12298\n",
      "Saved the embedding for festive.\n",
      "fidgety is at index 856\n",
      "Saved the embedding for fidgety.\n",
      "fiendish is at index 13383\n",
      "Saved the embedding for fiendish.\n",
      "fierce is at index 11039\n",
      "Saved the embedding for fierce.\n",
      "fiery is at index 19068\n",
      "Saved the embedding for fiery.\n",
      "fighting is at index 2190\n",
      "Saved the embedding for fighting.\n",
      "fine is at index 2051\n",
      "Saved the embedding for fine.\n",
      "finished is at index 1550\n",
      "Saved the embedding for finished.\n",
      "firm is at index 933\n",
      "Saved the embedding for firm.\n",
      "fishy is at index 3539\n",
      "Saved the embedding for fishy.\n",
      "fixated is at index 4190\n",
      "Saved the embedding for fixated.\n",
      "fixed is at index 4460\n",
      "Saved the embedding for fixed.\n",
      "flabbergasted is at index 2342\n",
      "Saved the embedding for flabbergasted.\n",
      "flaming is at index 37222\n",
      "Saved the embedding for flaming.\n",
      "flat is at index 3269\n",
      "Saved the embedding for flat.\n",
      "flaunting is at index 2342\n",
      "Saved the embedding for flaunting.\n",
      "flighty is at index 2524\n",
      "Saved the embedding for flighty.\n",
      "flippant is at index 2342\n",
      "Saved the embedding for flippant.\n",
      "flipped is at index 18626\n",
      "Saved the embedding for flipped.\n",
      "flirtation is at index 33743\n",
      "Saved the embedding for flirtation.\n",
      "flirtatious is at index 33743\n",
      "Saved the embedding for flirtatious.\n",
      "flirty is at index 2342\n",
      "Saved the embedding for flirty.\n",
      "floored is at index 27325\n",
      "Saved the embedding for floored.\n",
      "flummoxed is at index 2342\n",
      "Saved the embedding for flummoxed.\n",
      "flustered is at index 2342\n",
      "Saved the embedding for flustered.\n",
      "focus is at index 1056\n",
      "Saved the embedding for focus.\n",
      "focused is at index 2061\n",
      "Saved the embedding for focused.\n",
      "focusing is at index 5650\n",
      "Saved the embedding for focusing.\n",
      "foiled is at index 9565\n",
      "Saved the embedding for foiled.\n",
      "foolish is at index 22789\n",
      "Saved the embedding for foolish.\n",
      "forbearing is at index 34550\n",
      "Saved the embedding for forbearing.\n",
      "forbidding is at index 34550\n",
      "Saved the embedding for forbidding.\n",
      "forced is at index 1654\n",
      "Saved the embedding for forced.\n",
      "forceful is at index 32165\n",
      "Saved the embedding for forceful.\n",
      "forfeited is at index 31844\n",
      "Saved the embedding for forfeited.\n",
      "forlorn is at index 13\n",
      "Saved the embedding for forlorn.\n",
      "fortunate is at index 10583\n",
      "Saved the embedding for fortunate.\n",
      "forward is at index 556\n",
      "Saved the embedding for forward.\n",
      "foul is at index 6962\n",
      "Saved the embedding for foul.\n",
      "fractious is at index 38251\n",
      "Saved the embedding for fractious.\n",
      "fragile is at index 14283\n",
      "Saved the embedding for fragile.\n",
      "frantic is at index 27396\n",
      "Saved the embedding for frantic.\n",
      "fraudulent is at index 15381\n",
      "Saved the embedding for fraudulent.\n",
      "fraught is at index 25481\n",
      "Saved the embedding for fraught.\n",
      "frazzled is at index 26830\n",
      "Saved the embedding for frazzled.\n",
      "freaked is at index 7619\n",
      "Saved the embedding for freaked.\n",
      "frenzied is at index 26908\n",
      "Saved the embedding for frenzied.\n",
      "fretful is at index 31391\n",
      "Saved the embedding for fretful.\n",
      "friendliness is at index 1441\n",
      "Saved the embedding for friendliness.\n",
      "friendly is at index 5192\n",
      "Saved the embedding for friendly.\n",
      "fright is at index 32580\n",
      "Saved the embedding for fright.\n",
      "frightened is at index 26851\n",
      "Saved the embedding for frightened.\n",
      "frightening is at index 21111\n",
      "Saved the embedding for frightening.\n",
      "frigid is at index 25805\n",
      "Saved the embedding for frigid.\n",
      "frisky is at index 6664\n",
      "Saved the embedding for frisky.\n",
      "frolicker is at index 856\n",
      "Saved the embedding for frolicker.\n",
      "frown is at index 41588\n",
      "Saved the embedding for frown.\n",
      "frowning is at index 41588\n",
      "Saved the embedding for frowning.\n",
      "frozen is at index 9214\n",
      "Saved the embedding for frozen.\n",
      "frumpy is at index 6664\n",
      "Saved the embedding for frumpy.\n",
      "frustrated is at index 8164\n",
      "Saved the embedding for frustrated.\n",
      "frustration is at index 8413\n",
      "Saved the embedding for frustration.\n",
      "fulfilled is at index 20218\n",
      "Saved the embedding for fulfilled.\n",
      "fumed is at index 856\n",
      "Saved the embedding for fumed.\n",
      "fuming is at index 856\n",
      "Saved the embedding for fuming.\n",
      "fun is at index 1531\n",
      "Saved the embedding for fun.\n",
      "funny is at index 6269\n",
      "Saved the embedding for funny.\n",
      "furious is at index 15940\n",
      "Saved the embedding for furious.\n",
      "furiously is at index 39202\n",
      "Saved the embedding for furiously.\n",
      "furiousness is at index 15940\n",
      "Saved the embedding for furiousness.\n",
      "furrowed is at index 15503\n",
      "Saved the embedding for furrowed.\n",
      "furtive is at index 856\n",
      "Saved the embedding for furtive.\n",
      "fury is at index 22228\n",
      "Saved the embedding for fury.\n",
      "fussy is at index 856\n",
      "Saved the embedding for fussy.\n",
      "galled is at index 821\n",
      "Saved the embedding for galled.\n",
      "galling is at index 19869\n",
      "Saved the embedding for galling.\n",
      "gasp is at index 41681\n",
      "Saved the embedding for gasp.\n",
      "gasped is at index 44918\n",
      "Saved the embedding for gasped.\n",
      "gasping is at index 1123\n",
      "Saved the embedding for gasping.\n",
      "gay is at index 5100\n",
      "Saved the embedding for gay.\n",
      "gazing is at index 40804\n",
      "Saved the embedding for gazing.\n",
      "genial is at index 12358\n",
      "Saved the embedding for genial.\n",
      "gentle is at index 16634\n",
      "Saved the embedding for gentle.\n",
      "genuine is at index 8916\n",
      "Saved the embedding for genuine.\n",
      "ghastly is at index 34648\n",
      "Saved the embedding for ghastly.\n",
      "giddy is at index 821\n",
      "Saved the embedding for giddy.\n",
      "giggle is at index 821\n",
      "Saved the embedding for giggle.\n",
      "giggling is at index 33786\n",
      "Saved the embedding for giggling.\n",
      "glad is at index 7785\n",
      "Saved the embedding for glad.\n",
      "gladdened is at index 5921\n",
      "Saved the embedding for gladdened.\n",
      "gladiola is at index 7785\n",
      "Saved the embedding for gladiola.\n",
      "gladness is at index 7785\n",
      "Saved the embedding for gladness.\n",
      "gladsome is at index 5921\n",
      "Saved the embedding for gladsome.\n",
      "glare is at index 37355\n",
      "Saved the embedding for glare.\n",
      "glaring is at index 26077\n",
      "Saved the embedding for glaring.\n",
      "glazed is at index 5921\n",
      "Saved the embedding for glazed.\n",
      "glee is at index 821\n",
      "Saved the embedding for glee.\n",
      "gleeful is at index 22460\n",
      "Saved the embedding for gleeful.\n",
      "gleefully is at index 22460\n",
      "Saved the embedding for gleefully.\n",
      "glib is at index 5921\n",
      "Saved the embedding for glib.\n",
      "gloating is at index 5921\n",
      "Saved the embedding for gloating.\n",
      "gloom is at index 31752\n",
      "Saved the embedding for gloom.\n",
      "gloomy is at index 32627\n",
      "Saved the embedding for gloomy.\n",
      "glowering is at index 5921\n",
      "Saved the embedding for glowering.\n",
      "glowing is at index 22285\n",
      "Saved the embedding for glowing.\n",
      "glum is at index 5921\n",
      "Saved the embedding for glum.\n",
      "gnarl is at index 31021\n",
      "Saved the embedding for gnarl.\n",
      "gobsmacked is at index 213\n",
      "Saved the embedding for gobsmacked.\n",
      "good is at index 205\n",
      "Saved the embedding for good.\n",
      "goofy is at index 36302\n",
      "Saved the embedding for goofy.\n",
      "gossipy is at index 20445\n",
      "Saved the embedding for gossipy.\n",
      "grandiose is at index 2821\n",
      "Saved the embedding for grandiose.\n",
      "grateful is at index 6161\n",
      "Saved the embedding for grateful.\n",
      "gratified is at index 20153\n",
      "Saved the embedding for gratified.\n",
      "grave is at index 9753\n",
      "Saved the embedding for grave.\n",
      "great is at index 372\n",
      "Saved the embedding for great.\n",
      "greedy is at index 34405\n",
      "Saved the embedding for greedy.\n",
      "greeting is at index 25801\n",
      "Saved the embedding for greeting.\n",
      "grief is at index 12903\n",
      "Saved the embedding for grief.\n",
      "grieved is at index 821\n",
      "Saved the embedding for grieved.\n",
      "grieving is at index 22567\n",
      "Saved the embedding for grieving.\n",
      "grim is at index 17081\n",
      "Saved the embedding for grim.\n",
      "grimace is at index 17081\n",
      "Saved the embedding for grimace.\n",
      "grimacing is at index 17081\n",
      "Saved the embedding for grimacing.\n",
      "grin is at index 30986\n",
      "Saved the embedding for grin.\n",
      "grinning is at index 39662\n",
      "Saved the embedding for grinning.\n",
      "griping is at index 11155\n",
      "Saved the embedding for griping.\n",
      "gross is at index 4200\n",
      "Saved the embedding for gross.\n",
      "grossed is at index 4200\n",
      "Saved the embedding for grossed.\n",
      "grouchy is at index 22970\n",
      "Saved the embedding for grouchy.\n",
      "growl is at index 1733\n",
      "Saved the embedding for growl.\n",
      "growling is at index 1733\n",
      "Saved the embedding for growling.\n",
      "grudge is at index 4435\n",
      "Saved the embedding for grudge.\n",
      "grudging is at index 4435\n",
      "Saved the embedding for grudging.\n",
      "gruff is at index 15551\n",
      "Saved the embedding for gruff.\n",
      "grumbling is at index 4435\n",
      "Saved the embedding for grumbling.\n",
      "grumpy is at index 4435\n",
      "Saved the embedding for grumpy.\n",
      "grunt is at index 44376\n",
      "Saved the embedding for grunt.\n",
      "grunting is at index 39204\n",
      "Saved the embedding for grunting.\n",
      "guarded is at index 25853\n",
      "Saved the embedding for guarded.\n",
      "guilty is at index 2181\n",
      "Saved the embedding for guilty.\n",
      "gulp is at index 821\n",
      "Saved the embedding for gulp.\n",
      "haggard is at index 1368\n",
      "Saved the embedding for haggard.\n",
      "halfhearted is at index 457\n",
      "Saved the embedding for halfhearted.\n",
      "halted is at index 12856\n",
      "Saved the embedding for halted.\n",
      "hapless is at index 2489\n",
      "Saved the embedding for hapless.\n",
      "happiness is at index 11098\n",
      "Saved the embedding for happiness.\n",
      "happy is at index 1372\n",
      "Saved the embedding for happy.\n",
      "harassed is at index 16835\n",
      "Saved the embedding for harassed.\n",
      "hard is at index 543\n",
      "Saved the embedding for hard.\n",
      "hardened is at index 33631\n",
      "Saved the embedding for hardened.\n",
      "harmful is at index 11190\n",
      "Saved the embedding for harmful.\n",
      "harried is at index 12280\n",
      "Saved the embedding for harried.\n",
      "harsh is at index 9776\n",
      "Saved the embedding for harsh.\n",
      "hate is at index 4157\n",
      "Saved the embedding for hate.\n",
      "hateful is at index 26393\n",
      "Saved the embedding for hateful.\n",
      "hating is at index 40873\n",
      "Saved the embedding for hating.\n",
      "hatred is at index 13453\n",
      "Saved the embedding for hatred.\n",
      "haughty is at index 2489\n",
      "Saved the embedding for haughty.\n",
      "haunted is at index 22717\n",
      "Saved the embedding for haunted.\n",
      "hazy is at index 2489\n",
      "Saved the embedding for hazy.\n",
      "headshake is at index 471\n",
      "Saved the embedding for headshake.\n",
      "heartache is at index 1144\n",
      "Saved the embedding for heartache.\n",
      "heartbroken is at index 1144\n",
      "Saved the embedding for heartbroken.\n",
      "hearted is at index 1144\n",
      "Saved the embedding for hearted.\n",
      "heartsick is at index 7754\n",
      "Saved the embedding for heartsick.\n",
      "heated is at index 10819\n",
      "Saved the embedding for heated.\n",
      "heavyhearted is at index 2016\n",
      "Saved the embedding for heavyhearted.\n",
      "heckle is at index 17835\n",
      "Saved the embedding for heckle.\n",
      "heedful is at index 25432\n",
      "Saved the embedding for heedful.\n",
      "heinous is at index 30091\n",
      "Saved the embedding for heinous.\n",
      "helpful is at index 7163\n",
      "Saved the embedding for helpful.\n",
      "helpless is at index 22445\n",
      "Saved the embedding for helpless.\n",
      "hesitant is at index 24668\n",
      "Saved the embedding for hesitant.\n",
      "hesitantly is at index 36279\n",
      "Saved the embedding for hesitantly.\n",
      "hesitating is at index 36279\n",
      "Saved the embedding for hesitating.\n",
      "hesitation is at index 28946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for hesitation.\n",
      "high is at index 239\n",
      "Saved the embedding for high.\n",
      "hollering is at index 1368\n",
      "Saved the embedding for hollering.\n",
      "homicidal is at index 9486\n",
      "Saved the embedding for homicidal.\n",
      "honest is at index 5322\n",
      "Saved the embedding for honest.\n",
      "honorable is at index 28537\n",
      "Saved the embedding for honorable.\n",
      "hope is at index 1034\n",
      "Saved the embedding for hope.\n",
      "hopeful is at index 7917\n",
      "Saved the embedding for hopeful.\n",
      "hopefulness is at index 7917\n",
      "Saved the embedding for hopefulness.\n",
      "hopeless is at index 24418\n",
      "Saved the embedding for hopeless.\n",
      "hoping is at index 2818\n",
      "Saved the embedding for hoping.\n",
      "horny is at index 46216\n",
      "Saved the embedding for horny.\n",
      "horrible is at index 11385\n",
      "Saved the embedding for horrible.\n",
      "horrified is at index 27807\n",
      "Saved the embedding for horrified.\n",
      "horrify is at index 48067\n",
      "Saved the embedding for horrify.\n",
      "horrifying is at index 28242\n",
      "Saved the embedding for horrifying.\n",
      "horror is at index 8444\n",
      "Saved the embedding for horror.\n",
      "hostile is at index 11928\n",
      "Saved the embedding for hostile.\n",
      "hostility is at index 22069\n",
      "Saved the embedding for hostility.\n",
      "hot is at index 2131\n",
      "Saved the embedding for hot.\n",
      "hotshot is at index 2131\n",
      "Saved the embedding for hotshot.\n",
      "huffiness is at index 1368\n",
      "Saved the embedding for huffiness.\n",
      "huffy is at index 1368\n",
      "Saved the embedding for huffy.\n",
      "humble is at index 14083\n",
      "Saved the embedding for humble.\n",
      "humbled is at index 10080\n",
      "Saved the embedding for humbled.\n",
      "humdrum is at index 10080\n",
      "Saved the embedding for humdrum.\n",
      "humiliated is at index 32386\n",
      "Saved the embedding for humiliated.\n",
      "humility is at index 27352\n",
      "Saved the embedding for humility.\n",
      "humming is at index 35774\n",
      "Saved the embedding for humming.\n",
      "humor is at index 12073\n",
      "Saved the embedding for humor.\n",
      "humored is at index 10080\n",
      "Saved the embedding for humored.\n",
      "humorous is at index 31214\n",
      "Saved the embedding for humorous.\n",
      "hunger is at index 12226\n",
      "Saved the embedding for hunger.\n",
      "hungry is at index 11130\n",
      "Saved the embedding for hungry.\n",
      "hunted is at index 32602\n",
      "Saved the embedding for hunted.\n",
      "hurt is at index 2581\n",
      "Saved the embedding for hurt.\n",
      "hurtful is at index 2581\n",
      "Saved the embedding for hurtful.\n",
      "hurting is at index 12780\n",
      "Saved the embedding for hurting.\n",
      "hush is at index 1368\n",
      "Saved the embedding for hush.\n",
      "hushed is at index 33476\n",
      "Saved the embedding for hushed.\n",
      "hyper is at index 8944\n",
      "Saved the embedding for hyper.\n",
      "hyperactive is at index 8944\n",
      "Saved the embedding for hyperactive.\n",
      "hypnotized is at index 39040\n",
      "Saved the embedding for hypnotized.\n",
      "hypocritical is at index 37769\n",
      "Saved the embedding for hypocritical.\n",
      "hysteria is at index 35099\n",
      "Saved the embedding for hysteria.\n",
      "hysterical is at index 38561\n",
      "Saved the embedding for hysterical.\n",
      "idiotic is at index 13561\n",
      "Saved the embedding for idiotic.\n",
      "ignorant is at index 27726\n",
      "Saved the embedding for ignorant.\n",
      "ignoring is at index 15515\n",
      "Saved the embedding for ignoring.\n",
      "ill is at index 4812\n",
      "Saved the embedding for ill.\n",
      "imaginative is at index 35026\n",
      "Saved the embedding for imaginative.\n",
      "immature is at index 39001\n",
      "Saved the embedding for immature.\n",
      "immersed is at index 31971\n",
      "Saved the embedding for immersed.\n",
      "impacted is at index 7284\n",
      "Saved the embedding for impacted.\n",
      "impartial is at index 24283\n",
      "Saved the embedding for impartial.\n",
      "impassioned is at index 4023\n",
      "Saved the embedding for impassioned.\n",
      "impassive is at index 4023\n",
      "Saved the embedding for impassive.\n",
      "impatience is at index 43635\n",
      "Saved the embedding for impatience.\n",
      "impatient is at index 32601\n",
      "Saved the embedding for impatient.\n",
      "imperious is at index 21245\n",
      "Saved the embedding for imperious.\n",
      "impersonal is at index 23153\n",
      "Saved the embedding for impersonal.\n",
      "impertinent is at index 21245\n",
      "Saved the embedding for impertinent.\n",
      "impish is at index 4023\n",
      "Saved the embedding for impish.\n",
      "implicated is at index 23316\n",
      "Saved the embedding for implicated.\n",
      "imploring is at index 12956\n",
      "Saved the embedding for imploring.\n",
      "important is at index 505\n",
      "Saved the embedding for important.\n",
      "impressed is at index 6889\n",
      "Saved the embedding for impressed.\n",
      "impulsive is at index 4023\n",
      "Saved the embedding for impulsive.\n",
      "inactive is at index 25986\n",
      "Saved the embedding for inactive.\n",
      "inadequate is at index 15650\n",
      "Saved the embedding for inadequate.\n",
      "inarticulate is at index 11\n",
      "Saved the embedding for inarticulate.\n",
      "inattentive is at index 11\n",
      "Saved the embedding for inattentive.\n",
      "inaudible is at index 11\n",
      "Saved the embedding for inaudible.\n",
      "inauthentic is at index 11\n",
      "Saved the embedding for inauthentic.\n",
      "incapable is at index 30256\n",
      "Saved the embedding for incapable.\n",
      "incensed is at index 5853\n",
      "Saved the embedding for incensed.\n",
      "incertain is at index 5853\n",
      "Saved the embedding for incertain.\n",
      "incertitude is at index 5853\n",
      "Saved the embedding for incertitude.\n",
      "incited is at index 5853\n",
      "Saved the embedding for incited.\n",
      "incomprehensible is at index 42494\n",
      "Saved the embedding for incomprehensible.\n",
      "inconspicuous is at index 40817\n",
      "Saved the embedding for inconspicuous.\n",
      "incredulity is at index 38366\n",
      "Saved the embedding for incredulity.\n",
      "incredulous is at index 38366\n",
      "Saved the embedding for incredulous.\n",
      "incredulously is at index 38366\n",
      "Saved the embedding for incredulously.\n",
      "inculpate is at index 5853\n",
      "Saved the embedding for inculpate.\n",
      "incurious is at index 5853\n",
      "Saved the embedding for incurious.\n",
      "indecipherable is at index 32227\n",
      "Saved the embedding for indecipherable.\n",
      "indecision is at index 32227\n",
      "Saved the embedding for indecision.\n",
      "indecisive is at index 32227\n",
      "Saved the embedding for indecisive.\n",
      "indifferent is at index 34657\n",
      "Saved the embedding for indifferent.\n",
      "indifferently is at index 34657\n",
      "Saved the embedding for indifferently.\n",
      "indignant is at index 9473\n",
      "Saved the embedding for indignant.\n",
      "indolent is at index 9473\n",
      "Saved the embedding for indolent.\n",
      "inebriated is at index 11\n",
      "Saved the embedding for inebriated.\n",
      "inert is at index 43783\n",
      "Saved the embedding for inert.\n",
      "infatuating is at index 4047\n",
      "Saved the embedding for infatuating.\n",
      "inferior is at index 28510\n",
      "Saved the embedding for inferior.\n",
      "inferiority is at index 28510\n",
      "Saved the embedding for inferiority.\n",
      "inflamed is at index 11411\n",
      "Saved the embedding for inflamed.\n",
      "informal is at index 14110\n",
      "Saved the embedding for informal.\n",
      "informing is at index 21835\n",
      "Saved the embedding for informing.\n",
      "infuriated is at index 26974\n",
      "Saved the embedding for infuriated.\n",
      "inhibited is at index 45427\n",
      "Saved the embedding for inhibited.\n",
      "inhibiting is at index 38512\n",
      "Saved the embedding for inhibiting.\n",
      "inimical is at index 11\n",
      "Saved the embedding for inimical.\n",
      "injured is at index 1710\n",
      "Saved the embedding for injured.\n",
      "innocent is at index 7850\n",
      "Saved the embedding for innocent.\n",
      "inpatient is at index 11\n",
      "Saved the embedding for inpatient.\n",
      "inquiring is at index 27874\n",
      "Saved the embedding for inquiring.\n",
      "inquisitive is at index 27874\n",
      "Saved the embedding for inquisitive.\n",
      "insane is at index 18544\n",
      "Saved the embedding for insane.\n",
      "inscrutable is at index 7540\n",
      "Saved the embedding for inscrutable.\n",
      "insecure is at index 27810\n",
      "Saved the embedding for insecure.\n",
      "insecurity is at index 19401\n",
      "Saved the embedding for insecurity.\n",
      "insensitive is at index 29401\n",
      "Saved the embedding for insensitive.\n",
      "insidious is at index 40012\n",
      "Saved the embedding for insidious.\n",
      "insinuating is at index 32016\n",
      "Saved the embedding for insinuating.\n",
      "insistence is at index 24974\n",
      "Saved the embedding for insistence.\n",
      "insistent is at index 7540\n",
      "Saved the embedding for insistent.\n",
      "insisting is at index 13875\n",
      "Saved the embedding for insisting.\n",
      "insolent is at index 23799\n",
      "Saved the embedding for insolent.\n",
      "insouciance is at index 7540\n",
      "Saved the embedding for insouciance.\n",
      "insouciant is at index 7540\n",
      "Saved the embedding for insouciant.\n",
      "inspired is at index 4083\n",
      "Saved the embedding for inspired.\n",
      "inspiring is at index 11653\n",
      "Saved the embedding for inspiring.\n",
      "instigating is at index 9084\n",
      "Saved the embedding for instigating.\n",
      "instructing is at index 20587\n",
      "Saved the embedding for instructing.\n",
      "insubordinate is at index 7540\n",
      "Saved the embedding for insubordinate.\n",
      "insular is at index 7540\n",
      "Saved the embedding for insular.\n",
      "insulted is at index 32149\n",
      "Saved the embedding for insulted.\n",
      "insulting is at index 22602\n",
      "Saved the embedding for insulting.\n",
      "intelligence is at index 2316\n",
      "Saved the embedding for intelligence.\n",
      "intense is at index 5676\n",
      "Saved the embedding for intense.\n",
      "intensely is at index 29727\n",
      "Saved the embedding for intensely.\n",
      "intensity is at index 10603\n",
      "Saved the embedding for intensity.\n",
      "intensive is at index 12296\n",
      "Saved the embedding for intensive.\n",
      "intent is at index 5927\n",
      "Saved the embedding for intent.\n",
      "intentional is at index 18797\n",
      "Saved the embedding for intentional.\n",
      "interacting is at index 23140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for interacting.\n",
      "interest is at index 773\n",
      "Saved the embedding for interest.\n",
      "interested is at index 2509\n",
      "Saved the embedding for interested.\n",
      "interjecting is at index 3222\n",
      "Saved the embedding for interjecting.\n",
      "internalizing is at index 3425\n",
      "Saved the embedding for internalizing.\n",
      "interrogating is at index 28592\n",
      "Saved the embedding for interrogating.\n",
      "interrupting is at index 22749\n",
      "Saved the embedding for interrupting.\n",
      "intimidated is at index 25443\n",
      "Saved the embedding for intimidated.\n",
      "intimidating is at index 23292\n",
      "Saved the embedding for intimidating.\n",
      "intolerant is at index 39348\n",
      "Saved the embedding for intolerant.\n",
      "intoxicated is at index 20600\n",
      "Saved the embedding for intoxicated.\n",
      "intrigue is at index 30368\n",
      "Saved the embedding for intrigue.\n",
      "intrigued is at index 28622\n",
      "Saved the embedding for intrigued.\n",
      "intriguing is at index 14816\n",
      "Saved the embedding for intriguing.\n",
      "introspective is at index 22845\n",
      "Saved the embedding for introspective.\n",
      "invested is at index 5221\n",
      "Saved the embedding for invested.\n",
      "investigate is at index 4830\n",
      "Saved the embedding for investigate.\n",
      "investigative is at index 13222\n",
      "Saved the embedding for investigative.\n",
      "investigatory is at index 25463\n",
      "Saved the embedding for investigatory.\n",
      "invigorated is at index 12259\n",
      "Saved the embedding for invigorated.\n",
      "involved is at index 963\n",
      "Saved the embedding for involved.\n",
      "irascible is at index 10209\n",
      "Saved the embedding for irascible.\n",
      "irate is at index 10209\n",
      "Saved the embedding for irate.\n",
      "ire is at index 25509\n",
      "Saved the embedding for ire.\n",
      "ireful is at index 25509\n",
      "Saved the embedding for ireful.\n",
      "irked is at index 10209\n",
      "Saved the embedding for irked.\n",
      "ironic is at index 25553\n",
      "Saved the embedding for ironic.\n",
      "irony is at index 21490\n",
      "Saved the embedding for irony.\n",
      "irresolute is at index 10209\n",
      "Saved the embedding for irresolute.\n",
      "irritable is at index 26570\n",
      "Saved the embedding for irritable.\n",
      "irritably is at index 26570\n",
      "Saved the embedding for irritably.\n",
      "irritated is at index 35270\n",
      "Saved the embedding for irritated.\n",
      "irritation is at index 32776\n",
      "Saved the embedding for irritation.\n",
      "isolated is at index 8067\n",
      "Saved the embedding for isolated.\n",
      "jabbed is at index 27916\n",
      "Saved the embedding for jabbed.\n",
      "jaded is at index 1236\n",
      "Saved the embedding for jaded.\n",
      "jarred is at index 25413\n",
      "Saved the embedding for jarred.\n",
      "jarring is at index 35659\n",
      "Saved the embedding for jarring.\n",
      "jaunty is at index 1236\n",
      "Saved the embedding for jaunty.\n",
      "jawed is at index 15345\n",
      "Saved the embedding for jawed.\n",
      "jealous is at index 27064\n",
      "Saved the embedding for jealous.\n",
      "jeering is at index 4112\n",
      "Saved the embedding for jeering.\n",
      "jesting is at index 1236\n",
      "Saved the embedding for jesting.\n",
      "jilted is at index 1236\n",
      "Saved the embedding for jilted.\n",
      "jittery is at index 1236\n",
      "Saved the embedding for jittery.\n",
      "jocular is at index 1236\n",
      "Saved the embedding for jocular.\n",
      "joking is at index 22024\n",
      "Saved the embedding for joking.\n",
      "jolly is at index 1236\n",
      "Saved the embedding for jolly.\n",
      "jolted is at index 1236\n",
      "Saved the embedding for jolted.\n",
      "jovial is at index 1236\n",
      "Saved the embedding for jovial.\n",
      "joy is at index 5823\n",
      "Saved the embedding for joy.\n",
      "joyful is at index 32076\n",
      "Saved the embedding for joyful.\n",
      "joyfulness is at index 5823\n",
      "Saved the embedding for joyfulness.\n",
      "joyless is at index 5823\n",
      "Saved the embedding for joyless.\n",
      "joyous is at index 5823\n",
      "Saved the embedding for joyous.\n",
      "jubilant is at index 1236\n",
      "Saved the embedding for jubilant.\n",
      "jubilation is at index 1236\n",
      "Saved the embedding for jubilation.\n",
      "judgemental is at index 17219\n",
      "Saved the embedding for judgemental.\n",
      "judging is at index 17298\n",
      "Saved the embedding for judging.\n",
      "judgmental is at index 7579\n",
      "Saved the embedding for judgmental.\n",
      "judicious is at index 21392\n",
      "Saved the embedding for judicious.\n",
      "jumpy is at index 3704\n",
      "Saved the embedding for jumpy.\n",
      "justified is at index 14267\n",
      "Saved the embedding for justified.\n",
      "keen is at index 5609\n",
      "Saved the embedding for keen.\n",
      "kind is at index 761\n",
      "Saved the embedding for kind.\n",
      "kindhearted is at index 761\n",
      "Saved the embedding for kindhearted.\n",
      "kiss is at index 13301\n",
      "Saved the embedding for kiss.\n",
      "knowing is at index 4730\n",
      "Saved the embedding for knowing.\n",
      "knowledgable is at index 216\n",
      "Saved the embedding for knowledgable.\n",
      "knowledgeable is at index 26782\n",
      "Saved the embedding for knowledgeable.\n",
      "kosher is at index 36930\n",
      "Saved the embedding for kosher.\n",
      "lackadaisical is at index 1762\n",
      "Saved the embedding for lackadaisical.\n",
      "lackluster is at index 28369\n",
      "Saved the embedding for lackluster.\n",
      "laconic is at index 784\n",
      "Saved the embedding for laconic.\n",
      "lambaste is at index 17988\n",
      "Saved the embedding for lambaste.\n",
      "lamentable is at index 25532\n",
      "Saved the embedding for lamentable.\n",
      "lamenting is at index 25532\n",
      "Saved the embedding for lamenting.\n",
      "lascivious is at index 784\n",
      "Saved the embedding for lascivious.\n",
      "laugh is at index 7923\n",
      "Saved the embedding for laugh.\n",
      "laughing is at index 11339\n",
      "Saved the embedding for laughing.\n",
      "laughter is at index 16805\n",
      "Saved the embedding for laughter.\n",
      "lazy is at index 22414\n",
      "Saved the embedding for lazy.\n",
      "leaving is at index 1618\n",
      "Saved the embedding for leaving.\n",
      "lecherous is at index 2084\n",
      "Saved the embedding for lecherous.\n",
      "lecturing is at index 25673\n",
      "Saved the embedding for lecturing.\n",
      "leering is at index 2084\n",
      "Saved the embedding for leering.\n",
      "leery is at index 2084\n",
      "Saved the embedding for leery.\n",
      "letdown is at index 905\n",
      "Saved the embedding for letdown.\n",
      "lethargic is at index 35370\n",
      "Saved the embedding for lethargic.\n",
      "levelheaded is at index 672\n",
      "Saved the embedding for levelheaded.\n",
      "lewd is at index 31942\n",
      "Saved the embedding for lewd.\n",
      "libidinous is at index 21748\n",
      "Saved the embedding for libidinous.\n",
      "lifeless is at index 37019\n",
      "Saved the embedding for lifeless.\n",
      "lighthearted is at index 1109\n",
      "Saved the embedding for lighthearted.\n",
      "lipped is at index 784\n",
      "Saved the embedding for lipped.\n",
      "listening is at index 6288\n",
      "Saved the embedding for listening.\n",
      "listless is at index 889\n",
      "Saved the embedding for listless.\n",
      "lively is at index 20902\n",
      "Saved the embedding for lively.\n",
      "livid is at index 784\n",
      "Saved the embedding for livid.\n",
      "loaded is at index 7973\n",
      "Saved the embedding for loaded.\n",
      "loath is at index 4600\n",
      "Saved the embedding for loath.\n",
      "loathe is at index 4600\n",
      "Saved the embedding for loathe.\n",
      "loathing is at index 4600\n",
      "Saved the embedding for loathing.\n",
      "loathsome is at index 4600\n",
      "Saved the embedding for loathsome.\n",
      "locked is at index 5930\n",
      "Saved the embedding for locked.\n",
      "loneliness is at index 27942\n",
      "Saved the embedding for loneliness.\n",
      "lonely is at index 20100\n",
      "Saved the embedding for lonely.\n",
      "longing is at index 36171\n",
      "Saved the embedding for longing.\n",
      "looking is at index 546\n",
      "Saved the embedding for looking.\n",
      "loony is at index 4600\n",
      "Saved the embedding for loony.\n",
      "loss is at index 872\n",
      "Saved the embedding for loss.\n",
      "lost is at index 685\n",
      "Saved the embedding for lost.\n",
      "loud is at index 7337\n",
      "Saved the embedding for loud.\n",
      "lousy is at index 38909\n",
      "Saved the embedding for lousy.\n",
      "love is at index 657\n",
      "Saved the embedding for love.\n",
      "loving is at index 8520\n",
      "Saved the embedding for loving.\n",
      "lowliness is at index 614\n",
      "Saved the embedding for lowliness.\n",
      "lurid is at index 30461\n",
      "Saved the embedding for lurid.\n",
      "lustful is at index 30864\n",
      "Saved the embedding for lustful.\n",
      "lusting is at index 30864\n",
      "Saved the embedding for lusting.\n",
      "lusty is at index 30864\n",
      "Saved the embedding for lusty.\n",
      "lying is at index 6480\n",
      "Saved the embedding for lying.\n",
      "mad is at index 7758\n",
      "Saved the embedding for mad.\n",
      "maddened is at index 475\n",
      "Saved the embedding for maddened.\n",
      "madness is at index 24714\n",
      "Saved the embedding for madness.\n",
      "malcontent is at index 8196\n",
      "Saved the embedding for malcontent.\n",
      "maleficent is at index 8196\n",
      "Saved the embedding for maleficent.\n",
      "malevolent is at index 2943\n",
      "Saved the embedding for malevolent.\n",
      "malice is at index 39625\n",
      "Saved the embedding for malice.\n",
      "malicious is at index 15237\n",
      "Saved the embedding for malicious.\n",
      "malignant is at index 8196\n",
      "Saved the embedding for malignant.\n",
      "maniacal is at index 41288\n",
      "Saved the embedding for maniacal.\n",
      "manipulative is at index 39802\n",
      "Saved the embedding for manipulative.\n",
      "marveled is at index 25591\n",
      "Saved the embedding for marveled.\n",
      "master is at index 4710\n",
      "Saved the embedding for master.\n",
      "mean is at index 1266\n",
      "Saved the embedding for mean.\n",
      "meaningful is at index 6667\n",
      "Saved the embedding for meaningful.\n",
      "meditative is at index 5679\n",
      "Saved the embedding for meditative.\n",
      "meek is at index 162\n",
      "Saved the embedding for meek.\n",
      "melancholic is at index 45565\n",
      "Saved the embedding for melancholic.\n",
      "melancholy is at index 40602\n",
      "Saved the embedding for melancholy.\n",
      "mellow is at index 34384\n",
      "Saved the embedding for mellow.\n",
      "menace is at index 24213\n",
      "Saved the embedding for menace.\n",
      "menacing is at index 32002\n",
      "Saved the embedding for menacing.\n",
      "mental is at index 2536\n",
      "Saved the embedding for mental.\n",
      "merrily is at index 9374\n",
      "Saved the embedding for merrily.\n",
      "merry is at index 35814\n",
      "Saved the embedding for merry.\n",
      "mesmerized is at index 31294\n",
      "Saved the embedding for mesmerized.\n",
      "miffed is at index 475\n",
      "Saved the embedding for miffed.\n",
      "mild is at index 10439\n",
      "Saved the embedding for mild.\n",
      "mincing is at index 5251\n",
      "Saved the embedding for mincing.\n",
      "mindful is at index 20807\n",
      "Saved the embedding for mindful.\n",
      "mindless is at index 41406\n",
      "Saved the embedding for mindless.\n",
      "mirrored is at index 31349\n",
      "Saved the embedding for mirrored.\n",
      "mirth is at index 475\n",
      "Saved the embedding for mirth.\n",
      "mirthful is at index 475\n",
      "Saved the embedding for mirthful.\n",
      "misanthropic is at index 3834\n",
      "Saved the embedding for misanthropic.\n",
      "mischief is at index 26245\n",
      "Saved the embedding for mischief.\n",
      "mischievous is at index 3834\n",
      "Saved the embedding for mischievous.\n",
      "mischievousness is at index 3834\n",
      "Saved the embedding for mischievousness.\n",
      "miserable is at index 20161\n",
      "Saved the embedding for miserable.\n",
      "misery is at index 23110\n",
      "Saved the embedding for misery.\n",
      "misgiving is at index 3834\n",
      "Saved the embedding for misgiving.\n",
      "mislead is at index 34747\n",
      "Saved the embedding for mislead.\n",
      "mistrust is at index 34873\n",
      "Saved the embedding for mistrust.\n",
      "mistrustful is at index 34873\n",
      "Saved the embedding for mistrustful.\n",
      "mistrusting is at index 34873\n",
      "Saved the embedding for mistrusting.\n",
      "misunderstood is at index 32085\n",
      "Saved the embedding for misunderstood.\n",
      "mockery is at index 34641\n",
      "Saved the embedding for mockery.\n",
      "mocking is at index 27813\n",
      "Saved the embedding for mocking.\n",
      "mockingly is at index 16177\n",
      "Saved the embedding for mockingly.\n",
      "modest is at index 6473\n",
      "Saved the embedding for modest.\n",
      "monotone is at index 6154\n",
      "Saved the embedding for monotone.\n",
      "monster is at index 13317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for monster.\n",
      "moody is at index 6711\n",
      "Saved the embedding for moody.\n",
      "mopey is at index 475\n",
      "Saved the embedding for mopey.\n",
      "morose is at index 14628\n",
      "Saved the embedding for morose.\n",
      "mortified is at index 18631\n",
      "Saved the embedding for mortified.\n",
      "motivated is at index 7958\n",
      "Saved the embedding for motivated.\n",
      "mournful is at index 15213\n",
      "Saved the embedding for mournful.\n",
      "mournfulness is at index 15213\n",
      "Saved the embedding for mournfulness.\n",
      "mourning is at index 19293\n",
      "Saved the embedding for mourning.\n",
      "mouthed is at index 475\n",
      "Saved the embedding for mouthed.\n",
      "moved is at index 1410\n",
      "Saved the embedding for moved.\n",
      "muddled is at index 475\n",
      "Saved the embedding for muddled.\n",
      "mum is at index 8562\n",
      "Saved the embedding for mum.\n",
      "murderous is at index 32883\n",
      "Saved the embedding for murderous.\n",
      "musical is at index 4388\n",
      "Saved the embedding for musical.\n",
      "musing is at index 11721\n",
      "Saved the embedding for musing.\n",
      "muster is at index 27665\n",
      "Saved the embedding for muster.\n",
      "mute is at index 33758\n",
      "Saved the embedding for mute.\n",
      "muted is at index 21677\n",
      "Saved the embedding for muted.\n",
      "muttering is at index 16119\n",
      "Saved the embedding for muttering.\n",
      "mysterious is at index 12754\n",
      "Saved the embedding for mysterious.\n",
      "mystical is at index 39795\n",
      "Saved the embedding for mystical.\n",
      "mystified is at index 37763\n",
      "Saved the embedding for mystified.\n",
      "naive is at index 25672\n",
      "Saved the embedding for naive.\n",
      "napping is at index 295\n",
      "Saved the embedding for napping.\n",
      "narrow is at index 6787\n",
      "Saved the embedding for narrow.\n",
      "nasty is at index 15455\n",
      "Saved the embedding for nasty.\n",
      "natural is at index 1632\n",
      "Saved the embedding for natural.\n",
      "natured is at index 23577\n",
      "Saved the embedding for natured.\n",
      "naughty is at index 38384\n",
      "Saved the embedding for naughty.\n",
      "nausea is at index 27214\n",
      "Saved the embedding for nausea.\n",
      "nauseated is at index 39117\n",
      "Saved the embedding for nauseated.\n",
      "nauseous is at index 39117\n",
      "Saved the embedding for nauseous.\n",
      "needy is at index 28166\n",
      "Saved the embedding for needy.\n",
      "nefarious is at index 33952\n",
      "Saved the embedding for nefarious.\n",
      "negating is at index 15183\n",
      "Saved the embedding for negating.\n",
      "negative is at index 2430\n",
      "Saved the embedding for negative.\n",
      "negativity is at index 30269\n",
      "Saved the embedding for negativity.\n",
      "neglected is at index 20428\n",
      "Saved the embedding for neglected.\n",
      "nerdy is at index 38286\n",
      "Saved the embedding for nerdy.\n",
      "nerved is at index 295\n",
      "Saved the embedding for nerved.\n",
      "nerves is at index 17358\n",
      "Saved the embedding for nerves.\n",
      "nervous is at index 7464\n",
      "Saved the embedding for nervous.\n",
      "nervously is at index 40968\n",
      "Saved the embedding for nervously.\n",
      "nervousness is at index 7464\n",
      "Saved the embedding for nervousness.\n",
      "nescient is at index 295\n",
      "Saved the embedding for nescient.\n",
      "nettled is at index 1161\n",
      "Saved the embedding for nettled.\n",
      "neutral is at index 7974\n",
      "Saved the embedding for neutral.\n",
      "neutrality is at index 18755\n",
      "Saved the embedding for neutrality.\n",
      "nice is at index 2579\n",
      "Saved the embedding for nice.\n",
      "noisy is at index 28269\n",
      "Saved the embedding for noisy.\n",
      "nonbelief is at index 786\n",
      "Saved the embedding for nonbelief.\n",
      "nonchalance is at index 786\n",
      "Saved the embedding for nonchalance.\n",
      "nonchalant is at index 786\n",
      "Saved the embedding for nonchalant.\n",
      "noncommittal is at index 786\n",
      "Saved the embedding for noncommittal.\n",
      "noncompliant is at index 786\n",
      "Saved the embedding for noncompliant.\n",
      "nonplussed is at index 786\n",
      "Saved the embedding for nonplussed.\n",
      "nonsensical is at index 42475\n",
      "Saved the embedding for nonsensical.\n",
      "normal is at index 2340\n",
      "Saved the embedding for normal.\n",
      "nosey is at index 8658\n",
      "Saved the embedding for nosey.\n",
      "nostalgic is at index 28055\n",
      "Saved the embedding for nostalgic.\n",
      "nosy is at index 13736\n",
      "Saved the embedding for nosy.\n",
      "numb is at index 31086\n",
      "Saved the embedding for numb.\n",
      "obedient is at index 44729\n",
      "Saved the embedding for obedient.\n",
      "objecting is at index 7626\n",
      "Saved the embedding for objecting.\n",
      "objection is at index 24763\n",
      "Saved the embedding for objection.\n",
      "objective is at index 4554\n",
      "Saved the embedding for objective.\n",
      "obliged is at index 23964\n",
      "Saved the embedding for obliged.\n",
      "obliging is at index 23762\n",
      "Saved the embedding for obliging.\n",
      "oblivious is at index 35606\n",
      "Saved the embedding for oblivious.\n",
      "observant is at index 20717\n",
      "Saved the embedding for observant.\n",
      "observing is at index 21981\n",
      "Saved the embedding for observing.\n",
      "obsessed is at index 17593\n",
      "Saved the embedding for obsessed.\n",
      "obstinate is at index 30896\n",
      "Saved the embedding for obstinate.\n",
      "occupied is at index 9533\n",
      "Saved the embedding for occupied.\n",
      "odd is at index 8372\n",
      "Saved the embedding for odd.\n",
      "odious is at index 7452\n",
      "Saved the embedding for odious.\n",
      "off is at index 160\n",
      "Saved the embedding for off.\n",
      "offended is at index 22169\n",
      "Saved the embedding for offended.\n",
      "offensive is at index 2555\n",
      "Saved the embedding for offensive.\n",
      "ogling is at index 1021\n",
      "Saved the embedding for ogling.\n",
      "okay is at index 8578\n",
      "Saved the embedding for okay.\n",
      "on is at index 15\n",
      "Saved the embedding for on.\n",
      "open is at index 490\n",
      "Saved the embedding for open.\n",
      "openness is at index 23163\n",
      "Saved the embedding for openness.\n",
      "opposed is at index 4340\n",
      "Saved the embedding for opposed.\n",
      "oppositional is at index 39734\n",
      "Saved the embedding for oppositional.\n",
      "oppressed is at index 32881\n",
      "Saved the embedding for oppressed.\n",
      "optimism is at index 9743\n",
      "Saved the embedding for optimism.\n",
      "optimistic is at index 7168\n",
      "Saved the embedding for optimistic.\n",
      "ordering is at index 12926\n",
      "Saved the embedding for ordering.\n",
      "orgasmic is at index 39396\n",
      "Saved the embedding for orgasmic.\n",
      "ornery is at index 50\n",
      "Saved the embedding for ornery.\n",
      "ouch is at index 1021\n",
      "Saved the embedding for ouch.\n",
      "out is at index 66\n",
      "Saved the embedding for out.\n",
      "outburst is at index 28999\n",
      "Saved the embedding for outburst.\n",
      "outcry is at index 19900\n",
      "Saved the embedding for outcry.\n",
      "outed is at index 66\n",
      "Saved the embedding for outed.\n",
      "outlandish is at index 35785\n",
      "Saved the embedding for outlandish.\n",
      "outrage is at index 10618\n",
      "Saved the embedding for outrage.\n",
      "outraged is at index 22339\n",
      "Saved the embedding for outraged.\n",
      "outspoken is at index 16120\n",
      "Saved the embedding for outspoken.\n",
      "overbearing is at index 81\n",
      "Saved the embedding for overbearing.\n",
      "overexcited is at index 39919\n",
      "Saved the embedding for overexcited.\n",
      "overjoyed is at index 81\n",
      "Saved the embedding for overjoyed.\n",
      "overshadowed is at index 22140\n",
      "Saved the embedding for overshadowed.\n",
      "overstrung is at index 81\n",
      "Saved the embedding for overstrung.\n",
      "overwhelmed is at index 13203\n",
      "Saved the embedding for overwhelmed.\n",
      "overworked is at index 81\n",
      "Saved the embedding for overworked.\n",
      "overwrought is at index 42674\n",
      "Saved the embedding for overwrought.\n",
      "pain is at index 2400\n",
      "Saved the embedding for pain.\n",
      "pained is at index 181\n",
      "Saved the embedding for pained.\n",
      "painful is at index 8661\n",
      "Saved the embedding for painful.\n",
      "painfully is at index 32020\n",
      "Saved the embedding for painfully.\n",
      "panic is at index 9810\n",
      "Saved the embedding for panic.\n",
      "panicked is at index 28604\n",
      "Saved the embedding for panicked.\n",
      "panicky is at index 5730\n",
      "Saved the embedding for panicky.\n",
      "paralyzed is at index 28582\n",
      "Saved the embedding for paralyzed.\n",
      "paranoid is at index 33554\n",
      "Saved the embedding for paranoid.\n",
      "passionate is at index 8840\n",
      "Saved the embedding for passionate.\n",
      "passive is at index 18718\n",
      "Saved the embedding for passive.\n",
      "patience is at index 11383\n",
      "Saved the embedding for patience.\n",
      "patient is at index 3186\n",
      "Saved the embedding for patient.\n",
      "patronizing is at index 18528\n",
      "Saved the embedding for patronizing.\n",
      "pause is at index 13787\n",
      "Saved the embedding for pause.\n",
      "pausing is at index 6044\n",
      "Saved the embedding for pausing.\n",
      "peaceful is at index 7053\n",
      "Saved the embedding for peaceful.\n",
      "peculiar is at index 28178\n",
      "Saved the embedding for peculiar.\n",
      "peering is at index 3723\n",
      "Saved the embedding for peering.\n",
      "peeved is at index 32734\n",
      "Saved the embedding for peeved.\n",
      "peevish is at index 3723\n",
      "Saved the embedding for peevish.\n",
      "pensive is at index 181\n",
      "Saved the embedding for pensive.\n",
      "peppy is at index 3723\n",
      "Saved the embedding for peppy.\n",
      "perceptive is at index 228\n",
      "Saved the embedding for perceptive.\n",
      "perfidious is at index 32168\n",
      "Saved the embedding for perfidious.\n",
      "perky is at index 228\n",
      "Saved the embedding for perky.\n",
      "perplexed is at index 33708\n",
      "Saved the embedding for perplexed.\n",
      "perplexing is at index 33708\n",
      "Saved the embedding for perplexing.\n",
      "persistent is at index 13109\n",
      "Saved the embedding for persistent.\n",
      "personable is at index 621\n",
      "Saved the embedding for personable.\n",
      "perturbed is at index 32819\n",
      "Saved the embedding for perturbed.\n",
      "perverse is at index 41271\n",
      "Saved the embedding for perverse.\n",
      "pesky is at index 38432\n",
      "Saved the embedding for pesky.\n",
      "pessimism is at index 36494\n",
      "Saved the embedding for pessimism.\n",
      "pessimistic is at index 32415\n",
      "Saved the embedding for pessimistic.\n",
      "pestered is at index 19024\n",
      "Saved the embedding for pestered.\n",
      "petitioning is at index 5265\n",
      "Saved the embedding for petitioning.\n",
      "petrified is at index 4716\n",
      "Saved the embedding for petrified.\n",
      "petty is at index 25070\n",
      "Saved the embedding for petty.\n",
      "petulant is at index 4716\n",
      "Saved the embedding for petulant.\n",
      "picked is at index 2738\n",
      "Saved the embedding for picked.\n",
      "piercing is at index 38105\n",
      "Saved the embedding for piercing.\n",
      "pinched is at index 7756\n",
      "Saved the embedding for pinched.\n",
      "pious is at index 44843\n",
      "Saved the embedding for pious.\n",
      "piqued is at index 181\n",
      "Saved the embedding for piqued.\n",
      "pissed is at index 34449\n",
      "Saved the embedding for pissed.\n",
      "pitiable is at index 8516\n",
      "Saved the embedding for pitiable.\n",
      "pitiful is at index 8516\n",
      "Saved the embedding for pitiful.\n",
      "pity is at index 31373\n",
      "Saved the embedding for pity.\n",
      "pitying is at index 31373\n",
      "Saved the embedding for pitying.\n",
      "placated is at index 15155\n",
      "Saved the embedding for placated.\n",
      "placation is at index 15155\n",
      "Saved the embedding for placation.\n",
      "placid is at index 15155\n",
      "Saved the embedding for placid.\n",
      "plain is at index 10798\n",
      "Saved the embedding for plain.\n",
      "plaintive is at index 46560\n",
      "Saved the embedding for plaintive.\n",
      "planning is at index 1884\n",
      "Saved the embedding for planning.\n",
      "playful is at index 23317\n",
      "Saved the embedding for playful.\n",
      "playfully is at index 310\n",
      "Saved the embedding for playfully.\n",
      "pleading is at index 17532\n",
      "Saved the embedding for pleading.\n",
      "pleasant is at index 16219\n",
      "Saved the embedding for pleasant.\n",
      "pleased is at index 4343\n",
      "Saved the embedding for pleased.\n",
      "pleasing is at index 25234\n",
      "Saved the embedding for pleasing.\n",
      "pleasurable is at index 19518\n",
      "Saved the embedding for pleasurable.\n",
      "pleasure is at index 10483\n",
      "Saved the embedding for pleasure.\n",
      "pleasured is at index 19518\n",
      "Saved the embedding for pleasured.\n",
      "pliant is at index 2968\n",
      "Saved the embedding for pliant.\n",
      "plotting is at index 22849\n",
      "Saved the embedding for plotting.\n",
      "poignant is at index 27274\n",
      "Saved the embedding for poignant.\n",
      "pointed is at index 3273\n",
      "Saved the embedding for pointed.\n",
      "poised is at index 10137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for poised.\n",
      "polite is at index 24908\n",
      "Saved the embedding for polite.\n",
      "pompous is at index 34415\n",
      "Saved the embedding for pompous.\n",
      "ponder is at index 31930\n",
      "Saved the embedding for ponder.\n",
      "pondering is at index 13362\n",
      "Saved the embedding for pondering.\n",
      "pooping is at index 4202\n",
      "Saved the embedding for pooping.\n",
      "pop is at index 3495\n",
      "Saved the embedding for pop.\n",
      "posing is at index 12681\n",
      "Saved the embedding for posing.\n",
      "positive is at index 1313\n",
      "Saved the embedding for positive.\n",
      "positivity is at index 8593\n",
      "Saved the embedding for positivity.\n",
      "possibly is at index 3544\n",
      "Saved the embedding for possibly.\n",
      "pout is at index 181\n",
      "Saved the embedding for pout.\n",
      "pouting is at index 181\n",
      "Saved the embedding for pouting.\n",
      "pouty is at index 181\n",
      "Saved the embedding for pouty.\n",
      "powerful is at index 2247\n",
      "Saved the embedding for powerful.\n",
      "powerless is at index 33128\n",
      "Saved the embedding for powerless.\n",
      "pranking is at index 3349\n",
      "Saved the embedding for pranking.\n",
      "precarious is at index 27180\n",
      "Saved the embedding for precarious.\n",
      "predatory is at index 29216\n",
      "Saved the embedding for predatory.\n",
      "prejudiced is at index 34286\n",
      "Saved the embedding for prejudiced.\n",
      "preoccupied is at index 1198\n",
      "Saved the embedding for preoccupied.\n",
      "prepared is at index 2460\n",
      "Saved the embedding for prepared.\n",
      "preparing is at index 4568\n",
      "Saved the embedding for preparing.\n",
      "pretending is at index 23748\n",
      "Saved the embedding for pretending.\n",
      "pretentious is at index 11857\n",
      "Saved the embedding for pretentious.\n",
      "prideful is at index 7040\n",
      "Saved the embedding for prideful.\n",
      "priggish is at index 3349\n",
      "Saved the embedding for priggish.\n",
      "primed is at index 32575\n",
      "Saved the embedding for primed.\n",
      "private is at index 940\n",
      "Saved the embedding for private.\n",
      "processing is at index 5774\n",
      "Saved the embedding for processing.\n",
      "propositioning is at index 16104\n",
      "Saved the embedding for propositioning.\n",
      "proud is at index 2602\n",
      "Saved the embedding for proud.\n",
      "provocative is at index 21051\n",
      "Saved the embedding for provocative.\n",
      "provoke is at index 28184\n",
      "Saved the embedding for provoke.\n",
      "provoked is at index 24972\n",
      "Saved the embedding for provoked.\n",
      "provoking is at index 35359\n",
      "Saved the embedding for provoking.\n",
      "prying is at index 181\n",
      "Saved the embedding for prying.\n",
      "psycho is at index 37338\n",
      "Saved the embedding for psycho.\n",
      "psychotic is at index 41559\n",
      "Saved the embedding for psychotic.\n",
      "puckish is at index 9258\n",
      "Saved the embedding for puckish.\n",
      "puerile is at index 181\n",
      "Saved the embedding for puerile.\n",
      "pugnacious is at index 181\n",
      "Saved the embedding for pugnacious.\n",
      "punished is at index 14459\n",
      "Saved the embedding for punished.\n",
      "punishing is at index 23477\n",
      "Saved the embedding for punishing.\n",
      "punitive is at index 21987\n",
      "Saved the embedding for punitive.\n",
      "punk is at index 19742\n",
      "Saved the embedding for punk.\n",
      "puppyish is at index 20830\n",
      "Saved the embedding for puppyish.\n",
      "purposeful is at index 3508\n",
      "Saved the embedding for purposeful.\n",
      "pursed is at index 26934\n",
      "Saved the embedding for pursed.\n",
      "put is at index 342\n",
      "Saved the embedding for put.\n",
      "putting is at index 2057\n",
      "Saved the embedding for putting.\n",
      "puzzled is at index 36742\n",
      "Saved the embedding for puzzled.\n",
      "puzzlement is at index 47037\n",
      "Saved the embedding for puzzlement.\n",
      "qualms is at index 22043\n",
      "Saved the embedding for qualms.\n",
      "quarrelsome is at index 39486\n",
      "Saved the embedding for quarrelsome.\n",
      "queasy is at index 1192\n",
      "Saved the embedding for queasy.\n",
      "quenched is at index 2677\n",
      "Saved the embedding for quenched.\n",
      "questionable is at index 12474\n",
      "Saved the embedding for questionable.\n",
      "questioning is at index 8026\n",
      "Saved the embedding for questioning.\n",
      "questioningly is at index 864\n",
      "Saved the embedding for questioningly.\n",
      "quiet is at index 5128\n",
      "Saved the embedding for quiet.\n",
      "quietness is at index 5128\n",
      "Saved the embedding for quietness.\n",
      "quilt is at index 2677\n",
      "Saved the embedding for quilt.\n",
      "quirky is at index 22364\n",
      "Saved the embedding for quirky.\n",
      "quizzical is at index 29316\n",
      "Saved the embedding for quizzical.\n",
      "rabid is at index 39660\n",
      "Saved the embedding for rabid.\n",
      "racked is at index 20208\n",
      "Saved the embedding for racked.\n",
      "radiant is at index 35787\n",
      "Saved the embedding for radiant.\n",
      "rage is at index 14706\n",
      "Saved the embedding for rage.\n",
      "raged is at index 31927\n",
      "Saved the embedding for raged.\n",
      "ragged is at index 910\n",
      "Saved the embedding for ragged.\n",
      "raging is at index 23333\n",
      "Saved the embedding for raging.\n",
      "rancorous is at index 21560\n",
      "Saved the embedding for rancorous.\n",
      "randy is at index 910\n",
      "Saved the embedding for randy.\n",
      "rapt is at index 34524\n",
      "Saved the embedding for rapt.\n",
      "rattled is at index 21602\n",
      "Saved the embedding for rattled.\n",
      "raving is at index 910\n",
      "Saved the embedding for raving.\n",
      "reactive is at index 34729\n",
      "Saved the embedding for reactive.\n",
      "ready is at index 1227\n",
      "Saved the embedding for ready.\n",
      "realization is at index 24179\n",
      "Saved the embedding for realization.\n",
      "reassured is at index 29336\n",
      "Saved the embedding for reassured.\n",
      "rebellious is at index 38017\n",
      "Saved the embedding for rebellious.\n",
      "rebuke is at index 28155\n",
      "Saved the embedding for rebuke.\n",
      "recalling is at index 20239\n",
      "Saved the embedding for recalling.\n",
      "receptive is at index 33052\n",
      "Saved the embedding for receptive.\n",
      "reckless is at index 13508\n",
      "Saved the embedding for reckless.\n",
      "recoil is at index 44983\n",
      "Saved the embedding for recoil.\n",
      "recoiling is at index 3872\n",
      "Saved the embedding for recoiling.\n",
      "reflecting is at index 10811\n",
      "Saved the embedding for reflecting.\n",
      "reflection is at index 12456\n",
      "Saved the embedding for reflection.\n",
      "reflective is at index 22213\n",
      "Saved the embedding for reflective.\n",
      "refulgent is at index 769\n",
      "Saved the embedding for refulgent.\n",
      "refusing is at index 10520\n",
      "Saved the embedding for refusing.\n",
      "regret is at index 9917\n",
      "Saved the embedding for regret.\n",
      "regretful is at index 9917\n",
      "Saved the embedding for regretful.\n",
      "rejected is at index 3946\n",
      "Saved the embedding for rejected.\n",
      "rejecting is at index 19695\n",
      "Saved the embedding for rejecting.\n",
      "rejection is at index 16117\n",
      "Saved the embedding for rejection.\n",
      "rejoicing is at index 24586\n",
      "Saved the embedding for rejoicing.\n",
      "relaxation is at index 26545\n",
      "Saved the embedding for relaxation.\n",
      "relaxed is at index 11956\n",
      "Saved the embedding for relaxed.\n",
      "relentless is at index 16476\n",
      "Saved the embedding for relentless.\n",
      "relief is at index 3500\n",
      "Saved the embedding for relief.\n",
      "relieved is at index 15126\n",
      "Saved the embedding for relieved.\n",
      "relived is at index 6258\n",
      "Saved the embedding for relived.\n",
      "reluctant is at index 11923\n",
      "Saved the embedding for reluctant.\n",
      "reluctantly is at index 33146\n",
      "Saved the embedding for reluctantly.\n",
      "remorse is at index 23312\n",
      "Saved the embedding for remorse.\n",
      "remorseful is at index 23312\n",
      "Saved the embedding for remorseful.\n",
      "repelled is at index 25633\n",
      "Saved the embedding for repelled.\n",
      "repressed is at index 2851\n",
      "Saved the embedding for repressed.\n",
      "reproach is at index 2851\n",
      "Saved the embedding for reproach.\n",
      "reproachful is at index 2851\n",
      "Saved the embedding for reproachful.\n",
      "repugnance is at index 2851\n",
      "Saved the embedding for repugnance.\n",
      "repugnant is at index 2851\n",
      "Saved the embedding for repugnant.\n",
      "repulsed is at index 2851\n",
      "Saved the embedding for repulsed.\n",
      "repulsion is at index 2851\n",
      "Saved the embedding for repulsion.\n",
      "resent is at index 31379\n",
      "Saved the embedding for resent.\n",
      "resentful is at index 31379\n",
      "Saved the embedding for resentful.\n",
      "resenting is at index 31379\n",
      "Saved the embedding for resenting.\n",
      "resentment is at index 27111\n",
      "Saved the embedding for resentment.\n",
      "reserved is at index 1875\n",
      "Saved the embedding for reserved.\n",
      "resignation is at index 6985\n",
      "Saved the embedding for resignation.\n",
      "resigned is at index 6490\n",
      "Saved the embedding for resigned.\n",
      "resilience is at index 13790\n",
      "Saved the embedding for resilience.\n",
      "resistance is at index 5910\n",
      "Saved the embedding for resistance.\n",
      "resistant is at index 19152\n",
      "Saved the embedding for resistant.\n",
      "resistent is at index 11942\n",
      "Saved the embedding for resistent.\n",
      "resisting is at index 18907\n",
      "Saved the embedding for resisting.\n",
      "resolute is at index 5032\n",
      "Saved the embedding for resolute.\n",
      "resolved is at index 8179\n",
      "Saved the embedding for resolved.\n",
      "responsive is at index 20666\n",
      "Saved the embedding for responsive.\n",
      "restful is at index 1079\n",
      "Saved the embedding for restful.\n",
      "resting is at index 18403\n",
      "Saved the embedding for resting.\n",
      "restless is at index 36844\n",
      "Saved the embedding for restless.\n",
      "restlessness is at index 1079\n",
      "Saved the embedding for restlessness.\n",
      "restrained is at index 25063\n",
      "Saved the embedding for restrained.\n",
      "restraint is at index 20219\n",
      "Saved the embedding for restraint.\n",
      "retaliating is at index 18570\n",
      "Saved the embedding for retaliating.\n",
      "retaliatory is at index 18570\n",
      "Saved the embedding for retaliatory.\n",
      "rethinking is at index 769\n",
      "Saved the embedding for rethinking.\n",
      "reticence is at index 5494\n",
      "Saved the embedding for reticence.\n",
      "reticent is at index 5494\n",
      "Saved the embedding for reticent.\n",
      "revengeful is at index 13543\n",
      "Saved the embedding for revengeful.\n",
      "reverent is at index 26911\n",
      "Saved the embedding for reverent.\n",
      "revolted is at index 34633\n",
      "Saved the embedding for revolted.\n",
      "revulsion is at index 6910\n",
      "Saved the embedding for revulsion.\n",
      "righteous is at index 37909\n",
      "Saved the embedding for righteous.\n",
      "rigid is at index 24577\n",
      "Saved the embedding for rigid.\n",
      "riled is at index 910\n",
      "Saved the embedding for riled.\n",
      "riotous is at index 13069\n",
      "Saved the embedding for riotous.\n",
      "riveted is at index 32886\n",
      "Saved the embedding for riveted.\n",
      "roar is at index 31733\n",
      "Saved the embedding for roar.\n",
      "roguish is at index 4533\n",
      "Saved the embedding for roguish.\n",
      "roiled is at index 4533\n",
      "Saved the embedding for roiled.\n",
      "rough is at index 6744\n",
      "Saved the embedding for rough.\n",
      "roused is at index 910\n",
      "Saved the embedding for roused.\n",
      "rude is at index 21820\n",
      "Saved the embedding for rude.\n",
      "rueful is at index 910\n",
      "Saved the embedding for rueful.\n",
      "ruffled is at index 910\n",
      "Saved the embedding for ruffled.\n",
      "ruminating is at index 11122\n",
      "Saved the embedding for ruminating.\n",
      "rustled is at index 18309\n",
      "Saved the embedding for rustled.\n",
      "ruthless is at index 25597\n",
      "Saved the embedding for ruthless.\n",
      "sad is at index 5074\n",
      "Saved the embedding for sad.\n",
      "sadden is at index 23330\n",
      "Saved the embedding for sadden.\n",
      "saddened is at index 19934\n",
      "Saved the embedding for saddened.\n",
      "sadistic is at index 5074\n",
      "Saved the embedding for sadistic.\n",
      "sadness is at index 17437\n",
      "Saved the embedding for sadness.\n",
      "salacious is at index 6641\n",
      "Saved the embedding for salacious.\n",
      "salivating is at index 6641\n",
      "Saved the embedding for salivating.\n",
      "sanctimonious is at index 27600\n",
      "Saved the embedding for sanctimonious.\n",
      "sane is at index 37091\n",
      "Saved the embedding for sane.\n",
      "sanguine is at index 579\n",
      "Saved the embedding for sanguine.\n",
      "sappy is at index 2241\n",
      "Saved the embedding for sappy.\n",
      "sarcasm is at index 38522\n",
      "Saved the embedding for sarcasm.\n",
      "sarcastic is at index 39580\n",
      "Saved the embedding for sarcastic.\n",
      "sardonic is at index 579\n",
      "Saved the embedding for sardonic.\n",
      "sassy is at index 579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for sassy.\n",
      "sated is at index 579\n",
      "Saved the embedding for sated.\n",
      "satiated is at index 4005\n",
      "Saved the embedding for satiated.\n",
      "satirical is at index 33937\n",
      "Saved the embedding for satirical.\n",
      "satisfaction is at index 11658\n",
      "Saved the embedding for satisfaction.\n",
      "satisfied is at index 10028\n",
      "Saved the embedding for satisfied.\n",
      "satisfy is at index 15332\n",
      "Saved the embedding for satisfy.\n",
      "saturnine is at index 4005\n",
      "Saved the embedding for saturnine.\n",
      "saucy is at index 2241\n",
      "Saved the embedding for saucy.\n",
      "savage is at index 32264\n",
      "Saved the embedding for savage.\n",
      "scandalized is at index 4220\n",
      "Saved the embedding for scandalized.\n",
      "scare is at index 13207\n",
      "Saved the embedding for scare.\n",
      "scared is at index 8265\n",
      "Saved the embedding for scared.\n",
      "scary is at index 10222\n",
      "Saved the embedding for scary.\n",
      "scattered is at index 12827\n",
      "Saved the embedding for scattered.\n",
      "schadenfreude is at index 8447\n",
      "Saved the embedding for schadenfreude.\n",
      "scheming is at index 30315\n",
      "Saved the embedding for scheming.\n",
      "scoffer is at index 34564\n",
      "Saved the embedding for scoffer.\n",
      "scoffing is at index 34564\n",
      "Saved the embedding for scoffing.\n",
      "scorn is at index 38430\n",
      "Saved the embedding for scorn.\n",
      "scorned is at index 2850\n",
      "Saved the embedding for scorned.\n",
      "scornful is at index 38430\n",
      "Saved the embedding for scornful.\n",
      "scowl is at index 2850\n",
      "Saved the embedding for scowl.\n",
      "scowling is at index 2850\n",
      "Saved the embedding for scowling.\n",
      "scream is at index 22093\n",
      "Saved the embedding for scream.\n",
      "screaming is at index 11347\n",
      "Saved the embedding for screaming.\n",
      "scrutinizing is at index 18470\n",
      "Saved the embedding for scrutinizing.\n",
      "sealed is at index 10497\n",
      "Saved the embedding for sealed.\n",
      "searching is at index 6062\n",
      "Saved the embedding for searching.\n",
      "secretive is at index 27174\n",
      "Saved the embedding for secretive.\n",
      "secretively is at index 3556\n",
      "Saved the embedding for secretively.\n",
      "secure is at index 2823\n",
      "Saved the embedding for secure.\n",
      "sedate is at index 10195\n",
      "Saved the embedding for sedate.\n",
      "seduction is at index 10195\n",
      "Saved the embedding for seduction.\n",
      "seductive is at index 10195\n",
      "Saved the embedding for seductive.\n",
      "seething is at index 842\n",
      "Saved the embedding for seething.\n",
      "self is at index 1403\n",
      "Saved the embedding for self.\n",
      "sensual is at index 18105\n",
      "Saved the embedding for sensual.\n",
      "sentimental is at index 32693\n",
      "Saved the embedding for sentimental.\n",
      "serene is at index 842\n",
      "Saved the embedding for serene.\n",
      "serious is at index 1473\n",
      "Saved the embedding for serious.\n",
      "seriousness is at index 24146\n",
      "Saved the embedding for seriousness.\n",
      "servile is at index 18527\n",
      "Saved the embedding for servile.\n",
      "set is at index 278\n",
      "Saved the embedding for set.\n",
      "severe is at index 3814\n",
      "Saved the embedding for severe.\n",
      "shabby is at index 1481\n",
      "Saved the embedding for shabby.\n",
      "shady is at index 31665\n",
      "Saved the embedding for shady.\n",
      "shaken is at index 17548\n",
      "Saved the embedding for shaken.\n",
      "shaky is at index 22032\n",
      "Saved the embedding for shaky.\n",
      "shame is at index 9208\n",
      "Saved the embedding for shame.\n",
      "shamed is at index 1481\n",
      "Saved the embedding for shamed.\n",
      "shamefaced is at index 9208\n",
      "Saved the embedding for shamefaced.\n",
      "shameful is at index 26722\n",
      "Saved the embedding for shameful.\n",
      "shameless is at index 36778\n",
      "Saved the embedding for shameless.\n",
      "sharp is at index 4406\n",
      "Saved the embedding for sharp.\n",
      "sheepish is at index 14336\n",
      "Saved the embedding for sheepish.\n",
      "sheepishness is at index 14336\n",
      "Saved the embedding for sheepishness.\n",
      "shelled is at index 79\n",
      "Saved the embedding for shelled.\n",
      "shifty is at index 37503\n",
      "Saved the embedding for shifty.\n",
      "shock is at index 4817\n",
      "Saved the embedding for shock.\n",
      "shocked is at index 6649\n",
      "Saved the embedding for shocked.\n",
      "shocking is at index 8777\n",
      "Saved the embedding for shocking.\n",
      "shockingly is at index 36804\n",
      "Saved the embedding for shockingly.\n",
      "shook is at index 14774\n",
      "Saved the embedding for shook.\n",
      "shout is at index 18066\n",
      "Saved the embedding for shout.\n",
      "shouting is at index 14487\n",
      "Saved the embedding for shouting.\n",
      "shrewd is at index 36943\n",
      "Saved the embedding for shrewd.\n",
      "shy is at index 9152\n",
      "Saved the embedding for shy.\n",
      "shyness is at index 9152\n",
      "Saved the embedding for shyness.\n",
      "sick is at index 4736\n",
      "Saved the embedding for sick.\n",
      "sicken is at index 579\n",
      "Saved the embedding for sicken.\n",
      "sickened is at index 4736\n",
      "Saved the embedding for sickened.\n",
      "sigh is at index 27305\n",
      "Saved the embedding for sigh.\n",
      "silenced is at index 30125\n",
      "Saved the embedding for silenced.\n",
      "silent is at index 8454\n",
      "Saved the embedding for silent.\n",
      "silliness is at index 38052\n",
      "Saved the embedding for silliness.\n",
      "silly is at index 15470\n",
      "Saved the embedding for silly.\n",
      "simmering is at index 25726\n",
      "Saved the embedding for simmering.\n",
      "simper is at index 16207\n",
      "Saved the embedding for simper.\n",
      "simpering is at index 16207\n",
      "Saved the embedding for simpering.\n",
      "simple is at index 2007\n",
      "Saved the embedding for simple.\n",
      "simplicity is at index 25342\n",
      "Saved the embedding for simplicity.\n",
      "sincere is at index 19255\n",
      "Saved the embedding for sincere.\n",
      "sinful is at index 44364\n",
      "Saved the embedding for sinful.\n",
      "singing is at index 6970\n",
      "Saved the embedding for singing.\n",
      "sinister is at index 27570\n",
      "Saved the embedding for sinister.\n",
      "sinisterly is at index 27570\n",
      "Saved the embedding for sinisterly.\n",
      "sizing is at index 39328\n",
      "Saved the embedding for sizing.\n",
      "skeptic is at index 42386\n",
      "Saved the embedding for skeptic.\n",
      "skeptical is at index 14992\n",
      "Saved the embedding for skeptical.\n",
      "skeptically is at index 42386\n",
      "Saved the embedding for skeptically.\n",
      "skepticism is at index 22222\n",
      "Saved the embedding for skepticism.\n",
      "sketchy is at index 15923\n",
      "Saved the embedding for sketchy.\n",
      "skittish is at index 2972\n",
      "Saved the embedding for skittish.\n",
      "slack is at index 25163\n",
      "Saved the embedding for slack.\n",
      "sleazy is at index 18388\n",
      "Saved the embedding for sleazy.\n",
      "sleepy is at index 33782\n",
      "Saved the embedding for sleepy.\n",
      "slick is at index 19038\n",
      "Saved the embedding for slick.\n",
      "slothful is at index 3369\n",
      "Saved the embedding for slothful.\n",
      "slow is at index 2635\n",
      "Saved the embedding for slow.\n",
      "sluggish is at index 16642\n",
      "Saved the embedding for sluggish.\n",
      "sly is at index 40568\n",
      "Saved the embedding for sly.\n",
      "smarmy is at index 5278\n",
      "Saved the embedding for smarmy.\n",
      "smart is at index 2793\n",
      "Saved the embedding for smart.\n",
      "smashed is at index 13263\n",
      "Saved the embedding for smashed.\n",
      "smile is at index 6675\n",
      "Saved the embedding for smile.\n",
      "smiley is at index 6675\n",
      "Saved the embedding for smiley.\n",
      "smiling is at index 12382\n",
      "Saved the embedding for smiling.\n",
      "smirk is at index 5278\n",
      "Saved the embedding for smirk.\n",
      "smirking is at index 44414\n",
      "Saved the embedding for smirking.\n",
      "smoldering is at index 5278\n",
      "Saved the embedding for smoldering.\n",
      "smooching is at index 5278\n",
      "Saved the embedding for smooching.\n",
      "smooth is at index 6921\n",
      "Saved the embedding for smooth.\n",
      "smug is at index 41283\n",
      "Saved the embedding for smug.\n",
      "smugness is at index 41283\n",
      "Saved the embedding for smugness.\n",
      "snake is at index 16173\n",
      "Saved the embedding for snake.\n",
      "snappy is at index 4543\n",
      "Saved the embedding for snappy.\n",
      "snarky is at index 4543\n",
      "Saved the embedding for snarky.\n",
      "snarl is at index 4543\n",
      "Saved the embedding for snarl.\n",
      "snarled is at index 4543\n",
      "Saved the embedding for snarled.\n",
      "snarling is at index 4543\n",
      "Saved the embedding for snarling.\n",
      "snarly is at index 4543\n",
      "Saved the embedding for snarly.\n",
      "sneaky is at index 39399\n",
      "Saved the embedding for sneaky.\n",
      "sneer is at index 18013\n",
      "Saved the embedding for sneer.\n",
      "sneering is at index 18013\n",
      "Saved the embedding for sneering.\n",
      "sneeze is at index 18013\n",
      "Saved the embedding for sneeze.\n",
      "sneezing is at index 18013\n",
      "Saved the embedding for sneezing.\n",
      "snicker is at index 4543\n",
      "Saved the embedding for snicker.\n",
      "snickering is at index 4543\n",
      "Saved the embedding for snickering.\n",
      "snide is at index 4543\n",
      "Saved the embedding for snide.\n",
      "sniggering is at index 4543\n",
      "Saved the embedding for sniggering.\n",
      "sniveling is at index 4543\n",
      "Saved the embedding for sniveling.\n",
      "snobbish is at index 4543\n",
      "Saved the embedding for snobbish.\n",
      "snobby is at index 4543\n",
      "Saved the embedding for snobby.\n",
      "snooty is at index 4543\n",
      "Saved the embedding for snooty.\n",
      "snotty is at index 579\n",
      "Saved the embedding for snotty.\n",
      "sociable is at index 17380\n",
      "Saved the embedding for sociable.\n",
      "soft is at index 3793\n",
      "Saved the embedding for soft.\n",
      "solemn is at index 29807\n",
      "Saved the embedding for solemn.\n",
      "solicitous is at index 22706\n",
      "Saved the embedding for solicitous.\n",
      "solitary is at index 24429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for solitary.\n",
      "solitude is at index 41813\n",
      "Saved the embedding for solitude.\n",
      "somber is at index 16487\n",
      "Saved the embedding for somber.\n",
      "somberly is at index 16487\n",
      "Saved the embedding for somberly.\n",
      "somnolent is at index 16487\n",
      "Saved the embedding for somnolent.\n",
      "soothed is at index 98\n",
      "Saved the embedding for soothed.\n",
      "sore is at index 12867\n",
      "Saved the embedding for sore.\n",
      "sorrow is at index 26130\n",
      "Saved the embedding for sorrow.\n",
      "sorrowful is at index 26130\n",
      "Saved the embedding for sorrowful.\n",
      "sorry is at index 6661\n",
      "Saved the embedding for sorry.\n",
      "sour is at index 16933\n",
      "Saved the embedding for sour.\n",
      "spaced is at index 42926\n",
      "Saved the embedding for spaced.\n",
      "spacing is at index 39152\n",
      "Saved the embedding for spacing.\n",
      "spastic is at index 2292\n",
      "Saved the embedding for spastic.\n",
      "speaking is at index 2686\n",
      "Saved the embedding for speaking.\n",
      "specious is at index 12002\n",
      "Saved the embedding for specious.\n",
      "speculative is at index 21779\n",
      "Saved the embedding for speculative.\n",
      "speechless is at index 1901\n",
      "Saved the embedding for speechless.\n",
      "spent is at index 1240\n",
      "Saved the embedding for spent.\n",
      "spirited is at index 27206\n",
      "Saved the embedding for spirited.\n",
      "spiritless is at index 4780\n",
      "Saved the embedding for spiritless.\n",
      "spite is at index 14117\n",
      "Saved the embedding for spite.\n",
      "spiteful is at index 14117\n",
      "Saved the embedding for spiteful.\n",
      "spoiled is at index 29136\n",
      "Saved the embedding for spoiled.\n",
      "spooked is at index 2292\n",
      "Saved the embedding for spooked.\n",
      "squeamish is at index 33380\n",
      "Saved the embedding for squeamish.\n",
      "staggered is at index 37646\n",
      "Saved the embedding for staggered.\n",
      "stalker is at index 1690\n",
      "Saved the embedding for stalker.\n",
      "stare is at index 27655\n",
      "Saved the embedding for stare.\n",
      "staring is at index 19311\n",
      "Saved the embedding for staring.\n",
      "starstruck is at index 999\n",
      "Saved the embedding for starstruck.\n",
      "started is at index 554\n",
      "Saved the embedding for started.\n",
      "startled is at index 37747\n",
      "Saved the embedding for startled.\n",
      "stately is at index 194\n",
      "Saved the embedding for stately.\n",
      "steadfast is at index 25781\n",
      "Saved the embedding for steadfast.\n",
      "steady is at index 5204\n",
      "Saved the embedding for steady.\n",
      "stealthy is at index 27026\n",
      "Saved the embedding for stealthy.\n",
      "steamed is at index 11235\n",
      "Saved the embedding for steamed.\n",
      "steaming is at index 11235\n",
      "Saved the embedding for steaming.\n",
      "steeling is at index 3689\n",
      "Saved the embedding for steeling.\n",
      "steely is at index 1690\n",
      "Saved the embedding for steely.\n",
      "stern is at index 23427\n",
      "Saved the embedding for stern.\n",
      "stiff is at index 13116\n",
      "Saved the embedding for stiff.\n",
      "stifled is at index 1690\n",
      "Saved the embedding for stifled.\n",
      "stifling is at index 1690\n",
      "Saved the embedding for stifling.\n",
      "still is at index 202\n",
      "Saved the embedding for still.\n",
      "stillness is at index 202\n",
      "Saved the embedding for stillness.\n",
      "stimulated is at index 42040\n",
      "Saved the embedding for stimulated.\n",
      "stinky is at index 1690\n",
      "Saved the embedding for stinky.\n",
      "stirred is at index 26158\n",
      "Saved the embedding for stirred.\n",
      "stoic is at index 20572\n",
      "Saved the embedding for stoic.\n",
      "stoical is at index 20572\n",
      "Saved the embedding for stoical.\n",
      "stolid is at index 1690\n",
      "Saved the embedding for stolid.\n",
      "stoned is at index 1690\n",
      "Saved the embedding for stoned.\n",
      "storming is at index 2130\n",
      "Saved the embedding for storming.\n",
      "stormy is at index 2130\n",
      "Saved the embedding for stormy.\n",
      "stout is at index 34636\n",
      "Saved the embedding for stout.\n",
      "straight is at index 1359\n",
      "Saved the embedding for straight.\n",
      "strained is at index 15718\n",
      "Saved the embedding for strained.\n",
      "strange is at index 7782\n",
      "Saved the embedding for strange.\n",
      "stressed is at index 5882\n",
      "Saved the embedding for stressed.\n",
      "stricken is at index 35876\n",
      "Saved the embedding for stricken.\n",
      "strict is at index 8414\n",
      "Saved the embedding for strict.\n",
      "strong is at index 670\n",
      "Saved the embedding for strong.\n",
      "struck is at index 2322\n",
      "Saved the embedding for struck.\n",
      "stubborn is at index 20476\n",
      "Saved the embedding for stubborn.\n",
      "stubbornness is at index 20476\n",
      "Saved the embedding for stubbornness.\n",
      "studious is at index 15863\n",
      "Saved the embedding for studious.\n",
      "studying is at index 7739\n",
      "Saved the embedding for studying.\n",
      "stumped is at index 1690\n",
      "Saved the embedding for stumped.\n",
      "stung is at index 1690\n",
      "Saved the embedding for stung.\n",
      "stunned is at index 12144\n",
      "Saved the embedding for stunned.\n",
      "stupefaction is at index 1690\n",
      "Saved the embedding for stupefaction.\n",
      "stupefied is at index 1690\n",
      "Saved the embedding for stupefied.\n",
      "stupefy is at index 1690\n",
      "Saved the embedding for stupefy.\n",
      "stupid is at index 12103\n",
      "Saved the embedding for stupid.\n",
      "stuporous is at index 1690\n",
      "Saved the embedding for stuporous.\n",
      "suave is at index 2628\n",
      "Saved the embedding for suave.\n",
      "subdued is at index 20247\n",
      "Saved the embedding for subdued.\n",
      "sublime is at index 32477\n",
      "Saved the embedding for sublime.\n",
      "submissive is at index 2849\n",
      "Saved the embedding for submissive.\n",
      "suffering is at index 3606\n",
      "Saved the embedding for suffering.\n",
      "suggestive is at index 38907\n",
      "Saved the embedding for suggestive.\n",
      "sulking is at index 26648\n",
      "Saved the embedding for sulking.\n",
      "sulky is at index 26648\n",
      "Saved the embedding for sulky.\n",
      "sullen is at index 2628\n",
      "Saved the embedding for sullen.\n",
      "sullenness is at index 2628\n",
      "Saved the embedding for sullenness.\n",
      "sunny is at index 5419\n",
      "Saved the embedding for sunny.\n",
      "superior is at index 10295\n",
      "Saved the embedding for superior.\n",
      "superiority is at index 32951\n",
      "Saved the embedding for superiority.\n",
      "suppressed is at index 31683\n",
      "Saved the embedding for suppressed.\n",
      "suppressing is at index 38919\n",
      "Saved the embedding for suppressing.\n",
      "suppression is at index 25276\n",
      "Saved the embedding for suppression.\n",
      "sure is at index 686\n",
      "Saved the embedding for sure.\n",
      "surly is at index 8113\n",
      "Saved the embedding for surly.\n",
      "surprise is at index 2755\n",
      "Saved the embedding for surprise.\n",
      "surprised is at index 3911\n",
      "Saved the embedding for surprised.\n",
      "surprising is at index 6167\n",
      "Saved the embedding for surprising.\n",
      "surprisingly is at index 10262\n",
      "Saved the embedding for surprisingly.\n",
      "surreptitious is at index 8113\n",
      "Saved the embedding for surreptitious.\n",
      "suspect is at index 1985\n",
      "Saved the embedding for suspect.\n",
      "suspecting is at index 1985\n",
      "Saved the embedding for suspecting.\n",
      "suspense is at index 31803\n",
      "Saved the embedding for suspense.\n",
      "suspicion is at index 8551\n",
      "Saved the embedding for suspicion.\n",
      "suspicious is at index 7775\n",
      "Saved the embedding for suspicious.\n",
      "suspiciously is at index 7775\n",
      "Saved the embedding for suspiciously.\n",
      "suspiciousness is at index 7775\n",
      "Saved the embedding for suspiciousness.\n",
      "swaggering is at index 3514\n",
      "Saved the embedding for swaggering.\n",
      "swearing is at index 21854\n",
      "Saved the embedding for swearing.\n",
      "sympathetic is at index 22869\n",
      "Saved the embedding for sympathetic.\n",
      "sympathizing is at index 19023\n",
      "Saved the embedding for sympathizing.\n",
      "sympathy is at index 16554\n",
      "Saved the embedding for sympathy.\n",
      "taciturn is at index 36502\n",
      "Saved the embedding for taciturn.\n",
      "talkative is at index 1067\n",
      "Saved the embedding for talkative.\n",
      "talking is at index 1686\n",
      "Saved the embedding for talking.\n",
      "tantalized is at index 33496\n",
      "Saved the embedding for tantalized.\n",
      "tart is at index 27468\n",
      "Saved the embedding for tart.\n",
      "tasteful is at index 24867\n",
      "Saved the embedding for tasteful.\n",
      "tattling is at index 45951\n",
      "Saved the embedding for tattling.\n",
      "taunt is at index 44048\n",
      "Saved the embedding for taunt.\n",
      "taunting is at index 326\n",
      "Saved the embedding for taunting.\n",
      "taut is at index 326\n",
      "Saved the embedding for taut.\n",
      "tearful is at index 7366\n",
      "Saved the embedding for tearful.\n",
      "teary is at index 7366\n",
      "Saved the embedding for teary.\n",
      "tease is at index 29993\n",
      "Saved the embedding for tease.\n",
      "teasing is at index 29752\n",
      "Saved the embedding for teasing.\n",
      "tempered is at index 31380\n",
      "Saved the embedding for tempered.\n",
      "tempest is at index 32196\n",
      "Saved the embedding for tempest.\n",
      "tempestuous is at index 32196\n",
      "Saved the embedding for tempestuous.\n",
      "tempted is at index 23448\n",
      "Saved the embedding for tempted.\n",
      "tenacious is at index 2724\n",
      "Saved the embedding for tenacious.\n",
      "tender is at index 8780\n",
      "Saved the embedding for tender.\n",
      "tenderness is at index 8780\n",
      "Saved the embedding for tenderness.\n",
      "tense is at index 13554\n",
      "Saved the embedding for tense.\n",
      "tensed is at index 7281\n",
      "Saved the embedding for tensed.\n",
      "tension is at index 8556\n",
      "Saved the embedding for tension.\n",
      "tentative is at index 22948\n",
      "Saved the embedding for tentative.\n",
      "terrified is at index 19419\n",
      "Saved the embedding for terrified.\n",
      "terror is at index 5231\n",
      "Saved the embedding for terror.\n",
      "terrorized is at index 5231\n",
      "Saved the embedding for terrorized.\n",
      "terrorizing is at index 5231\n",
      "Saved the embedding for terrorizing.\n",
      "terse is at index 8470\n",
      "Saved the embedding for terse.\n",
      "testy is at index 1296\n",
      "Saved the embedding for testy.\n",
      "tetchy is at index 326\n",
      "Saved the embedding for tetchy.\n",
      "thankful is at index 12025\n",
      "Saved the embedding for thankful.\n",
      "thinking is at index 2053\n",
      "Saved the embedding for thinking.\n",
      "thought is at index 802\n",
      "Saved the embedding for thought.\n",
      "thoughtful is at index 16801\n",
      "Saved the embedding for thoughtful.\n",
      "thoughtfulness is at index 802\n",
      "Saved the embedding for thoughtfulness.\n",
      "threat is at index 1856\n",
      "Saved the embedding for threat.\n",
      "threatened is at index 3711\n",
      "Saved the embedding for threatened.\n",
      "threatening is at index 5608\n",
      "Saved the embedding for threatening.\n",
      "thrilled is at index 8689\n",
      "Saved the embedding for thrilled.\n",
      "thrown is at index 5629\n",
      "Saved the embedding for thrown.\n",
      "thunderstruck is at index 4775\n",
      "Saved the embedding for thunderstruck.\n",
      "thwarted is at index 28299\n",
      "Saved the embedding for thwarted.\n",
      "ticked is at index 10457\n",
      "Saved the embedding for ticked.\n",
      "tickled is at index 10457\n",
      "Saved the embedding for tickled.\n",
      "tied is at index 3016\n",
      "Saved the embedding for tied.\n",
      "tiered is at index 3318\n",
      "Saved the embedding for tiered.\n",
      "tight is at index 3229\n",
      "Saved the embedding for tight.\n",
      "tightlipped is at index 3229\n",
      "Saved the embedding for tightlipped.\n",
      "timid is at index 39649\n",
      "Saved the embedding for timid.\n",
      "timidly is at index 39649\n",
      "Saved the embedding for timidly.\n",
      "timidness is at index 39649\n",
      "Saved the embedding for timidness.\n",
      "tired is at index 7428\n",
      "Saved the embedding for tired.\n",
      "tiredly is at index 7428\n",
      "Saved the embedding for tiredly.\n",
      "tiredness is at index 7428\n",
      "Saved the embedding for tiredness.\n",
      "titillated is at index 13515\n",
      "Saved the embedding for titillated.\n",
      "tolerant is at index 32836\n",
      "Saved the embedding for tolerant.\n",
      "tongue is at index 15686\n",
      "Saved the embedding for tongue.\n",
      "tormented is at index 16535\n",
      "Saved the embedding for tormented.\n",
      "touched is at index 6699\n",
      "Saved the embedding for touched.\n",
      "tough is at index 1828\n",
      "Saved the embedding for tough.\n",
      "toying is at index 7\n",
      "Saved the embedding for toying.\n",
      "tragic is at index 8805\n",
      "Saved the embedding for tragic.\n",
      "tragical is at index 2664\n",
      "Saved the embedding for tragical.\n",
      "tranquil is at index 33535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for tranquil.\n",
      "tranquility is at index 36474\n",
      "Saved the embedding for tranquility.\n",
      "transfixed is at index 30387\n",
      "Saved the embedding for transfixed.\n",
      "traumatized is at index 25178\n",
      "Saved the embedding for traumatized.\n",
      "trembling is at index 44912\n",
      "Saved the embedding for trembling.\n",
      "trepid is at index 6110\n",
      "Saved the embedding for trepid.\n",
      "trepidation is at index 6110\n",
      "Saved the embedding for trepidation.\n",
      "trickster is at index 7610\n",
      "Saved the embedding for trickster.\n",
      "tricky is at index 12792\n",
      "Saved the embedding for tricky.\n",
      "triumphant is at index 32025\n",
      "Saved the embedding for triumphant.\n",
      "troubled is at index 9895\n",
      "Saved the embedding for troubled.\n",
      "troublesome is at index 34056\n",
      "Saved the embedding for troublesome.\n",
      "troubling is at index 15554\n",
      "Saved the embedding for troubling.\n",
      "trusting is at index 28969\n",
      "Saved the embedding for trusting.\n",
      "trustworthy is at index 32101\n",
      "Saved the embedding for trustworthy.\n",
      "tumultuous is at index 23787\n",
      "Saved the embedding for tumultuous.\n",
      "turbulent is at index 23415\n",
      "Saved the embedding for turbulent.\n",
      "twinkly is at index 11901\n",
      "Saved the embedding for twinkly.\n",
      "umbrage is at index 7252\n",
      "Saved the embedding for umbrage.\n",
      "umbrageous is at index 7252\n",
      "Saved the embedding for umbrageous.\n",
      "unaffected is at index 32512\n",
      "Saved the embedding for unaffected.\n",
      "unagitated is at index 542\n",
      "Saved the embedding for unagitated.\n",
      "unamused is at index 542\n",
      "Saved the embedding for unamused.\n",
      "unappreciative is at index 542\n",
      "Saved the embedding for unappreciative.\n",
      "unapproachable is at index 542\n",
      "Saved the embedding for unapproachable.\n",
      "unassertive is at index 542\n",
      "Saved the embedding for unassertive.\n",
      "unassuming is at index 542\n",
      "Saved the embedding for unassuming.\n",
      "unaware is at index 14021\n",
      "Saved the embedding for unaware.\n",
      "unbelief is at index 46646\n",
      "Saved the embedding for unbelief.\n",
      "unbelievable is at index 14011\n",
      "Saved the embedding for unbelievable.\n",
      "unbelieving is at index 46646\n",
      "Saved the embedding for unbelieving.\n",
      "unbothered is at index 542\n",
      "Saved the embedding for unbothered.\n",
      "uncaring is at index 16511\n",
      "Saved the embedding for uncaring.\n",
      "uncertain is at index 9684\n",
      "Saved the embedding for uncertain.\n",
      "uncertainly is at index 9684\n",
      "Saved the embedding for uncertainly.\n",
      "uncertainty is at index 4983\n",
      "Saved the embedding for uncertainty.\n",
      "uncivil is at index 16511\n",
      "Saved the embedding for uncivil.\n",
      "uncomfortable is at index 9800\n",
      "Saved the embedding for uncomfortable.\n",
      "uncommitted is at index 32275\n",
      "Saved the embedding for uncommitted.\n",
      "uncommunicative is at index 32275\n",
      "Saved the embedding for uncommunicative.\n",
      "uncomprehending is at index 32275\n",
      "Saved the embedding for uncomprehending.\n",
      "uncompromising is at index 32213\n",
      "Saved the embedding for uncompromising.\n",
      "unconcerned is at index 28198\n",
      "Saved the embedding for unconcerned.\n",
      "unconfident is at index 542\n",
      "Saved the embedding for unconfident.\n",
      "unconvinced is at index 28198\n",
      "Saved the embedding for unconvinced.\n",
      "uncooperative is at index 542\n",
      "Saved the embedding for uncooperative.\n",
      "uncurious is at index 16511\n",
      "Saved the embedding for uncurious.\n",
      "undecided is at index 28598\n",
      "Saved the embedding for undecided.\n",
      "underhanded is at index 223\n",
      "Saved the embedding for underhanded.\n",
      "understanding is at index 2969\n",
      "Saved the embedding for understanding.\n",
      "undesirable is at index 39028\n",
      "Saved the embedding for undesirable.\n",
      "unease is at index 12515\n",
      "Saved the embedding for unease.\n",
      "uneasily is at index 12515\n",
      "Saved the embedding for uneasily.\n",
      "uneasiness is at index 12515\n",
      "Saved the embedding for uneasiness.\n",
      "uneasy is at index 29569\n",
      "Saved the embedding for uneasy.\n",
      "unemotional is at index 542\n",
      "Saved the embedding for unemotional.\n",
      "unenthusiastic is at index 542\n",
      "Saved the embedding for unenthusiastic.\n",
      "unexcited is at index 39432\n",
      "Saved the embedding for unexcited.\n",
      "unexpected is at index 7152\n",
      "Saved the embedding for unexpected.\n",
      "unfamiliar is at index 21942\n",
      "Saved the embedding for unfamiliar.\n",
      "unfathomable is at index 9515\n",
      "Saved the embedding for unfathomable.\n",
      "unfazed is at index 9515\n",
      "Saved the embedding for unfazed.\n",
      "unfeeling is at index 9515\n",
      "Saved the embedding for unfeeling.\n",
      "unfocused is at index 47306\n",
      "Saved the embedding for unfocused.\n",
      "unforeseen is at index 33257\n",
      "Saved the embedding for unforeseen.\n",
      "unforgiving is at index 34262\n",
      "Saved the embedding for unforgiving.\n",
      "unforthcoming is at index 9515\n",
      "Saved the embedding for unforthcoming.\n",
      "unfortunate is at index 9327\n",
      "Saved the embedding for unfortunate.\n",
      "unfriendly is at index 9515\n",
      "Saved the embedding for unfriendly.\n",
      "unhappy is at index 13865\n",
      "Saved the embedding for unhappy.\n",
      "unhinged is at index 542\n",
      "Saved the embedding for unhinged.\n",
      "unimpressed is at index 542\n",
      "Saved the embedding for unimpressed.\n",
      "uninformed is at index 21969\n",
      "Saved the embedding for uninformed.\n",
      "uninspired is at index 542\n",
      "Saved the embedding for uninspired.\n",
      "uninterested is at index 542\n",
      "Saved the embedding for uninterested.\n",
      "uninvolved is at index 542\n",
      "Saved the embedding for uninvolved.\n",
      "unique is at index 2216\n",
      "Saved the embedding for unique.\n",
      "unlikeable is at index 7328\n",
      "Saved the embedding for unlikeable.\n",
      "unmoved is at index 30780\n",
      "Saved the embedding for unmoved.\n",
      "unnerved is at index 31550\n",
      "Saved the embedding for unnerved.\n",
      "unpleasant is at index 26262\n",
      "Saved the embedding for unpleasant.\n",
      "unprepared is at index 35578\n",
      "Saved the embedding for unprepared.\n",
      "unquiet is at index 542\n",
      "Saved the embedding for unquiet.\n",
      "unreactive is at index 21153\n",
      "Saved the embedding for unreactive.\n",
      "unresolved is at index 29909\n",
      "Saved the embedding for unresolved.\n",
      "unrestrained is at index 12254\n",
      "Saved the embedding for unrestrained.\n",
      "unruffled is at index 542\n",
      "Saved the embedding for unruffled.\n",
      "unsatisfied is at index 36010\n",
      "Saved the embedding for unsatisfied.\n",
      "unsettled is at index 30933\n",
      "Saved the embedding for unsettled.\n",
      "unsociable is at index 9977\n",
      "Saved the embedding for unsociable.\n",
      "unspeaking is at index 542\n",
      "Saved the embedding for unspeaking.\n",
      "unspoken is at index 542\n",
      "Saved the embedding for unspoken.\n",
      "unstrung is at index 542\n",
      "Saved the embedding for unstrung.\n",
      "unsuccessful is at index 15943\n",
      "Saved the embedding for unsuccessful.\n",
      "unsure is at index 17118\n",
      "Saved the embedding for unsure.\n",
      "unsurprised is at index 36637\n",
      "Saved the embedding for unsurprised.\n",
      "unsuspecting is at index 32276\n",
      "Saved the embedding for unsuspecting.\n",
      "unswayed is at index 9977\n",
      "Saved the embedding for unswayed.\n",
      "unsympathetic is at index 542\n",
      "Saved the embedding for unsympathetic.\n",
      "untouched is at index 29929\n",
      "Saved the embedding for untouched.\n",
      "untroubled is at index 7587\n",
      "Saved the embedding for untroubled.\n",
      "untrusting is at index 7587\n",
      "Saved the embedding for untrusting.\n",
      "unwanted is at index 15067\n",
      "Saved the embedding for unwanted.\n",
      "unwavering is at index 10963\n",
      "Saved the embedding for unwavering.\n",
      "unwelcoming is at index 10963\n",
      "Saved the embedding for unwelcoming.\n",
      "unwell is at index 542\n",
      "Saved the embedding for unwell.\n",
      "unwilling is at index 20656\n",
      "Saved the embedding for unwilling.\n",
      "unyielding is at index 542\n",
      "Saved the embedding for unyielding.\n",
      "up is at index 62\n",
      "Saved the embedding for up.\n",
      "upbeat is at index 14899\n",
      "Saved the embedding for upbeat.\n",
      "uplifting is at index 17627\n",
      "Saved the embedding for uplifting.\n",
      "uppity is at index 1717\n",
      "Saved the embedding for uppity.\n",
      "upset is at index 4904\n",
      "Saved the embedding for upset.\n",
      "uptight is at index 18256\n",
      "Saved the embedding for uptight.\n",
      "useless is at index 23584\n",
      "Saved the embedding for useless.\n",
      "vacant is at index 11042\n",
      "Saved the embedding for vacant.\n",
      "vacuous is at index 18721\n",
      "Saved the embedding for vacuous.\n",
      "vanquished is at index 44400\n",
      "Saved the embedding for vanquished.\n",
      "vehement is at index 45373\n",
      "Saved the embedding for vehement.\n",
      "vengeful is at index 748\n",
      "Saved the embedding for vengeful.\n",
      "venomous is at index 32051\n",
      "Saved the embedding for venomous.\n",
      "vex is at index 37894\n",
      "Saved the embedding for vex.\n",
      "vexation is at index 37894\n",
      "Saved the embedding for vexation.\n",
      "vexed is at index 37894\n",
      "Saved the embedding for vexed.\n",
      "vicious is at index 16339\n",
      "Saved the embedding for vicious.\n",
      "victorious is at index 22518\n",
      "Saved the embedding for victorious.\n",
      "vigilant is at index 17258\n",
      "Saved the embedding for vigilant.\n",
      "vile is at index 32359\n",
      "Saved the embedding for vile.\n",
      "villainous is at index 17031\n",
      "Saved the embedding for villainous.\n",
      "vindictive is at index 21339\n",
      "Saved the embedding for vindictive.\n",
      "violence is at index 1476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the embedding for violence.\n",
      "violent is at index 4153\n",
      "Saved the embedding for violent.\n",
      "viperous is at index 748\n",
      "Saved the embedding for viperous.\n",
      "vituperative is at index 14306\n",
      "Saved the embedding for vituperative.\n",
      "vocal is at index 7578\n",
      "Saved the embedding for vocal.\n",
      "vocalized is at index 7578\n",
      "Saved the embedding for vocalized.\n",
      "vulgar is at index 28792\n",
      "Saved the embedding for vulgar.\n",
      "vulnerability is at index 15661\n",
      "Saved the embedding for vulnerability.\n",
      "vulnerable is at index 4478\n",
      "Saved the embedding for vulnerable.\n",
      "wacky is at index 885\n",
      "Saved the embedding for wacky.\n",
      "waiting is at index 2445\n",
      "Saved the embedding for waiting.\n",
      "wanted is at index 770\n",
      "Saved the embedding for wanted.\n",
      "wanting is at index 6923\n",
      "Saved the embedding for wanting.\n",
      "wanton is at index 236\n",
      "Saved the embedding for wanton.\n",
      "wariness is at index 997\n",
      "Saved the embedding for wariness.\n",
      "warm is at index 3279\n",
      "Saved the embedding for warm.\n",
      "wary is at index 13441\n",
      "Saved the embedding for wary.\n",
      "wasted is at index 14260\n",
      "Saved the embedding for wasted.\n",
      "watch is at index 1183\n",
      "Saved the embedding for watch.\n",
      "watchful is at index 1183\n",
      "Saved the embedding for watchful.\n",
      "watching is at index 2494\n",
      "Saved the embedding for watching.\n",
      "wavering is at index 13332\n",
      "Saved the embedding for wavering.\n",
      "weariness is at index 3568\n",
      "Saved the embedding for weariness.\n",
      "weary is at index 31554\n",
      "Saved the embedding for weary.\n",
      "weeping is at index 39423\n",
      "Saved the embedding for weeping.\n",
      "weird is at index 7735\n",
      "Saved the embedding for weird.\n",
      "welcome is at index 2814\n",
      "Saved the embedding for welcome.\n",
      "welcoming is at index 10423\n",
      "Saved the embedding for welcoming.\n",
      "whatever is at index 3046\n",
      "Saved the embedding for whatever.\n",
      "whimpering is at index 31754\n",
      "Saved the embedding for whimpering.\n",
      "whimsical is at index 29363\n",
      "Saved the embedding for whimsical.\n",
      "whisper is at index 37539\n",
      "Saved the embedding for whisper.\n",
      "whistle is at index 16867\n",
      "Saved the embedding for whistle.\n",
      "white is at index 1104\n",
      "Saved the embedding for white.\n",
      "wicked is at index 28418\n",
      "Saved the embedding for wicked.\n",
      "wild is at index 3418\n",
      "Saved the embedding for wild.\n",
      "willful is at index 40960\n",
      "Saved the embedding for willful.\n",
      "willing is at index 2882\n",
      "Saved the embedding for willing.\n",
      "wily is at index 885\n",
      "Saved the embedding for wily.\n",
      "wink is at index 39422\n",
      "Saved the embedding for wink.\n",
      "wired is at index 26977\n",
      "Saved the embedding for wired.\n",
      "wishful is at index 2813\n",
      "Saved the embedding for wishful.\n",
      "wistful is at index 885\n",
      "Saved the embedding for wistful.\n",
      "wistfully is at index 885\n",
      "Saved the embedding for wistfully.\n",
      "withdraw is at index 8202\n",
      "Saved the embedding for withdraw.\n",
      "withdrawn is at index 13375\n",
      "Saved the embedding for withdrawn.\n",
      "withheld is at index 22292\n",
      "Saved the embedding for withheld.\n",
      "withholding is at index 25661\n",
      "Saved the embedding for withholding.\n",
      "woe is at index 885\n",
      "Saved the embedding for woe.\n",
      "woeful is at index 19958\n",
      "Saved the embedding for woeful.\n",
      "wonder is at index 5170\n",
      "Saved the embedding for wonder.\n",
      "wondering is at index 8020\n",
      "Saved the embedding for wondering.\n",
      "wonderment is at index 5170\n",
      "Saved the embedding for wonderment.\n",
      "wooly is at index 24815\n",
      "Saved the embedding for wooly.\n",
      "woozy is at index 24815\n",
      "Saved the embedding for woozy.\n",
      "worn is at index 10610\n",
      "Saved the embedding for worn.\n",
      "worried is at index 3915\n",
      "Saved the embedding for worried.\n",
      "worrisome is at index 29611\n",
      "Saved the embedding for worrisome.\n",
      "worry is at index 4022\n",
      "Saved the embedding for worry.\n",
      "worrying is at index 12648\n",
      "Saved the embedding for worrying.\n",
      "worryingly is at index 4022\n",
      "Saved the embedding for worryingly.\n",
      "wounded is at index 5424\n",
      "Saved the embedding for wounded.\n",
      "wow is at index 26388\n",
      "Saved the embedding for wow.\n",
      "wrathful is at index 30220\n",
      "Saved the embedding for wrathful.\n",
      "wrathfully is at index 30220\n",
      "Saved the embedding for wrathfully.\n",
      "wrecked is at index 30090\n",
      "Saved the embedding for wrecked.\n",
      "wretched is at index 42824\n",
      "Saved the embedding for wretched.\n",
      "wronged is at index 1593\n",
      "Saved the embedding for wronged.\n",
      "wroth is at index 885\n",
      "Saved the embedding for wroth.\n",
      "wry is at index 885\n",
      "Saved the embedding for wry.\n",
      "yawn is at index 39654\n",
      "Saved the embedding for yawn.\n",
      "yawning is at index 39654\n",
      "Saved the embedding for yawning.\n",
      "yearning is at index 76\n",
      "Saved the embedding for yearning.\n",
      "yell is at index 28930\n",
      "Saved the embedding for yell.\n",
      "yelling is at index 16600\n",
      "Saved the embedding for yelling.\n",
      "yielding is at index 25438\n",
      "Saved the embedding for yielding.\n",
      "yuck is at index 1423\n",
      "Saved the embedding for yuck.\n",
      "zany is at index 992\n",
      "Saved the embedding for zany.\n",
      "zealous is at index 992\n",
      "Saved the embedding for zealous.\n",
      "zen is at index 992\n",
      "Saved the embedding for zen.\n",
      "zoned is at index 992\n",
      "Saved the embedding for zoned.\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "# This cell will write out output embeddings       #\n",
    "# for all the words in my vocabulary, using RoBERTa#\n",
    "# fine-tuned twice on Common Crawl training text.  #\n",
    "####################################################\n",
    "\n",
    "# THESE EMBEDDINGS GIVE A SCORE OF 1.0 FOR ALL WORD PAIRS ON THE\n",
    "# SYNONYMY SCORING TASK: DO NOT USE!!!\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = RobertaTokenizer.from_pretrained('./output_CC-ab/')\n",
    "model = RobertaForMaskedLM.from_pretrained('./output_CC-ab/', config=config)\n",
    "config = RobertaConfig.from_pretrained('./output_CC-ab/')\n",
    "config.output_hidden_states = True\n",
    "embeddings_file = '/home/jupyter/Notebooks/crystal/NLP/nlp_testing/embeddings_context_vocab/roberta_output_CC_ab.txt'\n",
    "\n",
    "for v in vocab:\n",
    "    v_tensor = torch.tensor([tokenizer.encode(v)])\n",
    "    # Print the index of the test word.\n",
    "    print(f'{v} is at index {v_tensor[0][1].item()}')\n",
    "    v_embed = model.roberta.embeddings(v_tensor)\n",
    "#     print(v_embed)\n",
    "    try:\n",
    "        with open(embeddings_file, 'a') as f:\n",
    "            f.write(v)\n",
    "            for value in v_embed[0][0]:\n",
    "                f.write(' ' + str(value.item()))\n",
    "            f.write('\\n')\n",
    "        print(f'Saved the embedding for {v}.')\n",
    "    except:\n",
    "        print('Oh no! Unable to write to the embeddings file.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crystal-venv-3.6",
   "language": "python",
   "name": "crystal-venv-3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
